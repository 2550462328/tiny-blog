{"Java基础": {"6f1eee81aaa16c884f4ae5ea5e6233b4": {"id": "6f1eee81aaa16c884f4ae5ea5e6233b4", "item": "Java基础", "title": "AQS原理分析", "date": "2024-08-22", "summary": "AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中", "body": "\n之前“ReentrantLock源码分析”一节简单讲了AQS的概述以及ReentrantLock是怎么利用AQS实现独占锁的，本节重点讲AQS的原理和补充说明ReentrantLock的condition部分\n\n**AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中**。\n\n\n\nAQS提供了两种方式来获取资源，一种是独占模式，一种是共享模式。\n\n使用AQS框架需要定义一个类继承AbstractQueuedSynchronizer类，重写其中的方法，主要实现的是对共享资源state的获取和释放方式，至于具体线程等待队列的维护（如获取资源失败入队，唤醒出队等）已经由AQS封装好的。\n\n1）对于独占模式，需要重写tryAcquire(arg) ，tryRelease(int arg)方法。\n\n2）对于共享模式，需要重写tryAcquireShared(arg) ，tryReleaseShared(int arg)方法。\n\n事实上AQS中除了这些方法外其他方法都是final的，无法被其他类使用。\n\n\n\n#### **1、LockSupport**\n\n之前在看ReentrantLock.lock和ReentrantLock.unlock方法中可以看到最后阻塞线程和激活线程使用的是LockSupport.park()和LockSupport.unpark()方法，那么LockSupport是什么？\n\n我认为LockSupport相当于Lock的一个工具类，主要用途就是**实现对线程的阻塞和解除对线程的阻塞**\n\npark()和unpark()的原理是基于“许可证”（一种信号量机制），park的时候消耗一个“许可证”，unpark()的时候会提供一个“许可证”（注意多次不会叠加），当许可证为0的时候，线程就会阻塞了，等待发放“许可证”。\n\n\n\n##### **（1）park方法**\n\n###### 1）park()\n\n```\n3.   public static void park() {  \n\n4.       UNSAFE.park(false, 0L);  \n\n5.   }  \n\n6.  //unsafe.class中  \n\n7.  public native void park(boolean var1, long var2);  \n```\n\n调用jvm的本地方法将当前线程阻塞。\n\n\n\n###### 2）park(Object blocker)\n\n```\n2.  public static void park(Object blocker) {  \n\n3.      Thread t = Thread.currentThread();  \n\n4.      setBlocker(t, blocker);  \n\n5.      UNSAFE.park(false, 0L);  \n\n6.      setBlocker(t, null);  \n\n7.  }  \n\n8.  private static void setBlocker(Thread t, Object arg) {  \n\n9.      UNSAFE.putObject(t, parkBlockerOffset, arg);  \n\n10. }  \n```\n\n这里在线程阻塞前和线程阻塞后都会setBlocker()，但是setBlocker有什么用？为什么设置两次？\n\n这里第一个setBlocker就是设置当前Thread对象中的parkBlocker变量，**用来记录线程被阻塞时被谁阻塞的,用于线程监控和分析工具来定位原因的**。\n\n第二个setBlocker是进行还原操作，防止另一个Thread获取到了错误了parkBlocker。\n\n\n\n获取这个blocker采用的是内存偏移量方式，查找parkBlocker字段相对于Thread的内存偏移量，然后根据这个内存偏移量去查找变量值\n\n```\n1.  public static Object getBlocker(Thread t) {  \n\n2.      if (t == null)  \n\n3.          throw new NullPointerException();  \n\n4.      return UNSAFE.getObjectVolatile(t, parkBlockerOffset);  \n\n5.  }  \n\n6.  parkBlockerOffset = UNSAFE.objectFieldOffset(tk.getDeclaredField(\"parkBlocker\"));  \n```\n\n\n\n为什么要基于内存的方式去设置/获取blocker？直接写个方法不就行了？\n\nparkBlocker就是在线程处于阻塞的情况下才被赋值。线程都已经被阻塞了,如果不通过这种内存的方法,而是直接调用线程内的方法,线程是不会回应调用的。\n\n\n\n关于blocker做的小案例，获取blocker的变换情况\n\n```\n1.  public static void main(String[] args) throws InterruptedException {  \n\n2.      Thread thread = Thread.currentThread();  \n\n3.      Thread thread1 = new Thread(() -> {  \n\n4.          try {  \n\n5.              TimeUnit.SECONDS.sleep(1);  \n\n6.          } catch (InterruptedException e) {  \n\n7.          }  \n\n8.          System.out.println(thread.getName() + \"before block : block info is \" + LockSupport.getBlocker(thread));  \n\n9.          LockSupport.unpark(thread);  \n\n10.     });  \n\n11.     thread1.start();  \n\n12.     LockSupport.park(new String(\"aa\"));  \n\n13.     System.out.println(thread.getName() + \"after block : block info is \" + LockSupport.getBlocker(thread));  \n\n14. }  \n```\n\n\n\n输出\n\n```\n1.  mainbefore block : block info is blocker  \n\n2.  mainafter block : block info is null  \n```\n\n\n\n###### 3）parkNanos(Object blocker, long nanos)\n\n```\n1.  public static void parkNanos(Object blocker, long nanos) {  \n\n2.      if (nanos > 0) {  \n\n3.          Thread t = Thread.currentThread();  \n\n4.          setBlocker(t, blocker);  \n\n5.          UNSAFE.park(false, nanos);  \n\n6.          setBlocker(t, null);  \n\n7.      }  \n\n8.  }  \n```\n\n和park(Objectblocker)的区别就是多个限时操作，在规定时间内没有获取到“许可证”会直接返回。\n\n\n\npark在下面三种情况会直接返回\n\n- 调用线程被中断,则park方法会返回\n- unpark方法先于park调用会直接返回\n- 其他某个线程将当前线程作为目标调用 unpark\n- park方法还可以在其他任何时间\"毫无理由\"地返回,因此**通常必须在重新检查返回条件的循环里调用此方法**。从这个意义上说,park是“忙碌等待”的一种优化,它不会浪费这么多的时间进行自旋,但是必须将它与 unpark配对使用才更高效\n\n\n\n##### （2）unpark\n\n```\n2.  public static void unpark(Thread thread) {  \n\n3.      if (thread != null)  \n\n4.          UNSAFE.unpark(thread);  \n\n5.  }  \n\n6.  //unsafe.class中  \n\n7.  public native void unpark(Object var1);  \n```\n\n解除指定线程的阻塞，必须指定线程。\n\n\n\npark()和unpark()不会有“Thread.suspend和Thread.resume所可能引发的死锁”问题,由于许可证的存在，调用park 的线程和另一个试图将其 unpark 的线程之间的竞争将保持活性。\n\n\n\n##### （3）park/unpark和wait/nofity的区别\n\n首先对比一下调用park和wait后通过jstack打印出来的堆栈情况\n\n![img](http://pcc.huitogo.club/f52b1a35236229069c79db578b44eff2)\n\n![img](http://pcc.huitogo.club/6a43d4c94b4b97c81f9fde8fd16b807c)\n\n\n\n两者区别如下：\n\n1）LockSuport主要是针对Thread进行阻塞处理,可以指定阻塞队列的目标对象,每次可以指定具体的线程唤醒。Object.wait()是以对象为纬度,阻塞当前的线程和唤醒单个(随机)或者所有线程。\n\n2）Thead在调用wait之前，当前线程必须先获得该对象的监视器(synchronized)，被唤醒之后需要重新获取到监视器才能继续执行.而LockSupport可以随意进行park或者unpark。\n\n3）park时遇到interrupt会直接返回继续执行，而wait的时候遇到interrupt会抛出异常。\n\n\n\n#### **2、Node**\n\nAQS维护了一个FIFO的双向队列，具体就体现在Node类的head和tail两个变量，顾名思义，head保存了头节点，tail保存了尾节点。\n\n```\n1.  private transient volatile Node head;  \n\n2.  private transient volatile Node tail;\n```\n\n\n\nNode类中的SHARED是用来标记该线程是获取共享资源时被放入等待队列，EXCLUSIVE用来标记该线程是获取独占资源时被放入等待队列（就是上面的双向队列）。我们可以看出Node类其实就是保存了放入等待队列的线程，而有的线程是因为获取共享资源失败放入等待队列的，而有的线程是因为获取独占资源失败而被放入等待队列的，所以这里需要有一个标记去区分。\n\n```\n1.  static final Node SHARED = new Node();  \n\n2.  static final Node EXCLUSIVE = null; \n```\n\n\n\n在Node类中，还有一个字段：waitStatus，它有五个取值，分别是：\n\n- SIGNAL：值为-1，当前节点在入队后、进入休眠状态前，应确保将其prev节点类型改为SIGNAL，以便后者取消或释放时将当前节点唤醒。\n- CANCELLED：值为1，被取消的，在等待队列中等待的线程超时或被中断，该状态的节点将会被清除。\n- CONDITION：值为-2，该节点处于条件队列中，当其他线程调用了Condition的signal()方法后，节点转移到AQS的等待队列中，特别要注意的是，条件队列和AQS的等待队列并不是一回事。\n- PROPAGATE：值为-3。用处暂时不清楚。\n- 0：默认值。\n\n\n\n#### **3、ConditionObject**\n\nConditionObject实现了Condition接口，Condition必须被绑定到一个独占锁上使用，在ReentrantLock中，有一个newCondition方法\n\nConditionObject帮助AQS实现了类似wait/notify的功能，帮助已经获取到lock的线程在没有达到条件的时候挂起（await），在条件满足后被通知（signal）。\n\n因此那些被挂起的线程也要用一个队列来装载它们，这个队列叫**条件队列**。\n\n需要注意的是**条件队列是一条单向队列**，它是通过Node类中的nextWaiter进行连接。\n\n\n\n条件队列和之前的双向同步队列的关系如下：\n\n当节点从同步队列进入条件队列（condition.await()）\n\n![img](http://pcc.huitogo.club/e4d7cfa7a93258529322f0c15099ab36)\n\n\n\n当节点从条件队列进入同步队列(condition.signal())\n\n![img](http://pcc.huitogo.club/b679dfe02ef1d9e7f65c3fa373ccc74c)\n\n\n\n下面看一下它的关键方法\n\n##### **（1）await()**\n\nawait就是获取锁的线程让出锁然后将自己加入条件队列并阻塞，源码如下\n\n```\n1.  public final void await() throws InterruptedException {  \n\n2.      if (Thread.interrupted())  \n\n3.          throw new InterruptedException();  \n\n4.      Node node = addConditionWaiter();  \n\n5.      int savedState = fullyRelease(node);  \n\n6.      int interruptMode = 0;  \n\n7.      while (!isOnSyncQueue(node)) {  \n\n8.          LockSupport.park(this);  \n\n9.          if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)  \n\n10.             break;  \n\n11.     }  \n\n12.     if (acquireQueued(node, savedState) && interruptMode != THROW_IE)  \n\n13.         interruptMode = REINTERRUPT;  \n\n14.     if (node.nextWaiter != null) // clean up if cancelled  \n\n15.         unlinkCancelledWaiters();  \n\n16.     if (interruptMode != 0)  \n\n17.         reportInterruptAfterWait(interruptMode);  \n\n18. }  \n```\n\n\n\n根据源码来思考它是怎么实现以上步骤的\n\n首先是将当前线程的节点加入条件队列，addConditionWaiter\n\n```\n1.  private Node addConditionWaiter() {  \n\n2.      Node t = lastWaiter;  \n\n3.      // If lastWaiter is cancelled, clean out.  \n\n4.      if (t != null && t.waitStatus != Node.CONDITION) {  \n\n5.          unlinkCancelledWaiters();  \n\n6.          t = lastWaiter;  \n\n7.      }  \n\n8.      Node node = new Node(Thread.currentThread(), Node.CONDITION);  \n\n9.      if (t == null)  \n\n10.         firstWaiter = node;  \n\n11.     else  \n\n12.         t.nextWaiter = node;  \n\n13.     lastWaiter = node;  \n\n14.     return node;  \n\n15. }\n```\n\n先clean up了一下CANCALLED节点，保证新建节点的上一个节点不是CANCELLED的，接着放在队列最后面。\n\n\n\n然后是当前线程让出所持有的锁，fullyRelease方法\n\n```\n1.  final int fullyRelease(Node node) {  \n\n2.      boolean failed = true;  \n\n3.      try {  \n\n4.          int savedState = getState();  \n\n5.          if (release(savedState)) {  \n\n6.              failed = false;  \n\n7.              return savedState;  \n\n8.          } else {  \n\n9.              throw new IllegalMonitorStateException();  \n\n10.         }  \n\n11.     } finally {  \n\n12.         if (failed)  \n\n13.             node.waitStatus = Node.CANCELLED;  \n\n14.     }  \n\n15. }  \n```\n\n调用的主要是之前讲unlock方法时用到的release方法，将锁的owner清空后唤醒后一个SIGNAL的节点，需要注意的是直接将state清零而不是减一操作了，所以叫fullRelease。\n\n\n\n不出意外此时节点已经进入条件队列，但在阻塞之前还是判断一下比较好，isOnSyncQueue方法\n\n```\n1.  final boolean isOnSyncQueue(Node node) {  \n\n2.      if (node.waitStatus == Node.CONDITION || node.prev == null)   \n\n3.          return false;  \n\n4.      if (node.next != null) // If has successor, it must be on queue  \n\n5.          return true;  \n\n6.      return findNodeFromTail(node);  \n\n7.  }  \n```\n\n从节点状态和prev/next角度简单判断，如果都不满足就在同步队列里面遍历查询，**但是这里为什么从尾部开始遍历？**\n\n\n\n确定该节点已经进入条件队列了，将它阻塞（LockSupport.park）\n\n当它醒过来的时候，先看看它是不是因为被interrupted吵醒了，checkInterruptWhileWaiting方法\n\n```\n1.  private int checkInterruptWhileWaiting(Node node) {  \n\n2.      return Thread.interrupted() ?  \n\n3.          (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;  \n\n4.  }  \n\n5.  final boolean transferAfterCancelledWait(Node node) {  \n\n6.      if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {  \n\n7.          enq(node);  \n\n8.          return true;  \n\n9.      }  \n\n10.     while (!isOnSyncQueue(node))  \n\n11.         Thread.yield();  \n\n12.     return false;  \n\n13. }  \n```\n\n被interrupted吵醒后判断后续的处理应该是抛出InterruptedException还是重新中断，判断的标准是**在线程中断的时候是否有signal方法调用**\n\n1）如果compareAndSetWaitStatus(node, Node.CONDITION,0)执行成功，则说明中断发生时，没有signal的调用，因为signal方法会将状态设置为0。\n\n2）如果第1步执行成功，则将node添加到Sync队列中，并返回true，表示中断在signal之前；\n\n3）如果第1步失败，则检查当前线程的node是否已经在Sync队列中了，如果不在Sync队列中，则让步给其他线程执行，直到当前的node已经被signal方法添加到Sync队列中，然后返回false，表示中断前没有signal执行。\n\n\n\n**被interrupted中断或者正常唤醒并加入同步队列**后，当前线程尝试获取锁acquireQueued(node,savedState)，只有获取到了锁这个方法才会返回，返回值代表当前线程有没有被中断，修改interruptMode的值，如果有中断（interruptMode!=0）然后执行reportInterruptAfterWait方法\n\n```\n1.  private void reportInterruptAfterWait(int interruptMode)  \n\n2.      throws InterruptedException {  \n\n3.      if (interruptMode == THROW_IE)  \n\n4.          throw new InterruptedException();  \n\n5.      else if (interruptMode == REINTERRUPT)  \n\n6.          selfInterrupt();  \n\n7.  }  \n```\n\n\n\n##### **（2）awaitNanos(long nanosTimeout)**\n\nawaitNanos指的是有限等待，**在规定时间内没有被唤醒（中断或者正常），就会被放回到同步队列**\n\n```\n1.  public final long awaitNanos(long nanosTimeout)  \n\n2.          throws InterruptedException {  \n\n3.      if (Thread.interrupted())  \n\n4.          throw new InterruptedException();  \n\n5.      Node node = addConditionWaiter();  \n\n6.      int savedState = fullyRelease(node);  \n\n7.      final long deadline = System.nanoTime() + nanosTimeout;  \n\n8.      int interruptMode = 0;  \n\n9.      while (!isOnSyncQueue(node)) {  \n\n10.         if (nanosTimeout <= 0L) {  \n\n11.             transferAfterCancelledWait(node);  \n\n12.             break;  \n\n13.         }  \n\n14.         if (nanosTimeout >= spinForTimeoutThreshold)  \n\n15.             LockSupport.parkNanos(this, nanosTimeout);  \n\n16.         if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)  \n\n17.             break;  \n\n18.         nanosTimeout = deadline - System.nanoTime();  \n\n19.     }  \n\n20.     if (acquireQueued(node, savedState) && interruptMode != THROW_IE)  \n\n21.         interruptMode = REINTERRUPT;  \n\n22.     if (node.nextWaiter != null)  \n\n23.         unlinkCancelledWaiters();  \n\n24.     if (interruptMode != 0)  \n\n25.         reportInterruptAfterWait(interruptMode);  \n\n26.     return deadline - System.nanoTime();  \n\n27. }  \n```\n\n\n\n##### **（3）awaitUninterruptibly()**\n\n之前看await()的源码我们知道它是会对interrupted的情况做出回应，也就是interrupted唤醒线程后，会判断throwException还是reInterrupted。\n\n这里awaitUninterruptibly方法顾名思义**不会对interrupted做出回应，并且interrupted后会重新park**\n\n```\n1.  public final void awaitUninterruptibly() {  \n\n2.      Node node = addConditionWaiter();  \n\n3.      int savedState = fullyRelease(node);  \n\n4.      boolean interrupted = false;  \n\n5.      while (!isOnSyncQueue(node)) {  \n\n6.          LockSupport.park(this); \n\n7.  //这里只是记录一下中断状态，然后重新循环进入park \n\n8.          if (Thread.interrupted())  \n\n9.              interrupted = true;  \n\n10.     }  \n\n11.     if (acquireQueued(node, savedState) || interrupted)  \n\n12.         selfInterrupt();  \n\n13. }  \n```\n\n\n\n##### **（4）signal()**\n\n通过上面await的源码我们知道线程被唤醒后会将它的节点从条件队列放到同步队列中去竞争锁的，所以带着这个目的来看signal方法\n\n```\n1.  public final void signal() {  \n\n2.      if (!isHeldExclusively())  \n\n3.          throw new IllegalMonitorStateException();  \n\n4.      Node first = firstWaiter;  \n\n5.      if (first != null)  \n\n6.          doSignal(first);  \n\n7.  }  \n\n8.  private void doSignal(Node first) {  \n\n9.      do {  \n\n10.         if ( (firstWaiter = first.nextWaiter) == null)  \n\n11.             lastWaiter = null;  \n\n12.         first.nextWaiter = null;  //这里已经将节点的nextWaiter置为空\n\n13.     } while (!transferForSignal(first) &&  \n\n14.              (first = firstWaiter) != null);  \n\n15. }  \n```\n\n在指定ConditionObject的条件队列中唤醒firstWaiter，也就是**修改waitstatus并加入同步队列**；如果唤醒失败就唤醒nextWaiter，以此类推，**所以说signal唤醒实际上不是随机的**，只是加入条件队列的节点顺序可能不一样。\n\n\n\n核心唤醒方法transferForSignal\n\n```\n1.  final boolean transferForSignal(Node node) {  \n\n2.      if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))  \n\n3.          return false;  \n\n4.      Node p = enq(node);  \n\n5.      int ws = p.waitStatus;  \n\n6.      if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))  \n\n7.          LockSupport.unpark(node.thread);  \n\n8.      return true;  \n\n9.  }  \n```\n\n\n\n##### **（5）signalAll()**\n\n唤醒指定ConditionObject条件队列中的所有等待节点，也就是遍历节点依次唤醒\n\n核心方法如下\n\n```\n1.  private void doSignalAll(Node first) {  \n\n2.      lastWaiter = firstWaiter = null;  \n\n3.      do {  //遍历唤醒\n\n4.          Node next = first.nextWaiter;  \n\n5.          first.nextWaiter = null;  \n\n6.          transferForSignal(first);  \n\n7.          first = next;  \n\n8.      } while (first != null);  \n\n9.  }  \n```\n\n\n\n在await和signal之前都会判断一下当前线程是不是owner（调用方法isHeldExclusively()），跟wait/notify之前必须要拿到对象监视器一样。\n\n**signal只是将节点从条件队列放到等待队列**，还要等待unlock的时候获取锁（unlock的时候会unpark同步队列中的第二个节点）。\n\n\n\n这里思考过signal会不会将别的CondionObject条件队列节点放到同步队列中（错误唤醒），然后看到了ConditionObject对象中的两个变量\n\n```\n1.  /** First node of condition queue. */  \n\n2.  private transient Node firstWaiter;  \n\n3.  /** Last node of condition queue. */  \n\n4.  private transient Node lastWaiter;  \n```\n\n当我们调用condition.await的时候，就是在这个ConditionObject中构建一条单向队列，使用firstWaiter和lastWaiter来记录，所以说**每一个ConditionObject对象单独维护一条单向条件队列**，所以也就不会冲突了。\n\n\n\n#### **4、基于AQS的开源框架**\n\n以 **ReentrantLock** 为例，state 初始化为 0，表示未锁定状态。A 线程 lock()时，会调用 tryAcquire()独占该锁并将 state+1。此后，其他线程再 tryAcquire()时就会失败，直到 A 线程 unlock()到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证 state 是能回到零态的。\n\n\n\n**CountDownLatch**是共享锁的一种实现,它默认构造 AQS 的 state 值为 count。当线程使用countDown方法时,其实使用了tryReleaseShared方法以CAS的操作来减少state,直至state为0就代表所有的线程都调用了countDown方法。当调用await方法的时候，如果state不为0，就代表仍然有线程没有调用countDown方法，那么就把已经调用过countDown的线程都放入阻塞队列Park,并自旋CAS判断state == 0，直至最后一个线程调用了countDown，使得state == 0，于是阻塞的线程便判断成功，全部往下执行。\n\n\n\ncountDownLatch的一些经典使用场景\n\n1）某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减 1 countdownlatch.countDown()，当计数器的值变为 0 时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。\n\n2）实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。\n\n\n\n**Semaphore**与CountDownLatch一样，也是共享锁的一种实现。它默认构造AQS的state为permits。当执行任务的线程数量超出permits,那么多余的线程将会被放入阻塞队列Park,并自旋判断state是否大于0。只有当state大于0的时候，阻塞的线程才能继续执行,此时先前执行任务的线程继续执行release方法，release方法使得state的变量会加1，那么自旋的线程便会判断成功。 如此，每次只有最多不超过permits数量的线程能自旋成功，便限制了执行任务线程的数量。\n\n\n\n**CyclicBarrier** 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，CyclicBarrier 内部通过一个 count 变量作为计数器，cout 的初始值为 parties 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减一。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。\n\n\n\nCyclicBarrier 的经典使用案例有：\n\n1）CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。\n\nCountDownLatch的实现是基于AQS的，而CycliBarrier是基于 ReentrantLock(ReentrantLock也属于AQS同步器)和 Condition 的。\n\nCountDownLatch 是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而 CyclicBarrier 更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。\n\n\n\n#### **5、总结**\n\n（1）LockSupport的park和unpark底层是基于jvm本地方法的，AQS实现阻塞和解除阻塞是基于LockSupport。\n\n\n\n（2）AQS的实质是两种队列，一条双向同步队列，一条或多条单向条件队列\n\n1）线程在获取不到lock之后会进入同步队列，找一个安全的位置（前置节点的waitstatus是SIGNAL，保证前置节点结束后会唤醒后置节点）将自己阻塞，等待唤醒后去获取锁。\n\n2）线程在被await后会放弃lock并进入等待队列，在清理一次CANCELLED节点后将自己阻塞，等待唤醒后加入同步队列去获取锁（会对中断做出回应）。\n\n\n\n（3）只有同步队列中的第二个节点才有资格去获取锁。\n\n\n\n（4）公平锁和非公平锁的区别就是非公平锁每个线程都可以先直接尝试修改state的值（获取锁），然后在失败的情况下才会加入同步队列等待；公平锁就是要老老实实的在同步队列中排队。\n\n\n\n（5）AQS只是一个框架，提供了很多方法给其他类重写从而实现不同的功能，如ReentrantLock实现了独占锁，Semaphore和CountDownLatch实现了共享锁，主要重写的逻辑和方法就是获取锁和释放锁。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 5}, "1023dd375278adba96593fb6f8c99c33": {"id": "1023dd375278adba96593fb6f8c99c33", "item": "Java基础", "title": "CountDownLatch源码分析", "date": "2024-08-22", "summary": "CountDownLatch 是 Java 中的一个同步工具类。它允许一个或多个线程等待其他线程完成操作。通过设置初始计数值，其他线程每完成一项任务就调用 countDown 方法减少计数值，当计数值为 0 时，等待的线程被唤醒继续执行。", "body": "\n学习CountDownLatch的源码无非从两个方法入手，countdown和await。\n\n注意CountDownLatch的底层是AQS框架的共享模式，所以会有大量的AQS的源码混合。\n\n#### 1. await\n\nCountDownLatch是一个计时器，在计时器没有到达0的时候，所有调用await的线程都会被阻塞，被阻塞的线程去哪儿了，当然是变成了Node放到AQS的同步队列了。看源码吧\n\n```\n1.  public void await() throws InterruptedException {  \n\n2.      sync.acquireSharedInterruptibly(1);  \n\n3.  }  \n\n4.  public final void acquireSharedInterruptibly(int arg)  \n\n5.          throws InterruptedException {  \n\n6.      if (Thread.interrupted())  \n\n7.          throw new InterruptedException();  \n\n8.      if (tryAcquireShared(arg) < 0)  \n\n9.          doAcquireSharedInterruptibly(arg);  \n\n10. }  \n```\n\n\n\nCountDownLatch中重写的tryAcquireShared非常简单，就是判断state ==0\n\n```\n1.  protected int tryAcquireShared(int acquires) {  \n\n2.      return (getState() == 0) ? 1 : -1;  \n\n3.  }  \n```\n\n\n\nstate的值怎么来的呢，看CountDownLatch的构造方法\n\n```\n1.  public CountDownLatch(int count) {  \n\n2.      if (count < 0) throw new IllegalArgumentException(\"count < 0\");  \n\n3.      this.sync = new Sync(count);  \n\n4.  }  \n\n5.  Sync(int count) {  \n\n6.        setState(count);  \n\n7.  }  \n```\n\n就是将我们定义的countDownLatch的阀值作为state的值，在AQS里面我们可以将这个state称之为“资源”更好理解。AQS是一个框架，不会想着你去实现什么，它只关心你能不能获取到资源，获取到资源之后怎么做。\n\n\n\n回头重点看下doAcquireSharedInterruptibly方法，顾名思义它是会响应中断的\n\n```\n1.  private void doAcquireSharedInterruptibly(int arg)  \n\n2.      throws InterruptedException {  \n\n3.      final Node node = addWaiter(Node.SHARED);  \n\n4.      boolean failed = true;  \n\n5.      try {  \n\n6.          for (;;) {  \n\n7.              final Node p = node.predecessor();  \n\n8.              if (p == head) {  \n\n9.                  int r = tryAcquireShared(arg);  \n\n10.                 if (r >= 0) {  \n\n11.                     setHeadAndPropagate(node, r);  \n\n12.                     p.next = null; // help GC  \n\n13.                     failed = false;  \n\n14.                     return;  \n\n15.                 }  \n\n16.             }  \n\n17.             if (shouldParkAfterFailedAcquire(p, node) &&  \n\n18.                 parkAndCheckInterrupt())  \n\n19.                 throw new InterruptedException();  \n\n20.         }  \n\n21.     } finally {  \n\n22.         if (failed)  \n\n23.             cancelAcquire(node);  \n\n24.     }  \n\n25. }  \n```\n\n注意这里引入了一个新的Node类型SHARED。\n\n\n\n整体逻辑和我们之前学ReentrantLock的时候探索到的AQS独占式的源码差不多。那么一个线程它获取不到资源的时候会怎么做呢？\n\n加入AQS的同步队列 --> 将自己放到安全的位置并阻塞 -->在被唤醒的时候查看自己是不是队列中第二个节点-->如果是老二就去竞争资源-->拿到资源后成为头节点并唤醒后面的节点\n\n这里可以类比一下和之前AQS独占式acquire的代码了，独占式在拿到资源后只会setHead()，就是把自己激活去运行，但是咱们共享式大兄弟就不会了，它还会提醒后面的兄弟们setHeadAndPropagate()，果然是好兄弟啊。\n\n\n\n好兄弟归好兄弟，人家是有前提的，看看前提吧\n\n```\n1.  private void setHeadAndPropagate(Node node, int propagate) {  \n\n2.      Node h = head; // Record old head for check below  \n\n3.      setHead(node);  \n\n4.      if (propagate > 0 || h == null || h.waitStatus < 0 ||  \n\n5.          (h = head) == null || h.waitStatus < 0) {  \n\n6.          Node s = node.next;  \n\n7.          if (s == null || s.isShared())  \n\n8.              doReleaseShared();  \n\n9.      }  \n\n10. }  \n```\n\n这里propagate 代表资源，前提就是**还有剩余资源**，或者新老head节点为空，或者新老节点处于signal状态。\n\n\n\n看看是怎么通知后面的兄弟们吧，doReleaseShared方法\n\n```\n1.  private void doReleaseShared() {  \n\n2.      for (;;) {  \n\n3.          Node h = head;  \n\n4.          if (h != null && h != tail) {  \n\n5.              int ws = h.waitStatus;  \n\n6.              if (ws == Node.SIGNAL) {  \n\n7.                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))  \n\n8.                      continue;            // loop to recheck cases  \n\n9.                  unparkSuccessor(h);  \n\n10.             }  \n\n11.             else if (ws == 0 &&  \n\n12.                      !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))  \n\n13.                 continue;                // loop on failed CAS  \n\n14.         }  \n\n15.         if (h == head)                   // loop if head changed  \n\n16.             break;  \n\n17.     }  \n\n18. }  \n```\n\n最终的目的是unpark所有的后继节点，前面的节点都变成propagate 。\n\n当h==head的时候说明链表循环结束了，没有后继节点可以通知了。\n\n\n\n好了，来理清一下await的流程\n\n如果state!=0的话，就将当前线程加入AQS同步队列阻塞起来，在被唤醒的时候如果拿到了资源会唤醒整个链表。\n\n\n\n#### 2. countDown\n\ncountDown的意思很简单了，就是去修改state的值，在state降到0的时候就去唤醒整个链表\n\n```\n1.  public void countDown() {  \n\n2.      sync.releaseShared(1);  \n\n3.  }  \n\n4.  public final boolean releaseShared(int arg) {  \n\n5.      if (tryReleaseShared(arg)) {  \n\n6.          doReleaseShared();  \n\n7.          return true;  \n\n8.      }  \n\n9.      return false;  \n\n10. }  \n```\n\n这里唤醒整个链表还是用到了await里面的doReleaseShared方法。\n\n\n\n#### 3. 总结\n\n1. countdownLatch底层是AQS的共享模式。\n2. AQS的共享式跟独占式的区别就在于一个线程拿到资源后会不会去通知后继节点（整个链表）。\n3. 在AQS里面是从资源的角度去实现的，AQS是一个框架，不会想着你去实现什么，它只关心你能不能获取到资源，获取到资源之后怎么做，以及释放资源后会发生什么。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "7872d3b5467409af8cc37d594a5e8a7d": {"id": "7872d3b5467409af8cc37d594a5e8a7d", "item": "Java基础", "title": "ConcurrentHashMap源码分析", "date": "2024-08-22", "summary": "ConcurrentHashMap 是 Java 中的高并发容器。它通过分段锁等机制实现高效的多线程并发操作，支持多线程同时读，写操作也能较好地控制锁粒度，减少争用，确保线程安全，在多线程环境下提供出色的性能表现。", "body": "\n首先提出一些问题？\n\n1）多线程操作的时候读写并发吗？\n\n2）每次扩容大小？扩容的时候允许读写吗？\n\n3）多线程怎么帮助扩容？\n\n4）多线程怎么计数的？\n\n5）无锁式实现并发怎么做的？\n\n答案在本文中找.......\n\nStart GO！！！\n\n\n\n#### **1、为什么会使用concurrentHashMap这个集合？**\n\n因为传统的hashMap在多线程并发的情况是不安全的，所以使用了concurrentHashMap代替了多线程下的hashMap\n\n\n\n#### **2、concurrentHashMap的成员常量**\n\n##### （1）限制值（用于边界值等条件判断）\n\n```\n2.  // map的最大容量  \n\n3.  private static final int MAXIMUM_CAPACITY = 1 << 30;   \n\n4.  // map的初始容量  \n\n5.  private static final int DEFAULT_CAPACITY = 16;  \n\n6.  // 虚拟机限制的最大数组长度，用在Collection.toArray()时限制大小  \n\n7.  static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;  \n\n8.  // map默认并发数(兼容jdk1.7)  \n\n9.  private static final int DEFAULT_CONCURRENCY_LEVEL = 16;  \n\n10. // 扩容因子(兼容jdk1.7),jdk1.8中使用n - ( n \\>\\> 2)代替 \\*0.75f  \n\n11. private static final float LOAD_FACTOR = 0.75f;  \n\n12. // 链表转树的临界节点数  \n\n13. static final int TREEIFY_THRESHOLD = 8;  \n\n14. // 树转链表的临界节点数  \n\n15. static final int UNTREEIFY_THRESHOLD = 6;  \n\n16. // 链表转树时Node[]的长度不小于64  \n\n17. static final int MIN_TREEIFY_CAPACITY = 64;  \n\n18. // 每个线程帮助扩容的时候最少要处理的hash桶数，这个值如果太小会导致多线程竞争数过多  \n\n19. // 在计算的时候 认为一个CPU可以处理8个线程的并发，所以每个线程需要处理的hash桶数是(table.length) / 8 / CPU个数 如果小于 16 就让他等于16  \n\n20. private static final int MIN_TRANSFER_STRIDE = 16;  \n\n21. // 每个扩容都唯一的生成戳的数，最小是6  \n\n22. private static int RESIZE_STAMP_BITS = 16;  \n\n23. // 最大的扩容线程的数量(2\\^16 - 1)  \n\n24. private static final int MAX_RESIZERS = (1 \\<\\< (32 - RESIZE_STAMP_BITS)) - 1;  \n\n25. // 移位量，把生成戳移位后保存在sizeCtl中当做扩容线程计数的基数，向反方向移位后能够反解出生成戳  \n\n26. private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;\n\n27. // 可使用的CPU内核数\n\n28. static final int NCPU = Runtime.getRuntime().availableProcessors();\n```\n\n\n\n##### （2）Node节点的hash值相关\n\n```\n30. // 下面是一些特殊节点的hash值，正常节点hash在spread函数都会生成正数  \n\n31. // 这个hash值出现在扩容的时候会有一个Forwarding的临时节点，它不存储实际的数据  \n\n32. // 如果旧数组的一个hash桶中全部的节点都迁移到新数组中，旧数组就在这个hash桶中放置一个ForwardingNode  \n\n33. // 读操作或者迭代读时碰到ForwardingNode时，将操作转发到扩容后的新的table数组上去执行，写操作碰见它时，则尝试帮助扩容  \n\n34. static final int MOVED = -1;   \n\n35. // 这个hash值出现在树的头部节点TreeBin，它指向树的根节点root  \n\n36. // TreeBin维护了一个简单读写锁  \n\n37. static final int TREEBIN = -2;   \n\n38. // ReservationNode的hash值，ReservationNode是一个保留节点，相当于一个预留位置，不会保存实际的数据，正常情况是不会出现的  \n\n39. static final int RESERVED = -3;   \n\n40. // 用于和负数hash值进行 & 运算，将其转化为正数（绝对值不相等  \n\n41. static final int HASH_BITS = 0x7fffffff;   \n```\n\n\n\n#### **3、cocurrentHashMap的成员变量**\n\n##### （1）跟多线程扩容相关\n\n```\n44. // 存放node节点的数组  \n\n45. transient volatile Node<K, V>[] table;  \n\n\n46. /** 扩容后的新的table数组，只有在扩容时才有用 \n\n47.   * nextTable != null，说明扩容方法还没有真正退出，一般可以认为是此时还有线程正在进行扩容 \n\n48.   */  \n\n49. private transient volatile Node<K, V>[] nextTable;  \n\n\n50.    /** \n\n51.     * 非常重要的属性 \n\n52.     * sizeCtl = -1，表示有线程正在进行真正的初始化操作 \n\n53.     * sizeCtl = -(1 + nThreads)，表示有nThreads个线程正在进行扩容操作（实际上不是这么计算参与线程的） \n\n54.     * sizeCtl > 0，表示接下来的真正的初始化操作中使用的容量，或者初始化/扩容完成后的threshold（table.length * 3/4） \n\n55.     * sizeCtl = 0，默认值，此时在真正的初始化操作中使用默认容量 \n\n56.     */  \n\n57. private transient volatile int sizeCtl;  \n\n\n58. /** \n\n59.  * 调整大小时要分割的下一个表索引(上一个transfer任务的起始下标index 加上1)。 \n\n60.  * transfer时方向是从大到小的，迭代时是下标从小往大，二者方向相反，尽量减少扩容时transefer和迭代两者同时处理一个hash桶的情况 \n\n61.  * 顺序相反时，二者相遇过后，迭代没处理的都是已经transfer的hash桶，transfer没处理的，都是已经迭代的hash桶，冲突会变少 \n\n62.  * 下标在[nextIndex - 实际的stride （下界要 >= 0）, nextIndex - 1]内的hash桶，就是每个transfer的任务区间 \n\n63.  * 每次接受一个transfer任务，都要CAS执行 transferIndex = transferIndex - 实际的stride，保证一个transfer任务不会被几个线程同时获取（相当于任务队列的size减1） \n\n64.  * 当没有线程正在执行transfer任务时，一定有transferIndex <= 0，这是判断是否需要帮助扩容的重要条件（相当于任务队列为空） \n\n65.  */  \n\n66. private transient volatile int transferIndex;  \n```\n\n\n\n##### （2）跟高效的并发计数方式有关\n\n```\n68. // 下面三个主要与统计数目有关，可以参考jdk1.8新引入的java.util.concurrent.atomic.LongAdder的源码，帮助理解  \n\n69. // 计数器基本值，主要在没有碰到多线程竞争时使用，需要通过CAS进行更新  \n\n70. private transient volatile long baseCount;  \n\n\n71. // CAS自旋锁标志位，用于初始化，或者counterCells扩容时  \n\n72. private transient volatile int cellsBusy;  \n\n\n73. // 用于高并发的计数单元，如果初始化了这些计数单元，那么跟table数组一样，长度必须是2^n的形式  \n\n74. private transient volatile CounterCell[] counterCells;  \n```\n\n\n\n#### **4、concurrentHashMap的构造函数**\n\nJdk1.8的构造函数是不带loadFactor的，带loadFactor是为了向下兼容jdk1.7\n\n```\n1.  public ConcurrentHashMapDebug(int initialCapacity) {  \n\n2.      if (initialCapacity < 0)  \n\n3.          throw new IllegalArgumentException();  \n\n4.      int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY  \n\n5.              : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));  \n\n6.      this.sizeCtl = cap;  \n\n7.  }  \n\n8.  public ConcurrentHashMapDebug(Map<? extends K, ? extends V> m) {  \n\n9.      this.sizeCtl = DEFAULT_CAPACITY;  \n\n10.     putAll(m);  \n\n11. }  \n```\n\n可以看到在构造函数中没有初始化table数组，将sizeCtrl值设为cap\n\n\n\n#### **5、concurrentHashMap的内部类**\n\n![img](http://pcc.huitogo.club/6dfd2b8ff985c4540a44cea5c94da2c8)\n\n\n\n#### **6、concurrentHashMap的cas方法**\n\n```\n3. // 用来返回节点数组的指定位置的节点的原子操作  \n\n4.  static final <K, V> Node<K, V> tabAt(Node<K, V>[] tab, int i) {  \n\n5.      return (Node<K, V>) U.getObjectVolatile(tab, ((long) i << ASHIFT) + ABASE);  \n\n6.  }  \n\n\n7.  // cas操作，用来在指定位置修改值  \n\n8.  static final <K, V> boolean casTabAt(Node<K, V>[] tab, int i, Node<K, V> c, Node<K, V> v) {  \n\n9.      return U.compareAndSwapObject(tab, ((long) i << ASHIFT) + ABASE, c, v);  \n\n10. }  \n\n\n11. // 原子操作，在指定位置设置值  \n\n12. static final <K, V> void setTabAt(Node<K, V>[] tab, int i, Node<K, V> v) {  \n\n13.     U.putObjectVolatile(tab, ((long) i << ASHIFT) + ABASE, v);  \n\n14. }  \n```\n\n可以看到底层都是通过Unsafe类实现cas操作的\n\n\n\n#### **7、concurrentHashMap的putVal()方法**\n\n为什么单独讲这个方法呢，因为这个方法算是concurrentHashMap的一个核心，多线程情况下对于concurrentHashMap来说主要的竞争就是写写竞争，还包括单线程初始化table、多线程帮助扩容、并发计数等核心操作。\n\n\n\n除了一些核心操作外，跟HashMap还是类似的（链表和红黑树的操作），可以参考HashMap的源码来学习。\n\nputVal的源码如下：\n\n```\n1.  final V putVal(K key, V value, boolean onlyIfAbsent) {   \n\n2.      if (key == null || value == null)  \n\n3.          throw new NullPointerException();  \n\n4.      int hash = spread(key.hashCode());  // 计算key的hash值  \n\n5.      int binCount = 0; // 单个链表上元素的个数  \n\n6.      for (Node<K, V>[] tab = table;;) {   \n\n7.          Node<K, V> f; // 计算key后下标的Node  \n\n8.          int n, i, fh;  // n是table长度  i是key所在链表在node数组中的下标  fh是Node的hash值  \n\n9.          if (tab == null || (n = tab.length) == 0) // 如果node数组为空，初始化数组  \n\n10.             tab = initTable();   \n\n11.         else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { // 如果计算的Key所在的位置为空，直接添加  \n\n12.             if (casTabAt(tab, i, null, new Node<K, V>(hash, key, value, null)))   \n\n13.                 break;   \n\n14.         } else if ((fh = f.hash) == MOVED) // 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段  \n\n15.             tab = helpTransfer(tab, f);  // 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失  \n\n16.         else { // 如果计算的key所在的位置有值的话  \n\n17.             V oldVal = null;  \n\n18.             synchronized (f) { // 给这个Node加锁  \n\n19.                 if (tabAt(tab, i) == f) { // 再次确认之前计算下标取出的Node还是那个位置  \n\n20.                     if (fh >= 0) { // fh >= 0 时 Node所在的位置是一个链表，fh = -2时是一个树  \n\n21.                         binCount = 1; //自身一个Node，所以所在链表初始长度为1  \n\n22.                         for (Node<K, V> e = f;; ++binCount) { // 遍历链表  \n\n23.                             K ek;  \n\n24.                             if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { // 如果取出的Node刚好Key就是要新增的key  \n\n25.                                 oldVal = e.val;  \n\n26.                                 if (!onlyIfAbsent) // 没有存在不可替换选项时，覆盖旧value  \n\n27.                                     e.val = value;  \n\n28.                                 break;  \n\n29.                             }  \n\n30.                             Node<K, V> pred = e;  \n\n31.                             if ((e = e.next) == null) { // 如果取出的Node的Key不是要新增的key  \n\n32.                                 pred.next = new Node<K, V>(hash, key, value, null); // 将新增的node放到尾部  \n\n33.                                 break;  \n\n34.                             }  \n\n35.                         }  \n\n36.                     } else if (f instanceof TreeBin) { // Node所在的位置是一棵树  \n\n37.                         Node<K, V> p;  \n\n38.                         binCount = 2;  // 树的头节点+自身，所以所在链表初始长度为2  \n\n39.                         if ((p = ((TreeBin<K, V>) f).putTreeVal(hash, key, value)) != null) { // 将新节点添加到树中  \n\n40.                             oldVal = p.val;  \n\n41.                             if (!onlyIfAbsent)  \n\n42.                                 p.val = value;  \n\n43.                         }  \n\n44.                     }  \n\n45.                 }  \n\n46.             }  \n\n47.             if (binCount != 0) {  \n\n48.                 if (binCount >= TREEIFY_THRESHOLD) // 判断是要转换成树还是扩容数组  \n\n49.                     treeifyBin(tab, i);  \n\n50.                 if (oldVal != null)  \n\n51.                     return oldVal; // 返回的替换前的旧值  \n\n52.                 break;  \n\n53.             }  \n\n54.         }  \n\n55.     }  \n\n56.     addCount(1L, binCount); // 并发计数  \n\n57.     return null;  \n\n58. }  \n```\n\n\n\n上面代码分成下面步骤\n\n1） table未初始化，进行单线程初始化\n\n2）table初始化了，经计算放置Node的下标处为null，直接cas放置值\n\n3）table初始化了，经计算放置Node的下标处有节点，但节点的hash值为MOVED（表示table数组正在扩容），那么此时放弃添加，帮助扩容（到下个循环在添加）。\n\n4）table初始化了，节点的hash值不为MOVED，这个时候就把存在的节点synchronized，判断是链表还是树（进行添加）。\n\n5）判断链表上的个数，如果超过8 是扩容还是转红黑树。\n\n6）因为添加了一个值，就要进行计数（+1）。\n\n\n\n看完步骤再细看方法\n\n##### **（1）initTable()**\n\n初始化数组，保证单线程进行\n\n```\n1.  /** \n\n2.     * 初始化数组table， \n\n3.     * 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权 \n\n4.     * 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组 \n\n5.     * 否则的话初始化一个默认大小(16)的数组 \n\n6.     * 然后设置sizeCtl的值为数组长度的3/4 \n\n7.     */  \n\n8.  private final Node<K, V>[] initTable() {  \n\n9.      Node<K, V>[] tab;  \n\n10.     int sc;  \n\n11.     while ((tab = table) == null || tab.length == 0) {  \n\n12.         if ((sc = sizeCtl) < 0) //小于0的时候表示在别的线程在初始化表或扩展表，要保证单线程扩容，进行线程礼让  \n\n13.             Thread.yield();   \n\n14.         else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { //尝试cas修改sizeCtl(类似加锁) 设定为-1表示要初始化表了  \n\n15.             try {  \n\n16.                 if ((tab = table) == null || tab.length == 0) {  \n\n17.                     int n = (sc > 0) ? sc : DEFAULT_CAPACITY;  \n\n18.                     @SuppressWarnings(\"unchecked\")  \n\n19.                     Node<K, V>[] nt = (Node<K, V>[]) new Node<?, ?>[n];  \n\n20.                     table = tab = nt;  \n\n21.                     sc = n - (n >>> 2);  //初始化后，sizeCtl长度为数组长度的3/4  \n\n22.                 }  \n\n23.             } finally {  \n\n24.                 sizeCtl = sc;   \n\n25.             }  \n\n26.             break;  \n\n27.         }  \n\n28.     }  \n\n29.     return tab;  \n\n30. }  \n```\n\n\n\n##### **（2）spread(key.hashCode())**\n\n计算key的hash散列值\n\n```\n1.  static final int spread(int h) {  \n\n2.      return (h ^ (h >>> 16)) & HASH_BITS;  // HASH_BITS =  1111111111111111111111111111111\n\n3.  }\n```\n\n这里将（h >>> 16）^ h就是将key的hash值的高16位跟低16位进行异或，跟hashMap中操作一样，但是这里多了一个逻辑与运算。这里是**为了防止前面的异或操作出现负数的情况**，保证spread方法的返回值是一个正数。试想如果异或结果是-1或者-2的话不就跟特殊Node的Hash值冲突了么？\n\n\n\n##### **（3）helpTransfer(Node<K, V>[] tab, Node<K, V> f)**\n\n多线程帮助扩容\n\n```\n1.  final Node<K, V>[] helpTransfer(Node<K, V>[] tab, Node<K, V> f) {  \n\n2.      Node<K, V>[] nextTab;  \n\n3.      int sc;  \n\n4.      if (tab != null && (f instanceof ForwardingNode) && (nextTab = ((ForwardingNode<K, V>) f).nextTable) != null) {  \n\n5.          int rs = resizeStamp(tab.length); // 通过resizeStamp生成唯一戳，来保证这次扩容的唯一性，防止出现扩容重叠的现象  \n\n6.          while (nextTab == nextTable && table == tab && (sc = sizeCtl) < 0) {  \n\n7.              if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex <= 0)  \n\n8.                  break;  \n\n9.              if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {  \n\n10.                 transfer(tab, nextTab); // 将tab扩容到nextTab  \n\n11.                 break;  \n\n12.             }  \n\n13.         }  \n\n14.         return nextTab;  \n\n15.     }  \n\n16.     return table;  \n\n17. }  \n```\n\n\n\n**这里需要先搞清楚的是rs是什么？sc又是什么？**\n\n**rs = resizeStamp(tab.length);**\n\n```\n1.  /** \n\n2.   * 返回与扩容有关的一个生成戳rs，每次新的扩容，都有一个不同的n，这个生成戳就是根据n来计算出来的一个数字，n不同，这个数字也不同 \n\n3.   * 保证 rs << RESIZE_STAMP_SHIFT（16） 必须是负数 \n\n4.   * numberOfLeadingZeros方法返回无符号整型i的最高非零位前面的0的个数，包括符号位在内，如果是负数直接返回0 \n\n5.   */  \n\n6.  static final int resizeStamp(int n) {  \n\n7.      return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));  \n\n8.  }  \n```\n\n\n\n这里1 << (RESIZE_STAMP_BITS - 1)就是2^15 (1000 0000 0000 0000)\n\nInteger.numberOfLeadingZeros(n) 表示int（32位）类型n的最高非零位前面的0的个数\n\n![img](http://pcc.huitogo.club/b876356bfc821fa6cd7577f9bd5f7269)\n\n两者进行逻辑或操作的话，会让Integer.numberOfLeadingZeros(n)结果的第16个位置为1，当n为32的时候，rs就是1000 0000 0001 1010 （32794）\n\n如果将rs << RESIZE_STAMP_BITS（16）的话，即第32位为1（符号位），所以必是负数\n\n\n\n**sc就是sizeCtrl**\n\n源码注释解释说：sizeCtl = -(1 + nThreads)，表示有nThreads个线程正在进行扩容操作（实际上不是这么计算参与线程的）\n\n在tryPresize中，第一条扩容线程会将sizeCtl变成(rs << RESIZE_STAMP_SHIFT) + 2)，sizeCtl就是在这个时候变成负数（除了初始化table的时候变成 - 1除外）。\n\n```\nU. compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)\n```\n\n\n\n上面说了rs<<16后一定是一个负数，sizeCtrl此时一定是一个负数，所以\n\nA. sizeCtrl的高16位就是rs\n\nB. sizeCtrl的低16位就是扩容的线程数 + 1，上面 + 2 表示此时有一个线程在扩容\n\n\n\n这个时候就可以过来理解helpfer的源码了：\n\n1）判断当前table正在扩容（ForwardindNode只在扩容的时候出现）。\n\n2）再判断当前是多线程在扩容中（sizeCtl < 0）\n\n3）在帮助扩容之前还有几个前提条件，也就是如何理解这4个if\n\n　A. **（sc>>>RESIZE_STAMP_SHIFT） != rs**：sc >>>16 就是rs了，如果两者不相等，说明底层数组的长度改变了，说明扩容结束了，所以直接跳出循环，不在需要进行协助扩容了\n\n　B. **transferIndex <= 0**：表示所有的transfer任务都被领取光了，没有剩余的hash桶给自己这个线程来transfer，此时线程不能再帮助扩容了\n\n　C. **sc == rs + 1**：表示扩容线程已经达到最大值，在ConcurrentHashMap永远不相等。\n\n　D. **sc == rs + MAX_RESIZERS**：表示扩容线程已经达到最大值，在ConcurrentHashMap永远不相等\n\n4）4个if条件后就进入扩容环节了（领取任务），当然前提要将sc + 1（多了一个线程参与扩容）。\n\n\n\n##### **（4）treeifyBin(Node<K, V>[] tab, int index)**\n\n将tab扩容或者在index处的链表转红黑树\n\n```\n1.  private final void treeifyBin(Node<K, V>[] tab, int index) {  //TODO  \n\n2.      Node<K, V> b;  \n\n3.      @SuppressWarnings(\"unused\")  \n\n4.      int n, sc;  \n\n5.      if (tab != null) {  \n\n6.          if ((n = tab.length) < MIN_TREEIFY_CAPACITY)  \n\n7.              tryPresize(n << 1);   // 扩容  \n\n8.          else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {  \n\n9.              synchronized (b) {  \n\n10.                 if (tabAt(tab, index) == b) {  \n\n11.                     TreeNode<K, V> hd = null, tl = null; // hd 头节点 tl 尾节点  \n\n12.                     for (Node<K, V> e = b; e != null; e = e.next) {   \n\n13.                         TreeNode<K, V> p = new TreeNode<K, V>(e.hash, e.key, e.val, null, null);  \n\n14.                         if ((p.prev = tl) == null)  \n\n15.                             hd = p;  \n\n16.                         else  \n\n17.                             tl.next = p;  \n\n18.                         tl = p;  \n\n19.                     }  \n\n20.                     setTabAt(tab, index, new TreeBin<K, V>(hd)); //将链表转换后的红黑树的头节点放在table的index所在的位置  \n\n21.                 }  \n\n22.             }  \n\n23.         }  \n\n24.     }  \n\n25. }  \n```\n\n\n\n这里的tryPresize(n << 1) 扩容方法下面再讲，判断链表转红黑树的时候需要知道Node数组有个桶是红黑树的话，这个桶在Node数组上的头节点不是root节点，而是一个TreeBin。\n\n```\nsetTabAt(tab, index, new TreeBin<K, V>(hd))\n```\n\n这里TreeBin + TreeNode 的功能相当于hashMap中的TreeNode，TreeBin指向root节点\n\n\n\n**这里为什么用TreeBin呢？**\n\nTreeBin的源码：\n\n```\n1.  static final class TreeBin<K, V> extends Node<K, V> {  \n\n2.      TreeNode<K, V> root;  \n\n3.      volatile TreeNode<K, V> first;  \n\n4.      volatile Thread waiter;  \n\n5.      volatile int lockState;  \n\n6.      static final int WRITER = 1; // 写锁  \n\n7.      static final int WAITER = 2; // 等待中  \n\n8.      static final int READER = 4; // 读写锁  \n\n9.      TreeBin(TreeNode<K, V> b) {  \n\n10.         super(TREEBIN, null, null, null);  \n\n11.         // ...  \n\n12.     }  \n\n\n13.     private final void lockRoot() {  \n\n14.         if (!U.compareAndSwapInt(this, LOCKSTATE, 0, WRITER))  \n\n15.             contendedLock(); // offload to separate method  \n\n16.     }  \n\n\n17.     private final void unlockRoot() {  \n\n18.         lockState = 0;  \n\n19.     }  \n\n\n20.     private final void contendedLock() {  \n\n21.         boolean waiting = false;  \n\n22.         for (int s;;) {  \n\n23.             if (((s = lockState) & ~WAITER) == 0) {  \n\n24.                 if (U.compareAndSwapInt(this, LOCKSTATE, s, WRITER)) {  \n\n25.                     if (waiting)  \n\n26.                         waiter = null;  \n\n27.                     return;  \n\n28.                 }  \n\n29.             } else if ((s & WAITER) == 0) {  \n\n30.                 if (U.compareAndSwapInt(this, LOCKSTATE, s, s | WAITER)) {  \n\n31.                     waiting = true;  \n\n32.                     waiter = Thread.currentThread();  \n\n33.                 }  \n\n34.             } else if (waiting)  \n\n35.                 LockSupport.park(this);  \n```\n\n从上面大概源码中我们知道这里是利用**TreeBin维护了一个简单的读写锁**，在putTreeVal和removeTreeNode方法中使用到。\n\n\n\n##### **（5）tryPresize(int size)**\n\n进行扩容（并非扩容的实际代码）\n\n源码如下：\n\n```\n1.  private final void tryPresize(int size) {    \n\n2.      int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1);  \n\n3.      int sc;  \n\n4.      while ((sc = sizeCtl) >= 0) {  // 这里一直获取最新得sizeCtl 直到“拿到锁”，compareAndSwapInt替换成功  \n\n5.          Node<K, V>[] tab = table;  \n\n6.          int n;  \n\n7.          if (tab == null || (n = tab.length) == 0) {  // 出现tab为null的情况就是初始化map用的是传入一个Map,这样一上来就得扩容数组，从而tab都是空得  \n\n8.              n = (sc > c) ? sc : c; // sc理论上是小于c的，大于c的情况仅限于上面的情况，sc = Default_Capablity 而size是传入map的size  \n\n9.              if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {  \n\n10.                 try {  \n\n11.                     if (table == tab) {  \n\n12.                         @SuppressWarnings(\"unchecked\")  \n\n13.                         Node<K, V>[] nt = (Node<K, V>[]) new Node<?, ?>[n];   \n\n14.                         table = nt;  \n\n15.                         sc = n - (n >>> 2); // sizeCtl = table.length * (3/4)  \n\n16.                     }  \n\n17.                 } finally {  \n\n18.                     sizeCtl = sc;  \n\n19.                 }  \n\n20.             }  \n\n21.         } else if (c <= sc || n >= MAXIMUM_CAPACITY)  \n\n22.             break;  \n\n23.         else if (tab == table) {  \n\n24.             int rs = resizeStamp(n); // ???  计算本次扩容的生成戳  rs >>> RESIZE_STAMP_SHIFT 必是负数   \n\n25.             if (sc < 0) { // 如果正在扩容Table的话，则帮助扩容  \n\n26.                 Node<K, V>[] nt;  \n\n27.                 if ((sc >>> 2) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex <= 0) // MAX_RESIZERS是最大扩容的数量  \n\n29.                     break;  \n\n30.                 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) // 这里的sc是线程数 多线程帮助扩容  \n\n31.                     transfer(tab, nt); // 将第一个参数的table中的元素，移动到第二个元素的table中去，  \n\n32.             } else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)) // 试着让自己成为第一个执行transfer任务的线程  \n\n33.                 transfer(tab, null); // 当第二个参数为null的时候，会创建一个两倍大小的table  \n\n34.         }  \n\n35.     }  \n\n36. }  \n```\n\n\n\n上述步骤流程如下：\n\n1）先判断这次扩容是不是putAll引起的，也就是table是空的，如果是的话，我扩容的大小就是大于map.size * 2 + map.size + 1的最小2的幂次数，这里map是putAll时的map参数，同时是map.size < MAXIMUM_CAPACITY(2 ^ 30)的前提下。\n\n2） 如果不是putAll引起的，就是实打实的想扩容，那么判断下现在有没有线程正在扩容\n\n3）有线程扩容，就helpTransfer（帮助扩容），将tab扩容成nextTable，这里和helpTransfer代码有一点不一样的就是if中加了一个判断条件(nt = nextTable) == null ：表示整个扩容过程已经结束，或者扩容过程处于一个单线程的阶段（transfer方法中创建nextTable是由单线程完成的），此时不能帮助扩容。\n\n4）当前没有其他线程正在扩容，尝试将自己设置为第一个扩容的，就是设置sizeCtl的值为 (rs << RESIZE_STAMP_SHIFT) + 2，这时候nextTable是null的，所以这时候扩容的大小也就是tab.length * 2（原大小的两倍）。\n\n\n\n##### **（6）transfer(Node<K, V>[] tab, Node<K, V>[] nextTab)**\n\n这个就是扩容的实质性代码了\n\n```\n1.  private final void transfer(Node<K, V>[] tab, Node<K, V>[] nextTab) { // TODO  \n\n2.      int n = tab.length, stride;  \n\n3.      if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)  \n\n4.          stride = MIN_TRANSFER_STRIDE;   \n\n5.      if (nextTab == null) { // 如果new tab为空的话 就初始化一个两倍于原table的数组  \n\n6.          try {  \n\n7.              @SuppressWarnings(\"unchecked\")  \n\n8.              Node<K, V>[] nt = (Node<K, V>[]) new Node<?, ?>[n << 1];  \n\n9.              nextTab = nt;  \n\n10.         } catch (Throwable ex) { //处理内存不足导致的OOM，以及table数组超过最大长度，这两种情况都实际上无法再进行扩容了  \n\n11.             sizeCtl = Integer.MAX_VALUE;  \n\n12.             return;  \n\n13.         }  \n\n14.         nextTable = nextTab;  \n\n15.         transferIndex = n;  \n\n16.     }  \n\n17.     int nextn = nextTab.length;  \n\n18.   // 转发节点，在旧数组的一个hash桶中所有节点都被迁移完后，放置在这个hash桶中，表明已经迁移完，对它的读操作会转发到新数组  \n\n19.     ForwardingNode<K, V> fwd = new ForwardingNode<K, V>(nextTab);  \n\n20.     boolean advance = true;  \n\n21.     boolean finishing = false; // to ensure sweep before committing nextTab  \n\n\n22.     for (int i = 0, bound = 0;;) {  \n\n23.         Node<K, V> f;  \n\n24.         int fh;  \n\n25.         while (advance) {  // 这里相当于每个线程领取任务  \n\n26.             int nextIndex, nextBound;  \n\n27.             if (--i >= bound || finishing) // 一次transfer任务还没有执行完毕  \n\n28.                 advance = false;  \n\n29.             else if ((nextIndex = transferIndex) <= 0) { // transfer任务已经没有了，表明可以准备退出扩容了  \n\n30.                 i = -1;  \n\n31.                 advance = false;  \n\n32.             } else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex,  \n\n33.                     nextBound = (nextIndex > stride ? nextIndex - stride : 0))) { // // 尝试申请一个transfer任务  \n\n34.                 bound = nextBound; // 申请到任务后标记自己的任务区间 bound = nextIndex - stride  \n\n35.                 i = nextIndex - 1;  \n\n36.                 advance = false;  \n\n37.             }  \n\n38.         }  \n\n\n39.         if (i < 0 || i >= n || i + n >= nextn) {  // 处理扩容重叠  \n\n40.             int sc;  \n\n41.             if (finishing) {  \n\n42.                 nextTable = null;  \n\n43.                 table = nextTab;  \n\n44.                 sizeCtl = (n << 1) - (n >>> 1);  \n\n45.                 return;  \n\n46.             }  \n\n47.             if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {  \n\n48.                 if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)  \n\n49.                     return;  \n\n50.                 finishing = advance = true;  \n\n51.                 i = n; // recheck before commit  \n\n52.             }  \n\n53.         } else if ((f = tabAt(tab, i)) == null) //  hash桶本身为null，不用迁移，直接尝试安放一个转发节点  \n\n54.             advance = casTabAt(tab, i, null, fwd);  \n\n55.         else if ((fh = f.hash) == MOVED)  \n\n56.             advance = true; // already processed  \n\n57.         else {   \n\n58.             synchronized (f) {    \n\n59.                 if (tabAt(tab, i) == f) {   \n\n60.                     Node<K, V> ln, hn;  \n\n61.                     if (fh >= 0) { //链表处理  \n\n62.                            /* \n\n63.                             * 因为n的值为数组的长度，且是power(2,x)的，所以，在&操作的结果只可能是0或者n \n\n64.                             * 根据这个规则 \n\n65.                             *         0-->  放在新表的相同位置 \n\n66.                             *         n-->  放在新表的（n+原来位置） \n\n67.                             *         'rehash（重新散列）'的操作跟hashMap一样 \n\n68.                             */  \n\n69.                         int runBit = fh & n;    \n\n70.                         Node<K, V> lastRun = f;  \n\n71.                          /* \n\n72.                             * lastRun 表示的是需要复制的最后一个节点 \n\n73.                             * 每当新节点的hash&n -> b 发生变化的时候，就把runBit设置为这个结果b \n\n74.                             * 这样for循环之后，runBit的值就是最后不变的hash&n的值 \n\n75.                             * 而lastRun的值就是最后一次导致hash&n 发生变化的节点(假设为p节点) \n\n76.                             * 为什么要这么做呢？因为p节点后面的节点的hash&n 值跟p节点是一样的， \n\n77.                             * 所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置 \n\n78.                             * 在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了 \n\n79.                             * 这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序 \n\n80.                             */  \n\n81.                         for (Node<K, V> p = f.next; p != null; p = p.next) {  \n\n82.                             int b = p.hash & n;  \n\n83.                             if (b != runBit) {  \n\n84.                                 runBit = b;  \n\n85.                                 lastRun = p;  \n\n86.                             }  \n\n87.                         }  \n\n88.                         if (runBit == 0) { // (注一) 这里可以认为设置完runBit = 0之后的节点都是不用复制到新数组的  \n\n89.                             ln = lastRun;  \n\n90.                             hn = null;  \n\n91.                         } else { // （注二）这里可以认为设置完runBit != 0之后的节点都是需要复制到新数组的  \n\n92.                             hn = lastRun;  \n\n93.                             ln = null;  \n\n94.                         }  \n\n95.                         for (Node<K, V> p = f; p != lastRun; p = p.next) { // 这里轮询链表节点p，根据(ph & n) == 0判断是否要复制  \n\n96.                             int ph = p.hash;  \n\n97.                             K pk = p.key;  \n\n98.                             V pv = p.val;  \n\n99.                             if ((ph & n) == 0)  \n\n100.                                 ln = new Node<K, V>(ph, pk, pv, ln); // 将不需要复制的节点放在上述(注一) lastRun的前面，如果为空相当于重新构建一个链表  \n\n101.                             else  \n\n102.                                 hn = new Node<K, V>(ph, pk, pv, hn); //将需要复制的节点放在上述(注二) lastRun的前面，如果为空相当于重新构建一个链表  \n\n103.                         }  \n\n104.                         setTabAt(nextTab, i, ln); // 将ln所在的链表放置在原地  \n\n105.                         setTabAt(nextTab, i + n, hn); // 将hn所在的链表放在在原地 + n的位置  \n\n106.                         setTabAt(tab, i, fwd); // 在旧tab的位置 放置 ForwardingNode节点  \n\n107.                         advance = true; //进入下一个循环  \n\n108.                     } else if (f instanceof TreeBin) { // 红黑树处理  \n\n109.                         TreeBin<K, V> t = (TreeBin<K, V>) f;  \n\n110.                         TreeNode<K, V> lo = null, loTail = null; //  \n\n111.                         TreeNode<K, V> hi = null, hiTail = null;  \n\n112.                         int lc = 0, hc = 0;  \n\n113.                         for (Node<K, V> e = t.first; e != null; e = e.next) {  \n\n114.                             int h = e.hash;  \n\n115.                             TreeNode<K, V> p = new TreeNode<K, V>(h, e.key, e.val, null, null);  \n\n116.                             if ((h & n) == 0) { // 将不需要复制的节点 整合到 lo ~ loTail上  \n\n117.                                 if ((p.prev = loTail) == null)  \n\n118.                                     lo = p;  \n\n119.                                 else  \n\n120.                                     loTail.next = p;  \n\n121.                                 loTail = p;  \n\n122.                                 ++lc;  \n\n123.                             } else { // 将需要复制的节点 整合到 hi ~ hiTail上  \n\n124.                                 if ((p.prev = hiTail) == null)  \n\n125.                                     hi = p;  \n\n126.                                 else  \n\n127.                                     hiTail.next = p;  \n\n128.                                 hiTail = p;  \n\n129.                                 ++hc;  \n\n130.                             }  \n\n131.                         }  \n\n\n132.                         // 判断新生成的两个红黑树 是否要转成链表  \n\n133.                         ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin<K, V>(lo) : t;  \n\n134.                         hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin<K, V>(hi) : t;  \n\n135.                         setTabAt(nextTab, i, ln);  \n\n136.                         setTabAt(nextTab, i + n, hn);  \n\n137.                         setTabAt(tab, i, fwd);  \n\n138.                         advance = true;  \n\n139.                     }  \n\n140.                 }  \n\n141.             }  \n\n142.         }  \n\n143.     }  \n```\n\n\n\n上述扩容的步骤可以解释如下：\n\n1）先计算每个线程需要处理的桶数（这里叫stride）\n\n2）判断新的table是否为空，如果为空就整一个原来tab两倍的容器。\n\n3）再进入循环，每个线程申领自己的任务，（transferIndex~transferIndex-stride）之间的桶数就是该线程的转移任务。每完成一个桶判断一下任务完成没有（是否到达了bound），如果完成了是否还能再申领任务，需要注意的是这里**处理桶数是从后往前进行处理**，迭代遍历是从前往后遍历，可以有效解决扩容时进行迭代引起的冲撞，如果冲撞了就找到放置在旧tab的ForwardingNode节点，通过它找到newTable。\n\n4）领完任务之后需要预防一下**扩容重叠**的问题，简单的来解释就是线程A正在将数组从n->2n进行扩容（在处理中），线程B也在将数组从n->2n进行扩容，然后线程B成功扩容完了结束线程。这时候线程C要将数组从2n->4n扩容，然后线程A扩容完了，想要再领任务，这时候领的任务是从2n->4n了，但是线程A中的还是n->2n得目标，所以扩容重叠，具体可以看下面得解释。\n\n5）线程处理任务之前需要思考一下，先是如果正在处理的桶中没有数据，直接在这个地方放一个ForwardingNode节点，然后就是这个桶是不是被别人处理过了，这时候转到下一个桶。\n\n\n\n6）下面是线程处理任务的正式环节了，需要分别处理链表和红黑树的情况\n\nA. 桶中的是链表，这时候仍然利用好hashMap中的优良写法，直接key.hash & tab.length == 0判断Node需不需要搬家（搬到tab.length + 当前位置）\n\n这里有一个优化的地方就是我假设链表的后面一串都是要复制的，或者都不需要复制的，那么我就不需要大张旗鼓的一个个处理后面这些了，直接找到他们的头，让它加入我们新构建的链表，这样它的小弟就屁颠屁颠的过来了（代码中的runBit就是那个分界线）。然后在newTable放置好新构建的需要复制的链表和不需要复制的链表就阔以咯。\n\nB. 桶中的红黑树，对待红黑树就没有上面那个骚操作了，老老实实的构建需要复制的红黑树和不需要复制的红黑树，然后放置进newTable。这里需要注意的就是红黑树需不要降解成链表的问题。\n\n\n\n构建的过程，如图：\n\n![img](http://pcc.huitogo.club/6ff664fd81123ac93d7abf585ddfd318)\n\n\n\n##### **（7）addCount(long x, int check)**\n\n高并发计数的方法\n\n源码如下：\n\n```\n1.  private final void addCount(long x, int check) {  \n\n2.      CounterCell[] as;  \n\n3.      long b, s;    \n\n4.      // counterCells不为null的时候代表这时候是有冲突的  \n\n5.      // 所以在尝试修改baseCount基础值失败后进入并发计数模式，也就是调用fullAddCount  \n\n6.      if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {  \n\n7.          CounterCell a;  \n\n8.          long v;  \n\n9.          int m;  \n\n10.         boolean uncontended = true;  \n\n11.         if (as == null || (m = as.length - 1) < 0 || (a = as[ThreadLocalRandom.getProbe() & m]) == null  \n\n12.                 || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {  \n\n13.             fullAddCount(x, uncontended); // 这里跟LongAdder是一样的，可以去看LongAdder源码分析  \n\n14.             return;   \n\n15.         }  \n\n16.         if (check <= 1)  \n\n17.             return;  \n\n18.         s = sumCount();  \n\n19.     }  \n\n20.     if (check >= 0) { // check是桶中的Node数量，这里判断是否要扩容，代码类似helpTransfer  \n\n21.         Node<K, V>[] tab, nt;  \n\n22.         int n, sc;  \n\n23.         while (s >= (long) (sc = sizeCtl) && (tab = table) != null && (n = tab.length) < MAXIMUM_CAPACITY) {  \n\n24.             int rs = resizeStamp(n);  \n\n25.             if (sc < 0) {  \n\n26.                 if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS  \n\n27.                         || (nt = nextTable) == null || transferIndex <= 0)  \n\n28.                     break;  \n\n29.                 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))  \n\n30.                     transfer(tab, nt);  \n\n31.             } else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2))  \n\n32.                 transfer(tab, null);  \n\n33.             s = sumCount();  \n\n34.         }  \n\n35.     }  \n\n36. }  \n```\n\n\n\n这里如果看了俺的LongAdder源码分析的话也是很简单的\n\n流程步骤如下\n\n1）先试着去修改baseCount的值（+1），看过sumCount的源码知道concurrentHash的size就是baseCount + CounterCell[]的值，如果修改失败就是有冲突了，这时候调用fullAddCount()，其实就是Striped64.longAccumulate()，进行累积值。\n\n2）再判断新增后是否要扩容，走的就是helpTransfer代码，没线程就自己扩容，有线程就帮助扩容。\n\n\n\n#### **8、总结一下concurrentHashMap的同步机制**\n\n首先是读操作，从源码中可以看出来，在get操作中，根本没有使用同步机制，也没有使用unsafe方法，所以读操作是支持并发操作的。\n\n那么写操作呢？\n\n分析这个之前，先看看什么情况下会引起数组的扩容，扩容是通过transfer方法来进行的。而调用transfer方法的只有trePresize、helpTransfer和addCount三个方法。\n\n这三个方法又是分别在什么情况下进行调用的呢？\n\n　1）tryPresize是在treeIfybin和putAll方法中调用，treeIfybin主要是在put添加元素完之后，判断该数组节点相关元素是不是已经超过8个的时候，如果超\n\n　过则会调用这个方法来扩容数组或者把链表转为树。\n\n　2）helpTransfer是在当一个线程要对table中元素进行操作的时候，如果检测到节点的HASH值为MOVED的时候，就会调用helpTransfer方法，在\n\n　helpTransfer中再调用transfer方法来帮助完成数组的扩容\n\n　3）addCount是在当对数组进行操作，使得数组中存储的元素个数发生了变化的时候会调用的方法。\n\n\n\n**所以引起数组扩容的情况如下：**\n\n1）只有在往map中添加元素的时候，在某一个节点的数目已经超过了8个，同时数组的长度又小于64的时候，才会触发数组的扩容。\n\n2）当数组中元素达到了sizeCtl的数量的时候，则会调用transfer方法来进行扩容\n\n\n\n**那么在扩容的时候，可以不可以对数组进行读写操作呢？**\n\n事实上是可以的。当在进行数组扩容的时候，如果当前节点还没有被处理（也就是说还没有设置为fwd节点），那就可以进行设置操作。\n\n如果该节点已经被处理了，则当前线程也会加入到扩容的操作中去。\n\n\n\n**那么，多个线程又是如何同步处理的呢？**\n\n在ConcurrentHashMap中，同步处理主要是通过Synchronized和unsafe两种方式来完成的。\n\n1）在取得sizeCtl、某个位置的Node的时候，使用的都是unsafe的方法，来达到并发安全的目的。\n\n2）当需要在某个位置设置节点的时候，则会通过Synchronized的同步机制来锁定该位置的节点。\n\n3）在数组扩容的时候，则通过处理的步长和fwd节点来达到并发安全的目的，通过CAS设置hash值为MOVED。\n\n4）当把某个位置的节点复制到扩张后的table的时候，也通过Synchronized的同步机制来保证线程安全。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 3}, "3ea12ca4448759debbc47720e24c354f": {"id": "3ea12ca4448759debbc47720e24c354f", "item": "Java基础", "title": "ArrayList源码分析", "date": "2024-08-22", "summary": "ArrayList 是 Java 中的一种动态数组实现。它可以自动扩容以适应存储更多元素。支持快速随机访问，通过索引可高效地获取和设置元素。但在插入和删除元素时，可能需要移动大量元素，效率较低。适用于频繁读取、少量插入删除的场景。", "body": "\n#### 1. ArrayList的概述\n\n1. **ArrayList是可以动态增长和缩减的索引序列，它是基于数组实现的List类**。我们对ArrayList类的实例的所有的操作底层都是基于数组的。\n2. 该类封装了一个动态再分配的Object[]数组，每一个类对象都有一个capacity属性，表示它们所封装的Object[]数组的长度，当向ArrayList中添加元素时，该属性值会自动增加，如果向ArrayList中**添加大量元素**，可使用ensureCapacity方法**一次性增加**capacity，可以减少增加重分配的次数**提高性能**。\n3. ArrayList和Vector的区别是：ArrayList是线程不安全的，当多条线程访问同一个ArrayList集合时，程序需要手动保证该集合的同步性，而Vector则是线程安全的。\n\n4. ArrayList和Collection的关系\n\n![img](http://pcc.huitogo.club/1669175a6a1385a593b5f92d9765171c)\n\n\n\n#### 2. ArrayList继承结构和层次关系\n\n![img](http://pcc.huitogo.club/ae3d57544fa5aae08f8875d94ce23dc0)\n\n\n\n**2.1 为什么先继承AbstractList，而让AbstractList先实现List<E>？而不是让ArrayList直接实现List<E>？**\n\n**接口中全都是抽象的方法（jdk1.8后的default方法除外），而抽象类中可以有抽象方法，还可以有具体的实现方法**，正是利用了这一点，让AbstractList实现接口中一些通用的方法，而具体的类，如ArrayList就继承这个AbstractList类，拿到一些通用的方法，然后自己在实现一些自己特有的方法\n\n\n\n**2.2 ArrayList实现了哪些接口？**\n\n1） List<E>接口\n\nArrayList的父类AbstractList也实现了List<E>接口，那为什么子类ArrayList还是去实现一遍呢？\n\n网址贴出来\n\n[http://stackoverflow.com/questions/2165204/why-does-linkedhashsete-extend-hashsete-and-implement-sete]\n\n开发这个collection 的作者Josh说。\n\n这其实是一个**mistake，因为他写这代码的时候觉得这个会有用处，但是其实并没什么用**，但因为没什么影响，就一直留到了现在。\n\n\n\n2）RandomAccess接口\n\n这个是一个**标记性接口**，它的作用就是用来快速随机存取，有关效率的问题，在实现了该接口的话，那么使用普通的for循环来遍历，性能更高，例如arrayList。\n\n而没有实现该接口的话，使用Iterator来迭代，这样性能更高，例如linkedList。所以这个标记性只是为了让我们知道我们用什么样的方式去获取数据性能更好。\n\n\n\n3） Cloneable接口\n\n实现了该接口，就可以使用Object.Clone()方法了。\n\n\n\n4）Serializable接口\n\n实现该序列化接口，表明该类可以被序列化\n\n\n\n#### 3. 类属性\n\n```\n1.  // 版本号  \n\n2.  private static final long serialVersionUID = 8683452581122892189L;  \n\n3.  // 缺省容量  \n\n4.  private static final int DEFAULT_CAPACITY = 10;  \n\n5.  // 空对象数组  \n\n6.  private static final Object[] EMPTY_ELEMENTDATA = {};  \n\n7.  // 缺省空对象数组  \n\n8.  private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};  \n\n9.  // 元素数组  \n\n10. transient Object[] elementData;  \n\n11. // 实际元素大小，默认为0  \n\n12. private int size;  \n\n13. // 最大数组容量  \n\n14. private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;  \n```\n\n\n\n在父类AbstractList中有个重要属性**modCount**，主要用于迭代的fast-fail。\n\n在使用迭代器对list迭代的过程中，会进行判断。\n\n```\n1.  final void checkForComodification() {  \n\n2.      if (modCount != expectedModCount)  \n\n3.          throw new ConcurrentModificationException();  \n\n4.  }  \n```\n\n这里的modCount来源于list，是数组修改的次数，发生add()、remove()的时候都会修改这个值，expectedModCount初始化赋值是modCount，但是list中没有方法会去更改这个expectedModCount，所以是一个固定值。所以当list发生修改操作的时候，modCount会改变，expectedModCount不会改变，所以上面方法检查后会报异常，所以**在list进行迭代过程中不可以对list进行add、remove操作**。\n\n\n\n#### 4. 构造方法\n\n##### 4.1 无参构造方法\n\n```\n1.  public ArrayList() {　　  \n\n2.       super();     //调用父类中的无参构造方法，父类中的是个空的构造方法  \n\n3.       //EMPTY_ELEMENTDATA：是个空的Object[]， 将elementData初始化，elementData也是个Object[]类型。空的Object[]会给默认大小10  \n\n4.       this.elementData = EMPTY_ELEMENTDATA  \n\n5.   }  \n```\n\n\n\n##### 4.2 有参构造函数一\n\n```\n1.  public ArrayList(int initialCapacity) {  \n\n2.      super(); //父类中空的构造方法  \n\n3.      if (initialCapacity < 0)  //判断如果自定义大小的容量小于0，则报下面这个非法数据异常  \n\n4.          throw new IllegalArgumentException(\"Illegal Capacity: \"+  initialCapacity);  \n\n6.      this.elementData = new Object[initialCapacity]; //将自定义的容量大小当成初始化elementData的大小  \n\n7.  }  \n```\n\n\n\n##### 4.3 有参构造函数二（不常用）\n\n```\n9.  public ArrayList(Collection<? extends E> c) {  \n\n10.    elementData = c.toArray();    //转换为数组  \n\n11.    size = elementData.length;   //数组中的数据个数  \n\n12.    // c.toArray might (incorrectly) not return Object[] (see 6260652)  \n\n13.    // 每个集合的toarray()的实现方法不一样，所以需要判断一下，如果不是Object[].class类型，那么就需要使用ArrayList中的方法去改造一下。  \n\n14.    if (elementData.getClass() != Object[].class)   \n\n15.        elementData = Arrays.copyOf(elementData, size, Object[].class);  \n\n16. }　　\n```\n\n\n\n总结：**arrayList的构造方法就做一件事情，就是初始化一下储存数据的容器，其实本质上就是一个数组，在其中就叫elementData。**\n\n\n\n#### 5. 核心方法\n\n##### 5.1 add方法\n\n![img](http://pcc.huitogo.club/3d6bea0cd89a5c64b7bb4b238e1c6b05)\n\n\n\n**1）boolean add(E)：默认直接在末尾添加元素**\n\n```\n2.  public boolean add(E e) {      \n\n3.  //确定内部容量是否够了，size是数组中数据的个数，因为要添加一个元素，所以size+1，先判断size+1的这个个数数组能否放得下，就在这个方法中去判断是否数组.length是否够用了。  \n\n4.      ensureCapacityInternal(size + 1);  // Increments modCount!!  \n\n5.   //在数据中正确的位置上放上元素e，并且size++  \n\n6.      elementData[size++] = e;  \n\n7.      return true;  \n\n8.  } \n```\n\n\n\nensureCapacityInternal(size + 1)代码\n\n```\n1.  private void ensureCapacityInternal(int minCapacity) {  \n\n2.      if (elementData == EMPTY_ELEMENTDATA) { // 判断初始化的elementData是不是空的数组，也就是没有长度  \n\n3.      // 因为如果是空的话，minCapacity=size+1；其实就是等于1，空的数组没有长度就存放不了  \n\n4.      // 所以就将minCapacity变成10，也就是默认大小  \n\n5.          minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);  \n\n6.      }  \n\n7.      //确认实际的容量，上面只是将minCapacity=10，这个方法就是真正的判断elementData是否够用  \n\n8.      ensureExplicitCapacity(minCapacity);  \n\n9.  }  \n```\n\n\n\nensureExplicitCapacity(minCapacity)代码\n\n```\n1.  private void ensureExplicitCapacity(int minCapacity) {  \n\n2.      modCount++;  \n\n3.      // minCapacity如果大于了实际elementData的长度，就要增加elementData的length      \n\n4.      if (minCapacity - elementData.length > 0)  \n\n5.          //arrayList能自动扩展大小的关键方法就在这里了  \n\n6.          grow(minCapacity);  \n\n7.      }  \n\n8.  }  \n```\n\n\n\n**Q1：minCapacity到底是什么？**\n\n**就是增加elementData容量所需要到达的最小值，minCapacity = size + 1**\n\n第一种情况：由于elementData初始化时是空的数组，那么第一次add的时候，minCapacity=size+1；也就minCapacity=1，在上一个方法（确定内部容量ensureCapacityInternal）就会判断出是空的数组，就会给将minCapacity=10，到这一步为止，还没有改变elementData的大小。\n\n第二种情况：elementData不是空的数组了，那么在add的时候，minCapacity=size+1；也就是minCapacity代表着elementData中增加之后的实际数据个数，拿着它判断elementData的length是否够用，如果length 不够用，那么肯定要扩大容量，不然增加的这个元素就会溢出。\n\n\n\ngrow(minCapacity)代码\n\n```\n1.  private void grow(int minCapacity) {  \n\n2.       int oldCapacity = elementData.length;  //将扩充前的elementData大小给oldCapacity  \n\n3.       int newCapacity = oldCapacity + (oldCapacity >> 1);//newCapacity就是1.5倍的oldCapacity  \n\n4.       if (newCapacity - minCapacity < 0)//这句话就是适用于elementData就空数组的时候，length=0，那么oldCapacity=0，newCapacity=0，所以这个判断成立，在这里就是真正的初始化elementData的大小了，就是为10  \n\n5.           newCapacity = minCapacity;  \n\n6.       if (newCapacity - MAX_ARRAY_SIZE > 0)//如果newCapacity超过了最大的容量限制，就调用hugeCapacity，也就是将能给的最大值给newCapacity  \n\n7.           newCapacity = hugeCapacity(minCapacity);  \n\n8.       //新的容量大小已经确定好了，就copy数组，改变容量大小。  \n\n9.       elementData = Arrays.copyOf(elementData, newCapacity);  \n\n10.  }  \n```\n\n\n\nhugeCapacity(minCapacity)代码\n\n```\n1.  private static int hugeCapacity(int minCapacity) {  \n\n2.      if (minCapacity < 0) // overflow  \n\n3.          throw new OutOfMemoryError();  \n\n4.      return (minCapacity > MAX_ARRAY_SIZE) ?   Integer.MAX_VALUE :  MAX_ARRAY_SIZE;  \n\n7.  }  \n```\n\n\n\n**2）void add(int，E)：在特定位置添加元素，也就是插入元素**\n\n```\n9.  public void add(int index, E element) {  \n\n10.     rangeCheckForAdd(index);//检查index也就是插入的位置是否合理。  \n\n11.     ensureCapacityInternal(size + 1);  // Increments modCount!!  \n\n12.     //这个方法就是用来在插入元素之后，要将index之后的元素都往后移一位，  \n\n13.     System.arraycopy(elementData, index, elementData, index + 1,  size - index);  \n\n15.     //在目标位置上存放元素  \n\n16.     elementData[index] = element;  \n\n17.     size++;//size增加1  \n\n18. }   \n```\n\nSystem.arraycopy(...)：将elementData中从index开始size-index长度的元素复制到elementData从index+1的元素中。\n\n\n\n总结add方法：\n\n正常情况下会扩容1.5倍，特殊情况下（新扩展数组大小已经达到了最大值）则只取最大值。\n\n\n\n举例说明一：\n\n```\n1.  List<Integer> lists = new ArrayList<Integer>();  \n\n2.  lists.add(8); \n```\n\n\n\n下图给出了未指定初始长度时最初与最后的elementData的大小。\n\n![img](http://pcc.huitogo.club/26cc3666c10ba900c9e25d224ffa4f3b)\n\n在add方法之前开始elementData ={}；调用add方法时会继续调用，直至grow，最后elementData的大小变为10，之后再返回到add函数，把8放在elementData[0]中\n\n\n\n举例说明二：\n\n```\n1.  List<Integer> lists = new ArrayList<Integer>(6);  \n\n2.  lists.add(8);  \n```\n\n\n\n下图是给定初始长度时最初和最后的elementData的大小\n\n![img](http://pcc.huitogo.club/794e478e0644ce6efee91037a3bb1da2)\n\n在调用add方法之前，elementData的大小已经为6，之后再进行传递，不会进行扩容处理\n\n\n\n##### 5.2 remove方法\n\n![img](http://pcc.huitogo.club/46fc3ec8dc06b375af946c78d96839c0)\n\n\n\n**1）remove(int)：通过删除指定位置上的元素**\n\n```\n2.  public E remove(int index) {  \n\n3.      rangeCheck(index);//检查index的合理性  \n\n4.      modCount++;//这个作用很多，比如用来检测快速失败的一种标志。  \n\n5.      E oldValue = elementData(index);//通过索引直接找到该元素  \n\n6.      int numMoved = size - index - 1;//计算要移动的位数，如果在末尾remove就不需要移动  \n\n7.      if (numMoved > 0)  \n\n8.          System.arraycopy(elementData, index+1, elementData, index,   numMoved);  \n\n10.     //将--size上的位置赋值为null，让gc(垃圾回收机制)更快的回收它。  \n\n11.     elementData[--size] = null;   \n\n12.     //返回删除的元素。  \n\n13.     return oldValue;  \n\n14. }  \n```\n\n\n\n**2）remove(Object)：这个方法可以看出来，arrayList是可以存放null值的**\n\n```\n16.  //fastRemove(index)方法的内部跟remove(index)的实现几乎一样，这里最主要是知道arrayList可以存储null值  \n\n17.  public boolean remove(Object o) {  \n\n18.     if (o == null) {  \n\n19.         for (int index = 0; index < size; index++)  \n\n20.             if (elementData[index] == null) {  \n\n21.                 fastRemove(index);  \n\n22.                 return true;  \n\n23.             }  \n\n24.     } else {  \n\n25.         for (int index = 0; index < size; index++)  \n\n26.             if (o.equals(elementData[index])) {  \n\n27.                 fastRemove(index);  \n\n28.                 return true;  \n\n29.             }  \n\n30.     }  \n\n31.     return false;  \n\n32. }  \n```\n\n\n\n**3）clear()：将elementData中每个元素都赋值为null，等待垃圾回收将这个给回收掉，所以叫clear**\n\n```\n34. public void clear() {  \n\n35.      modCount++;  \n\n36.      // clear to let GC do its work  \n\n37.      for (int i = 0; i < size; i++)  \n\n38.          elementData[i] = null;  \n\n39.      size = 0;  \n\n40.  }  \n```\n\n\n\n**4）removeAll(collection c)**\n\n```\n42. public boolean removeAll(Collection<?> c) {  \n\n43.     return batchRemove(c, false);//批量删除  \n\n44. }  \n```\n\n\n\nbatchRemove(Collection, Boolean)：用于两个方法，一个removeAll()：它只清楚指定集合中的元素，这时传入的Boolean值为false；retainAll()用来测试两个集合是否有交集，这时传入的Boolean值为true。\n\n```\n1.  private boolean batchRemove(Collection<?> c, boolean complement) {  \n\n2.       final Object[] elementData = this.elementData; //记录原集合A  \n\n3.       int r = 0, w = 0;   \n\n4.       boolean modified = false;  // 是否移除了数据，也就是batchRemove的返回值  \n\n5.       try {  \n\n6.           for (; r < size; r++)  \n\n7.               // 分两种情形  \n\n8.               // complement = true时，也就是retainAll方法，这时在集合A中记录交集，w为交集个数  \n\n9.               // complement = false时，也就是removeAll方法，这时在集合A中记录集合c中没有的值，w为剩余元素个数  \n\n10.              if (c.contains(elementData[r]) == complement)  \n\n11.                  elementData[w++] = elementData[r];  \n\n12.      } finally {  \n\n13.          // Preserve behavioral compatibility with AbstractCollection,  \n\n14.          // even if c.contains() throws.  \n\n15.          //理论上循环结束时r=size，这里是处理在循环过程中出现异常的情况  \n\n16.          if (r != size) {  \n\n17.              //将剩下的元素都赋值给集合A，  \n\n18.              System.arraycopy(elementData, r,  elementData, w,   size - r);  \n\n21.              w += size - r;  \n\n22.          }  \n\n23.          // 这里是处理记录完交集或者不相关的值后，对于w和size之间这段元素的回收  \n\n24.          if (w != size) {  \n\n25.              // clear to let GC do its work  \n\n26.              for (int i = w; i < size; i++)  \n\n27.                  elementData[i] = null;  \n\n28.              modCount += size - w;  \n\n29.              size = w;  \n\n30.              // 当w != size时，就以为着有交集或者有元素相等  \n\n31.              modified = true;  \n\n32.          }  \n\n33.      }  \n\n34.      return modified;  \n\n35.  }  \n```\n\n\n\n总结：用户使用remove方法移除指定下标的元素，此时会把指定下标到数组末尾的元素向前移动一个单位，并且会把数组最后一个元素设置为null，这样是为了方便之后将整个数组不被使用时，会被GC，可以作为小的技巧使用。\n\n\n\n##### 5.3 set方法\n\n```\n2.  public E set(int index, E element) {  \n\n3.      // 检验索引是否合法  \n\n4.      rangeCheck(index);  \n\n5.      // 旧值  \n\n6.      E oldValue = elementData(index);  \n\n7.      // 赋新值  \n\n8.      elementData[index] = element;  \n\n9.      // 返回旧值  \n\n10.     return oldValue;  \n\n11. } \n```\n\n\n\n##### 5.4 查找方法\n\n**1）indexOf()方法**\n\n```\n14. // 从首开始查找数组里面是否存在指定元素  \n\n15. public int indexOf(Object o) {  \n\n16.     if (o == null) { // 查找的元素为空  \n\n17.         for (int i = 0; i < size; i++) // 遍历数组，找到第一个为空的元素，返回下标  \n\n18.             if (elementData[i]==null)  \n\n19.                 return i;  \n\n20.     } else { // 查找的元素不为空  \n\n21.         for (int i = 0; i < size; i++) // 遍历数组，找到第一个和指定元素相等的元素，返回下标  \n\n22.             if (o.equals(elementData[i]))  \n\n23.                 return i;  \n\n24.     }   \n\n25.     // 没有找到，返回空  \n\n26.     return -1;  \n\n27. }  \n```\n\n说明：从头开始查找与指定元素相等的元素，注意是可以查找null元素的，意味着ArrayList中可以存放null元素的。与此函数对应的lastIndexOf，表示从尾部开始查找。\n\n\n\n**2）get()方法**\n\n```\n2.  public E get(int index) {  \n\n3.      // 检验索引是否合法  \n\n4.      rangeCheck(index);  \n\n5.      return elementData(index);  \n\n6.  }  \n```\n\n说明：这里来使用的是**elementData()方法**返回元素值，不是直接从elementData数组中获取；**返回的值都经过了向下转型（Object -> E）**，这些是对我们应用程序屏蔽的小细节。\n\n\n\n#### 6. 总结\n\n1. arrayList可以存放null。\n2. arrayList本质上就是一个elementData数组。\n3. arrayList区别于数组的地方在于能够自动扩展大小，其中关键的方法就是grow()方法。\n4. arrayList中removeAll(collection c)和clear()的区别就是removeAll可以删除批量指定的元素，而clear是全是删除集合中的元素。\n5. arrayList由于本质是数组，所以它在数据的查询方面会很快，而在插入删除这些方面，性能下降很多，有移动很多数据才能达到应有的效果。\n6. arrayList实现了RandomAccess，所以在遍历它的时候推荐使用for循环。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 2}, "a7844af8a48998efd7e91f1b23664390": {"id": "a7844af8a48998efd7e91f1b23664390", "item": "Java基础", "title": "ArrayDeque源码分析", "date": "2024-08-22", "summary": "ArrayDeque 是 Java 中的一个双端队列实现。它可以在两端高效地进行插入和删除操作。既可用作栈，也能当队列。采用数组实现，能动态扩容。在多线程环境下不安全，适用于单线程或并发控制场景下对两端操作频繁的情况。", "body": "\n#### 1. ArrayDeque介绍\n\n1. 从 ArrayDeque 命名就能看出他的实现基于**可扩容动态数组**，每次队列满了就会进行扩容，除非扩容至 int 边界才会抛出异常\n2. **ArrayDeque 不允许元素为 null**\n3. ArrayDeque 的主要成员是一个 elements 数组和 int 的 head 与 tail 索引，head 是队列的头部元素索引，而 tail 是队列下一个要添加的元素的索引，**elements的默认容量是 16 且默认容量必须是 2 的幂次，不足 2 的幂次会自动向上调整为 2的幂次**\n4. ArrayDeque可以高效的进行**元素查找和尾部插入取出**，是用作队列、双端队列、栈的绝佳选择，**性能比LinkedList还要好**\n\n\n\n#### 2. ArrayDeque的结构\n\nArrayDeque的整体继承结构如下：\n\n![img](http://pcc.huitogo.club/dd7a502ee462bba2b4baf16e16eb5157)\n\n\n\nArrayDeque的内部结构元素如下：\n\n```\n1.  //存储元素的数组  \n\n2.  transient Object[] elements; // 非private访问限制，以便内部类访问  \n\n3.   /** \n\n4.    * 头部节点序号 \n\n5.    */  \n\n6.   transient int head;  \n\n7.   /** \n\n8.    * 尾部节点序号，（指向最后一点节点的后一个位置） \n\n9.    */  \n\n10.  transient int tail;  \n\n11.  /** \n\n12.   * 双端队列的最小容量，必须是2的幂 \n\n13.   */  \n\n14.  private static final int MIN_INITIAL_CAPACITY = 8;  \n```\n\n\n\n#### 3. ArrayDeque的常用方法\n\n![img](http://pcc.huitogo.club/bac373f510c77fc094888a5f3a95e473)\n\n\n\n1. ArrayDeque 获取队列头部元素的 element()、getFirst()、peek()、peekFirst()操作，其都是调用 getFirst() 实现的，**访问队列头部元素但不删除**\n2. ArrayDeque 删除队列头部元素的 remove()、removeFirst()、poll()、pollFirst()操作，其都是调用 pollFirst() 实现的，**移除队列头部元素且返回被移除的元素**\n3. ArrayDeque 添加元素到队列尾部的操作可以发现 add(E e)、offer(E e)、offerLast(E e)、addLast(E e) 操作都是调用 addLast(E e) 实现的\n\n\n\n**Q1：为什么会有这么多方法？**\n\n其实主要是为了模拟不同的数据结构，如栈操作：pop，push，peek，队列操作：add，offer，remove，poll，peek，element，双端队列操作：addFirst，addLast，getFirst，getLast，peekFirst，peekLast，removeFirst，removeLast，pollFirst，pollLast。\n\n\n\n#### 4. 为什么说ArrayDeque是循环数组？\n\n传统的非循环数组中，在尾部添加元素的时候如果添加元素下标等于数组长度那么就要进行扩容操作，但是，在ArrayDeque中是一个双端队列，我们操作ArrayDeque的物理逻辑如下：\n\n![img](http://pcc.huitogo.club/0d60f4701417a6d8ce4360124545b5ce)\n\n\n\n正如上图中最后的多次操作结果所示，如果此时我们再 add 操作一个元素到 tail索引处则 tail+1 会变成 8导致数组越界，理论上来说这时候应该进行扩容操作了，但是由于下标为 0、1、2、3 处没有存储元素，直接扩容有些浪费（**ArrayList为了避免浪费是通过拷贝将删除之后的元素整体前挪一位**）\n\n\n\n现在看一下addLast的源码，是怎么处理这种情况的\n\n```\n1.  public void addLast(E e) {  \n\n2.      if (e == null)  \n\n3.          throw new NullPointerException();  \n\n4.      elements[tail] = e;  \n\n5.      if ( (tail = (tail + 1) & (elements.length - 1)) == head)  \n\n6.          doubleCapacity();  \n\n7.  } \n```\n\n可以看到为了高效利用数组中现有的剩余空间就有了 addLast(E e) 中的代码 **(tail = (tail + 1) & (elements.length - 1))**;\n\n如果让我们来写这个循环实现代码的话可能就是，判断一下有没有超过最大容量给tail赋值再判断一下head的位置，最后再扩容，这里用一个位运算解决了所有逻辑，可以说很精妙，在ArrayDeque的源码中有多处这样的边界判断，**这里也就是ArrayDeque循环数组的核心**\n\n\n\n假设 elements 默认初始化长度是 8，则当前 tail +1（8=1000）按位与上数组长度减一（7=0111）的结果为十进制的 0，所以下一个被addLast(E e) 的元素实际会放在索引为 0 的位置，再下一个会放在索引为 1的位置，如下图：\n\n![img](http://pcc.huitogo.club/a9774c4d3f5f81d21f0ef115195e7036)\n\n**所以 ArrayDeque是一个双向循环队列，其基于数组实现了双向循环操作（依赖按位与操作循环），初始容量必须是2 的幂次，默认为 16，存储的元素不能为空，非线程并发安全。**\n\n\n\n#### 5. ArrayDeque什么时候扩容，是怎么扩容的？\n\n在上面addLast的源码中，以及ArrayDeque双向循环列队的原理，我们知道随着出队入队不断操作，如果 tail 移动到 length-1 之后数组的第一个位置 0 处没有元素则需要将 tail 指向 0，依次循环，**当 tail 如果等于 head 时说明数组要满了，接下来需要进行数组扩容**\n\n\n\n扩容操作的源码如下：\n\n```\n1.  private void doubleCapacity() {  \n\n2.      assert head == tail;  \n\n3.      int p = head;  \n\n4.      int n = elements.length;  \n\n5.      int r = n - p;// number of elements to the right of p  \n\n6.      // 新容量直接翻倍  \n\n7.      int newCapacity = n << 1;  \n\n8.      if (newCapacity < 0) throw new IllegalStateException(\"Sorry, deque too big\");  \n\n9.      Object[] a = new Object[newCapacity];  \n\n10.     //扩容后分两次复制，head到当前数组末尾  \n\n11.     System.arraycopy(elements, p, a, 0, r);  \n\n12.     // 当前数组头到tail位置   \n\n13.     System.arraycopy(elements, 0, a, r, p);  \n\n14.     //相关索引置位  \n\n15.     elements = a;  \n\n16.     head = 0;  \n\n17.     tail = n;  \n\n18. }  \n```\n\n\n\n可以看到扩容也是按2的幂次方扩容的，先将head到数组末尾的数据复制到新数组的头部，将数组头到tail的部分复制到新数组的后面，上面的扩容操作流程演示如下：\n\n![img](http://pcc.huitogo.club/4145ff77bfb468ecf199dc89ca910ed8)\n\n\n\n#### 6. ArrayDeque的初始数组容量怎么定义的？扩容大小为什么必须是2的幂次方？\n\nArrayDeque的构造方法源码如下：\n\n```\n1.  public ArrayDeque(int numElements) {  \n\n2.      allocateElements(numElements);  \n\n3.  }  \n\n\n4.  private void allocateElements(int numElements) {  \n\n5.      elements = new Object[calculateSize(numElements)];  \n\n6.  }  \n\n\n7.  private static int calculateSize(int numElements) {  \n\n8.      int initialCapacity = MIN_INITIAL_CAPACITY;  \n\n9.      if (numElements >= initialCapacity) {  \n\n10.         initialCapacity = numElements;  \n\n11.         initialCapacity |= (initialCapacity >>>  1);  \n\n12.         initialCapacity |= (initialCapacity >>>  2);  \n\n13.         initialCapacity |= (initialCapacity >>>  4);  \n\n14.         initialCapacity |= (initialCapacity >>>  8);  \n\n15.         initialCapacity |= (initialCapacity >>> 16);  \n\n16.         initialCapacity++;  \n\n17.         if (initialCapacity < 0)   // Too many elements, must back off  \n\n18.             initialCapacity >>>= 1;// Good luck allocating 2 ^ 30 elements  \n\n19.     }  \n\n20.     return initialCapacity;  \n\n21. }  \n```\n\n这里重点需要关注的是calculateSize的源码，**将指定的容量计算成比它大的最小2的幂次方值**\n\n\n\n先讨论一下这个计算的实现原理：\n\n在Java中，int类型是占4字节，也就是32位。简单起见，这里以一个8位二进制数来演示前三次操作。假设这个二进制数对应的十进制为89，整个过程如下：\n\n![img](http://pcc.huitogo.club/73a66363170cfdcf0bdf1aee6869d8f5)\n\n\n\n可以看到最后，除了第一位，其他位全部变成了1，然后这个结果再加一，即得到大于89的最小的2次幂，也许你会想，为什么右移的数值要分别是1，2，4，8，16呢？\n\n事实上，在这系列操作中，其他位只是配角，**我们只需要关注第一个不为0的位即可**，假设其为第n位，先右移一位然后进行或操作，得到的结果，第n位和第n-1位肯定为1，这样就有两个位为1了，然后进行右移两位，再进行或操作，那么第n位到第n-3位一定都为1，然后右移4位，依次类推。int为32位，因此，最后只需要移动16位即可。1+2+4+8+16 = 31，所以经过这一波操作，原数字对应的二进制，操作得到的结果将是从其第一个不为0的位开始，往后的位均为1。\n\n在calculateSize中计算完比指定数大的最小2的幂次方数值后，还有一个需要考虑的就是如果扩容到了2^32 - 1，也就是int的最大值，这时候再加1，也就是超过int最大值怎么办？\n\n```\n1.  if (initialCapacity < 0)   \n\n2.      initialCapacity >>>= 1;\n```\n\n第32位为1的情况下，第32位为符号位，1代表负数，这样的话就必须回退一步，将得到的数右移一位（即2 ^ 30）\n\n\n\n知道calculateSize的计算原理后再看一下为什么是2的幂次方值？为什么扩容的时候也是 << 1？\n\n**因为只有容量为 2 的幂次时 ((tail + 1) & (elements.length - 1)) 操作中的(elements.length - 1) 二进制最高位永远为 0，当 (tail + 1)与其按位与操作时才能保证循环归零置位。**\n\n\n\n#### 7. ArrayDeque的增删改查源码？\n\n增的话主要看addLast和addFirst就可以了，addLast源码上面有，这里看一下addFirst的源码：\n\n```\n1.  public void addFirst(E e) {  \n\n2.       if (e == null)  \n\n3.           throw new NullPointerException();  \n\n4.       elements[head = (head - 1) & (elements.length - 1)] = e;  \n\n5.       if (head == tail)  \n\n6.           doubleCapacity();  \n\n7.   }  \n```\n\n这里head = (head - 1) & (elements.length - 1)和addLast中的tail = (tail + 1) & (elements.length - 1)作用一样，都是实现循环数组的核心\n\n\n\n查的话主要看一下getFirst和getLast，peekFirst和peekLast类似\n\n```\n1.  public E getFirst() {  \n\n2.      @SuppressWarnings(\"unchecked\")  \n\n3.      E result = (E) elements[head];  \n\n4.      if (result == null)  \n\n5.          throw new NoSuchElementException();  \n\n6.      return result;  \n\n7.  }  \n\n\n8.  public E getLast() {  \n\n9.      @SuppressWarnings(\"unchecked\")  \n\n10.     E result = (E) elements[(tail - 1) & (elements.length - 1)];  \n\n11.     if (result == null)  \n\n12.         throw new NoSuchElementException();  \n\n13.     return result;  \n\n14. }      \n```\n\n\n\n删的话分两种\n\n一种是头尾移除元素，主要看一下pollFirst和pollLast\n\n```\n1.  public E pollFirst() {  \n\n2.      int h = head;  \n\n3.      @SuppressWarnings(\"unchecked\")  \n\n4.      E result = (E) elements[h];  \n\n5.      // 如果结果为null则返回null  \n\n6.      if (result == null)  \n\n7.          return null;  \n\n8.      elements[h] = null;     // Must null out slot  \n\n9.      head = (h + 1) & (elements.length - 1);  \n\n10.     return result;  \n\n11. }  \n\n\n12. public E pollLast() {  \n\n13.     int t = (tail - 1) & (elements.length - 1);  \n\n14.     @SuppressWarnings(\"unchecked\")  \n\n15.     E result = (E) elements[t];  \n\n16.     if (result == null)  \n\n17.         return null;  \n\n18.     elements[t] = null;  \n\n19.     tail = t;  \n\n20.     return result;  \n\n21. }  \n```\n\n\n\n另一种就是在数组中间移除元素，这个就比较复杂了，ArrayDeque使用removeFirstOccurrence和removeLastOccurrence来实现从数组中移除第一个出现指定元素和最后一个出现指定元素的位置，源码如下：\n\n```\n1.  public boolean removeFirstOccurrence(Object o) {  \n\n2.      if (o == null)  \n\n3.          return false;  \n\n4.      int mask = elements.length - 1;  \n\n5.      int i = head;  \n\n6.      Object x;  \n\n7.      while ( (x = elements[i]) != null) {  \n\n8.          if (o.equals(x)) {  \n\n9.              delete(i);  \n\n10.             return true;  \n\n11.         }  \n\n12.         i = (i + 1) & mask;  \n\n13.     }  \n\n14.     return false;  \n\n15. }  \n\n\n16. public boolean removeLastOccurrence(Object o) {  \n\n17.     if (o == null)  \n\n18.         return false;  \n\n19.     int mask = elements.length - 1;  \n\n20.     int i = (tail - 1) & mask;  \n\n21.     Object x;  \n\n22.     while ( (x = elements[i]) != null) {  \n\n23.         if (o.equals(x)) {  \n\n24.             delete(i);  \n\n25.             return true;  \n\n26.         }  \n\n27.         i = (i - 1) & mask;  \n\n28.     }  \n\n29.     return false;  \n\n30. }  \n```\n\n其实都是通过循环遍历的方式进行查找一个是从head开始往后查找，一个是从tail开始往前查找\n\n\n\n主要使用到的是ArrayDeque的私有方法delete(int i)来删除中间元素，删除中间元素时，即使是循环数组，也需要批量移动数组元素了，所以删除中间元素实际上面临三个问题，一是需要在左侧或右侧删除，二是需要挪动头或尾，三是优化需要，尽量少得移动数组元素。 ArrayDeque实际上是先从第三个问题入手的，先判断中间元素里head近还是离tail近，然后移动较近的那一端。 不过，较近的一端只是逻辑上较近，物理数组上，可能被分成了两截，这就需要做**两次数组元素的批量移动**。\n\n```\n1.  private boolean delete(int i) {  \n\n2.      // 先做不变性检测，判断是否当前结构满足删除需求  \n\n3.      checkInvariants();  \n\n4.      final Object[] elements = this.elements;  \n\n5.      // mask即掩码  \n\n6.      final int mask = elements.length - 1;  \n\n7.      final int h = head;  \n\n8.      final int t = tail;  \n\n9.      // front代表i到头部的距离  \n\n10.     final int front = (i - h) & mask;  \n\n11.     // back代表i到尾部的距离  \n\n12.     final int back  = (t - i) & mask;  \n\n13.     // 再次校验，如果i到头部的距离大于等于尾部到头部的距离，表示当前队列已经被修改了，通过最开始检测后，i是不应该满足该条件的  \n\n14.     if (front >= ((t - h) & mask))  \n\n15.         throw new ConcurrentModificationException();  \n\n16.     // 为移动尽量少的元素做优化，如果离头部比较近，则将该位置到头部的元素进行移动，如果离尾部比较近，则将该位置到尾部的元素进行移动  \n\n17.     if (front < back) {  \n\n18.         if (h <= i) {  \n\n19.             System.arraycopy(elements, h, elements, h + 1, front);  \n\n20.         } else { // Wrap around  \n\n21.             System.arraycopy(elements, 0, elements, 1, i);  \n\n22.             elements[0] = elements[mask];  \n\n23.             System.arraycopy(elements, h, elements, h + 1, mask - h);  \n\n24.         }  \n\n25.         elements[h] = null;  \n\n26.         head = (h + 1) & mask;  \n\n27.         return false;  \n\n28.     } else {  \n\n29.         if (i < t) { // Copy the null tail as well  \n\n30.             System.arraycopy(elements, i + 1, elements, i, back);  \n\n31.             tail = t - 1;  \n\n32.         } else { // Wrap around  \n\n33.             System.arraycopy(elements, i + 1, elements, i, mask - i);  \n\n34.             elements[mask] = elements[0];  \n\n35.             System.arraycopy(elements, 1, elements, 0, t);  \n\n36.             tail = (t - 1) & mask;  \n\n37.         }  \n\n38.         return true;  \n\n39.     }  \n\n40. }    \n```\n\n这个delete还是花了一点心思的，不仅做了两次校验，还对元素移动进行了优化\n\n\n\n#### 8. ArrayDeque可以逆向遍历吗？\n\n当然可以，ArrayDeque作为双向队列，有head和tail两个标识可以作为反向遍历的根本，源码如下：\n\n```\n1.  public Iterator<E> descendingIterator() {  \n\n2.      return new DescendingIterator();  \n\n3.  }  \n\n\n4.  private class DescendingIterator implements Iterator<E> {  \n\n5.      private int cursor = tail;  \n\n6.      private int fence = head;  \n\n7.      private int lastRet = -1;  \n\n8.      public boolean hasNext() {  \n\n9.          return cursor != fence;  \n\n10.     }  \n\n11.     public E next() {  \n\n12.         if (cursor == fence)  \n\n13.             throw new NoSuchElementException();  \n\n14.         cursor = (cursor - 1) & (elements.length - 1);  \n\n15.         @SuppressWarnings(\"unchecked\")  \n\n16.         E result = (E) elements[cursor];  \n\n17.         // 如果移除了尾部元素，会导致 tail != fence  \n\n18.         // 如果移除了头部元素，会导致 result == null  \n\n19.         if (head != fence || result == null)   //这种检测比较弱，如果先移除一个尾部元素，然后再添加一个尾部元素，那么tail依旧和fence相等，这种情况就检测不出来了\n\n20.             throw new ConcurrentModificationException();  \n\n21.         lastRet = cursor;  \n\n22.         return result;  \n\n23.     }  \n\n\n24.     public void remove() {  \n\n25.         if (lastRet < 0)  \n\n26.             throw new IllegalStateException();  \n\n27.         if (!delete(lastRet)) {  \n\n28.             cursor = (cursor + 1) & (elements.length - 1);  \n\n29.             fence = head;  \n\n30.         }  \n\n31.         lastRet = -1;  \n\n32.     }  \n\n33. }  \n```\n\n\n\n#### 9. ArrayDeque是怎么计算队列长度的？\n\n当tail > head的时候比较好计算，但是在tail < head的时候，也就是物理上元素不连续的时候怎么计算？\n\n如果让我们自己写，可能也是分条件判断，分别计算两截的数据\n\n\n\n但是ArrayDeque完美的运用位运算解决这个问题\n\n```\n1. return (tail - head) & (elements.length - 1); \n```\n\n当物理上被分为两截时，tail-head会是负数，整个操作相当于取模运算，例如，当tail为3，head为14，物理数组长度16时，运算的就是11110101&00001111，值为00000101，也就是5。\n\n\n\n#### 10. ArrayDeque怎么转换成数组的？\n\n从基本操作上，如果物理上不连续，先复制右侧，再补上左侧。\n\ntoArray的问题在于新数组的长度是动态的，为了生成大小刚好的新数组，ArrayDeque使用了Arrays工具类来实现这个特定长度的数组，并同时实现对head一侧数据的复制：\n\ntoArray的源码如下：\n\n```\n1.  public Object[] toArray() {  \n\n2.      return copyElements(new Object[size()]);  \n\n3.  }  \n\n\n4.  private <T> T[] copyElements(T[] a) {  \n\n5.      if (head < tail) {  \n\n6.          System.arraycopy(elements, head, a, 0, size());  \n\n7.      } else if (head > tail) {  \n\n8.          int headPortionLen = elements.length - head;  \n\n9.          System.arraycopy(elements, head, a, 0, headPortionLen);  \n\n10.         System.arraycopy(elements, 0, a, headPortionLen, tail);  \n\n11.     }  \n\n12.     return a;  \n\n13. }  \n```\n\n这样的话，如果物理空间连续，就直接复制完成；\n\n但如果物理空间不连续，第一次Arrays.copyOfRange需要保证一次性生成足够的物理空间，所以end的值不能是length（否则长度就只有length-head这么长），而应该是tail+length。\n\n\n\n#### 11. 怎么看待ArrayDeque的存取和查询效率？\n\n因为ArrayDeque底层维护的是一个数组，所以在查询方面效率高，在增删方面，在ArrayList中因为增删元素的话需要移动大量元素，所以效率比较低，但\n\n是在ArrayDeque中如果在头尾增删的话不用移动，在中间增删的话，优化了移动的步骤，同时减少了System.arrayCopy方法的使用，所以ArrayDeque这个数据集合的性能非常优良。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "06985baf3073169892b49a630c977e1a": {"id": "06985baf3073169892b49a630c977e1a", "item": "Java基础", "title": "CyclicBarrierr源码分析", "date": "2024-08-22", "summary": "CyclicBarrier 是 Java 中的同步工具类。它允许一组线程互相等待，到达一个共同的屏障点后再一起继续执行。可用于多线程协作完成任务的场景，能重复使用，提高了多线程编程的效率和灵活性，确保线程按特定阶段同步执行。", "body": "\nCyclicBarrierr翻译过来是循环屏障，循环是指这个barrier在使用后（reset或者broken）可以再次使用；屏障是指所有执行await的线程都需要等待到达阀值之后才可以继续执行后面的代码。\n\n**CyclicBarrierr的底层使用的是ReentrantLock和Condition。**\n\n\n\n来看一下CyclicBarrierr的源码\n\n#### 1. 内部类Generation\n\n```\n2.  private static class Generation {  \n3.      boolean broken = false;  \n4.  }  \n```\n\nGeneration代表着一次Barrier的生命周期，里面只有一个属性broken\n\n当broken为true的时候，Barrier被打断，调用await()方法将会抛出BrokenBarrierException异常\n\n当broken为false的时候，Barrier有效\n\n参与CyclicBarrier的线程可能会关联多个Generation，但是只会有一个Generation处于active，其余的不是broken就是tripped了。\n\n**一次Barrier生命周期中Barrier的状态不会影响到下一次生命周期。**\n\n\n\n#### 2. 成员变量\n\n```\n2.  /** The lock for guarding barrier entry */  \n\n3.  private final ReentrantLock lock = new ReentrantLock();  \n\n4.  /** Condition to wait on until tripped */  \n\n5.  private final Condition trip = lock.newCondition();  \n\n6.  /** The number of parties */  \n\n7.  private final int parties;  \n\n8.  /* The command to run when tripped */  \n\n9.  private final Runnable barrierCommand;  \n\n10. /** The current generation */  \n\n11. private Generation generation = new Generation();  \n\n12. private int count;  \n```\n\n- lock：重入锁，是CyclicBarrier线程安全的关键\n\n- trip：条件队列的信号，控制着CyclicBarrier里所有线程的阻塞和唤醒。\n\n- parties：屏障的阀值\n\n- barrierCommand：最后一个进入屏障的线程需要做的事，进一步增加了CyclicBarrier的生命周期\n\n- generation：指向当前CyclicBarrier的生命周期\n\n- count：计数器，记录着到达阀值还需要的数据，范围在parties~0之间\n\n\n\n\n#### 3. 重要方法\n\n##### 3.1 await()\n\n```\n1.  public int await() throws InterruptedException, BrokenBarrierException {  \n\n2.      try {  \n\n3.          return dowait(false, 0L);  \n\n4.      } catch (TimeoutException toe) {  \n\n5.          throw new Error(toe); // cannot happen  \n\n6.      }  \n\n\n7.  }  \n\n8.  private int dowait(boolean timed, long nanos)  \n\n9.      throws InterruptedException, BrokenBarrierException,  \n\n10.            TimeoutException {  \n\n11.     final ReentrantLock lock = this.lock;  \n\n12.     lock.lock();  \n\n13.     try {  \n\n14.         final Generation g = generation;  \n\n15. //如果是broken状态，则抛出BrokenBarrierException异常。该bool值在breakBarrier方法中被设置为true\n\n16.         if (g.broken)  \n\n17.             throw new BrokenBarrierException();  \n\n18. //如果被中断了则设置broken为true，然后抛出InterruptedException异常\n\n19.         if (Thread.interrupted()) {  \n\n20. //将Barrier的当前生命周期的状态标记为不可用\n\n21.             breakBarrier();  \n\n22.             throw new InterruptedException();  \n\n23.         }  \n\n24. //进来一个线程后count会递减，直到0\n\n25.         int index = --count;  \n\n26. //如果index为0，说明有足够多的线程调用了await方法，此时应该放行所有线程\n\n27.         if (index == 0) {  // tripped  \n\n28.             boolean ranAction = false;  \n\n29.             try {  \n\n30.                 final Runnable command = barrierCommand;  \n\n31. //执行放行前的最后一步操作\n\n32.                 if (command != null)  \n\n33.                     command.run();  \n\n34. //如果command.run()出现异常，这里ranAction不会是true的\n\n35.                 ranAction = true;  \n\n36. //进入下一个生命周期\n\n37.                 nextGeneration();  \n\n38.                 return 0;  \n\n39.             } finally {  \n\n40.                 if (!ranAction)  \n\n41.                     breakBarrier();  \n\n42.             }  \n\n43.         }  \n\n44.         //阻塞当前线程直至被中断，打断或者超时\n\n45.         for (;;) {  \n\n46.             try {  \n\n47. //如果没有时间限制，直接将当前线程直接挂起\n\n48.                 if (!timed)  \n\n49.                     trip.await();  \n\n50.                 else if (nanos > 0L)  \n\n51. //如果有时间限制，阻塞一段时间\n\n52.                     nanos = trip.awaitNanos(nanos);  \n\n53.             } catch (InterruptedException ie) {  \n\n54. //当生命周期还是阻塞前的且有效\n\n55.                 if (g == generation && ! g.broken) {  \n\n56.                     breakBarrier();  \n\n57.                     throw ie;  \n\n58.                 } else {  \n\n59.                     Thread.currentThread().interrupt();  \n\n60.                 }  \n\n61.             }  \n\n62.    //如果Barrier被打断，则抛出BrokenBarrierException异常\n\n63.             if (g.broken)  \n\n64.                 throw new BrokenBarrierException();  \n\n65.    //意味着调用await时处于上一个生命周期，而此时却进入了下一个生命周期中\n\n66.             if (g != generation)  \n\n67.                 return index;  \n\n68.    //出现超时的情况\n\n69.             if (timed && nanos <= 0L) {  \n\n70.                 breakBarrier();  \n\n71.                 throw new TimeoutException();  \n\n72.             }  \n\n73.         }  \n\n74.     } finally {  \n\n75.         lock.unlock();  \n\n76.     }  \n\n77. }  \n```\n\n\n\nCyclicBarrier的主要功能都体现在这儿了，线程是如何阻塞的？以及怎么唤醒？\n\n1. 在阻塞之前先看一下先看下屏障状态是不是broken，当前线程有没有interrupted，屏障有没有到达阀值，注意如果到达阀值的话会执行barrierCommand并且进入下一个生命周期。\n\n2. 如果上面条件都错过，也就是说当前generation是active的，将当前线程阻塞（trip.await()），阻塞根据await方法有没有设置超时条件来分别处理。\n\n3. 在线程被唤醒后也根据正常唤醒和被interrupt分别处理，不正常唤醒会触发breakBarrier操作，使屏障失效。\n\n\n\n\n通过这个方法我们总结一下 barrier.await();的阀口开放除了达到阀值外还可以是\n\n- 有一个线程await超时了\n- 有一个await的线程被Interrupt了，前提是确定这个线程是start的\n- barrier被reset了，会释放当前所有在await的线程，没有到达await的线程不算\n- barrier被broken了,比如上面的reset就会breakBarrier\n\n上述情况**所有线程都抛出BrokenBarrierException**\n\n在finalTask中如果抛出异常所有await的线程也会抛出BrokenBarrierException，程序继续进行\n\n\n\n现在回过头来捡漏，看看await方法中的其他方法\n\n##### 3.2 breakBarrier()\n\n**breakBarrier()** 让当前生命周期中的屏障失效\n\n```\n1.  private void breakBarrier() {  \n\n2.      generation.broken = true;  \n\n3.      count = parties;  \n\n4.      trip.signalAll();  \n\n5.  }  \n```\n\n它会重置count的值，并且唤醒所有处于trip.await()中的线程\n\n\n\n##### 3.3 nextGeneration()\n\n**nextGeneration()** 使当前CyclicBarrier进入下一个生命周期\n\n```\n1.  private void nextGeneration() {  \n\n2.      // signal completion of last generation  \n\n3.      trip.signalAll();  \n\n4.      // set up next generation  \n\n5.      count = parties;  \n\n6.      generation = new Generation();  \n\n7.  }  \n```\n\n这里会new一个Generation，所有会存在多个Generation存在的情况\n\n\n\n##### 3.4 reset\n\n**reset()** 类似于强制刷新 = breakBarrier + nextGeneration\n\n```\n1.  public void reset() {  \n\n2.      final ReentrantLock lock = this.lock;  \n\n3.      lock.lock();  \n\n4.      try {  \n\n5.          breakBarrier();   // break the current generation  \n\n6.          nextGeneration(); // start a new generation  \n\n7.      } finally {  \n\n8.          lock.unlock();  \n\n9.      }  \n\n10. } \n```\n\n\n\n#### 4. 总结\n\n可以看出CyclicBarrier代码还是很简洁的，底层依赖ReentrantLock来实现线程安全，使用Condition来实现阻塞和唤醒，我发现到CyclitBarrier是不会让它里面await的线程回滚的（就是销毁），只要一出现什么意外情况屏障马上失效。\n\nCyclicBarrier适合那种所有线程等待一个条件，只有达到那个条件才继续执行下去的场景。而不像CountDownLatch，每个人都做完一件事了，再等待其他人去做另外一件事。CyclicBarrier强调的是每个人做自己事的时候都等一下，然后继续做手头上的事。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "0b614ab712754148aea4441bcdf6cfd8": {"id": "0b614ab712754148aea4441bcdf6cfd8", "item": "Java基础", "title": "Exchanger源码分析", "date": "2024-08-22", "summary": "Exchanger 是 Java 中的一个同步工具类。它允许两个线程在特定的同步点交换数据。可以在多线程环境中实现数据的交互与同步，提高程序的灵活性和效率。常用于两个线程间需要相互传递数据的场景，为并发编程提供了便利。", "body": "\n#### 1. 什么是Exchanger\n\n首先简单介绍下Exchanger是什么？以及怎么用\n\n故名思意，Exchanger就是一个交换器，用来**交换两个线程的数据**。\n\n\n\n怎么使用呢？\n\n这里已两个“玩家”私下进行装备交易来举例吧\n\n\n\n```\n1. public static void main(String[] args) { \n\n2.   Exchanger<String> exchanger = new Exchanger<>(); \n\n3.  \n\n4.   Thread thread1 = new Thread(()->{ \n\n5.  \n\n6.     String s1 = \"法师权杖\"; \n\n7.  \n\n8.     try { \n\n9.       System.out.println(Thread.currentThread().getName()+\" : 我要交换我的 [ \" + s1 + \" ]\"); \n\n10.       s1 = exchanger.exchange(s1); \n\n11.  \n\n12.       System.out.println(Thread.currentThread().getName()+\" : 我交换到的装备是 [ \" + s1 + \" ]\"); \n\n13.     } catch (InterruptedException ignored) { \n\n14.     } \n\n15.  \n\n16.   },\"地下道里的战士\"); \n\n17.  \n\n18.   Thread thread2 = new Thread(()->{ \n\n19.  \n\n20.     String s2 = \"战士盔甲\"; \n\n21.  \n\n22.     try { \n\n23.       System.out.println(Thread.currentThread().getName()+\" : 我要交换我的 [ \" + s2 + \" ]\"); \n\n24.       s2 = exchanger.exchange(s2); \n\n25.  \n\n26.       System.out.println(Thread.currentThread().getName()+\" : 我交换到的装备是 [ \" + s2 + \" ]\"); \n\n27.     } catch (InterruptedException ignored) { \n\n28.     } \n\n29.  \n\n30.   },\"一名落魄的法师\"); \n\n31.  \n\n32.   thread1.start(); \n\n33.   thread2.start(); \n\n34. } \n```\n\n\n\n通过以上的步骤，两个平民玩家在“安全交易”的前提下得到了自己想要的装备。\n\n当然我们今天的内容是Exchanger的源码分析\n\n先来看一下Exchanger的类UML:\n\n![img](http://pcc.huitogo.club/a8201f568e71efbc012f5a4b0e659f6f)\n\n\n\n\n\nParticipant是什么呢？\n\n```\n1. public Exchanger() { \n\n2.   participant = new Participant(); \n\n3. } \n\n4.  \n\n5. static final class Participant extends ThreadLocal<Node> { \n\n6.   public Node initialValue() { return new Node(); } \n\n7. } \n```\n\n\n\nParticipant重写了ThreadLocal的initialValue方法，也就是添加了默认值new Node\n\n所以相当于new Exchange()的时候会在当前线程内部生成一个Node\n\n\n\nNode是什么呢？\n\n```\n1. @sun.misc.Contended  \n\n2. static final class Node { \n\n3.   int index;       // arena的下标，多个槽位的时候利用 \n\n4.   int bound;       // 上一次记录的Exchanger.bound； \n\n5.   int collides;      // 在当前bound下CAS失败的次数；\n\n6.   int hash;        // 用于自旋； \n\n7.   Object item;      // 这个线程的当前项，也就是需要交换的数据；\n\n8.   volatile Object match; // 交换的数据 \n\n9.   volatile Thread parked; // 当阻塞时，设置此线程，不阻塞的话就不必了(因为会自旋) \n\n10. } \n```\n\n\n\n可以看出Node就是Exchanger实现数据交换的核心，重点是里面存放的item和match数值，记录着当前线程记录的值和期望交换的值。\n\n\n\n和 SynchronousQueue 的区别在于， SynchronousQueue 使用了一个变量来保存数据项，通过 isData 来区别 “存” 操作和 “取” 操作。而 Exchange 使用了 2 个变量，就不用使用 isData 来区分了。\n\n\n\n对于一个Node上交换数据我们叫单槽，同理使用多个Node交换数据叫多槽\n\n多槽其实就是个Node数组\n\n```\n // 多槽\n\n1. private volatile Node[] arena; \n```\n\n\n\n#### 2. 单槽交换数据\n\n通过追踪exchange方法，可以看到Exchanger是怎么在单槽和多槽之间选择的\n\n```\n1. public V exchange(V x) throws InterruptedException { \n\n2.   Object v; \n\n3.   Object item = (x == null) ? NULL_ITEM : x; // translate null args \n\n4.   if ((arena != null || \n\n5.     (v = slotExchange(item, false, 0L)) == null) && \n\n6.     ((Thread.interrupted() || // disambiguates null return \n\n7.      (v = arenaExchange(item, false, 0L)) == null))) \n\n8.     throw new InterruptedException(); \n\n9.   return (v == NULL_ITEM) ? null : (V)v; \n\n10. } \n```\n\n\n\n具有超时功能的exchange方法\n\n```\n1. public V exchange(V x, long timeout, TimeUnit unit) \n\n2.   throws InterruptedException, TimeoutException { \n\n3.   Object v; \n\n4.   Object item = (x == null) ? NULL_ITEM : x; \n\n5.   long ns = unit.toNanos(timeout); \n\n6.   if ((arena != null || \n\n7.     (v = slotExchange(item, true, ns)) == null) && \n\n8.     ((Thread.interrupted() || \n\n9.      (v = arenaExchange(item, true, ns)) == null))) \n\n10.     throw new InterruptedException(); \n\n11.   if (v == TIMED_OUT) \n\n12.     throw new TimeoutException(); \n\n13.   return (v == NULL_ITEM) ? null : (V)v; \n\n14. } \n```\n\n\n\n1. arena != nul，前面说到arena 是装Node的数组，当arena 不为空的时候自然是启用了多个Node了\n2. slotExchange(item, false, 0L)== null，这个我们接下来查看slotExchange的源码会知道在单槽失败的情况下（出现了竞争）会返回null\n\n\n\n看下slotExchange方法\n\n```\n1. private final Object slotExchange(Object item, boolean timed, long ns) { \n\n2.   // 得到一个初试的Node \n\n3.   Node p = participant.get(); \n\n4.   // 当前线程 \n\n5.   Thread t = Thread.currentThread(); \n\n6.   // 如果发生中断，返回null,会重设中断标志位，并没有直接抛异常 \n\n7.   if (t.isInterrupted()) // preserve interrupt status so caller can recheck \n\n8.     return null; \n\n9.  \n\n10.   for (Node q;;) { \n\n11.     // 槽位 solt不为null,则说明已经有线程在这里等待交换数据了 \n\n12.     if ((q = slot) != null) { \n\n13.       // 重置槽位 \n\n14.       if (U.compareAndSwapObject(this, SLOT, q, null)) { \n\n15.         //获取交换的数据 \n\n16.         Object v = q.item; \n\n17.         //等待线程需要的数据 \n\n18.         q.match = item; \n\n19.         //等待线程 \n\n20.         Thread w = q.parked; \n\n21.         //唤醒等待的线程 \n\n22.         if (w != null) \n\n23.           U.unpark(w); \n\n24.         return v; // 返回拿到的数据，交换完成 \n\n25.       } \n\n26.       // create arena on contention, but continue until slot null \n\n27.       //存在竞争，其它线程抢先了一步该线程，因此需要采用多槽位模式，这个后面再分析 \n\n28.       if (NCPU > 1 && bound == 0 && \n\n29.         U.compareAndSwapInt(this, BOUND, 0, SEQ)) \n\n30.         arena = new Node[(FULL + 2) << ASHIFT]; \n\n31.     } \n\n32.     else if (arena != null) //多槽位不为空，需要执行多槽位交换 \n\n33.       return null; // caller must reroute to arenaExchange \n\n34.     else { //还没有其他线程来占据槽位 \n\n35.       p.item = item; \n\n36.       // 设置槽位为p(也就是槽位被当前线程占据) \n\n37.       if (U.compareAndSwapObject(this, SLOT, null, p)) \n\n38.         break; // 退出无限循环 \n\n39.       p.item = null; // 如果设置槽位失败，则有可能其他线程抢先了，重置item,重新循环 \n\n40.     } \n\n41.   } \n\n42.  \n\n43.   //当前线程占据槽位，等待其它线程来交换数据 \n\n44.   int h = p.hash; \n\n45.   long end = timed ? System.nanoTime() + ns : 0L; \n\n46.   int spins = (NCPU > 1) ? SPINS : 1; \n\n47.   Object v; \n\n48.   // 直到成功交换到数据 \n\n49.   while ((v = p.match) == null) { \n\n50.     if (spins > 0) { // 自旋 \n\n51.       h ^= h << 1; h ^= h >>> 3; h ^= h << 10; \n\n52.       if (h == 0) \n\n53.         h = SPINS | (int)t.getId(); \n\n54.       else if (h < 0 && (--spins & ((SPINS >>> 1) - 1)) == 0) \n\n55.         // 主动让出cpu,这样可以提供cpu利用率（反正当前线程也自旋等待，还不如让其它任务占用cpu） \n\n56.         Thread.yield();  \n\n57.     } \n\n58.     else if (slot != p) //其它线程来交换数据了，修改了solt,但是还没有设置match,再稍等一会 \n\n59.       spins = SPINS; \n\n60.     //需要阻塞等待其它线程来交换数据 \n\n61.     //没发生中断，并且是单槽交换，没有设置超时或者超时时间未到 则继续执行 \n\n62.     else if (!t.isInterrupted() && arena == null && \n\n63.         (!timed || (ns = end - System.nanoTime()) > 0L)) { \n\n64.       // cas 设置BLOCKER，可以参考Thread 中的parkBlocker \n\n65.       U.putObject(t, BLOCKER, this); \n\n66.       // 需要挂起当前线程 \n\n67.       p.parked = t; \n\n68.       if (slot == p) \n\n69.         U.park(false, ns); // 阻塞当前线程 \n\n70.       // 被唤醒后   \n\n71.       p.parked = null; \n\n72.       // 清空 BLOCKER \n\n73.       U.putObject(t, BLOCKER, null); \n\n74.     } \n\n75.     // 不满足前面 else if 条件，交换失败，需要重置solt \n\n76.     else if (U.compareAndSwapObject(this, SLOT, p, null)) { \n\n77.       v = timed && ns <= 0L && !t.isInterrupted() ? TIMED_OUT : null; \n\n78.       break; \n\n79.     } \n\n80.   } \n\n81.   //清空match \n\n82.   U.putOrderedObject(p, MATCH, null); \n\n83.   p.item = null; \n\n84.   p.hash = h; \n\n85.   // 返回交换得到的数据（失败则为null） \n\n86.   return v; \n\n87. } \n```\n\n\n\n1. 当一个线程来交换数据时，如果发现槽位（solt）有数据时，说明其它线程已经占据了槽位，等待交换数据，那么当前线程就和该槽位进行数据交换，设置相应字段，如果交换失败，则说明其它线程抢先了该线程一步和槽位交换了数据，那么这个时候就存在竞争了，这个时候就会生成多槽位（area）,后面就会进行多槽位交换了。\n\n   \n\n2. 如果来交换的线程发现槽位没有被占据，啊哈，这个时候自己就把槽位占据了，如果占据失败，则有可能其他线程抢先了占据了槽位，重头开始循环。\n\n   \n\n3. 当来交换的线程占据了槽位后，就需要等待其它线程来进行交换数据了，首先自己需要进行一定时间的自旋，因为自旋期间有可能其它线程就来了，那么这个时候就可以进行数据交换工作，而不用阻塞等待了，如果不幸，进行了一定自旋后，没有其他线程到来，那么还是避免不了需要阻塞（如果设置了超时等待，发生了超时或中断异常，则退出，不阻塞等待），当准备阻塞线程的时候，发现槽位值变了，那么说明其它线程来交换数据了，但是还没有完全准备好数据，这个时候就不阻塞了，再稍微等那么一会，如果始终没有等到其它线程来交换，那么就挂起当前线程。\n\n   \n\n4. 当其它线程到来并成功交换数据后，会唤醒被阻塞的线程，阻塞的线程被唤醒后，拿到数据（如果是超时，或中断，则数据为null）返回，结束。\n\n![img](http://pcc.huitogo.club/a736276d42fc9704303ca2bd4a339383)\n\n\n\n\n\n#### 3. 多槽交换数据\n\n多线程如果竞争激烈，那么一个槽位显然就成了性能瓶颈了，因此就衍生出了多槽位交换，各自交换各自的，互不影响。\n\n多槽交换数是基于多槽，也就是我们之前的arena数组，那么这个数组是怎么产生的呢？\n\n\n\n在slotExchange中有\n\n```\n1. if (NCPU > 1 && bound == 0 && \n\n2.           U.compareAndSwapInt(this, BOUND, 0, SEQ)) \n\n3.           arena = new Node[(FULL + 2) << ASHIFT]; \n```\n\n\n\n先看一下这句话中涉及到的变量\n\n```\n1. /** \n\n2. * The byte distance (as a shift value) between any two used slots \n\n3. * in the arena. 1 << ASHIFT should be at least cacheline size. \n\n4. * CacheLine填充 \n\n5. */ \n\n6. private static final int ASHIFT = 7; \n\n7.  \n\n8. /** \n\n9. * The maximum supported arena index. The maximum allocatable \n\n10. * arena size is MMASK + 1. Must be a power of two minus one, less \n\n11. * than (1<<(31-ASHIFT)). The cap of 255 (0xff) more than suffices \n\n12. * for the expected scaling limits of the main algorithms. \n\n13. */ \n\n14. private static final int MMASK = 0xff; \n\n15.  \n\n16. /** \n\n17. * Unit for sequence/version bits of bound field. Each successful \n\n18. * change to the bound also adds SEQ. \n\n19. * bound的\"版本号\" \n\n20. */ \n\n21. private static final int SEQ = MMASK + 1; \n\n22.  \n\n23. /** The number of CPUs, for sizing and spin control */\nprivate static final int NCPU = Runtime.getRuntime().availableProcessors();\n\n24. \n\n25. /** \n\n26. * The maximum slot index of the arena: The number of slots that \n\n27. * can in principle hold all threads without contention, or at \n\n28. * most the maximum indexable value. \n\n29. */ \n\n30. static final int FULL = (NCPU >= (MMASK << 1)) ? MMASK : NCPU >>> 1; \n\n31.  \n\n32. /** \n\n33. * Elimination array; null until enabled (within slotExchange). \n\n34. * Element accesses use emulation of volatile gets and CAS. \n\n35. */ \n\n36. private volatile Node[] arena; \n\n37.  \n\n38. /** \n\n39. * The index of the largest valid arena position, OR'ed with SEQ \n\n40. * number in high bits, incremented on each update. The initial \n\n41. * update from 0 to SEQ is used to ensure that the arena array is \n\n42. * constructed only once. \n\n43. */ \n\n44. private volatile int bound; \n```\n\n\n\n所以初始化arena首先判断NCPU（cpu内核数），且bound是未初始化的（防止多线程初始化arena数组），然后将bound初始化值（也叫版本号）\n\n\n\nMMASK = 255 = 1111 1111（二进制）\n\nSEQ = 256 = 1 0000 0000（二进制）\n\nFULL = NCPU >= 510 ? 510 : NCPU / 2 （会有NCPU > 510个吗？超级电脑？）\n\n\n\n所以arena数组的初始值就是 FULL + 2 ，最大可能就是NCPU /2 + 2，至于<< ASHIFT 是为了填充缓存行的\n\n\n\n接下来正式看下arenaExchange的源码\n\n```\n1. private final Object arenaExchange(Object item, boolean timed, long ns) { \n\n2.   // 槽位数组 \n\n3.   Node[] a = arena; \n\n4.   //代表当前线程的Node \n\n5.   Node p = participant.get(); // p.index 初始值为 0 \n\n6.   for (int i = p.index;;) {           // access slot at i \n\n7.     int b, m, c; long j;            // j is raw array offset \n\n8.     //在槽位数组中根据\"索引\" i 取出数据 j相当于是 \"第一个\"槽位 \n\n9.     Node q = (Node)U.getObjectVolatile(a, j = (i << ASHIFT) + ABASE); \n\n10.     // 该位置上有数据(即有线程在这里等待交换数据) \n\n11.     if (q != null && U.compareAndSwapObject(a, j, q, null)) { \n\n12.       // 进行数据交换，这里和单槽位的交换是一样的 \n\n13.       Object v = q.item;           // release \n\n14.       q.match = item; \n\n15.       Thread w = q.parked; \n\n16.       if (w != null) \n\n17.         U.unpark(w); \n\n18.       return v; \n\n19.     } \n\n20.     // bound 是最大的有效的 位置，和MMASK相与，得到真正的存储数据的索引最大值 \n\n21.     else if (i <= (m = (b = bound) & MMASK) && q == null) { \n\n22.       // i 在这个范围内，该槽位也为空 \n\n23.  \n\n24.       //将需要交换的数据 设置给p \n\n25.       p.item = item;             // offer \n\n26.       //设置该槽位数据(在该槽位等待其它线程来交换数据) \n\n27.       if (U.compareAndSwapObject(a, j, null, p)) { \n\n28.         long end = (timed && m == 0) ? System.nanoTime() + ns : 0L; \n\n29.         Thread t = Thread.currentThread(); // wait \n\n30.         // 进行一定时间的自旋 \n\n31.         for (int h = p.hash, spins = SPINS;;) { \n\n32.           Object v = p.match; \n\n33.           //在自旋的过程中，有线程来和该线程交换数据 \n\n34.           if (v != null) { \n\n35.             //交换数据后，清空部分设置，返回交换得到的数据，over \n\n36.             U.putOrderedObject(p, MATCH, null); \n\n37.             p.item = null;       // clear for next use \n\n38.             p.hash = h; \n\n39.             return v; \n\n40.           } \n\n41.           else if (spins > 0) { \n\n42.             h ^= h << 1; h ^= h >>> 3; h ^= h << 10; // xorshift \n\n43.             if (h == 0)        // initialize hash \n\n44.               h = SPINS | (int)t.getId(); \n\n45.             else if (h < 0 &&     // approx 50% true \n\n46.                 (--spins & ((SPINS >>> 1) - 1)) == 0) \n\n47.               Thread.yield();    // two yields per wait \n\n48.           } \n\n49.           // 交换数据的线程到来，但是还没有设置好match，再稍等一会 \n\n50.           else if (U.getObjectVolatile(a, j) != p) \n\n51.             spins = SPINS;  \n\n52.           //符合条件，特别注意m==0 这个说明已经到达area 中最小的存储数据槽位了 \n\n53.           //没有其他线程在槽位等待了，所有当前线程需要阻塞在这里    \n\n54.           else if (!t.isInterrupted() && m == 0 && \n\n55.               (!timed || \n\n56.                (ns = end - System.nanoTime()) > 0L)) { \n\n57.             U.putObject(t, BLOCKER, this); // emulate LockSupport \n\n58.             p.parked = t;       // minimize window \n\n59.             // 再次检查槽位，看看在阻塞前，有没有线程来交换数据 \n\n60.             if (U.getObjectVolatile(a, j) == p)  \n\n61.               U.park(false, ns); // 挂起 \n\n62.             p.parked = null; \n\n63.             U.putObject(t, BLOCKER, null); \n\n64.           } \n\n65.           // 当前这个槽位一直没有线程来交换数据，准备换个槽位试试 \n\n66.           else if (U.getObjectVolatile(a, j) == p && \n\n67.               U.compareAndSwapObject(a, j, p, null)) { \n\n68.             //更新bound \n\n69.             if (m != 0)        // try to shrink \n\n70.               U.compareAndSwapInt(this, BOUND, b, b + SEQ - 1); \n\n71.             p.item = null; \n\n72.             p.hash = h; \n\n73.             // 减小索引值 往\"第一个\"槽位的方向挪动 \n\n74.             i = p.index >>>= 1;    // descend \n\n75.             // 发送中断，返回null \n\n76.             if (Thread.interrupted()) \n\n77.               return null; \n\n78.             // 超时 \n\n79.             if (timed && m == 0 && ns <= 0L) \n\n80.               return TIMED_OUT; \n\n81.             break;           // expired; restart 继续主循环 \n\n82.           } \n\n83.         } \n\n84.       } \n\n85.       else \n\n86.         //占据槽位失败，先清空item,防止成功交换数据后，p.item还引用着item \n\n87.         p.item = null;           // clear offer \n\n88.     } \n\n89.     else { // i 不在有效范围，或者被其它线程抢先了 \n\n90.       //更新p.bound \n\n91.       if (p.bound != b) {          // stale; reset \n\n92.         p.bound = b; \n\n93.         //新bound ，重置collides \n\n94.         p.collides = 0; \n\n95.         //i如果达到了最大，那么就递减 \n\n96.         i = (i != m || m == 0) ? m : m - 1; \n\n97.       } \n\n98.       else if ((c = p.collides) < m || m == FULL || \n\n99.           !U.compareAndSwapInt(this, BOUND, b, b + SEQ + 1)) { \n\n100.         p.collides = c + 1; // 更新冲突 \n\n101.         // i=0 那么就从m开始，否则递减i \n\n102.         i = (i == 0) ? m : i - 1;     // cyclically traverse \n\n103.       } \n\n104.       else \n\n105.         //递增，往后挪动 \n\n106.         i = m + 1;             // grow \n\n107.       // 更新index \n\n108.       p.index = i; \n\n109.     } \n\n110.   } \n\n111. } \n```\n\n\n\n可能不对（后述进一步查证修改）\n\n\n\n多槽的交换大致思想就是：当一个线程来交换的时候，如果”第一个”槽位是空的，那么自己就在那里等待，如果发现”第一个”槽位有等待线程，那么就直接交换，如果交换失败，说明其它线程在进行交换，那么就往后挪一个槽位，如果有数据就交换，没数据就等一会，但是不会阻塞在这里，在这里等了一会，发现还没有其它线程来交换数据，那么就往“第一个”槽位的方向挪，如果反复这样过后，挪到了第一个槽位，没有线程来交换数据了，那么自己就在”第一个”槽位阻塞等待。\n\n\n\n简单来说，如果有竞争冲突，那么就寻找后面的槽位，在后面的槽位等待一定时间，没有线程来交换，那么就又往前挪。\n\n\n\n#### 4. 总结\n\n**1 ）exchanger底层是CAS操作 + unsafe的park和unpark**\n\n**2）exchanger是分单槽和多槽的情况的**\n\n1. 在没有竞争的情况下，多线程在单槽上完成数据交换，线程A进入exchange，如果单槽为空，将自身Node放入槽中并unsafe.park；线程B进入exchange，如果单槽不为空，交换数据，并唤醒线程A\n2. 在有竞争的情况下，有竞争发生在线程B进入槽中发现单槽不为空，开开心心的准备交换自己的数据之前先将槽子置为空，但是这个过程失败了，说明槽中的数据已经被人取走了，只能走多槽模式\n3. 在多槽模式下，会有一个index记录槽的下标，index默认为0，如果槽0有竞争，那么线程B会去槽1进行交换或者等待交换，在多次失败或者其他情况后，index会往回走，也就是往槽0靠。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "e76a75fc03e224ffb65d87f2b06c6ec2": {"id": "e76a75fc03e224ffb65d87f2b06c6ec2", "item": "Java基础", "title": "HashMap源码分析", "date": "2024-08-22", "summary": "HashMap 是 Java 中常用的一种数据结构。它以键值对的形式存储数据，通过哈希算法实现快速的查找、插入和删除操作。非线程安全，允许键值为 null。存储数据时可能会出现哈希冲突，通过链表或红黑树解决，提高存储和检索效率。", "body": "\n#### **1、HashMap概述**\n\n##### **（1）javaDoc中描述**\n\n在jdk1.8的javadoc中描述如下：\n\n1）哈希表基于map接口的实现，这个实现提供了map所有的操作，并且提供了key和value可以为null，(HashMap和HashTable大致上是一样的除了hashmap是异步的和允许key和value为null)，这个类不确定map中元素的位置，特别要提的是，这个类也不确定元素的位置随着时间会不会保持不变。\n\n2）假设哈希函数将元素合适的分到了每个桶(其实就是指的数组中位置上的链表)中，则这个实现为基本的操作(get、put)提供了稳定的性能，**迭代这个集合视图需要的时间跟hashMap实例(key-value映射的数量)的容量(在桶中)成正比**，因此，如果迭代的性能很重要的话，就不要将初始容量设置的太高或者loadfactor设置的太低。\n\n3）HashMap的实例有两个参数影响性能，初始化容量(initialCapacity)和loadFactor加载因子，在哈希表中这个容量是桶的数量【也就是数组的长度】，一个初始化容量仅仅是在哈希表被创建时容量，在容量自动增长之前加载因子是衡量哈希表被允许达到的多少的。当entry的数量在哈希表中超过了加载因子乘以当前的容量，那么哈希表被修改(内部的数据结构会被重新建立)以至于哈希表有大约会增长到两倍\n\n4）通常来讲，默认的加载因子(0.75)能够在时间和空间上提供一个好的平衡，**更高的值会减少空间上的开支但是会增加查询花费的时间**（体现在HashMap类中get、put方法上），当设置初始化容量时，应该考虑到map中会存放 entry的数量和加载因子，以便最少次数的进行rehash操作，如果初始容量大于最大条目数除以加载因子，则不会发生rehash 操作。\n\n5）如果很多映射关系要存储在 HashMap 实例中，则相对于按需执行自动的 rehash操作以增大表的容量来说，使用**足够大的初始容量创建它将使得映射关系能更有效地存储**。\n\n\n\n##### **（2）hashMap数据结构和存储原理**\n\n###### **1）Jdk1.8之前，链表散列**\n\n链表散列 = 数组 + 链表\n\n![img](http://pcc.huitogo.club/f1f5d774dd6f42b884e89822779701b7)\n\n存放过程是：通过entry对象中的hash值来确定将该对象存放在数组中的哪个位置上，如果在这个位置上还有其他元素，则通过链表来存储这个元素。\n\n\n\nEntry对象：\n\n```\n1.  static class Entry<K,V> implements Map.Entry<K,V> {  \n\n2.  　　　  final K key;    // 键  \n\n3.  　　　　 V value;    // 值  \n\n4.  　　　　 Entry<K,V> next;//指向下一个entry对象  \n\n5.  　　　　 int hash; //通过key算过来的你hashcode值。 \n```\n\n\n\n###### **2）jdk1.8之后，增加了红黑树**\n\n![img](http://pcc.huitogo.club/91de4a309058ef205c721bdee92a7fdd)\n\n此时数据结构是 数组 + 链表 + RBT（红黑树）\n\n在桶中数据上升到8时，链表会变成RBT，在桶中数据下降到6时，RBT会变成链表\n\n\n\n#### **2、HashMap源码分析**\n\n##### **（1）HashMap属性**\n\n```\n3.  /** \n\n4.    * 数组的默认初始长度，java规定hashMap的数组长度必须是2的次方 \n\n5.    * 扩展长度时也是当前长度 << 1。 \n\n6.    */  \n\n7.  static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16  \n\n8.  // 数组的最大长度  \n\n9.  static final int MAXIMUM_CAPACITY = 1 << 30;  \n\n10. // 默认负载因子，当元素个数超过这个比例则会执行数组扩充操作。  \n\n11. static final float DEFAULT_LOAD_FACTOR = 0.75f;  \n\n12. // 树形化阈值，当链表节点个大于等于TREEIFY_THRESHOLD - 1时，  \n\n13. // 会将该链表换成红黑树。  \n\n14. static final int TREEIFY_THRESHOLD = 8;  \n\n15. // 解除树形化阈值，当链表节点小于等于这个值时，会将红黑树转换成普通的链表。  \n\n16. static final int **UNTREEIFY_THRESHOLD** = 6;  \n\n17. // 最小树形化的容量，即：当内部数组长度小于64时，不会将链表转化成红黑树，而是优先扩充数组。  \n\n18. static final int MIN_TREEIFY_CAPACITY = 64;  \n\n19. // 这个就是hashMap的内部数组了，而Node则是链表节点对象。  \n\n20. transient Node<K,V>[] table;  \n\n21. // 下面三个容器类成员，作用相同，实际类型为HashMap的内部类KeySet、Values、EntrySet。  \n\n22. // 他们的作用并不是缓存所有的key或者所有的value，内部并没有持有任何元素。  \n\n23. // 而是通过他们内部定义的方法，从三个角度（视图）操作HashMap，更加方便的迭代。  \n\n24. // 关注点分别是键，值，映射。  \n\n25. transient Set<K>        keySet;  // AbstractMap的成员  \n\n26. transient Collection<V> values; // AbstractMap的成员  \n\n27. transient Set<Map.Entry<K,V>> entrySet;  \n\n28. // 元素个数，注意和内部数组长度区分开来。  \n\n29. transient int size;  \n\n30. // 容器结构的修改次数，fail-fast机制。  \n\n31. transient int modCount;  \n\n32. // 阈值，超过这个值时扩充数组。 threshold = capacity * load factor，具体看上面的静态常量。  \n\n33. int threshold;  \n\n34. // 装栽因子，具体看上面的静态常量。  \n\n35. final float loadFactor;  \n```\n\n\n\n显然，HashMap的底层实现是基于一个Node的数组，Node实现的是Map的内部接口Entry\n\n```\n1.  static class Node<K,V> implements Map.Entry<K,V> {  \n\n2.  　　final int hash;  \n\n3.  　　final K key;  \n\n4.      V value;  \n\n5.      Node<K,V> next;  \n\n6.   }  \n```\n\n\n\n在链表变成红黑树的时候,Node也会变成TreeNode，TreeNode是Node的孙子类\n\n继承关系是: Node是单向链表节点，Entry是双向链表节点，TreeNode是红黑树节点。\n\n```\n1.  static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {  \n\n2.      TreeNode<K,V> parent;  // red-black tree links  \n\n3.      TreeNode<K,V> left;  \n\n4.      TreeNode<K,V> right;  \n\n5.      TreeNode<K,V> prev;    // needed to unlink next upon deletion  \n\n6.  }  \n```\n\n\n\n*Hashmap的变量都是trasient的，那么它是怎么序列化的？*\n\nHashMap内有两个用于序列化的函数 readObject(ObjectInputStream s) 和writeObject（ObjectOutputStreams），通过这个函数将table序列化。\n\n\n\n##### **（2）HashMap构造方法**\n\nhashMap中table数组一开始就已经是个没有长度的数组了，所以**构造方法中，并没有初始化数组的大小，数组在一开始就已经被创建了**，构造方法只做两件事情，一个是**初始化加载因子**，初始化扩充阀值。\n\n###### 1）HashMap()\n\n```\n1.  public HashMap() {  \n\n2.      this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);  \n\n3.  } \n```\n\n\n\n###### 2）HashMap(int)\n\n```\n1.  public HashMap(int initialCapacity) {  \n\n2.      this(initialCapacity, DEFAULT_LOAD_FACTOR);  \n\n3.  }  \n```\n\n\n\n###### 3）HashMap(int,float)\n\n```\n1.  public HashMap(int initialCapacity, float loadFactor) {  \n\n2.      // 初始参数边界检查  \n\n3.      if (initialCapacity < 0)  \n\n4.          throw new IllegalArgumentException(\"Illegal initial capacity: \" +  initialCapacity);  \n\n5.      if (initialCapacity > MAXIMUM_CAPACITY)  \n\n6.          initialCapacity = MAXIMUM_CAPACITY;  \n\n7.      if (loadFactor <= 0 || Float.isNaN(loadFactor))  \n\n8.          throw new IllegalArgumentException(\"Illegal load factor: \" +  loadFactor);                                          \n\n10.     this.loadFactor = loadFactor;  \n\n11.     // 初始化threshold大小  \n\n12.     this.threshold =  tableSizeFor(initialCapacity);      \n\n13. }  \n```\n\n\n\ntableSizeFor(initialCapacity)：数组容量必须是2的次方，所以就需要通过某个算法将我们给的数值转换成2的次方。\n\n```\n1.  //  Returns a power of two size for the given target capacity.  \n\n2.  // 返回给定目标容量的二次幂，这个方法可以将任意一个整数转换成2的次方。   \n\n3.  static final int tableSizeFor(int cap) {  \n\n4.      int n = cap - 1;  \n\n5.      n |= n >>> 1;  \n\n6.      n |= n >>> 2;  \n\n7.      n |= n >>> 4;  \n\n8.      n |= n >>> 8;  \n\n9.      n |= n >>> 16;  \n\n10.     return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;  \n\n11. }  \n```\n\n原理实际上就是补位，将原本为0的空位填补为1，最后加1时，最高有效位进1，其余变为0。 例如1010 0101最后会变成1111 1111，然后+1变成了 1 0000 0000，为2的8次方，上面代码中int n = cap - 1先减去1就是为了最后面这个+1操作\n\n\n\n###### 4）HashMap(Map<? extends K, ? extends V> m)\n\n```\n1.  public HashMap(Map<? extends K, ? extends V> m) {  \n\n2.      // 初始化填充因子  \n\n3.      this.loadFactor = DEFAULT_LOAD_FACTOR;  \n\n4.      // 将m中的所有元素添加至HashMap中  \n\n5.      putMapEntries(m, false);  \n\n6.  } \n```\n\n\n\nputMapEntries(m, false)：将m的所有元素存入本HashMap实例中\n\n```\n1.  final void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {  \n\n2.      int s = m.size();  \n\n3.      if (s > 0) {  \n\n4.          // 判断table是否已经初始化  \n\n5.          if (table == null) { //未初始化  \n\n6.              // 这里临时将集合m的容量作为扩容阀值 计算 table的capability  \n\n7.              float ft = ((float)s / loadFactor) + 1.0F;  \n\n8.              int t = ((ft < (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY);  \n\n10.             // 这里threshold为0 可以理解成初始化扩容阀值  \n\n11.             if (t > threshold)  \n\n12.                 threshold = tableSizeFor(t);  \n\n13.         }  \n\n14.         // 已初始化，并且m元素个数大于扩容阈值，进行扩容处理  \n\n15.         else if (s > threshold)  \n\n16.             resize();   //***\n\n17.         // 将m中的所有元素添加至HashMap中  \n\n18.         for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {  \n\n19.             K key = e.getKey();  \n\n20.             V value = e.getValue();  \n\n21.             // 这里是向table中放入一个Node的关键  \n\n22.             putVal(hash(key), key, value, false, evict);  //***\n\n23.         }  \n```\n\n\n\nresize()： 当capability到达threshold时进行扩容\n\n```\n1.  final Node<K,V>[] resize() {  \n\n2.      Node<K,V>[] oldTab = table; //记录扩容前的table  \n\n3.      int oldCap = (oldTab == null) ? 0 : oldTab.length; // 记录扩容前的容量  \n\n4.      int oldThr = threshold; // 记录扩容前的扩容阀值  \n\n5.      int newCap, newThr = 0; //扩容后的容量和阀值  \n\n6.      if (oldCap > 0) {   \n\n7.          if (oldCap >= MAXIMUM_CAPACITY) { // 如果扩容前容量已经到达上限了，没办法扩容  \n\n8.              threshold = Integer.MAX_VALUE;  \n\n9.              return oldTab;  \n\n10.         }  \n\n11.         else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY && oldCap >= DEFAULT_INITIAL_CAPACITY)  // 将扩容前的容量和阀值都增加一倍  \n\n13.             newThr = oldThr << 1; // double threshold  \n\n14.     }  \n\n15.     else if (oldThr > 0) // table未初始化，调用的是HashMap的有参构造方法初始化了threshold  \n\n16.         newCap = oldThr;  \n\n17.     else {      // table未初始化 调用的HashMap的默认构造方法   \n\n18.         newCap = DEFAULT_INITIAL_CAPACITY;  \n\n19.         newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);  \n\n20.     }  \n\n21.     if (newThr == 0) { // 对应的是oldThr > 0的情况，这里根据newCap初始化newThr  \n\n22.         float ft = (float)newCap * loadFactor;  // threshold = capability * loadFactor  \n\n23.         newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?  (int)ft : Integer.MAX_VALUE);  \n\n25.     }  \n\n26.     threshold = newThr;  \n\n27.     @SuppressWarnings({\"rawtypes\",\"unchecked\"})  \n\n28.      Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap]; // 创建新的table  \n\n29.     table = newTab;  \n\n30.     if (oldTab != null) { // 将oldTab数据放到newTab中，不保证newTab中Node的顺序和位置  \n\n31.         for (int j = 0; j < oldCap; ++j) {  \n\n32.             Node<K,V> e;  \n\n33.             if ((e = oldTab[j]) != null) {  \n\n34.                 oldTab[j] = null; // 清空oldTab值，方便gc  \n\n35.                 if (e.next == null) // 扩容前的Node是光秃秃的节点时 直接放到计算索引后的位置  \n\n36.                     newTab[e.hash & (newCap - 1)] = e; // 根据e.hash & (newCap - 1) 生成索引放到newTab中  \n\n37.                 else if (e instanceof TreeNode) //扩容前的Node如果是红黑树节点的话 将它分离   \n\n38.                     ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);  \n\n39.                 else { // preserve order  \n\n40.                     Node<K,V> loHead = null, loTail = null;  \n\n41.                     Node<K,V> hiHead = null, hiTail = null;  \n\n42.                     Node<K,V> next;  \n\n43.                     // 将同一桶中的元素根据e.hash & oldCap是否为0进行分割，分成两个不同的链表，完成rehash  ，因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置\n\n44.                     do {  \n\n45.                         next = e.next;  \n\n46.                         if ((e.hash & oldCap) == 0) {  \n\n47.                             if (loTail == null)  \n\n48.                                 loHead = e;  \n\n49.                             else  \n\n50.                                 loTail.next = e;  \n\n51.                             loTail = e;  \n\n52.                         }  \n\n53.                         else {  \n\n54.                             if (hiTail == null)  \n\n55.                                 hiHead = e;  \n\n56.                             else  \n\n57.                                 hiTail.next = e;  \n\n58.                             hiTail = e;  \n\n59.                         }  \n\n60.                     } while ((e = next) != null);  \n\n61.                     if (loTail != null) { // (e.hash & oldCap)为0组成的链表放在当前位置  \n\n62.                         loTail.next = null;  \n\n63.                         newTab[j] = loHead;  \n\n64.                     }  \n\n65.                     if (hiTail != null) { // (e.hash & oldCap)不为0组成的链表放在j + oldCap的位置  \n\n66.                         hiTail.next = null;  \n\n67.                         newTab[j + oldCap] = hiHead;  \n\n68.                     }  \n\n69.                 }  \n\n70.             }  \n\n71.         }  \n\n72.     }  \n\n73.     return newTab;  \n\n74. }  \n```\n\n\n\n进行扩容，会伴随着一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。在编写程序中，要尽量避免resize。\n\n在resize前和resize后的元素布局如下:\n\n![img](http://pcc.huitogo.club/9b317aabd3b474739b67a4cda0bdfb75)\n\n\n\nputVal(hash(key), key, value, false, evict)：在table中放入一个Node\n\n```\n1.  final V putVal(int hash, K key, V value, boolean onlyIfAbsent,  // onlyIfAbsent判断在key重复时是否覆盖   \n\n2.                   boolean evict) {    // evict参数用于LinkedHashMap中的尾部操作，这里没有实际意义      \n\n3.        Node<K,V>[] tab; Node<K,V> p; int n, i;　//定义变量tab是将要操作的Node数组引用，p表示tab上的某Node节点，n为tab的长度，i为tab的下标。  \n\n4.       if ((tab = table) == null || (n = tab.length) == 0)　 // table未初始化时进行初始化             　　　　  \n\n5.           n = (tab = resize()).length;　　　　　　　　　　　　　　　　　　　　　　　　          \n\n6.       if ((p = tab[i = (n - 1) & hash]) == null)  // 如果计算后的索引位置是否为空则直接赋值  \n\n7.            tab[i] = newNode(hash, key, value, null);　  \n\n8.       else {　　// 计算后索引位置有值的情况下，有三种情况：p为链表节点；p为红黑树节点；p是链表节点但长度为临界长度TREEIFY_THRESHOLD，再插入任何元素就要变成红黑树了。  \n\n9.           Node<K,V> e; K k;　//定义e引用即将插入的Node节点， k = p.key。  \n\n10.           if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))   // key值存在的情况下记录p，但不直接覆盖，后面需要判断onlyIfAbsent  \n\n11.               e = p;　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　    \n\n12.          else if (p instanceof TreeNode)  //p是红黑树节点，直接强制转型p后调用TreeNode.putTreeVal方法，返回的引用赋给e。  \n\n13.              e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);   // putTreeVal内部会进行遍历，存在相同hash时返回被覆盖的TreeNode，否则返回null。  \n\n14.         else {　  //  p为链表节点  \n\n15.              for (int binCount = 0; ; ++binCount) {　　　　// 遍历p节点所在的链表\n\n16.                  if ((e = p.next) == null) {　　　　　　　　　　　　　　　　　　　　  \n\n17.                      p.next = newNode(hash, key, value, null); // 将当前节点添加到末尾　　　　　　　　　　  \n\n18.                      if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  //插入成功后，要判断是否需要转换为红黑树，因为插入后链表长度加1，而binCount并不包含新节点，所以判断时要将临界阈值减1。  \n\n19.                         treeifyBin(tab, hash);　　//当新长度满足转换条件时，调用treeifyBin方法，将该链表转换为红黑树。 //***\n\n20.                      break;　　//如果不满足转换条件，插入操作到此结束了，break退出  \n\n21.                 }  \n\n22.                   if (e.hash == hash &&　((k = e.key) == key || (key != null && key.equals(k)))) //判断当前遍历的节点的key是否相同。  \n\n23.                      break;　//找到了相同key的节点后无需任何操作  \n\n24.                 p = e;　　// 将e指向p 以进行下一轮遍历 因为e = p.next  \n\n25.              }  \n\n26.           }  \n\n27.          if (e != null) { // 这时候开始处理 key重复的情况  \n\n28.              V oldValue = e.value;　　　　　　　　　　　　　　　　　　　　　　　　　　  \n\n29.              if (!onlyIfAbsent || oldValue == null)　　// 如果onlyIfAbsent 为true或者重复的key的value为空则进行覆盖　　　　　　　　　　　　　　　  \n30.                   e.value = value;　　　  \n\n31. 　　　　　afterNodeAccess(e);　　//这个函数在hashmap中没有任何操作，是个空函数，他存在主要是为了linkedHashMap的一些后续处理工作。  \n\n32.              return oldValue;　//返回的是被覆盖的oldValue。  \n\n33.          }  \n\n34.      }　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　   \n\n35.       ++modCount;　　　//值得一提的是，对key相同而覆盖oldValue的情况，在前面已经return，不会执行这里，所以那一类情况不算数据结构变化，并不改变modCount值。  \n\n36.      if (++size > threshold)　　　//判断是否达到了扩容标准。  \n\n37.           resize();　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　  \n\n38.      afterNodeInsertion(evict);　　　//这里与前面的afterNodeAccess同理，是用于linkedHashMap的尾部操作，HashMap中并无实际意义。  \n\n39.      return null;　　　 //对于真正进行插入元素的情况，put函数一律返回null。  \n\n40.  }  \n```\n\n\n\n##### **（3）HashMap的重要方法**\n\n###### **1）put方法**\n\n```\n1.  public V put(K key, V value) { // 调用的putVal，注意onlyIfAbsent为false，即覆盖key  \n\n2.       return putVal(hash(key), key, value, false, true);  \n\n3.   } \n```\n\n\n\nHashMap并没有直接提供putVal接口给用户调用，而是提供的put函数，而put函数就是通过putVal来插入元素的。\n\nput方法的流程图如下：\n\n![img](http://pcc.huitogo.club/ce501e471fc17d351ce46b17fbb6ebb4)\n\n\n\n解释起来的步骤如下：\n\n1）检查数组是否为空，执行resize()扩充；\n\n2）通过hash值计算数组索引，获取该索引位的首节点。\n\n3）如果首节点为null，直接添加节点到该索引位。\n\n4）如果首节点不为null，那么有3种情况\n\n　A. key和首节点的key相同，覆盖value；否则执行B或C\n\n　B. 如果首节点是红黑树节点（TreeNode），将键值对添加到红黑树。\n\n　C. 如果首节点是链表，将键值对添加到链表。添加之后会判断链表长度是否到达TREEIFY_THRESHOLD - 1这个阈值，“尝试”将链表转换成红黑树。\n\n最后判断当前元素个数是否大于threshold，扩充数组。\n\n\n\n###### **2）get方法**\n\nget(Object key)\n\n```\n1.  public V get(Object key) {  \n\n2.          Node<K,V> e;  \n\n3.          return (e = getNode(hash(key), key)) == null ? null : e.value;  \n\n4.      }  \n```\n\n\n\ngetNode(hash(key), key)\n\n```\n1.  final Node<K,V> getNode(int hash, Object key) {  \n\n2.      Node<K,V>[] tab; Node<K,V> first, e; int n; K k;  \n\n3.      // table已经初始化，长度大于0，根据hash寻找table中的项也不为空  \n\n4.      if ((tab = table) != null && (n = tab.length) > 0 &&   (first = tab[(n - 1) & hash]) != null) {  \n\n6.          // 桶中第一项(数组元素)相等  \n\n7.          if (first.hash == hash && // always check first node  \n\n8.              ((k = first.key) == key || (key != null && key.equals(k))))  \n\n9.              return first;  \n\n10.         // 桶中不止一个结点  \n\n11.         if ((e = first.next) != null) {  \n\n12.             // 为红黑树结点  \n\n13.             if (first instanceof TreeNode)  \n\n14.                 // 在红黑树中查找  \n\n15.                 return ((TreeNode<K,V>)first).getTreeNode(hash, key);  \n\n16.             // 否则，在链表中查找  \n\n17.             do {  \n\n18.                 if (e.hash == hash &&  ((k = e.key) == key || (key != null && key.equals(k))))  \n\n20.                     return e;  \n\n21.             } while ((e = e.next) != null);  \n\n22.         }  \n\n23.     }  \n\n24.     return null;  \n\n25. } \n```\n\nHashMap并没有直接提供getNode接口给用户调用，而是提供的get函数，而get函数就是通过getNode来取得元素的。\n\n\n\n###### **3）remove方法**\n\n```\n2.  public V remove(Object key) {  \n\n3.      Node<K,V> e;  \n\n4.      return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;  \n\n6.  }  \n```\n\n\n\nremoveNode(hash(key), key, null, false, true)：根据key移除单个节点\n\n```\n1.  final Node<K,V> removeNode(int hash, Object key, Object value,  // 这里value是在matchValue为true时进一步判断是否移除node的条件 value == node.value  \n\n2.                             boolean matchValue, boolean movable) { // matchValue 为true时表示删除它key对应的value，不删除key；movable为false时表示删除后不移动节点  \n\n3.      // tab 哈希数组，p 数组下标的节点，n 长度，index 当前数组下标  \n\n4.      Node<K,V>[] tab; \n    \n6.      Node<K,V> p; \n\n8.      int n, index;   \n\n5.      if ((tab = table) != null && (n = tab.length) > 0 &&   (p = tab[index = (n - 1) & hash]) != null) {  \n\n7.          //  node 存储要删除的节点，e 临时变量，k 当前节点的key，v 当前节点的value  \n\n8.          Node<K,V> node = null, e; K k; V v;  \n\n9.          if (p.hash == hash &&   ((k = p.key) == key || (key != null && key.equals(k)))) // 如果数组下标的节点正好是要删除的节点  \n\n11.             node = p;  \n\n12.         else if ((e = p.next) != null) { // 链表  \n\n13.             if (p instanceof TreeNode) // 当前数组节点是红黑树节点  \n\n14.                 node = ((TreeNode<K,V>)p).getTreeNode(hash, key);  \n\n15.             else {  \n\n16.                 do {  // 遍历链表 找到指定key的节点  \n\n17.                     if (e.hash == hash &&  ((k = e.key) == key ||  (key != null && key.equals(k)))) {  \n\n20.                         node = e;  \n\n21.                         break;  \n\n22.                     }  \n\n23.                     p = e;  \n\n24.                 } while ((e = e.next) != null);  \n\n25.             }  \n\n26.         }  \n\n27.         if (node != null && (!matchValue || (v = node.value) == value ||  (value != null && value.equals(v)))) {  // 判断是否要完全移除节点  \n\n29.             if (node instanceof TreeNode)  \n\n30.                 ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);  \n\n31.             else if (node == p) // 要移除的节点是头节点  \n\n32.                 tab[index] = node.next;  \n\n33.             else    \n\n34.                 p.next = node.next; // 把要删除的下一个结点设为上一个结点的下一个节点  \n\n35.             ++modCount;  \n\n36.             --size;  \n\n37.             afterNodeRemoval(node); // 此方法在hashMap中是为了让子类去实现，主要是对删除结点后的链表关系进行处理  \n\n38.             return node;  \n\n39.         }  \n\n40.     }  \n\n41.     return null;  \n\n42. }  \n```\n\n\n\n###### **4）set方法**\n\n元素的修改也是put方法，因为key是唯一的，所以修改元素，就是把新值覆盖旧值。\n\n\n\n#### **3、HashMap总结和问题**\n\n##### **（1）总结**\n\n1） 数组的初始容量为16，而容量是以2的次方扩充的，一是为了提高性能使用足够大的数组，二是为了能使用位运算代替取模预算。\n\n2）数组是否需要扩充是通过负载因子判断的，如果当前元素个数为数组容量的0.75时，就会扩充数组。这个0.75就是默认的负载因子，可由构造传入。我们也可以设置大于1的负载因子，这样数组就不会扩充，牺牲性能，节省内存。\n\n3）为了解决碰撞，数组中的元素是单向链表类型。当链表长度到达一个阈值时（7或8），会将链表转换成红黑树提高性能。而当链表长度缩小到另一个阈值时（6），又会将红黑树转换回单向链表提高性能，这里是一个平衡点。\n\n4）对于第三点补充说明，检查链表长度转换成红黑树之前，还会先检测当前数组数组是否到达一个阈值（64），如果没有到达这个容量，会放弃转换，先去扩充数组。所以上面也说了链表长度的阈值是7或8，因为会有一次放弃转换的操作。\n\n\n\n##### **（2）问题**\n\n###### 1）关于数据扩容?\n\n从putVal源代码中我们可以知道，当插入一个元素的时候size就加1，若size大于threshold的时候，就会进行扩容。\n\n假设我们的capacity大小为32，loadFator为0.75,则threshold为24 = 32 * 0.75，此时，插入了25个元素，并且插入的这25个元素都在同一个桶中，桶中的数据结构为红黑树，则还有31个桶是空的，也会进行扩容处理，其实，此时，还有31个桶是空的，好像似乎不需要进行扩容处理，但是是需要扩容处理的，因为此时我们的capacity大小可能不适当。\n\n我们前面知道，扩容处理会遍历所有的元素，时间复杂度很高；前面我们还知道，经过一次扩容处理后，元素会更加均匀的分布在各个桶中，会提升访问效率，所以说尽量避免进行扩容处理，也就意味着，遍历元素所带来的坏处大于元素在桶中均匀分布所带来的好处。　\n\n\n\n###### 2）为什么HashMap根据 (n - 1) & hash 求出了元素在node数组的下标?\n\n下面是hash方法的源码:\n\n```\n1.  static final int hash(Object key) {  \n\n2.      int h;  \n\n3.      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);  \n\n4.  }  \n```\n\nhash方法的作用是将hashCode进一步的混淆，**增加其“随机度”**，试图减少插入hashmap时的hash冲突，换句更专业的话来说就是提高离散性能。而这个方法知乎上有人回答时称为“**扰动函数**”。\n\n主要分三个阶段: **计算hashcode、高位运算和取模运算**\n\n这里通过key.hashCode()计算出key的哈希值，然后将哈希值h右移16位，再与原来的h做异或^运算——这一步是高位运算。设想一下，如果没有高位运算，那么hash值将是一个int型的32位数。而从2的-31次幂到2的31次幂之间，有将近几十亿的空间，如果我们的每一个HashMap的table都这么长，内存早就爆了，所以这个散列值不能直接用来最终的取模运算，而需要先加入高位运算，将高16位和低16位的信息\"融合\"到一起，也称为\"扰动函数\"。这样才能**保证hash值所有位的数值特征都保存下来而没有遗漏，从而使映射结果尽可能的松散**。\n\n最后，根据 n-1做与操作的取模运算。这里也能看出为什么HashMap要限制table的长度为2的n次幂，因为这样，n-1可以保证二进制展示形式是（以16为例）0000 0000 0000 0000 0000 0000 0000 1111。在做\"与\"操作时，就等同于截取hash二进制值得后四位数据作为下标。这里也可以看出\"扰动函数\"的重要性了，**如果高位不参与运算，那么高16位的hash特征几乎永远得不到展现，发生hash碰撞的几率就会增大，从而影响性能**。\n\n\n\n举例说明流程图如下：\n\n![img](http://pcc.huitogo.club/00df43f7f251cf218f0d4a8bcf134b1a)\n\n\n\n###### 3）在resize()扩容时为什么通过e.hash & oldCap是否为0来进行rehash？\n\n举例说明一下，下面n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash是key对应的哈希与高位运算结果（没有和n-1做&运算前）。\n\n![img](http://pcc.huitogo.club/e6436173d50d92b4a15332653ef37474)\n\n\n\n元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1位(红色)，因此新的index就会发生这样的变化：\n\n![img](http://pcc.huitogo.club/f4706b202ce78c2f4e91e46c191f375c)\n\n因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，也就是通过e.hash & oldCap来判断新增的bit是0还是1。\n\n**由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了**。\n\nJDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上面过程分析后**JDK1.8中hashMap进行rehash时不会倒置。**\n\n\n\n###### 4） jdk1.8底层是怎么维护entrySet()的？\n\nhashMap内部维护了一个entrySet集合\n\n```\n1.  /** \n\n2.   * Holds cached entrySet(). Note that AbstractMap fields are used \n\n3.   * for keySet() and values(). \n\n4.   */  \n\n5.  transient Set<Map.Entry<K,V>> entrySet;\n```\n\n\n\n在hashMap遍历的时候（通过entrySet()）会从这个集合里面取值，但是在查看put()和remove()源码后发现hashMap并没有显示的维护这个entrySet集合，那么它是怎么取到值进行遍历的呢？\n\n查看entrySet源码，发现在调用entrySet()会返回一个EntrySet对象，EntrySet有一个iterator方法返回一个EntryIterator迭代器\n\n```\n1.  final class EntrySet extends AbstractSet<Map.Entry<K,V>> {  \n\n2.      public final int size()                 { return size; }  \n\n3.      public final void clear()               { HashMap.this.clear(); }  \n\n4.      public final Iterator<Map.Entry<K,V>> iterator() {  \n\n5.          return new EntryIterator();  \n\n6.      }  \n\n7.      ...  \n\n8.  } \n```\n\n\n\n这个迭代器继承了HashIterator，那么关键在这个HashIterator\n\n```\n1.  abstract class HashIterator {  \n\n2.      Node<K,V> next;        // next entry to return  \n\n3.      Node<K,V> current;     // current entry  \n\n4.      int expectedModCount;  // for fast-fail  \n\n5.      int index;             // current slot  \n\n6.      // ... 构造方法 重置所有变量  \n\n7.       public final boolean hasNext() {  \n\n8.          return next != null;  \n\n9.      }  \n\n10.     // 这个就是迭代时获取值的next方法  \n\n11.     final Node<K,V> nextNode() {  \n\n12.         Node<K,V>[] t;  \n\n13.         Node<K,V> e = next;  \n\n14.         if (modCount != expectedModCount)  \n\n15.             throw new ConcurrentModificationException();  \n\n16.         if (e == null)  \n\n17.             throw new NoSuchElementException();  \n\n18.         if ((next = (current = e).next) == null && (t = table) != null) {  \n\n19.             do {} while (index < t.length && (next = t[index++]) == null);  \n\n20.         }  \n\n21.         return e;  \n\n22.     }  \n\n23.    ... \n```\n\n现在知道问题所在了，我们在通过迭代器遍历HashMap的时候，虽然表面是从entrySet中取值，但是**底层还是从table（Node数组）中进行取值，包括判断和删除操作都是对table操作**。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "af6731836a9204854b646aff8c91c091": {"id": "af6731836a9204854b646aff8c91c091", "item": "Java基础", "title": "LinkedHashMap源码分析", "date": "2024-08-22", "summary": "LinkedHashMap 是 Java 中的一种哈希表和链表结合的数据结构。它继承自 HashMap，能记住元素的插入顺序或访问顺序。在遍历元素时，可按照特定顺序输出。适用于需要保持顺序的场景，同时具备高效的查找、插入和删除性能。", "body": "\n#### 1. LinkedHashMap和HashMap\n\nlinkedHashMap的继承关系如下图：\n\n![img](http://pcc.huitogo.club/04c55ea76194a39cf961f26a61b04832)\n\n\n\n可以看出linkedHashMap是HashMap的子类，拥有HashMap的所有特性，比如高效的查找元素，同时，**LinkedHashMap还保持着内部元素的顺序**，可以根据**元素访问时间**或**元素插入时间**进行排序，**因此适用于需保持元素顺序的场景**。另外，由于LinkedHashMap有保持元素访问顺序的模式，所以也常被用作LRU缓存（Least-Recently-Used Cache，即最近最少使用缓存策略）\n\n\n\n**Q1：LinkedHashMap是怎么实现元素遍历的有序性的？**\n\n通过源码可以看到组成LinkedHashMap的元素节点，如下：\n\n```\n1.  static class Entry<K,V> extends HashMap.Node<K,V> {  \n\n2.      Entry<K,V> before, after;  \n\n3.      Entry(int hash, K key, V value, Node<K,V> next) {  \n\n4.          super(hash, key, value, next);  \n\n5.      }  \n\n6.  }  \n```\n\n可以看到LinkedHashMap中的元素除了维护HashMap的结构（数组+链表）外，还维护了一个双链表，正是因为**这个双链表才能让其中的元素保持某种顺序**。\n\n由于所有元素使用链表相连，所以遍历的效率略高于HashMap，因为HashMap遍历时，需要每个桶中先遍历到链表尾部，然后再遍历到下一个桶，当元素不多而空桶数量很多时，就会有很多次的无效访问，所以理论上来说，**LinkedHashMap的遍历效率是要比HashMap高的**。\n\n\n\n根据下图HashMap和LinkedHashMap的结构图可以看出：\n\n![img](http://pcc.huitogo.club/b169adf1efd70134f9777157ebb9236e)\n\n\n\n![img](http://pcc.huitogo.club/3eb96935e4e87afcbee2e5743664f552)\n\n\n\n**Q2：什么HashMap中的TreeNode先继承LinkedHashMap中的Entry，而不是直接继承HashMap的Node？**\n\n如果TreeNode直接继承自Node，则失去了链表的特性，LinkedHashMap继承HashMap后，则**需要再使用另一个内部类来继承TreeNode来使得其具有链表特性**，并且相关方法均需要重写，**大大的增加了工作量**，并且**代码的可维护性会下降**很多，另外，HashMap只会在桶中元素达到一定数量的时候才会将节点转换TreeNode，在哈希表散列良好的情况下，**TreeNode是很少被使用**到的，所以这一点点的空间浪费是值得的。\n\n\n\n#### 2. LinkedHashMap的插入和删除\n\n在之前我们讨论一个集合进行增删的时候原理就是维护底层的数据结构，这里LinkedHashMap也会理所当然的想到维护那个Entry的双链表。\n\n那既然不是直接维护双链表的话，那底层是怎么维护的？\n\n\n\n现在回顾一下上节HashMap源码中的put方法中主要方法putVal()\n\n```\n1.  final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {  \n\n3.      Node<K,V>[] tab; Node<K,V> p; int n, i;  \n\n4.      if ((tab = table) == null || (n = tab.length) == 0)  \n\n5.          n = (tab = resize()).length;  \n\n6.      if ((p = tab[i = (n - 1) & hash]) == null)  \n\n7.          tab[i] = newNode(hash, key, value, null);  //newNode方法在LinkedHashMap中被覆盖  \n\n8.      else {  \n\n9.          Node<K,V> e; K k;  \n\n10.         if (p.hash == hash &&  ((k = p.key) == key || (key != null && key.equals(k))))  \n\n12.             e = p;  \n\n13.         else if (p instanceof TreeNode)  \n\n14.             e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);  \n\n15.         else {  \n\n16.             for (int binCount = 0; ; ++binCount) {  \n\n17.                 if ((e = p.next) == null) {  \n\n18.                     p.next = newNode(hash, key, value, null);  \n\n19.                     if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  \n\n20.                         treeifyBin(tab, hash);  \n\n21.                     break;  \n\n22.                 }  \n\n23.                 if (e.hash == hash &&   ((k = e.key) == key || (key != null && key.equals(k))))  \n\n25.                     break;  \n\n26.                 p = e;  \n\n27.             }  \n\n28.         }  \n\n29.         if (e != null) { // existing mapping for key  \n\n30.             V oldValue = e.value;  \n\n31.             if (!onlyIfAbsent || oldValue == null)  \n\n32.                 e.value = value;  \n\n33.             afterNodeAccess(e); //关键方法A  \n\n34.             return oldValue;  \n\n35.         }  \n\n36.     }  \n\n37.     ++modCount;  \n\n38.     if (++size > threshold)  \n\n39.         resize();  \n\n40.     afterNodeInsertion(evict); //关键方法B  \n\n41.     return null;  \n\n42. } \n```\n\n\n\n在上述源码中，先看 afterNodeAccess(e)和afterNodeInsertion(true)以及在remove()方法中对应的afterNodeRemoval(e)，LinkedHashMap的核心也就是这些操作。\n\n\n\n**afterNodeAccess(e)**：在节点被访问之后进行双链表的调整（仅仅在accessOrder为true时进行，把当前访问的元素移动到链表尾部，这里的accessOrder为true时表示当前双链表按照访问时间排序，为false时也就是默认是插入时间排序）\n\n```\n1.  void afterNodeAccess(Node<K,V> e) { // move node to last  \n\n2.       LinkedHashMap.Entry<K,V> last;  \n\n3.       if (accessOrder && (last = tail) != e) {  \n\n4.           LinkedHashMap.Entry<K,V> p =    (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;  \n\n6.           p.after = null;  \n\n7.           if (b == null)  \n\n8.               head = a;  \n\n9.           else  \n\n10.              b.after = a;  \n\n11.          if (a != null)  \n\n12.              a.before = b;  \n\n13.          else  \n\n14.              last = b;  \n\n15.          if (last == null)  \n\n16.              head = p;  \n\n17.          else {  \n\n18.              p.before = last;  \n\n19.              last.after = p;  \n\n20.          }  \n\n21.          tail = p;  \n\n22.          ++modCount;  \n\n23.      }  \n\n24.  } \n```\n\n\n\n**afterNodeInsertion(true)**：在节点被插入后进行双链表的调整，插入节点时会判断是否需要移除链表头节点，默认实现是不移除的，可以通过继承LinkedHashMap并覆盖removeEldestEntry方法来改变该特性\n\n```\n1.  void afterNodeInsertion(boolean evict) { // possibly remove eldest  \n\n2.      LinkedHashMap.Entry<K,V> first;  \n\n3.      // 根据条件判断是否移除最近最少被访问的节点  \n\n4.      if (evict && (first = head) != null && removeEldestEntry(first)) {  \n\n5.          K key = first.key;  \n\n6.          removeNode(hash(key), key, null, false, true);  \n\n7.      }  \n\n8.  }  \n\n\n9.  // 移除最近最少被访问条件之一，通过覆盖此方法可实现不同策略的缓存  \n\n10. protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {  \n\n11.     return false;  \n\n12. } \n```\n\n我们可以继承LinkedHashMap类，**覆盖removeEldestEntry方法实现LRU缓存策略**。\n\n\n\n**afterNodeRemoval(e)**：在节点被移除后进行双链表的调整，移除调整其实很简单，就是把要移除的节点前一个节点的after引用指向后一个节点，把后一个节点的before引用指向前一个节点\n\n```\n1.  void afterNodeRemoval(Node<K,V> e) {  \n\n2.      LinkedHashMap.Entry<K,V> p =   (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;  \n\n4.      p.before = p.after = null;  \n\n5.      if (b == null)  \n\n6.          head = a;  \n\n7.      else  \n\n8.          b.after = a;  \n\n9.      if (a == null)  \n\n10.         tail = b;  \n\n11.     else  \n\n12.         a.before = b;  \n\n13. }\n```\n\n\n\n除了这样在增删时候对节点的位移操作外，还有一个LinkedHashMap覆盖父类的newNode()方法，这个方法就是新建一个节点，插入到现有双链表的尾部\n\n```\n1.  Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {  \n\n2.      LinkedHashMap.Entry<K,V> p =   new LinkedHashMap.Entry<K,V>(hash, key, value, e);  \n\n4.      //新建节点，然后链接到双链表的尾部  \n\n5.      linkNodeLast(p);  \n\n6.      return p;  \n\n7.  }  \n\n\n8.  private void linkNodeLast(LinkedHashMap.Entry<K,V> p) {  \n\n9.      LinkedHashMap.Entry<K,V> last = tail;  \n\n10.     tail = p;  \n\n11.     if (last == null)  \n\n12.         head = p;  \n\n13.     else {  \n\n14.         p.before = last;  \n\n15.         last.after = p;  \n\n16.     }  \n\n17. }  \n```\n\n\n\n总结一下在LinkedHashMap中维护双链表的过程，插入节点的时候，会调用覆盖过的newNode方法，将插入的元素链接的链表尾部，删除节点的时候，将该节点的前后节点相连即可，当节点被访问时，可以将其放到链表尾部\n\n\n\n#### 3. LinkedHashMap的内部类\n\n内部类除了Entry外还有迭代器类，键、值以及键值对的集合类\n\n##### 3.1 LinkedHashIterator类\n\n```\n1.  abstract class LinkedHashIterator {  \n\n2.      LinkedHashMap.Entry<K,V> next;  \n\n3.      LinkedHashMap.Entry<K,V> current;  \n\n4.      int expectedModCount;  \n\n\n5.      LinkedHashIterator() {  \n\n6.          next = head;  \n\n7.          expectedModCount = modCount;  \n\n8.          current = null;  \n\n9.      }  \n\n\n10.     public final boolean hasNext() {  \n\n11.         ...  \n\n12.     }  \n\n13.     final LinkedHashMap.Entry<K,V> nextNode() {  \n\n14.         ...  \n\n15.     }  \n\n16.     public final void remove() {  \n\n17.         ...  \n\n18.     }  \n\n19. }  \n```\n\n\n\n这是一个抽象类，实现了迭代器的主要方法，hashNext，remove，nextNode方法，相当于一个类模板，其他迭代器类只需要继承该类然后添加一个next方法即可\n\n```\n1.  final class LinkedKeyIterator extends LinkedHashIterator  implements Iterator<K> {  \n\n3.      public final K next() { return nextNode().getKey(); }  \n\n4.  }  \n\n5.  final class LinkedValueIterator extends LinkedHashIterator implements Iterator<V> {  \n\n7.      public final V next() { return nextNode().value; }  \n\n8.  }  \n\n9.  final class LinkedEntryIterator extends LinkedHashIterator implements Iterator<Map.Entry<K,V>> {  \n\n11.     public final Map.Entry<K,V> next() { return nextNode(); }  \n\n12. } \n```\n\n\n\n##### 3.2  键、值以及键值对的集合类\n\n三个集合视图类结构基本一致，跟HashMap中的对应集合视图其实基本是一毛一样的，只是在迭代器方法中返回各自的内部迭代器实例而已。其余逻辑基本一致。\n\n\n\n#### 4. LinkedHashMap总结\n\n在日常开发中，LinkedHashMap 的使用频率虽不及HashMap，但它也是不可或缺的重要实现。在 Java集合框架中，**HashMap**、**LinkedHashMap** 和 **TreeMap**三个映射类基于不同的数据结构，并实现了不同的功能。\n\nHashMap底层基于拉链式的散列结构，并在 JDK 1.8中引入红黑树优化过长链表的问题。基于这样结构，HashMap可提供高效的增删改查操作。\n\nLinkedHashMap在其之上，通过维护一条双向链表，实现了散列数据结构的有序遍历。TreeMap底层基于红黑树实现，利用红黑树的性质，实现了键值对排序功能。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "275c8abd22797772ee170cadb87b9ccf": {"id": "275c8abd22797772ee170cadb87b9ccf", "item": "Java基础", "title": "LinkedList源码分析", "date": "2024-08-22", "summary": "LinkedList 是 Java 中的一种数据结构。它以双向链表的形式存储数据，允许快速地在链表中间进行插入和删除操作。可高效地进行头尾节点的添加和移除。适用于频繁进行数据增减操作的场景，但随机访问元素的效率相对较低。", "body": "\n#### 1. LinkedList概述\n\nLinkedList的继承关系如图所示\n\n![img](http://pcc.huitogo.club/f2faa5d61f235ae45e9421e69d7e7ca9)\n\n\n\nLinkedList是一种**可以在任何位置进行高效地插入和移除操作的有序序列**，它是**基于双向链表**实现的。\n\nLinkedList 是一个继承于AbstractSequentialList的双向链表。它也可以被当作堆栈、队列或双端队列进行操作。\n\nLinkedList 实现 List 接口，能对它进行队列操作。\n\nLinkedList 实现 Deque 接口，即能将LinkedList当作**双端队列使用**。\n\nLinkedList 实现了Cloneable接口，即覆盖了函数clone()，能克隆。\n\nLinkedList 实现java.io.Serializable接口，这意味着LinkedList支持序列化，能通过序列化去传输。\n\nLinkedList 是非同步的。\n\n\n\n注意：LinkedList没有实现RandomAccess接口，所以不是随机存取，意味着**在遍历LinkedList的时候，使用Iterator遍历效率更高，\\**也可以使用\\**foreach增强循环，原理也是使用Iterator**！\n\n\n\n**Q1：为什么LinkedList和AbstractList之间多了一个AbstractSequentialList抽象类？**\n\n减少实现顺序存取（例如LinkedList）这种类的工作，通俗的讲就是方便，抽象出类似LinkedList这种类的一些共同的方法\n\n以后如果自己想实现**顺序存取**这种特性的类(就是链表形式)，那么就继承这个**AbstractSequentialList抽象类**，如果想像数组那样的**随机存取**的类，那么就去实现**AbstracList抽象类**\n\n\n\n#### 2. LinkedList的数据结构\n\n##### 2.1 单向链表\n\nelement：用来存放元素\n\nnext：用来指向下一个节点元素\n\n**通过每个结点的指针指向下一个结点从而链接起来的结构，最后一个节点的next指向null。**\n\n![img](http://pcc.huitogo.club/300caf64c8cf7ea2175a68a3da31404f)\n\n\n\n特殊：单向循环链表\n\n在单向链表的最后一个节点的next会指向头节点，而不是指向null，这样存成一个环\n\n![img](http://pcc.huitogo.club/7519e770e0e081c81a75396139f98ef9)\n\n\n\n##### 2.2 双向链表\n\n- element：存放元素\n\n- pre：用来指向前一个元素\n\n- next：指向后一个元素\n\n\n双向链表是包含**两个指针的，pre指向前一个节点，next指向后一个节点，但是第一个节点head的pre指向null，最后一个节点的tail指向null**\n\n![img](http://pcc.huitogo.club/6fa395efd43f363e4145cf69c6a0307a)\n\n\n\n特殊：双向循环链表\n\n**第一个节点的pre指向最后一个节点，最后一个节点的next指向第一个节点，也形成一个“环”**\n\n![img](http://pcc.huitogo.club/b58dc53d0147e96fea8c6cea16466ba5)\n\n\n\n##### 2.3  LinkedList\n\n![img](http://pcc.huitogo.club/af23638c59baac6019cb49b98eb0e2dc)\n\nLinkedList底层使用的**双向链表结构**，有一个头结点和一个尾结点，双向链表意味着我们可以从头开始正向遍历，或者是从尾开始逆向遍历，并且可以针对头部和尾部进行相应的操作。\n\n\n\n##### 3. 类属性\n\n```\n2.  // 实际元素个数  \n\n3.  transient int size = 0;  \n\n4.  // 头结点  \n\n5.  transient Node<E> first;  \n\n6.  // 尾结点  \n\n7.  transient Node<E> last; \n```\n\n头结点、尾结点都有transient关键字修饰，这也意味着在序列化时该域是不会序列化的\n\n\n\n##### 4. 构造方法\n\n##### 4.1 空参构造函数\n\n```\n3.  /** \n\n4.   * Constructs an empty list. \n\n5.   */  \n\n6.  public LinkedList() {}  \n```\n\n\n\n##### 4.2 有参构造函数\n\n```\n8.  //将集合c中的各个元素构建成LinkedList链表。  \n\n9.   public LinkedList(Collection<? extends E> c) {  \n\n10.   // 调用无参构造函数  \n\n11.      this();  \n\n12.      // 添加集合中所有的元素  \n\n13.      addAll(c);  \n\n14.  }  \n```\n\n\n\n链表的核心是Node节点，用于存放实际元素的地方\n\n```\n1.  private static class Node<E> {  \n\n2.      E item; // 数据域（当前节点的值）  \n\n3.      Node<E> next; // 后继（指向当前一个节点的后一个节点）  \n\n4.      Node<E> prev; // 前驱（指向当前节点的前一个节点）  \n\n\n5.      // 构造函数，赋值前驱后继  \n\n6.      Node(Node<E> prev, E element, Node<E> next) {  \n\n7.          this.item = element;  \n\n8.          this.next = next;  \n\n9.          this.prev = prev;  \n\n10.     }  \n\n11. }  \n```\n\n\n\n#### 5. LinkedList的核心方法\n\n方法实现的核心理念就是**操作节点的pre、next，打乱链表的顺序重新串起来。**\n\n##### 5.1 add方法\n\n![img](http://pcc.huitogo.club/0ba7b86441bd5f874e69f18f769a17e4)\n\n\n\n**1） add(E)**\n\n```\n2.  public boolean add(E e) {  \n\n3.     　　 // 添加到末尾  \n\n4.      　　linkLast(e);  \n\n5.      　　return true;  \n\n6.   }\n```\n\n\n\nlinkLast(e)代码\n\n```\n1.  // 向尾部添加节点  \n\n2.  void linkLast(E e) {  \n\n3.      final Node<E> l = last;     \n\n4.      final Node<E> newNode = new Node<>(l, e, null); //将e封装为节点，并且e.prev指向了最后一个节点  \n\n5.      last = newNode; //从尾部添加，所以newNode是最后一个节点   \n\n6.      if (l == null)    //当前链表为控制，newNode既是最后一个节点也是第一个节点  \n\n7.          first = newNode;  \n\n8.      else      \n\n9.          l.next = newNode; // 添加到末尾  \n\n10.     size++; //添加一个节点，size自增  \n\n11.     modCount++;  \n\n12. }  \n```\n\n\n\n下面是空LinkedList添加元素的结构图：\n\n![img](http://pcc.huitogo.club/6cd227cbbf0bccaa24d0f813ab40951c)\n\n\n\n**2） addAll(c)**\n\n```\n2.  public boolean addAll(Collection\\<? extends E\\> c) {  \n\n3.      return addAll(size, c);  \n\n4.  }  \n```\n\n\n\naddAll(size, c)，核心代码\n\n```\n1.  public boolean addAll(int index, Collection<? extends E> c) {  \n\n2.      // 检查index  \n\n3.      checkPositionIndex(index);  \n\n4.      //转换为Object数组  \n\n5.      Object[] a = c.toArray();  \n\n6.      int numNew = a.length;  \n\n7.      if (numNew == 0)  \n\n8.          return false;  \n\n9.      // pred是添加每一个元素时的前一个节点，succ是后一个节点  \n\n10.     Node<E> pred, succ;  \n\n11.     // 当前链表为空或者在末尾添加元素  \n\n12.     if (index == size) {  \n\n13.         // 在这种情况下待添加元素的后一个节点为空，前一个节点等于最后一个节点  \n\n14.         succ = null;  \n\n15.         pred = last;  \n\n16.     } else { 在链表中间插入元素  \n\n17.         // 这种情况，待添加元素的后一个节点就是插入前该位置的节点，也就是node(index)  \n\n18.         // 前一个节点自然就是之前位置节点的前一个节点  \n\n19.         succ = node(index);  \n\n20.         pred = succ.prev;  \n\n21.     }  \n\n22.     //遍历数组a中的元素，封装为一个个节点并插入链表中  \n\n23.     for (Object o : a) {  \n\n24.         @SuppressWarnings(\"unchecked\") E e = (E) o;  \n\n25.         // 封装节点  \n\n26.         Node<E> newNode = new Node<>(pred, e, null);  \n\n27.         if (pred == null) // 插入前链表为空，那么第一个节点就是newNode  \n\n28.             first = newNode;  \n\n29.         else  \n\n30.             pred.next = newNode;  \n\n31.         //将newNode变成pred，连接下一个节点  \n\n32.         pred = newNode;  \n\n33.     }  \n\n34.     // 遍历完待插入的所有节点后，怎么定义最后一个节点  \n\n35.     if (succ == null) { // 插入前链表为空或者在尾部添加节点  \n\n36.         last = pred; // 上面遍历时将最后一个newNode变成了pred，所以这种情况最后一个newNode就是last  \n\n37.     } else { //中间插入元素，succ是有值的，直接关联最后一个newNode即可  \n\n38.         pred.next = succ;  \n\n39.         succ.prev = pred;  \n\n40.     }  \n\n41.     //增加了几个元素，就把 size = size +numNew  \n\n42.     size += numNew;  \n\n43.     modCount++;  \n\n44.     return true;  \n\n45. } \n```\n\n\n\nnode函数是根据索引下标找到该结点并返回，参数中的index表示在索引下标为index的结点（实际上是第index + 1个结点）的前面插入\n\n```\n1.  Node<E> node(int index) {  \n\n2.      // 判断插入的位置在链表前半段或者是后半段  \n\n3.      if (index < (size >> 1)) { // 插入位置在前半段  \n\n4.          Node<E> x = first;   \n\n5.          for (int i = 0; i < index; i++) // 从头结点开始正向遍历  \n\n6.              x = x.next;  \n\n7.          return x; // 返回该结点  \n\n8.      } else { // 插入位置在后半段  \n\n9.          Node<E> x = last;   \n\n10.         for (int i = size - 1; i > index; i--) // 从尾结点开始反向遍历  \n\n11.             x = x.prev;  \n\n12.         return x; // 返回该结点  \n\n13.     }  \n\n14. } \n```\n\n这里有个小优化，节点在前半段则从头开始遍历，在后半段则从尾开始遍历，这样就保证了只需要遍历最多一半结点就可以找到指定索引的结点。\n\n\n\n**Q1：在addAll(size,c)中遍历前为什么要将集合c转换成数组进行遍历？**\n\n直接遍历 Collection，还要先生成它的 Iterator<E>，再遍历。倒不如，一次性转变成数组来遍历，更便捷\n\n\n\n##### 5.2 remove方法\n\n```\n2.  public boolean remove(Object o) {  \n\n3.  //这里可以看到，linkedList也能存储null  \n\n4.      if (o == null) {  \n\n5.          //循环遍历链表，直到找到null值，然后使用unlink移除该值。下面的这个else中也一样  \n\n6.          for (Node<E> x = first; x != null; x = x.next) {  \n\n7.              if (x.item == null) {  \n\n8.                  unlink(x);  \n\n9.                  return true;  \n\n10.             }  \n\n11.         }  \n\n12.     } else {  \n\n13.         for (Node<E> x = first; x != null; x = x.next) {  \n\n14.             if (o.equals(x.item)) {  \n\n15.                 unlink(x);  \n\n16.                 return true;  \n\n17.             }  \n\n18.         }  \n\n19.     }  \n\n20.     return false;  \n\n21. }  \n```\n\n\n\nunlink(x) 代码\n\n```\n1.  E unlink(Node<E> x) {  \n\n2.      // assert x != null;  \n\n3.      final E element = x.item;  \n\n4.      final Node<E> next = x.next;  \n\n5.      final Node<E> prev = x.prev;  \n\n6.      if (prev == null) { //说明移除的节点是头节点  \n\n7.          //first头节点应该指向下一个节点  \n\n8.          first = next;  \n\n9.      } else {  \n\n10.         //不是头节点  \n\n11.         prev.next = next;  \n\n12.         //解除x节点的前指向，解除关联让它gc  \n\n13.         x.prev = null;  \n\n14.     }  \n\n15.     if (next == null) { //说明移除的节点是尾节点  \n\n16.         last = prev;  \n\n17.     } else {  \n\n18.         //不是尾节点，prev和next进行关联  \n\n19.         next.prev = prev;  \n\n20.         // 解除x节点的前指向，解除关联让它gc  \n\n21.         x.next = null;  \n\n22.     }  \n\n23.     //x的前后指向都为null了，也把item为null，让gc回收它  \n\n24.     x.item = null;  \n\n25.     size--;    //移除一个节点，size自减  \n\n26.     modCount++;  \n\n27.     return element;    //由于一开始已经保存了x的值到element，所以返回。  \n\n28. }  \n```\n\n\n\n##### 5.3 get方法\n\n**1） get(index) 查询元素的方法**\n\n```\n31. public E get(int index) {  \n\n32.     checkElementIndex(index);  \n\n33.     return node(index).item;  \n\n34. }  \n```\n\n调用的就是node(index)方法\n\n\n\n**2）indexOf(Object o)**\n\n```\n2.  // 和remove代码类似，只是返回类型不一样  \n\n3.  public int indexOf(Object o) {  \n\n4.      int index = 0;  \n\n5.      if (o == null) {  \n\n6.          for (Node<E> x = first; x != null; x = x.next) {  \n\n7.              if (x.item == null)  \n\n8.                  return index;  \n\n9.              index++;  \n\n10.         }  \n\n11.     } else {  \n\n12.         for (Node<E> x = first; x != null; x = x.next) {  \n\n13.             if (o.equals(x.item))  \n\n14.                 return index;  \n\n15.             index++;  \n\n16.         }  \n\n17.     }  \n\n18.     return -1;  \n\n19. }  \n```\n\n\n\n#### 6. LinkedList的迭代器\n\n在LinkedList中除了有一个Node的内部类外，应该还能看到另外两个内部类，那就是ListItr，还有一个是DescendingIterator。\n\n##### 6.1 ListItr内部类\n\nListItr继承了ListIterator\n\n![img](http://pcc.huitogo.club/6af1f29da0e808b3bfb7602f949e9c1c)\n\n可以看出ListItr让linkedList**不光能像后迭代，也能向前迭代**而且在迭代的过程中，还能**移除、修改、添加值**的操作。\n\n\n\n##### 6.2 DescendingIterator内部类\n\n```\n2.  private class DescendingIterator implements Iterator<E> {  \n\n3.      private final ListItr itr = new ListItr(size());  \n\n4.      public boolean hasNext() {  \n\n5.          return itr.hasPrevious();  \n\n6.      }  \n\n7.      public E next() {  \n\n8.          return itr.previous();  \n\n9.      }  \n\n10.     public void remove() {  \n\n11.         itr.remove();  \n\n12.     }  \n\n13. }  \n```\n\n这个类**还是调用的ListItr**，作用是**封装一下Itr中几个方法**，**让使用者以正常的思维去写代码**，例如，在从后往前遍历的时候，也是跟从前往后遍历一样，使用next等操作，而不用使用特殊的previous。\n\n\n\n#### 7. 总结\n\n1. linkedList本质上是一个双向链表，通过一个Node内部类实现的这种链表结构。\n2. 能存储null值\n3. 跟arrayList相比较，就真正的知道了，LinkedList在删除和增加等操作上性能好，而ArrayList在查询的性能上好\n4. 从源码中看，它不存在容量不足的情况\n5. linkedList不光能够向前迭代，还能像后迭代，并且在迭代的过程中，可以修改值、添加值、还能移除值。\n6. linkedList不光能当链表，还能当队列使用，这个就是因为实现了Deque接口。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "b7862ba3900b220ec94472cb5b08013b": {"id": "b7862ba3900b220ec94472cb5b08013b", "item": "Java基础", "title": "LongAdder并发计数的底层原理", "date": "2024-08-22", "summary": "LongAdder 是 Java 中的一个高效并发累加器。它在高并发环境下，通过分散热点数据来减少竞争，多个线程可对不同的内部变量进行累加操作。相比 AtomicLong，在高并发场景下性能更好，适用于需要频繁进行累加操作的多线程环境。", "body": "\n**首先为什么在有AtomicLong的情况下使用LongAdder计数？**\n\nAtomicLong内部只有一个volatile long value，这种非阻塞的原子操作虽然说相对原有的阻塞算法来说已经很好了，但是在高并发下多线程同时竞争一个原子变量的更新操作，由于同一时间只会有一个线程CAS操作成功，**会造成大量的线程竞争失败后无限尝试重试**。这无疑浪费了很多开销。JDK8的LongAdder，就能解决高并发的递增或递减的原子操作。\n\n\n\n使用AtomicLong和LongAdder的流程图大致如下：\n\n![img](http://pcc.huitogo.club/23c6a670d08ea109223cb1efc41c3d17)\n\n\n\n**1. 先看一下LongAdder的父类Striped64的成员变量**\n\n```\n1.  static final int NCPU = Runtime.getRuntime().availableProcessors();  \n\n2.  transient volatile Cell[] cells;  \n\n3.  transient volatile long base;  \n\n4.  transient volatile int cellsBusy; \n```\n\n1）NCPU\n\n获取当前所有CPU的核心数总和，用于扩容的判断条件。\n\n2）Cell[] cells\n\n存放Cell的hash表，大小为2的幂\n\n3）long base\n\n基础值，在没有竞争时会更新这个值；在cells初始化的过程中，cells处于不可用的状态，这时候也会尝试将通过cas操作值累加到base\n\n\n\nCell[] cells 和 long base是保存数据的方法，AtomicInteger只有一个value，所有线程累加都要通过cas竞争value这一个变量，高并发下线程争用非常严重；\n\nLongAdder则有两个值用于累加，一个是base，它的作用类似于AtomicInteger里面的value，在没有竞争的情况不会用到cells数组，它为null，这时使用base做累加，有了竞争后cells数组就上场了，第一次初始化长度为2，以后每次扩容都是变为原来的两倍，直到cells数组的长度大于等于当前服务器cpu的数量为止就不在扩容（因为在线程数大于CPU的时候会发生更多的CAS失败）；每个线程会通过线程对cells[threadLocalRandomProbe%cells.length] 位置的Cell对象中的value做累加，这样相当于将线程绑定到了cells中的某个cell对象上；\n\n4）cellsBusy\n\n它有两个值0 或1，它的作用是当要修改cells数组时加锁，防止多线程同时修改cells数组，0为无锁，1为加锁，加锁的状况有三种\n\nA. cells数组初始化的时候；\n\nB. cells数组扩容的时候；\n\nC. 如果cells数组中某个元素为null，给这个位置创建新的Cell对象的时候；\n\n\n\n**2. LongAdder的数据单元模块是Cell，看一下Cell**\n\n```\n1.  @sun.misc.Contended static final class Cell {  \n\n2.          volatile long value;  \n\n3.          Cell(long x) { value = x; }  \n\n4.          final boolean cas(long cmp, long val) {  \n\n5.              return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val);  \n\n6.          }  \n\n7.          private static final sun.misc.Unsafe UNSAFE;  \n\n8.          private static final long valueOffset;  \n\n9.          static {  \n\n10.             ... // 初始化valueOffset  \n\n11.         }  \n\n12.     } \n```\n\n我们可以看到每一个Cell在初始化的时候long value = 0，每一次的原子操作相当于是调用了单个数组对象的CAS，也就是说如果失败重试那么仅仅只会影响这个数组对象。\n\n**注意的是这里@Contended用来避免CPU缓存行伪共享的问题（伪共享的详情看下面）。**\n\n\n\n**3. LongAdder的核心方法**\n\n**3.1 sum() 求和**\n\n```\n1.  public long sum() {  \n\n2.      Cell[] as = cells; Cell a;  \n\n3.      long sum = base;  \n\n4.      if (as != null) {  \n\n5.          for (int i = 0; i < as.length; ++i) {  \n\n6.              if ((a = as[i]) != null)  \n\n7.                  sum += a.value;  \n\n8.          }  \n\n9.      }  \n\n10.     return sum;  \n\n11. }  \n```\n\n可以看出LongAdder的数据和是有base数据和cell数组的数据和组成\n\n\n\n**3.2 add(long x) 累加值**\n\n```\n1.  public void add(long x) {  \n\n2.       Cell[] as; long b, v; int m; Cell a;  \n\n3.       if ((as = cells) != null || !casBase(b = base, b + x)) {   //（1）和（2）\n\n4.           boolean uncontended = true;  \n\n5.           if (as == null || (m = as.length - 1) < 0 ||   // （3）\n\n6.               (a = as[getProbe() & m]) == null ||   // （4）\n\n7.               !(uncontended = a.cas(v = a.value, v + x)))   // （5）\n\n8.               longAccumulate(x, null, uncontended);  \n\n9.       }  \n\n10.  }  \n```\n\n从上面代码可以看到\n\n1. 如果cell数组不为空的话，直接cas累加base的值，这个就类似于AtomLong了。\n2. 如果cell数组不为空，cas设置base值失败的话，开始计算当前线程应该访问cells中的哪个元素。\n3. 如果cell数组为空，直接调用longAccumulate进行cell数组初始化，初始大小为2，后面扩容都是2的幂数。\n4. 如果cells被初始化，且它的长度不为0，则通过getProbe方法获取当前线程Thread的threadLocalRandomProbe变量的值，初始为0，然后执行threadLocalRandomProbe&(cells.length-1),相当于m%cells.length;如果cells[threadLocalRandomProbe%cells.length]的位置为null，这说明这个位置从来没有线程做过累加，需要进入if继续执行，在这个位置创建一个新的Cell对象（cellBusy锁住cell数组，生成新的cell，将累积值x作为初始值）。\n5. 尝试cas累积映射元素的值，如果失败（当前位置有冲突）就调用longAccumulate重新获取映射元素。\n\n\n\n**4. Striped64的longAccumulate方法**\n\nLongAdder的add方法适用于cell存在且更新无竞争的情况，累积在base值即可，在发生竞争时则需要执行Striped4的longAccumulate方法（初始化cell数组、获取线程探针（映射元素）、设置cell[x]的值，case累积cell的value、进行扩容、累积base值等操作）\n\n\n\n先上源码\n\n```\n1.  final void longAccumulate(long x, LongBinaryOperator fn,  boolean wasUncontended) {   // 累积值、双目运算符、是否有竞争\n\n3.       int h;  \n\n4.       if ((h = getProbe()) == 0) {  \n\n5.            // 未初始化的  \n\n6.            ThreadLocalRandom.current();  // 强制初始化  \n\n7.            h = getProbe();  \n\n8.            wasUncontended = true;  \n\n9.       }  \n\n10.      // 最后的槽不为空则 true，也用于控制扩容，false重试。  \n\n11.      boolean collide = false;  \n\n12.      for (;;) {  \n\n13.           Cell[] as; Cell a; int n; long v;  \n\n14.           if ((as = cells) != null && (n = as.length) > 0) {  \n\n15.                // 表已经初始化  \n\n16.                if ((a = as[(n - 1) & h]) == null) {  \n\n17.                     // 线程所映射到的槽是空的。  \n\n18.                     if (cellsBusy == 0) {       // 尝试关联新的Cell  \n\n19.                          // 锁未被使用，乐观地创建并初始化cell。  \n\n20.                          Cell r = new Cell(x);  \n\n21.                          if (cellsBusy == 0 && casCellsBusy()) {  \n\n22.                               // 锁仍然是空闲的、且成功获取到锁  \n\n23.                               boolean created = false;  \n\n24.                               try {          // 在持有锁时再次检查槽是否空闲。  \n\n25.                                    Cell[] rs; int m, j;  \n\n26.                                    if ((rs = cells) != null &&  \n\n27.                                         (m = rs.length) > 0 &&  \n\n28.                                         rs[j = (m - 1) & h] == null) {  \n\n29.                                         // 所映射的槽仍为空  \n\n30.                                         rs[j] = r;         // 关联 cell 到槽  \n\n31.                                         created = true;  \n\n32.                                    }  \n\n33.                               } finally {  \n\n34.                                    cellsBusy = 0;     // 释放锁  \n\n35.                               }  \n\n36.                               if (created)  \n\n37.                                    break;       // 成功创建cell并关联到槽，退出  \n\n38.                               continue;       // 槽现在不为空了  \n\n39.                          }  \n\n40.                     }  \n\n41.                     // 锁被占用了，重试  \n\n42.                     collide = false;  \n\n43.                }  \n\n44.                // 槽被占用了  \n\n45.                else if (!wasUncontended)      // 已经知道 CAS 失败  \n\n46.                     wasUncontended = true;     // 在重散列后继续  \n\n47.                // 在当前槽的cell上尝试更新  \n\n48.                else if (a.cas(v = a.value, ((fn == null) ? v + x :   fn.applyAsLong(v, x))))  \n\n50.                     break;  \n\n51.                // 表大小达到上限或扩容了；  \n\n52.                // 表达到上限后就不会再尝试下面if的扩容了，只会重散列，尝试其他槽  \n\n53.                else if (n >= NCPU || cells != as)  \n\n54.                     collide = false;       // At max size or stale  \n\n55.                //  如果不存在冲突，则设置为存在冲突  \n\n56.                else if (!collide)  \n\n57.                     collide = true;  \n\n58.                // 有竞争，需要扩容  \n\n59.                else if (cellsBusy == 0 && casCellsBusy()) {  \n\n60.                     // 锁空闲且成功获取到锁  \n\n61.                     try {  \n\n62.                          if (cells == as) {     // 距上一次检查后表没有改变，扩容：加倍  \n\n63.                               Cell[] rs = new Cell[n << 1];  \n\n64.                               for (int i = 0; i < n; ++i)  \n\n65.                                    rs[i] = as[i];  \n\n66.                               cells = rs;  \n\n67.                          }  \n\n68.                     } finally {  \n\n69.                          cellsBusy = 0;    // 释放锁  \n\n70.                     }  \n\n71.                     collide = false;  \n\n72.                     continue;        // 在扩容后的表上重试  \n\n73.                }  \n\n74.                // 没法获取锁，重散列，尝试其他槽  \n\n75.                h = advanceProbe(h);  \n\n76.           }  \n\n77.           else if (cellsBusy == 0 && cells == as && casCellsBusy()) {  \n\n78.                // 加锁的情况下初始化表  \n\n79.                boolean init = false;  \n\n80.                try {         // Initialize table  \n\n81.                     if (cells == as) {  \n\n82.                          Cell[] rs = new Cell[2];  \n\n83.                          rs[h & 1] = new Cell(x);  \n\n84.                          cells = rs;  \n\n85.                          init = true;  \n\n86.                     }  \n\n87.                } finally {  \n\n88.                     cellsBusy = 0;     // 释放锁  \n\n89.                }  \n\n90.                if (init)  \n\n91.                     break;     // 成功初始化，已更新，跳出循环  \n\n92.           }  \n\n93.           else if (casBase(v = base, ((fn == null) ? v + x :   fn.applyAsLong(v, x))))  \n\n95.                // 表未被初始化，可能正在初始化，回退使用 base。  \n\n96.                break;       // 回退到使用 base  \n\n97.      }  \n\n98. }  \n```\n\n\n\n整理流程可以解释如下：\n\n```\nif 表已初始化\n\n    if 映射到的槽是空的，加锁后再次判断，如果仍然是空的，初始化cell并关联到槽。\n\n    else if （槽不为空）在槽上之前的CAS已经失败，重试。\n\n    else if （槽不为空、且之前的CAS没失败，）在此槽的cell上尝试更新\n\n    else if 表已达到容量上限或被扩容了，重试。\n\n    else if 如果不存在冲突，则设置为存在冲突，重试。\n\n    else if 如果成功获取到锁，则扩容。\n\n    else 重散列，尝试其他槽。\n\nelse if 锁空闲且获取锁成功，初始化表\n\nelse if 回退 base 上更新且成功则退出\n\nelse 继续下一次循环\n```\n\n\n\n**5. 线程怎么映射位置的**\n\nhash是LongAdder定位当前线程应该将值累加到cells数组哪个位置上的，所以hash的算法是非常重要的\n\njava的Thread类里面有一个成员变量\n\n```\n1.  @sun.misc.Contended(\"tlr\")  \n\n2.    int threadLocalRandomProbe;  \n```\n\nthreadLocalRandomProbe这个变量的值就是LongAdder用来hash定位Cells数组位置的，平时线程的这个变量一般用不到，它的值一直都是0。\n\n\n\n在LongAdder的父类Striped64里通过getProbe方法获取当前线程threadLocalRandomProbe的值\n\n```\n1.  static final int getProbe() {  \n\n2.      //PROBE是threadLocalRandomProbe变量在Thread类里面的偏移量，所以下面语句获取的就是threadLocalRandomProbe的值；  \n\n3.      return UNSAFE.getInt(Thread.currentThread(), PROBE);  \n\n4.  }  \n```\n\n\n\n线程对LongAdder的累加操作，在没有进入longAccumulate方法前，threadLocalRandomProbe一直都是0，当发生争用后才会进入longAccumulate方法中，进入该方法第一件事就是判断threadLocalRandomProbe是否为0，如果为0，则将其设置为**0x9e3779b9**\n\n```\n1.  int h;  \n\n2.  if ((h = getProbe()) == 0) {  \n\n3.      ThreadLocalRandom.current();   \n\n4.      h = getProbe();  \n\n5.      //设置未竞争标记为true  \n\n6.      wasUncontended = true;  \n\n7.  }\n```\n\n重点在这行ThreadLocalRandom.current();\n\n```\n1.  public static ThreadLocalRandom current() {  \n\n2.      if (UNSAFE.getInt(Thread.currentThread(), PROBE) == 0)  \n\n3.          localInit();  \n\n4.      return instance;  \n\n5.  }  \n```\n\n\n\n在current方法中判断如果probe的值为0，则执行locaInit()方法，将当前线程的probe设置为非0的值，该方法实现如下：\n\n```\n1.  static final void localInit() {  \n\n2.      //private static final AtomicInteger probeGenerator = new AtomicInteger();  \n\n3.      //private static final int PROBE_INCREMENT = 0x9e3779b9;  \n\n4.      int p = probeGenerator.addAndGet(PROBE_INCREMENT);  \n\n5.      //prob不能为0  \n\n6.      int probe = (p == 0) ? 1 : p; // skip 0  \n\n7.      long seed = mix64(seeder.getAndAdd(SEEDER_INCREMENT));  \n\n8.      //获取当前线程  \n\n9.      Thread t = Thread.currentThread();  \n\n10.     UNSAFE.putLong(t, SEED, seed);  \n\n11.     //将probe的值更新为probeGenerator的值  \n\n12.     UNSAFE.putInt(t, PROBE, probe);  \n\n13. } \n```\n\n\n\nprobeGenerator 是static类型的AtomicInteger类，**每执行一次localInit()方法，都会将probeGenerator累加一次0x9e3779b9这个值**，0x9e3779b9这个数字的得来是 2^32除以一个常数，这个常数就是传说中的黄金比例1.6180339887；然后将当前线程的threadLocalRandomProbe设置为probeGenerator的值，如果probeGenerator 为0，这取1\n\n\n\n**6. 扩容之后怎么重新定位线程的位置？**\n\n将prob的值左右移位 、异或操作三次\n\n```\n1.  static final int advanceProbe(int probe) {  \n\n2.      probe ^= probe << 13;   // xorshift  \n\n3.      probe ^= probe >>> 17;  \n\n4.      probe ^= probe << 5;  \n\n5.      UNSAFE.putInt(Thread.currentThread(), PROBE, probe);  \n\n6.      return probe;  \n\n7.  }  \n```\n\n\n\n**7. 总结一下Striped64的设计思路**\n\n表的条目是 **Cell 类**，一个**填充过**（通过 sun.misc.**Contended** ）的AtomicLong 的变体，用于减少缓存竞争。填充对于多数 Atomics 是过度杀伤的，因为它们一般不规则地分布在内存里，因此彼此间不会有太多冲突。但**存在于数组的原子对象将倾向于彼此相邻地放置，因此将通常共享缓存行**（对性能有巨大的副作用），在没有这个防备下。\n\n部分地，因为Cell相对比较大，我们避免创建它们直到需要时。**当没有竞争时，所有的更新都作用到base 字段**。根据第一次竞争（更新 base 的 CAS 失败），表被**初始化为大小2**。表的大小根据更多的竞争加倍，直到大于或等于CPU数量的最小的 2的幂。表的槽在它们需要之前保持空。\n\n一个单独的**自旋锁（“cellsBusy”）用于初始化和resize表**，还有用新的Cell填充槽。不需要阻塞锁，当锁不可得，线程尝试其他槽（或 base）。在这些重试中，会增加竞争和减少本地性，这仍然好于其他选择。\n\n通过 **ThreadLocalRandom 维护线程探针**字段，作为每线程的哈希码。我们让它们为 0来保持未初始化直到它们在槽 0竞争。然后初始化它们为通常不会互相冲突的值。当执行更新操作时，竞争和/或表冲突通过失败了的CAS来指示。根据冲突，如果表的大小小于容量，它的大小加倍，除非有些线程持有了锁。如果一个哈希后的槽是空的，且锁可得，创建新的Cell。否则，如果槽存在，重试CAS。**重试通过 “重散列，double hashing”来继续**，使用一个次要的哈希算法（Marsaglia XorShift）来尝试找到一个自由槽位。\n\n**表的大小是有上限**的，因为，当线程数多于CPU数时，假如每个线程绑定到一个CPU上，存在一个完美的哈希函数映射线程到槽上，消除了冲突。当我们到达容量，我们随机改变碰撞线程的哈希码搜索这个映射。因为搜索是随机的，冲突只能通过CAS失败来知道，收敛convergence 是慢的，因为**线程通常不会一直绑定到CPU上，可能根本不会发生**。然而，尽管有这些限制，在这些案例下观察到的竞争频率显著降低。\n\n当哈希到特定 Cell 的线程终止后，**Cell可能变为空闲的**，表加倍后导致没有线程哈希到扩展的 Cell也会出现这种情况。**我们不尝试去检测或移除这些Cell**，在实例长期运行的假设下，观察到的竞争水平将重现，所以 **Cell将最终被再次需要**。对于短期存活的实例，这没关系。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "72541cc4b89e2c5e6c217488719fa70c": {"id": "72541cc4b89e2c5e6c217488719fa70c", "item": "Java基础", "title": "PriorityQueue源码分析", "date": "2024-08-22", "summary": "PriorityQueue 是 Java 中的优先队列。它基于堆数据结构实现，能自动对元素进行排序。元素按照优先级顺序出队，优先级高的元素先出队。可自定义比较器决定优先级规则，常用于需要按特定顺序处理元素的场景，如任务调度等。", "body": "\n#### 1. PriorityQueue的数据结构\n\n- **PriorityQueue的内部结构是按照小顶堆的结构进行存储的**\n- **PriorityQueue不允许有空元素**\n\nPriorityQueue也是Queue的一个继承者，相比于一般的列表，它的特点便如它的名字一样，出队的时候可以按照优先级进行出队，所以不像LinkedList那样只能按照插入的顺序出队，PriorityQueue是可以根据给定的优先级顺序进行出队的。这里说的给定优先级顺序既可以是内部比较器，也可以是外部比较器。PriorityQueue内部是根据小顶堆的结构进行存储的，所谓小顶堆的意思，便是最小的元素总是在最上面，每次出队总是将堆顶元素移除，这样便能让出队变得有序。\n\n\n\n**Q1：什么是堆？**\n\n堆（英语：Heap）是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。\n\n\n\n**Q2：什么是二叉堆？**\n\n二叉堆（英语：binary heap）是一种特殊的堆，**二叉堆是完全二叉树或者是近似完全二叉树**。二叉堆满足堆特性：父节点的键值总是保持固定的序关系于任何一个子节点的键值，且每个节点的左子树和右子树都是一个二叉堆。\n\n\n\n**Q3：什么是完全二叉树？**\n\n在满二叉树的基础上叶子节点可以不是满的。\n\n\n\n**Q4：什么是大顶堆和小顶堆？**\n\n当父节点的键值总是大于或等于任何一个子节点的键值时为大顶堆。\n\n![img](http://pcc.huitogo.club/1067f009d7b7574ef662c8927ddd43b1)\n\n\n\n当父节点的键值总是小于或等于任何一个子节点的键值时为小顶堆。\n\n![img](http://pcc.huitogo.club/16bc42d3bca51e23d90cf31054fb520a)\n\n\n\n大顶堆或者小顶堆因为自己的特点，所以可以用数组表示\n\n下面是一个由10，16，20，22，18，25，26，30，24，23构成的小顶堆：\n\n![img](http://pcc.huitogo.club/d60d322460e29b0e0b1482fdb23b2628)\n\n将其从第一个元素开始依次从上到下，从左到右给每个元素添加一个序号，从0开始，这样就得到了相应元素在数组中的位置，而且这个序号是很有规则的，第**k个元素的左孩子的序号为2k+1，右孩子的序号为2k+2**，这样就很容易根据序号直接算出对应孩子的位置，**时间复杂度为o(1)**。这也就是为什么可以用数组来存储堆结构的原因了\n\n\n\n#### 2. PriorityQueue的继承结构\n\n![img](http://pcc.huitogo.club/727c7543dfb2befe35d8114b8d516709)\n\n\n\n#### 3. 内部成员\n\n```\n3.  // 默认初始化容量  \n\n4.  private static final int DEFAULT_INITIAL_CAPACITY = 11;  \n\n5.  /** \n\n6.   * 优先级队列是使用平衡二叉堆表示的: 节点queue[n]的两个孩子分别为 \n\n7.   * queue[2*n+1] 和 queue[2*(n+1)].  队列的优先级是由比较器或者 \n\n8.   * 元素的自然排序决定的， 对于堆中的任意元素n，其后代d满足：n<=d \n\n9.   * 如果堆是非空的，则堆中最小值为queue[0]。 \n\n10.  */  \n\n11. transient Object[] queue;   \n\n12. /** \n\n13.  * 队列中元素个数 \n\n14.  */  \n\n15. private int size = 0;  \n\n16. /** \n\n17.  * 比较器 \n\n18.  */  \n\n19. private final Comparator<? super E> comparator;  \n\n20. /** \n\n21.  * 修改次数 \n\n22.  */  \n\n23. transient int modCount = 0;   \n```\n\n内部使用的是一个Object数组进行元素的存储，并对该数组进行了详细的注释，所以不管是根据子节点找父节点，还是根据父节点找子节点都非常的方便。\n\n\n\n#### 4. 构造函数\n\n1）使用指定容量创建一个优先级队列，并使用指定比较器进行排序\n\n```\n3.  /** \n\n4.   * 使用指定容量创建一个优先级队列，并使用指定比较器进行排序。 \n\n5.   * 但如果指定的容量小于1则会抛出异常 \n\n6.   */  \n\n7.  public PriorityQueue(int initialCapacity,  Comparator<? super E> comparator) {  \n\n9.      if (initialCapacity < 1)  \n\n10.         throw new IllegalArgumentException();  \n\n11.     this.queue = new Object[initialCapacity];  \n\n12.     this.comparator = comparator;  \n\n13. }  \n```\n\n\n\n2）使用指定集合的所有元素构造一个优先级队列\n\n```\n15. /** \n\n16.  * 使用指定集合的所有元素构造一个优先级队列， \n\n17.  * 如果该集合为SortedSet或者PriorityQueue类型，则会使用相同的顺序进行排序， \n\n18.  * 否则，将使用元素的自然排序（此时元素必须实现comparable接口），否则会抛出异常 \n\n19.  * 并且集合中不能有null元素，否则会抛出异常 \n\n20.  */  \n\n21. @SuppressWarnings(\"unchecked\")  \n\n22. public PriorityQueue(Collection<? extends E> c) {  \n\n23.     if (c instanceof SortedSet<?>) {  \n\n24.         SortedSet<? extends E> ss = (SortedSet<? extends E>) c;  \n\n25.         this.comparator = (Comparator<? super E>) ss.comparator();  \n\n26.         **initElementsFromCollection(ss)**;  \n\n27.     }  \n\n28.     else if (c instanceof PriorityQueue<?>) {  \n\n29.         PriorityQueue<? extends E> pq = (PriorityQueue<? extends E>) c;  \n\n30.         this.comparator = (Comparator<? super E>) pq.comparator();  \n\n31.         **initFromPriorityQueue(pq)**;  \n\n32.     }  \n\n33.     else {  \n\n34.         this.comparator = null;  \n\n35.         **initFromCollection(c)**;  \n\n36.     }  \n\n37. }  \n```\n\n\n\n从集合中构造优先级队列的时候，调用了几个初始化函数\n\ninitFromPriorityQueue(pq)代码\n\n```\n1.  private void initFromPriorityQueue(PriorityQueue<? extends E> c) {  \n\n2.      if (c.getClass() == PriorityQueue.class) {  \n\n3.          this.queue = c.toArray();  \n\n4.          this.size = c.size();  \n\n5.      } else {  \n\n6.          initFromCollection(c);  \n\n7.      }  \n\n8.  }  \n```\n\n\n\ninitFromCollection(c)代码\n\n```\n1.  private void initFromCollection(Collection<? extends E> c) {  \n\n2.      initElementsFromCollection(c);  \n\n3.      heapify();  \n\n4.  }  \n```\n\n\n\ninitElementsFromCollection(ss)代码\n\n```\n1.  private void initElementsFromCollection(Collection<? extends E> c) {  \n\n2.      Object[] a = c.toArray();  \n\n3.      // If c.toArray incorrectly doesn't return Object[], copy it.  \n\n4.      if (a.getClass() != Object[].class)  \n\n5.          a = Arrays.copyOf(a, a.length, Object[].class);  \n\n6.      int len = a.length;  \n\n7.      if (len == 1 || this.comparator != null)  \n\n8.          for (int i = 0; i < len; i++)  \n\n9.              if (a[i] == null)  \n\n10.                 throw new NullPointerException();  \n\n11.     this.queue = a;  \n\n12.     this.size = a.length;  \n\n13. }  \n```\n\n\n\ninitFromPriorityQueue从另外一个优先级队列构造一个新的优先级队列，此时内部的数组元素不需要进行调整，只需要将原数组元素都复制过来即可。但是从其他非PriorityQueue的集合中构造优先级队列时，需要先将元素复制过来后再进行调整，调整主要使用的是上面的heapify方法：\n\n```\n1.  private void heapify() {  \n\n2.      // 从最后一个非叶子节点开始从下往上调整  \n\n3.      for (int i = (size >>> 1) - 1; i >= 0; i--)  \n\n4.         siftDown(i, (E) queue[i]);  \n\n5.  }  \n\n\n6.  // 划重点了，这个函数即对应上面的元素删除时从上往下调整的步骤  \n\n7.  private void siftDown(int k, E x) {  \n\n8.      if (comparator != null)  \n\n9.          // 如果比较器不为null，则使用比较器进行比较  \n\n10.         siftDownUsingComparator(k, x);  \n\n11.     else  \n\n12.         // 否则使用元素的compareTo方法进行比较  \n\n13.         siftDownComparable(k, x);  \n\n14. }  \n\n\n15. private void siftDownUsingComparator(int k, E x) {  \n\n16.     // 使用half记录队列size的一半，如果比half小的话，说明不是叶子节点  \n\n17.     // 因为最后一个节点的序号为size - 1，其父节点的序号为(size - 2) / 2或者(size - 3 ) / 2  \n\n18.     // 所以half所在位置刚好是第一个叶子节点  \n\n19.     int half = size >>> 1;  \n\n20.     while (k < half) {  \n\n21.         // 如果不是叶子节点，找出其孩子中较小的那个并用其替换  \n\n22.         int child = (k << 1) + 1;  \n\n23.         Object c = queue[child];  \n\n24.         int right = child + 1;  \n\n25.         if (right < size && comparator.compare((E) c, (E) queue[right]) > 0)  \n\n27.             c = queue[child = right];  \n\n28.         if (comparator.compare(x, (E) c) <= 0)  \n\n29.             break;  \n\n30.         // 用c替换  \n\n31.         queue[k] = c;  \n\n32.         k = child;  \n\n33.     }  \n\n35.     queue[k] = x;  \n\n36. }  \n\n37. // 同上，只是比较的时候使用的是元素的compareTo方法  \n\n\n38. private void siftDownComparable(int k, E x) {  \n\n39.     Comparable<? super E> key = (Comparable<? super E>)x;  \n\n40.     int half = size >>> 1;        // 如果是非叶子节点则继续循环  \n\n41.     while (k < half) {  \n\n42.         int child = (k << 1) + 1;  \n\n43.         Object c = queue[child];  \n\n44.         int right = child + 1;  \n\n45.         if (right < size && ((Comparable<? super E>) c).compareTo((E) queue[right]) > 0)  \n\n47.             c = queue[child = right];  \n\n48.         if (key.compareTo((E) c) <= 0)  \n\n49.             break;  \n\n50.         queue[k] = c;  \n\n51.         k = child;  \n\n52.     }  \n\n53.     queue[k] = key;  \n\n54. }  \n```\n\n\n\n上述调整的过程来举个例说明一下：\n\n比如初始集合是{14,7,12,6,9,4,17,23,10,15,3}，调整过程如下：\n\n**从最后一个非叶子节点从下往上调整**\n\n![img](http://pcc.huitogo.club/3a8db0c7bce1eaa992d2c180862ece78)\n\n![img](http://pcc.huitogo.club/937bd7bde0c028083f00c602c1b2ea33)\n\n\n\nsiftDown( 3,queue[3])不需要调整，跳过\n\n![img](http://pcc.huitogo.club/e3a0857b9d1c9f533c189c75ada82482)\n\n\n\nsiftDown( 1,queue[1])不需要调整，跳过\n\n![img](http://pcc.huitogo.club/109fb4dc013391077d1ba326c825d1c2)\n\n\n\n这样最小的元素就被顶上去了，有没有觉得有点像冒泡排序\n\n有对应的向下调整自然有相应的向上调正，并且**siftDown和siftUp是PriorityQueue的核心方法**。下面是siftUp的代码，和siftDown的实现十分类似。\n\n```\n1.  private void siftUp(int k, E x) {  \n\n2.      if (comparator != null)  \n\n3.          siftUpUsingComparator(k, x);  \n\n4.      else  \n\n5.          siftUpComparable(k, x);  \n\n6.  }  \n\n\n7.  @SuppressWarnings(\"unchecked\")  \n\n8.  private void siftUpComparable(int k, E x) {  \n\n9.      Comparable<? super E> key = (Comparable<? super E>) x;  \n\n10.     while (k > 0) {  \n\n11.         int parent = (k - 1) >>> 1;  \n\n12.         Object e = queue[parent];  \n\n13.         if (key.compareTo((E) e) >= 0)  \n\n14.             break;  \n\n15.         queue[k] = e;  \n\n16.         k = parent;  \n\n17.     }  \n\n18.     queue[k] = key;  \n\n19. }  \n\n\n20. @SuppressWarnings(\"unchecked\")  \n\n21. private void siftUpUsingComparator(int k, E x) {  \n\n22.     while (k > 0) {  \n\n23.         int parent = (k - 1) >>> 1;  \n\n24.         Object e = queue[parent];  \n\n25.         if (comparator.compare(x, (E) e) >= 0)  \n\n26.             break;  \n\n27.         queue[k] = e;  \n\n28.         k = parent;  \n\n29.     }  \n\n30.     queue[k] = x;  \n\n31. }  \n```\n\n\n\n#### 5. 主要方法源码\n\n##### 5.1 add\n\n```\n34. public boolean add(E e) {  \n\n35.     return offer(e);  \n\n36. }  \n\n\n37. public boolean offer(E e) {  \n\n38.     if (e == null)  \n\n39.         throw new NullPointerException();  \n\n40.     modCount++;  \n\n41.     int i = size;  \n\n42.     if (i >= queue.length)  \n\n43.         grow(i + 1);  \n\n44.     size = i + 1;  \n\n45.     if (i == 0)  \n\n46.         queue[0] = e;  \n\n47.     else  \n\n48.         siftUp(i, e);  \n\n49.     return true;  \n\n50. }  \n```\n\n\n\n增加过程免不了要扩容，PriortyQueue的扩容很简单，**如果当前容量比较小（小于64）的话进行双倍扩容，否则扩容50%**，源码如下：\n\n```\n1.  // 扩容函数  \n\n2.  private void grow(int minCapacity) {  \n\n3.      int oldCapacity = queue.length;  \n\n4.      // 如果当前容量比较小（小于64）的话进行双倍扩容，否则扩容50%  \n\n5.      int newCapacity = oldCapacity + ((oldCapacity < 64) ?  (oldCapacity + 2) : (oldCapacity >> 1));  \n\n8.      // 如果发现扩容后溢出了，则进行调整  \n\n9.      if (newCapacity - MAX_ARRAY_SIZE > 0)  \n\n10.         newCapacity = hugeCapacity(minCapacity);  \n\n11.     queue = Arrays.copyOf(queue, newCapacity);  \n\n12. }  \n\n\n13. // priorityQueue的最大容量  \n\n14. private static int hugeCapacity(int minCapacity) {  \n\n15.     if (minCapacity < 0) // overflow  \n\n16.         throw new OutOfMemoryError();  \n\n17.     return (minCapacity > MAX_ARRAY_SIZE) ?  \n\n18.         Integer.MAX_VALUE :  \n\n19.         MAX_ARRAY_SIZE;  \n\n20. }  \n```\n\n\n\n因为priorityQueue是一个单向Queue，**先进先出**的原则，所以添加也只能在**尾部添加**，在尾部添加完之后需要调整，下面就是添加一个元素15的示意图：\n\n![img](http://pcc.huitogo.club/c2f4c23dd0b4f835ff0d00cb3a7cbea4)\n\n![img](http://pcc.huitogo.club/d09fbcbc143c8324f6cc9155356a24f1)\n\n![img](http://pcc.huitogo.club/02f101f5c6ea3c477d0c6039731b7134)\n\n\n\n##### 5.2 remove\n\n删除元素分两种，一种是从顶部弹出元素，另一种是从数组中间删除元素\n\n第一种源码如下：\n\n```\n1.  public E poll() {  \n\n2.      if (size == 0)  \n\n3.          return null;  \n\n4.      int s = --size;  \n\n5.      modCount++;  \n\n6.      E result = (E) queue[0];  \n\n7.      E x = (E) queue[s];  \n\n8.      queue[s] = null;  \n\n9.      if (s != 0)  \n\n10.         siftDown(0, x);  \n\n11.     return result;  \n\n12. }  \n```\n\n\n\n从顶部弹出元素的示例图如下：\n\n![img](http://pcc.huitogo.club/caa297f18a23f2991e9bb5c19e6acec4)\n\n![img](http://pcc.huitogo.club/67b8b99a73610ec53aa49c6f65499cd6)\n\n![img](http://pcc.huitogo.club/a10b28f65f7d45462d7ec9bd629e2d1c)\n\n![img](http://pcc.huitogo.club/572d8a31d8beabde5c37083aec4ef303)\n\n原理就是**用最后的元素当替补，然后再从上往下进行调整**\n\n\n\n第二种源码如下：\n\n```\n1.  // 这里不是移除堆顶元素，而是移除指定元素  \n\n2.  public boolean remove(Object o) {  \n\n3.      // 先找到该元素的位置  \n\n4.      int i = indexOf(o);  \n\n5.      if (i == -1)  \n\n6.          return false;  \n\n7.      else {  \n\n8.          removeAt(i);  \n\n9.          return true;  \n\n10.     }  \n\n11. }  \n\n\n12. // 移除指定序号的元素  \n\n13. private E removeAt(int i) {  \n\n14.     // assert i >= 0 && i < size;  \n\n15.     modCount++;  \n\n16.     // s为最后一个元素的序号  \n\n17.     int s = --size;  \n\n18.     if (s == i)   \n\n19.         queue[i] = null;  \n\n20.     else {  \n\n21.         // moved记录最后一个元素的值  \n\n22.         E moved = (E) queue[s];  \n\n23.         queue[s] = null;  \n\n24.         // 用最后一个元素代替要移除的元素，并向下进行调整  \n\n25.         siftDown(i, moved);  \n\n26.         // 如果向下调整后发现moved还在该位置，则再向上进行调整  \n\n27.         if (queue[i] == moved) {  \n\n28.             siftUp(i, moved);  \n\n29.             if (queue[i] != moved)  \n\n30.                 return moved;  \n\n31.         }  \n\n32.     }  \n\n33.     return null;  \n\n34. }  \n```\n\n原理和第一个差不多，也是**用最后一个元素做替代，然后先从上往下调整，如果没有改动就再从下往上调整**。\n\n\n\n##### 5.3 indexof\n\n按元素查找下标：\n\n```\n1.  private int indexOf(Object o) {  \n\n2.      if (o != null) {  \n\n3.          // 查找时需要进行全局遍历，比搜索二叉树的查找效率要低  \n\n4.          for (int i = 0; i < size; i++)  \n\n5.              if (o.equals(queue[i]))  \n\n6.                  return i;  \n\n7.      }  \n\n8.      return -1;  \n\n9.  }  \n```\n\n\n\n查找元素是否存在：\n\n```\n1.  public boolean contains(Object o) {  \n\n2.      return indexOf(o) != -1;  \n\n3.  }  \n```\n\n\n\n#### 6. PriorityQueue的应用场景\n\n由于内部是用数组实现的小顶堆，所以堆适用的场景它都适用，比如典型的从n个元素中取出最小（最大）的前k个，这样的场景适用PriorityQueue就能以比较小的空间代价和还算ok的时间代价进行实现。\n\n另一种就是需要动态插入元素，并且元素有优先级，需要根据一定的规则进行优先级排序。比如任务队列，队列动态插入，后面的任务优先级高的需要被先执行，那么使用优先级队列就可以比较好的实现这样的需求。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "cb3c1d1abb23858c56c2871977979c3d": {"id": "cb3c1d1abb23858c56c2871977979c3d", "item": "Java基础", "title": "ReentrantLock加解锁流程", "date": "2024-08-22", "summary": "ReentrantLock中对共享资源的独占主要是通过AQS中的成员变量state来控制，通过CAS操作state值来实现加锁和释放锁。同时那些没有获取到锁的线程就会被放到AQS中维护的一个FIFO双向队列中，将它们阻塞起来，当state值被修改成0的时候（有线程释放锁了），这些线程会被唤醒去尝试修改state的值（获取锁）。", "body": "\nReentrantLock中对共享资源的独占主要是通过AQS中的成员变量state来控制，通过CAS操作state值来实现加锁和释放锁。同时那些没有获取到锁的线程就会被放到AQS中维护的一个FIFO双向队列中，将它们阻塞起来，当state值被修改成0的时候（有线程释放锁了），这些线程会被唤醒去尝试修改state的值（获取锁）。\n\n\n\n整个过程如下图\n\n![img](http://pcc.huitogo.club/88b658ccb23164875654dc6252f917e1)\n\n\n\n#### 1. lock方法\n\n```\n2.  public void lock() {  \n\n3.      sync.lock();  \n\n4.  }  \n```\n\n\n\n这里sync的设计使用了模板类，如下\n\n![img](http://pcc.huitogo.club/93b5e6c23745049e2af15c5cb5a7d29b)\n\n当ReentrantLock的构造是公平锁的时候，会调用FairSync.lock()，非公平锁的时候调用NonfairSync.lock()，所有释放锁和尝试获取锁也类似。\n\n\n\n我们先看看不公平锁，到底怎么不公平了？\n\nNonfairSync.lock()\n\n```\n1.  final void lock() {  \n\n2.      if (compareAndSetState(0, 1))  \n\n3.          setExclusiveOwnerThread(Thread.currentThread());  \n\n4.      else  \n\n5.          acquire(1);  \n\n6.  }  \n```\n\n这里就是CAS设置state的值，设置成功就留下名字证明当前资源被我占了（独占），设置设置失败的话会再给机会或者加入队列进行阻塞\n\n\n\nacquire方法\n\n```\n1.  public final void acquire(int arg) {  \n\n2.      if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  \n\n4.          selfInterrupt();  \n\n5.  } \n```\n\ntryAcquire方法尝试获取锁，如果成功就返回，如果不成功，则把当前线程和等待状态信息构建成一个Node节点，并将节点放入同步队列的尾部。然后为同步队列中的当前节点循环等待获取锁，直到成功。\n\n\n\n重点看下tryAcquire方法\n\n```\n1.  protected final boolean tryAcquire(int acquires) {  \n\n2.      return nonfairTryAcquire(acquires);  \n\n3.  }  \n\n4.  final boolean nonfairTryAcquire(int acquires) {  \n\n5.      final Thread current = Thread.currentThread();  \n\n6.      int c = getState();  \n\n7.      if (c == 0) {  \n\n8.          if (compareAndSetState(0, acquires)) {  \n\n9.              setExclusiveOwnerThread(current);  \n\n10.             return true;  \n\n11.         }  \n\n12.     }  \n\n13.     else if (current == getExclusiveOwnerThread()) {  \n\n14.         int nextc = c + acquires;  \n\n15.         if (nextc < 0) // overflow  \n\n16.             throw new Error(\"Maximum lock count exceeded\");  \n\n17.         setState(nextc);  \n\n18.         return true;  \n\n19.     }  \n\n20.     return false;  \n\n21. }  \n```\n\n可以看出线程还是在尝试修改state的值（获取锁），注意到tryAcquire的参数是1，也就是将state的值+1，这里为什么不直接将state的值在0到1之间转换呢？\n\n这里就体现ReentrantLock的锁**可重入性**了，在nonfairTryAcquire方法中会判断当前线程是不是锁的owner，如果是就不用再获取锁了，直接将state + 1，所以state的值可能是2、3、4等等，这里还有个细节就是判断state + 1 < 0，也就是超过int的边界了。\n\n\n\n回头看addWaiter方法\n\n```\n1.  private Node addWaiter(Node mode) {  \n\n2.      Node node = new Node(Thread.currentThread(), mode);  \n\n3.      Node pred = tail;  \n\n4.      if (pred != null) {  \n\n5.          node.prev = pred;  \n\n6.          if (compareAndSetTail(pred, node)) {  \n\n7.              pred.next = node;  \n\n8.              return node;  \n\n9.          }  \n\n10.     }  \n\n11.     enq(node);  \n\n12.     return node;  \n\n13. }  \n```\n\n也就是将当前Thread构造成Node放到AQS维护的双向队列的末尾，如果这个双向队列还没有创建（tail == null），先还要初始化。\n\naddWaiter方法返回新插入的Node作为acquireQueued方法的参数\n\n\n\nacquireQueued方法\n\n```\n1.  final boolean acquireQueued(final Node node, int arg) {  \n\n2.      boolean failed = true;  \n\n3.      try {  \n\n4.          boolean interrupted = false;  \n\n5.          for (;;) {  \n\n6.              final Node p = node.predecessor();  \n\n7.              if (p == head && tryAcquire(arg)) {  \n\n8.                  setHead(node);  \n\n9.                  p.next = null; // help GC  \n\n10.                 failed = false;  \n\n11.                 return interrupted;  \n\n12.             }  \n\n13.             if (shouldParkAfterFailedAcquire(p, node) &&  \n\n14.                 parkAndCheckInterrupt())  \n\n15.                 interrupted = true;  \n\n16.         }  \n\n17.     } finally {  \n\n18.         if (failed)  \n\n19.             cancelAcquire(node);  \n\n20.     }  \n\n21. }  \n```\n\n可以看出acquireQueued方法中一直在自旋，当前线程被唤醒后看看自己是不是队列中的第二个节点，如果是就尝试获取锁并将自身设置成头节点，如果不是或者获取失败将自己阻塞。\n\n\n\n检查自身是否安全（是否可以阻塞），shouldParkAfterFailedAcquire方法\n\n```\n1.  private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {  \n\n2.      int ws = pred.waitStatus;  \n\n3.      if (ws == Node.SIGNAL)  \n\n4.          return true;  \n\n5.      if (ws > 0) {  \n\n6.          do {  \n\n7.              node.prev = pred = pred.prev;  \n\n8.          } while (pred.waitStatus > 0);  \n\n9.          pred.next = node;  \n\n10.     } else {  \n\n11.         compareAndSetWaitStatus(pred, ws, Node.SIGNAL);  \n\n12.     }  \n\n13.     return false;  \n\n14. }  \n```\n\n如果当前节点前置节点状态是SIGNAL，就直接阻塞；如果是CANCELLED，就将当前节点连接到前面第一个waitstatus不是CANCELLED的节点（相当于剔除了CANCELLED节点）；其他状态就将前置节点状态设置成SIGNAL\n\n\n\n确认应该被阻塞后，调用parkAndCheckInterrupt方法\n\n```\n1.  private final boolean parkAndCheckInterrupt() {  \n\n2.      LockSupport.park(this);  \n\n3.      return Thread.interrupted();  \n\n4.  } \n```\n\nLockSupport.park()方法将当前线程挂起到WAITING状态，它需要等待一个中断、unpark方法来唤醒它。\n\n\n\n整个lock方法的流程如下\n\n![img](http://pcc.huitogo.club/f614767cc3626ea579d66f5f9d80d652)\n\n\n\n上面讲述的就是不公平锁获取到锁的步骤，那么公平锁有什么不一样？**为什么叫公平锁？**\n\n```\n1.  final void lock() {  \n\n2.      acquire(1);  \n\n3.  }  \n```\n\n\n\n可以看出公平锁不允许线程直接尝试设置state的值，而是排队tryAcquire\n\ntryAcquire\n\n```\n1.  protected final boolean tryAcquire(int acquires) {  \n\n2.      final Thread current = Thread.currentThread();  \n\n3.      int c = getState();  \n\n4.      if (c == 0) {  \n\n5.          if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) {  \n\n7.              setExclusiveOwnerThread(current);  \n\n8.              return true;  \n\n9.          }  \n\n10.     }  \n\n11.     else if (current == getExclusiveOwnerThread()) {  \n\n12.         int nextc = c + acquires;  \n\n13.         if (nextc < 0)  \n\n14.             throw new Error(\"Maximum lock count exceeded\");  \n\n15.         setState(nextc);  \n\n16.         return true;  \n\n17.     }  \n\n18.     return false;  \n\n19. }  \n```\n\n可以看出关键就在于hasQueuedPredecessors了，就是看看你是不是队列中第二个节点，如果不是，尝试获取锁的机会都没有。\n\n\n\n#### 2. unlock方法\n\n```\n2.  public void unlock() {  \n\n3.      sync.release(1);  \n\n4.  }  \n\n5.  public final boolean release(int arg) {  \n\n6.      if (tryRelease(arg)) {  \n\n7.          Node h = head;  \n\n8.          if (h != null && h.waitStatus != 0)  \n\n9.              unparkSuccessor(h);  \n\n10.         return true;  \n\n11.     }  \n\n12.     return false;  \n\n13. } \n```\n\n这里release会tryRelease释放当前锁并unparkSuccessor唤醒其他线程去争夺锁\n\n\n\ntryRelease方法\n\n```\n1.  protected final boolean tryRelease(int releases) {  \n\n2.      int c = getState() - releases;  \n\n3.      if (Thread.currentThread() != getExclusiveOwnerThread())  \n\n4.          throw new IllegalMonitorStateException();  \n\n5.      boolean free = false;  \n\n6.      if (c == 0) {  \n\n7.          free = true;  \n\n8.          setExclusiveOwnerThread(null);  \n\n9.      }  \n\n10.     setState(c);  \n\n11.     return free;  \n\n12. }  \n```\n\n这里就是判断state的值是不是0，只有当state为0才将锁的owner置为空，否则就将state - 1，因为之前讲的ReentrantLock锁的可重入性导致state的值可能不为1。\n\n\n\nunparkSuccessor方法\n\n```\n1.  private void unparkSuccessor(Node node) {  \n\n2.      int ws = node.waitStatus;  \n\n3.      if (ws < 0)  \n\n4.          compareAndSetWaitStatus(node, ws, 0);  \n\n5.      Node s = node.next;  \n\n6.      if (s == null || s.waitStatus > 0) {  \n\n7.          s = null;  \n\n8.          for (Node t = tail; t != null && t != node; t = t.prev)  \n\n9.              if (t.waitStatus <= 0)  \n\n10.                 s = t;  \n\n11.     }  \n\n12.     if (s != null)  \n\n13.         LockSupport.unpark(s.thread);  \n\n14. }\n```\n\n这里设置当前节点的waitstatus为0，然后唤醒它的后一个节点，如果后一个节点为空，就往后找第一个waitstatus不为CANCELLED的节点然后唤醒它。这里使用LockSupport.unpark方法将线程的状态变成RUNNING。\n\n\n\n#### 3. tryLock方法\n\ntryLock方法相当于直接调用NonfairSync.tryAcquire方法去尝试获取锁，如果获取失败不会将自身加入双向队列并阻塞。\n\n来看一下tryLock(long timeout, TimeUnit unit)怎么实现在规定时间内获取不到锁自动放弃的？\n\n```\n1.  public boolean tryLock(long timeout, TimeUnit unit)  \n\n2.          throws InterruptedException {  \n\n3.      return sync.tryAcquireNanos(1, unit.toNanos(timeout));  \n\n4.  }  \n\n5.  public final boolean tryAcquireNanos(int arg, long nanosTimeout)  \n\n6.          throws InterruptedException {  \n\n7.      if (Thread.interrupted())  \n\n8.          throw new InterruptedException();  \n\n9.      return tryAcquire(arg) ||  \n\n10.         doAcquireNanos(arg, nanosTimeout);  \n\n11. }  \n```\n\n\n\n核心在于doAcquireNanos方法，如果没有马上获取到锁就要执行这个方法\n\n```\n1.  private boolean doAcquireNanos(int arg, long nanosTimeout)  \n\n2.          throws InterruptedException {  \n\n3.      if (nanosTimeout <= 0L)  \n\n4.          return false;  \n\n5.      final long deadline = System.nanoTime() + nanosTimeout;  \n\n6.      final Node node = addWaiter(Node.EXCLUSIVE);  \n\n7.      boolean failed = true;  \n\n8.      try {  \n\n9.          for (;;) {  \n\n10.             final Node p = node.predecessor();  \n\n11.             if (p == head && tryAcquire(arg)) {  \n\n12.                 setHead(node);  \n\n13.                 p.next = null; // help GC  \n\n14.                 failed = false;  \n\n15.                 return true;  \n\n16.             }  \n\n17.             nanosTimeout = deadline - System.nanoTime();  \n\n18.             if (nanosTimeout <= 0L)  \n\n19.                 return false;  \n\n20.             if (shouldParkAfterFailedAcquire(p, node) && nanosTimeout > spinForTimeoutThreshold)  \n\n22.                 LockSupport.parkNanos(this, nanosTimeout);  \n\n23.             if (Thread.interrupted())  \n\n24.                 throw new InterruptedException();  \n\n25.         }  \n\n26.     } finally {  \n\n27.         if (failed)  \n\n28.             cancelAcquire(node);  \n\n29.     }  \n\n30. }  \n```\n\n这里核心就是使用了一个倒计时的概念，在规定时间内自旋等待获取锁，并且注意到park都是有时间限制的，调用的是LockSupport.parkNanos方法。\n\n关于ReentrantLock的Condition章节要在AQS详情里面讲，因为基本都是在AQS写的。\n\n\n\n#### 4. 总结\n\n1. ReentrantLock是基于AQS框架的，主要使用到AQS中的state和双向队列。\n2. ReentrantLock有较多的自旋CAS解决了多线程问题。\n3. 公平锁的情况优先进入双向队列的线程会被唤醒去获取锁，也有可能会获取失败。\n4. ReetrantLock是可重入的独占锁。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "1559f3c79d6cd138872967e850ed370a": {"id": "1559f3c79d6cd138872967e850ed370a", "item": "Java基础", "title": "ReferenceQueue源码分析", "date": "2024-08-22", "summary": "ReferenceQueue 是 Java 中的一个用于管理引用对象的队列。它与软引用、弱引用和虚引用配合使用，当被引用的对象被回收时，相应的引用对象会被加入到这个队列中。这有助于跟踪对象的回收情况，实现资源的有效管理。", "body": "\n#### 1. ReferenceQueue介绍\n\n**ReferenceQueue内部实现实际上是一个栈**\n\n\n\n下面是ReferenceQueue做数据监控的实例：\n\n```\n1.  private static ReferenceQueue<byte[]> rq = new ReferenceQueue<>();  \n\n2.  private static int _1M = 1024 * 1024;  \n\n\n3.  public static void main(String[] args) {  \n\n4.      Map<WeakReference<byte[]>, Object> map = new HashMap<>();   \n\n5.      Object value = new Object();  \n\n6.      Thread thread = new Thread(MyArrayDeque :: run);  \n\n7.      thread.setDaemon(true);  \n\n8.      thread.start();  \n\n9.      // 放入数据  \n\n10.     for(int i = 0; i < 100; i++) {  \n\n11.         byte[] bytes = new byte[_1M];  \n\n12.         WeakReference<byte[]> weakReference = new WeakReference<>(bytes, rq);  \n\n13.         map.put(weakReference, value);  \n\n14.     }  \n\n15.     System.out.println(\"map.size = \" + map.size());  \n\n16.     // 获取存活数据  \n\n17.     int aliveNum = 0;  \n\n18.     for(Entry<WeakReference<byte[]>, Object> entry : map.entrySet()) {  \n\n19.         if(entry != null) {  \n\n20.             if(entry.getKey().get() != null) {  \n\n21.                 aliveNum++;  \n\n22.             }  \n\n23.         }  \n\n24.     }  \n\n25.     System.out.println(\"100个对象存活的对象个数 = \" + aliveNum);  \n\n26. }  \n\n\n27. // 监控线程  \n\n28. public static void run() {  \n\n29.     int n=0;  \n\n30.     WeakReference k;  \n\n31.     try {  \n\n32.         while((k = (WeakReference) rq.remove()) != null) {  \n\n33.             System.out.println(++n + \"回收了\" + k);  \n\n34.         }  \n\n35.     } catch (InterruptedException e) {  \n\n36.         e.printStackTrace();  \n\n37.     }  \n\n38. }  \n```\n\n\n\n从上面实例我们知道，在map中的WeakReference对象失效后（被系统回收），会放入referenceQueue中，我们可以监控refenceQueue（通过阻塞的方式获取数据）来得知回收情况。\n\n\n\n#### 2. 成员变量\n\n```\n3.  static ReferenceQueue<Object> NULL = new Null<>();  \n\n4.  static ReferenceQueue<Object> ENQUEUED = new Null<>();  \n\n5.  // ReferenceQueue采用单链表的方式存储Reference\n\n6.  private volatile Reference<? extends T> head = null;\n\n7.  // 队列长度，线程安全\n\n8.  private long queueLength = 0;\n\n9.  // 加lock 做同步对象\n\n10. static private class Lock { };\n\n11. private Lock lock = new Lock();\n```\n\n\n\nNULL对象\n\n```\n1.  private static class Null<S> extends ReferenceQueue<S> {  \n\n2.      boolean enqueue(Reference<? extends S> r) {  \n\n3.          return false;  \n\n4.      }  \n\n5.  }  \n```\n\n在ReferenceQueue中入队（enqueue）时，将新来的Reference对象的queue置为ENQUEUED，在ReferenceQueue中出队（poll或者remove时），将被移除的Reference对象的queue置为NULL\n\n\n\n**Q1：这里为什么不直接new 两个ReferenceQueue，毕竟NULL只是简单继承了ReferenceQueue？**\n\n主要是因为ReferenceQueue的enqueue方法是加lock的，且**只用来给Reference类调用**，这里是**怕有人在ReferenceQueue中对NULL和ENQUEUED误操作**，即调用了enqueue方法，所以生成一个子类继承ReferenceQueue类并且覆盖了enqueue方法，直接return false。\n\n\n\n#### 3. 主要方法\n\n##### 3.1 入队\n\n```\n3.  // 这个方法仅会被Reference类调用  \n\n4.  boolean enqueue(Reference<? extends T> r) {   \n\n5.      synchronized (lock) {  \n\n6.          // 检测从获取这个锁之后，该Reference没有入队，并且没有被移除  \n\n7.          ReferenceQueue<?> queue = r.queue;  \n\n8.          if ((queue == NULL) || (queue == ENQUEUED)) {  \n\n9.              return false;  \n\n10.         }  \n\n11.         assert queue == this;  \n\n12.         // 将reference的queue标记为ENQUEUED  \n\n13.         r.queue = ENQUEUED;  \n\n14.         // 将r设置为链表的头结点  \n\n15.         r.next = (head == null) ? r : head;  \n\n16.         head = r;  \n\n17.         queueLength++;  \n\n18.         // 如果r的FinalReference类型，则将FinalRef+1  \n\n19.         if (r instanceof FinalReference) {  \n\n20.             sun.misc.VM.addFinalRefCount(1);  \n\n21.         }  \n\n22.         lock.notifyAll();  \n\n23.         return true;  \n\n24.     }  \n\n25. }  \n```\n\n这里是入队的方法，使用了lock对象锁进行同步，将传入的r添加到队列中，并重置头结点为传入的节点。\n\n\n\n##### 3.2  出队\n\n出队分两种，阻塞和非阻塞\n\n\n\n**非阻塞**，直接弹出头节点\n\n```\n1.  public Reference<? extends T> poll() {  \n\n2.      if (head == null)  \n\n3.          return null;  \n\n4.      synchronized (lock) {  \n\n5.          return  reallyPoll();  \n\n6.      }  \n\n7.  }  \n\n\n8.  private Reference<? extends T> reallyPoll() {       \n\n9.      Reference<? extends T> r = head;  \n\n10.     if (r != null) {  \n\n11.         head = (r.next == r) ? null : r.next;  \n\n13.         r.queue = NULL;  \n\n14.         r.next = r;  \n\n15.         queueLength--;  \n\n16.         if (r instanceof FinalReference) {  \n\n17.             sun.misc.VM.addFinalRefCount(-1);  \n\n18.         }  \n\n19.         return r;  \n\n20.     }  \n\n21.     return null;  \n\n22. }  \n```\n\n注意：**这里弹出的是头节点，也就是最新的元素，所以ReferenceQueue类似于Stack（先进后出）**\n\n\n\n**阻塞**，**阻塞到获取到一个Reference对象或者超时才会返回**\n\n```\n1.  /** \n\n2.    * 移除并返回队列首节点，此方法将阻塞到获取到一个Reference对象或者超时才会返回 \n\n3.    * timeout时间的单位是毫秒 \n\n4.    */  \n\n5.  public Reference<? extends T> remove(long timeout)  \n\n6.      throws IllegalArgumentException, InterruptedException{  \n\n7.      if (timeout < 0) {  \n\n8.          throw new IllegalArgumentException(\"Negative timeout value\");  \n\n9.      }  \n\n10.     synchronized (lock) {  \n\n11.         Reference<? extends T> r = reallyPoll();  \n\n12.         if (r != null) return r;  \n\n13.         long start = (timeout == 0) ? 0 : System.nanoTime();  \n\n14.         // 死循环，直到取到数据或者超时  \n\n15.         for (;;) {  \n\n16.            lock.wait(timeout);  \n\n17.             r = reallyPoll();  \n\n18.             if (r != null) return r;  \n\n19.             if (timeout != 0) {  \n\n20.                 // System.nanoTime方法返回的是纳秒，1毫秒=1纳秒*1000*1000  \n\n21.                 long end = System.nanoTime();  \n\n22.                 timeout -= (end - start) / 1000_000;  \n\n23.                 if (timeout <= 0) return null;  \n\n24.                 start = end;  \n\n25.             }  \n\n26.         }  \n\n27.     }  \n\n28. }  \n```\n\n\n\nremove方法和poll的区别就是它会**阻塞到超时或者取到一个Reference对象才会返回**。\n\n\n\n**Q1：在remove方法的阻塞时间内，lock锁是一直被占用的，那么其他需要用到lock锁的方法，比如enqueue可以使用吗？**\n\n答案是可以的，正如我们文章开头的例子里面，一边阻塞的从ReferenceQueue中获取数据，一边向HashMap中添加WeakReference对象，也就会触发WeakReference的enqueue方法。原因就是**虚拟机会通过其他方式将Reference对象塞进去**。（具体什么方式，呃呃呃）\n\n\n\n4. ### ReferenceQueue的应用场景\n\nReferenceQueue一般用来与SoftReference、WeakReference或者PhantomReference配合使用，将需要关注的引用对象注册到引用队列后，便可以通过监控该队列来判断关注的对象是否被回收，从而执行相应的方法\n\n\n\n主要使用场景：\n\n1. 使用引用队列进行数据监控，类似前面栗子的用法。\n2. 队列监控的反向操作，即意味着一个数据变化了，可以通过Reference对象反向拿到相关的数据，从而进行后续的处理。", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "24f96a6931eb8874daf50020a8cb5950": {"id": "24f96a6931eb8874daf50020a8cb5950", "item": "Java基础", "title": "Semaphore源码解析", "date": "2024-08-22", "summary": "Semaphore 是 Java 中的一种同步工具类。它通过控制一定数量的许可证来管理对共享资源的并发访问。可以限制同时访问资源的线程数量，当一个线程获取许可证后才能访问资源，使用完后释放许可证，方便实现资源的并发控制。", "body": "\nSemaphore是一种计数信号量，用于管理一组资源，内部是基于AQS的共享模式。它相当于给线程规定一个量从而控制允许活动的线程数。Semaphore更像一个许可证管理器。\n\n就好像我们小区的停车场，停车位肯定是有限的，在停车位满了的情况下只能等待别人把车子开走才能停进来，那么这个场景用Semaphore是可以实现的。\n\n\n\n简单的示例代码如下：\n\n```\n1.  public class SemaphoreTest {  \n\n2.      private Semaphore semaphore = new Semaphore(3,true);  \n\n3.      private ThreadPoolExecutor threadPool =  \n\n4.          new ThreadPoolExecutor(100, 1000, 1, TimeUnit.SECONDS, new LinkedBlockingQueue<>(1000));  \n\n5.      public static void main(String[] args) {  \n\n6.          new SemaphoreTest().doPark();  \n\n7.      }  \n\n8.      private void doPark() {  \n\n9.          for (int i = 0; i < 100; i++) {  \n\n10.             threadPool.execute(() -> {  \n\n11.                 String threadName = Thread.currentThread().getName();  \n\n12.                 if(\"pool-1-thread-99\".equals(threadName)){  \n\n13.                     System.out.println(\"semaphore.getQueueLength() = \" + semaphore.getQueueLength());  \n\n14.                     System.out.println(\"semaphore.hasQueuedThreads() = \" + semaphore.hasQueuedThreads());  \n\n15.                     System.out.println(\"semaphore.availablePermits() = \" + semaphore.availablePermits());  \n\n16.                     System.out.println(\"semaphore.drainPermits() = \" + semaphore.drainPermits());  \n\n17.                 }  \n\n18.                 try {  \n\n19.                     System.out.println(threadName + \"：我在准备停车\");  \n\n20.                     semaphore.acquire(1);  \n\n21. //                    semaphore.acquire();  \n\n22. //                    semaphore.acquireUninterruptibly(1);  \n\n23. //                    semaphore.tryAcquire();  \n\n24. //                    semaphore.tryAcquire(1);  \n\n25. //                    semaphore.tryAcquire(2,TimeUnit.SECONDS);  \n\n26.                 } catch (InterruptedException e) {  \n\n27.                     e.printStackTrace();  \n\n28.                 }  \n\n29.                 System.out.println(threadName + \"：我停进来了\");  \n\n30.                 System.out.println(\"\");  \n\n31.                 semaphore.release();  \n\n32.                 System.out.println(threadName + \"：我开走了\");  \n\n33.             });  \n\n34.         }  \n\n35.         threadPool.shutdown();  \n\n36.         while (true) {  \n\n37.             if (threadPool.isTerminated()) {  \n\n38.                 System.out.println(\"线程池关闭！\");  \n\n39.                 break;  \n\n40.             }  \n\n41.         }  \n\n42.     }  \n\n43. }  \n```\n\n在这里一个停车位就是一个许可证，Semaphore是门口看车库的管理员。只有其他车子（线程）开走了（relase）,等待的车子（线程）才可以获取许可证进来（acquire）。\n\n\n\n我们来看一下Semaphore对外开放的api\n\n```\nacquire()：阻塞等待获取一个许可证，可中断\n\nacquire(int permits)：阻塞获取permits个许可证，可中断\n\nacquireUninterruptibly()：阻塞等待获取一个许可证，不可中断\n\nacquireUninterruptibly(int permits)：阻塞等待获取permits个许可证，不可中断\n\ntryAcquire()：不阻塞等待获取一个许可证，立即返回\n\ntryAcquire(int permits)：不阻塞等待获取permits个许可证，立即返回\n\ntryAcquire(int permits, long timeout, TimeUnit unit)：不阻塞等待获取permits个许可证，有超时条件\n\navailablePermits()：剩余的可用许可证数量\n\ndrainPermits()：立即获取所有的可用许可证，并返回数量\n\ngetQueueLength()：获取正在等待许可证的线程数量\n\nhasQueuedThreads：判断有没有线程在等待许可证\n\nrelease()：释放一个许可证\n\nrelease(int permits)：释放permits个许可证\n```\n\n\n\n看完api方法后，来看一下重要方法的源码\n\n#### 1. acquire()\n\n```\n  \n2.  public void acquire() throws InterruptedException {  \n\n3.      sync.acquireSharedInterruptibly(1);  \n\n4.  }  \n\n\n5.  public final void acquireSharedInterruptibly(int arg)  \n\n6.          throws InterruptedException {  \n\n7.      if (Thread.interrupted())  \n\n8.          throw new InterruptedException();  \n\n9.      if (tryAcquireShared(arg) < 0)  \n\n10.         doAcquireSharedInterruptibly(arg);  \n\n11. }  \n```\n\n\n\n##### 1.1 tryAcquireShared(int acquires)\n\n看一下Semphore重写的的tryAcquireShared方法\n\n分fair和nonfair两种\n\n在nonfair中\n\n```\n1.  protected int tryAcquireShared(int acquires) {  \n\n2.      return nonfairTryAcquireShared(acquires);  \n\n3.  }  \n\n\n4.  final int nonfairTryAcquireShared(int acquires) {  \n\n5.      for (;;) {  \n\n6.          int available = getState();  \n\n7.          int remaining = available - acquires;  \n\n8.          if (remaining < 0 ||  \n\n9.              compareAndSetState(available, remaining))  \n\n10.             return remaining;  \n\n11.     }  \n\n12. }  \n```\n\n可以看出就是看看剩余的许可证数是不是大于我需要的许可证数，如果大于的就通过CAS将剩余的许可证数修改成减少后的数量，然后返回获取资源成功\n\n\n\n在fair中\n\n```\n1.  protected int tryAcquireShared(int acquires) {  \n\n2.      for (;;) {  \n\n3.          if (hasQueuedPredecessors())  \n\n4.              return -1;  \n\n5.          int available = getState();  \n\n6.          int remaining = available - acquires;  \n\n7.          if (remaining < 0 ||  \n\n8.              compareAndSetState(available, remaining))  \n\n9.              return remaining;  \n\n10.     }  \n\n11. }  \n```\n\n可以看出跟nonfair相比就多了一个hasQueuedPredecessors判断操作，fair就话必须要求当前线程节点排着队来获取资源。\n\n\n\n**如果获取不到资源当前线程怎么办呢？**\n\ndoAcquireSharedInterruptibly()方法会将当前线程阻塞等待唤醒\n\n```\n1.  private void doAcquireSharedInterruptibly(int arg)  \n\n2.      throws InterruptedException {  \n\n3.      final Node node = addWaiter(Node.SHARED);  \n\n4.      boolean failed = true;  \n\n5.      try {  \n\n6.          for (;;) {  \n\n7.              final Node p = node.predecessor();  \n\n8.              if (p == head) {  \n\n9.                  int r = tryAcquireShared(arg);  \n\n10.                 if (r >= 0) {  \n\n11.                     setHeadAndPropagate(node, r);  \n\n12.                     p.next = null; // help GC  \n\n13.                     failed = false;  \n\n14.                     return;  \n\n15.                 }  \n\n16.             }  \n\n17.             if (shouldParkAfterFailedAcquire(p, node) &&  \n\n18.                 parkAndCheckInterrupt())  \n\n19.                 throw new InterruptedException();  \n\n20.         }  \n\n21.     } finally {  \n\n22.         if (failed)  \n\n23.             cancelAcquire(node);  \n\n24.     }  \n\n25. }  \n```\n\nAQS中熟悉的操作，就不细讲了，对AQS独占式感兴趣的可以看ReentrantLock源码分析，对AQS共享式感兴趣的可以看CountDownLatch源码分析。\n\n\n\nacquire和acquireUninterruptibly的区别就是对interrupt事件的反应\n\nacquire()如下\n\n```\n1.  if (shouldParkAfterFailedAcquire(p, node) &&  \n\n2.      parkAndCheckInterrupt())  \n\n3.      throw new InterruptedException();  \n```\n\n会抛出InterruptedException\n\n\n\nacquireUninterruptibly()如下\n\n```\n1.  if (shouldParkAfterFailedAcquire(p, node) &&  \n\n2.      parkAndCheckInterrupt())  \n\n3.      interrupted = true;  \n```\n\n只是会记录一下interrupted，不会做出任何处理，该阻塞的还是阻塞\n\n\n\n来看一下tryAcquire()\n\n```\n1.  public boolean tryAcquire() {  \n\n2.      return sync.nonfairTryAcquireShared(1) >= 0;  \n\n3.  }  \n```\n\n会直接返回能不能立即获取到资源\n\n\n\n#### 2. release()\n\nrelease会释放许可证，当然释放了许可证意味着有了资源去争夺，所以会唤醒所有被park的线程\n\n```\n1.  public void release() {  \n\n2.      sync.releaseShared(1);  \n\n3.  }  \n\n\n4.  public final boolean releaseShared(int arg) {  \n\n5.      if (tryReleaseShared(arg)) {  \n\n6.          doReleaseShared();  \n\n7.          return true;  \n\n8.      }  \n\n9.      return false;  \n\n10. }  \n```\n\n\n\n根据上面的思路，先释放许可证，看一下Semaphore重写的tryReleaseShared方法\n\n```\n1.  protected final boolean tryReleaseShared(int releases) {  \n\n2.      for (;;) {  \n\n3.          int current = getState();  \n\n4.          int next = current + releases;  \n\n5.          if (next < current) // overflow  \n\n6.              throw new Error(\"Maximum permit count exceeded\");  \n\n7.          if (compareAndSetState(current, next))  \n\n8.              return true;  \n\n9.      }  \n\n10. }  \n```\n\n就是增加许可证数量，加了边界值判断\n\n\n\n然后unpark同步队列中阻塞的线程节点，看AQS中的doReleaseShared方法\n\n```\n1.  private void doReleaseShared() {  \n\n2.      for (;;) {  \n\n3.          Node h = head;  \n\n4.          if (h != null && h != tail) {  \n\n5.              int ws = h.waitStatus;  \n\n6.              if (ws == Node.SIGNAL) {  \n\n7.                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))  \n\n8.                      continue;            // loop to recheck cases  \n\n9.                  unparkSuccessor(h);  \n\n10.             }  \n\n11.             else if (ws == 0 &&  \n\n12.                      !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))  \n\n13.                 continue;                // loop on failed CAS  \n\n14.         }  \n\n15.         if (h == head)                   // loop if head changed  \n\n16.             break;  \n\n17.     }  \n\n18. }  \n```\n\n非常熟悉的大兄弟CyclicBarrier的操作，通知队列中所有的后继节点去获取资源，这也是AQS共享式的体现。\n\n\n\n总结：\n\n**Semaphore底层还是基于AQS共享式的，它通过一种许可证的方式进行资源的分配，允许多个线程在获取到资源的情况下运行，对于资源的获取和释放也可以是批量的。**", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "5a70c81029f3bca31abec5c2a63a4f7f": {"id": "5a70c81029f3bca31abec5c2a63a4f7f", "item": "Java基础", "title": "ThreadLocal全分析", "date": "2024-08-22", "summary": "ThreadLocal 为每个使用它的线程提供独立的变量副本。它能实现线程间数据隔离，避免多线程对共享变量的并发访问问题。不同线程可独立操作自己的变量，互不干扰，常用于存储线程局部的状态信息，如用户会话数据等。", "body": "\n#### **1、ThreadLocal的用处**\n\n当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。\n\n**ThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。**\n\n从线程的角度看，目标变量就像是线程的本地变量，这也是类名中“Local”所要表达的意思。\n\n\n\n#### **2、ThreadLocal的使用**\n\n基本使用如下：\n\n```\n1.  private ThreadLocal<String> threadLocal = new ThreadLocal<>();  \n\n2.   public static void main(String[] args) {  \n\n3.      CyclicBarrier cyclicBarrier = new CyclicBarrier(10);  \n\n4.      for (int i = 0; i < 10; i++) {  \n\n5.          TestThread testThread = new ThreadLocalTest().new TestThread(cyclicBarrier);  \n\n6.          testThread.start();  \n\n7.          // 等待线程执行完毕  \n\n8.          testThread.yield();  \n\n9.      }  \n\n10. }  \n\n\n11. class TestThread extends Thread {  \n\n12.     private CyclicBarrier cyclicBarrier;  \n\n13.     public TestThread(CyclicBarrier cyclicBarrier) {  \n\n14.         this.cyclicBarrier = cyclicBarrier;  \n\n15.     }  \n\n16.     @Override  \n\n17.     public void run() {  \n\n18.         try {  \n\n19.             // 保证10个线程同时启动  \n\n20.             cyclicBarrier.await();  \n\n21.             threadLocal.set(Thread.currentThread().getName());  \n\n22.             System.out.println(Thread.currentThread().getName() + \": \" +  threadLocal.get());  \n\n23.         } catch (Exception e) {  \n\n24.             e.printStackTrace();  \n\n25.         }   \n\n26.     }  \n\n27. }  \n```\n\n\n\n#### **3、一个简单的ThreadLocal**\n\n一个简单的ThreadLocal可以只包含set、get、initValue、clear四个方法。\n\n```\n1.  public class SimpleThreadLocal<T> {  \n\n2.      private Map<Thread, T> localMaps = Collections.synchronizedMap(new HashMap<>());  \n\n3.      protected T initValue() {  \n\n4.          return null;  \n\n5.      }  \n\n6.      public void set(T t) {  \n\n7.          localMaps.put(Thread.currentThread(), t);  \n\n8.      }  \n\n9.      public T get() {  \n\n10.         Thread thread = Thread.currentThread();  \n\n11.         T t = localMaps.get(thread);  \n\n12.         if (t == null && !localMaps.containsKey(thread)) {  \n\n13.             t = initValue();  \n\n14.             localMaps.put(thread, t);  \n\n15.         }  \n\n16.         return t;  \n\n17.     }  \n\n18.     public void clear() {  \n\n19.         localMaps.remove(Thread.currentThread());  \n\n20.     }  \n\n21. }  \n```\n\n\n\n#### **4、ThreadLocal源码的实现**\n\n##### （1）set方法\n\n源码如下\n\n```\n1.  public void set(T value) {  \n\n2.      Thread t = Thread.currentThread();  \n\n3.      ThreadLocalMap map = getMap(t);  \n\n4.      if (map != null)  \n\n5.          map.set(this, value);  \n\n6.      else  \n\n7.          createMap(t, value);  \n\n8.  }  \n```\n\n\n\n##### （2）getMap()代码\n\n```\n1.  ThreadLocalMap getMap(Thread t) {  \n\n2.      return t.threadLocals;  \n\n3.  }  \n```\n\n\n\nt.threadLocals是什么呢？\n\n```\n1.  class Thread implements Runnable {  \n\n2.      //...  \n\n3.      ThreadLocal.ThreadLocalMap threadLocals = null;  \n\n4.      //...  \n\n5.  }  \n```\n\n可以看到threadLocals是Thread里面的一个变量，它的类型是ThreadLocal.ThreadLocalMap，这个ThreadLocalMap下面再说，可以看到这里threadLocals赋值null\n\n那在哪里初始化的？\n\n\n\n还是回到set()方法，在map == null的时候，createMap(t, value)方法对threadLocals进行初始化\n\ncreateMap代码如下\n\n```\n1.  void createMap(Thread t, T firstValue) {  \n\n2.      t.threadLocals = new ThreadLocalMap(this, firstValue);  \n\n3.  }  \n```\n\n\n\n现在set()方法的流程就很清晰了\n\n1） 寻找当前线程的threadLocals，有的话直接put值，没有的话新建一个\n\n2）put值的时候，是将当前的ThreadLocal作为ThreadLocalMap的key，set方法的参数value作为ThreadLocalMap的value。\n\n看到这儿其实已经知道ThreadLocal怎么实现线程安全的了，对每一个线程都维护一个threadLocals变量，然后将当前的（threadLocal，value）插入threadLocals中。\n\n\n\nThreadLocal和Thread的关系如下图：\n\n![img](http://pcc.huitogo.club/b66dd36bddad099dd26ba8f933c31306)\n\n\n\n##### （3）get方法\n\nget方法源码如下\n\n```\n1.  public T get() {  \n\n2.      Thread t = Thread.currentThread();  \n\n3.      ThreadLocalMap map = getMap(t);  \n\n4.      if (map != null) {  \n\n5.          ThreadLocalMap.Entry e = map.getEntry(this);  \n\n6.          if (e != null) {  \n\n7.              @SuppressWarnings(\"unchecked\")  \n\n8.              T result = (T)e.value;  \n\n9.              return result;  \n\n10.         }  \n\n11.     }  \n\n12.     return setInitialValue();  \n\n13. }  \n```\n\n\n\n可以看到获取到了当前线程的threadLocals里面key为this.threadLocal的value值，如果当前线程threadLocals == null的话，初始化操作如下：\n\n```\n1.  private T setInitialValue() {  \n\n2.      T value = initialValue();  \n\n3.      Thread t = Thread.currentThread();  \n\n4.      ThreadLocalMap map = getMap(t);  \n\n5.      if (map != null)  \n\n6.          map.set(this, value);  \n\n7.      else  \n\n8.          createMap(t, value);  \n\n9.      return value;  \n\n10. }  \n```\n\n主要也就set/get方法了。\n\n\n\n#### **5、ThreadLocalMap是什么？**\n\nThreadLocalMap从字面上就可以看出这是一个保存ThreadLocal对象的map(其实是以它为Key)\n\n（1）Entry\n\n跟所有Map集合一样，ThreadLocalMap维护的也是一个Entry数组，初始化大小为16\n\n但是ThreadLocalMap的Entry其实是包装后的ThreadLocal\n\n\n\nEntry代码如下：\n\n```\n1.  static class Entry extends WeakReference<ThreadLocal<?>> {  \n\n2.      Object value;  \n\n3.     // 这里可以看到Entry的key是一个弱引用\n\n4.      Entry(ThreadLocal<?> k, Object v) {  \n\n5.          super(k);  \n\n6.          value = v;  \n\n7.      }  \n\n8.  }  \n```\n\n可以看到它就是个扩展了弱引用类型的ThreadLocal对象，并且它里面的“key”就是个弱引用的ThreadLocal。\n\n\n\n（2）构造函数\n\nThreadLocal的一个构造函数如下：\n\n```\n1.  ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {  \n\n2.      table = new Entry[INITIAL_CAPACITY];  \n\n3.      int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\n\n4.      table[i] = new Entry(firstKey, firstValue);  \n\n5.      size = 1; \n\n6.  // 设置扩容阀值 \n\n7.      setThreshold(INITIAL_CAPACITY);  \n\n8.  }  \n```\n\n可以看到它内部维护的Entry数组，并且初始化大小为16，在size > (2/3)length的时候会扩容。\n\n\n\n这里我们可以看到ThreadLocal是怎么定位一个key在Entry数组中的位置\n\n```\nfirstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1) \n```\n\n使用一个 static 的原子属性 AtomicInteger nextHashCode，通过每次增加 HASH_INCREMENT = 0x61c88647 ，然后 & (INITIAL_CAPACITY - 1) 取得在数组 private Entry[] table 中的索引。\n\n基本可以将ThreadLocalMap作为一个简单的Map集合看待。\n\n\n\n#### **6、ThreadLocal的内存回收**\n\n（1）Thread的回收\n\nthreadLocals作为Thread的一个变量，在Thread执行完毕后就会自动回收。\n\n\n\nThread的exit方法如下\n\n```\n1.  private void exit() {  \n\n2.       if (group != null) {  \n\n3.           group.threadTerminated(this);  \n\n4.           group = null;  \n\n5.       }  \n\n6.       target = null;  \n\n7.  // 这里线程退出时将threadLocals 置为null\n\n8.       threadLocals = null;  \n\n9.       inheritableThreadLocals = null;  \n\n10.      inheritedAccessControlContext = null;  \n\n11.      blocker = null;  \n\n12.      uncaughtExceptionHandler = null;  \n\n13.  } \n```\n\n\n\n（2）ThreadLocalMap的回收\n\n在一个Thread运行时间长的情况下，ThreadLocalMap也会根据情况在线程的生命期内回收ThreadLocalMap 的内存了，不然的话，Entry对象越多，那么ThreadLocalMap就会越来越大，占用的内存就会越来越多，所以对于已经不需要了的线程局部变量，就应该清理掉其对应的Entry对象。\n\n*怎么回收的呢？*\n\n还记得ThreadLocalMap.Entry的key是一个WeakReference对象吗？其实这也是ThreadLocalMap的一个细节，因为**当一个对象仅仅被weak reference指向, 而没有任何其他strong reference指向的时候, 如果GC运行, 那么这个对象就会被回收。**\n\n所以在jvm发生GC的时候，ThreadLocalMap.Entry里面的key会被回收，也就是key被置为null，但是key所在Entry还在存在的，那Entry什么时候回收？\n\n\n\nThreadLocalMap中在执行get、set、remove方法的时候都会对key为null的Entry进行处理\n\n比如get中会清除过期对象\n\n```\n1.  private Entry getEntryAfterMiss(ThreadLocal key, int i, Entry e) {  \n\n2.      Entry[] tab = table;  \n\n3.      int len = tab.length;  \n\n4.      while (e != null) {  \n\n5.          ThreadLocal k = e.get();  \n\n6.          if (k == key)  \n\n7.              return e;  \n\n8.         if (k == null) \n\n9.             expungeStaleEntry(i);  \n\n10.         else  \n\n11.             i = nextIndex(i, len);  \n\n12.         e = tab[i];  \n\n13.     }  \n\n14.     return null;  \n\n15. } \n```\n\n\n\n在set中会替换过期对象\n\n```\n1.  private void set(ThreadLocal key, Object value) {  \n\n2.       Entry[] tab = table;  \n\n3.       int len = tab.length;  \n\n4.       int i = key.threadLocalHashCode & (len-1);  \n\n5.       for (Entry e = tab[i];  \n\n6.            e != null;  \n\n7.            e = tab[i = nextIndex(i, len)]) {  \n\n8.           ThreadLocal k = e.get();  \n\n9.           if (k == key) {  \n\n10.              e.value = value;  \n\n11.              return;  \n\n12.          }  \n\n13.          if (k == null) { \n\n14.              replaceStaleEntry(key, value, i);  \n\n15.              return; \n\n16.          }  \n\n17.      }  \n\n18.      tab[i] = new Entry(key, value);  \n\n19.      int sz = ++size;  \n\n20.      if (!cleanSomeSlots(i, sz) && sz >= threshold)  \n\n21.          rehash();  \n\n22.  } \n```\n\n\n\n除此之外当数组长度 > 2/3 最大长度时发生扩容之前会尝试先进行回收\n\n```\n1.  if (!cleanSomeSlots(i, sz) && sz >= threshold)  \n\n2.      rehash();  \n```\n\n\n\ncleanSomeSlots回收方法源码如下：\n\n```\n1.  private boolean cleanSomeSlots(int i, int n) {  \n\n2.      boolean removed = false;  \n\n3.      Entry[] tab = table;  \n\n4.      int len = tab.length;  \n\n5.      do {  \n\n6.          i = nextIndex(i, len);  \n\n7.          Entry e = tab[i];  \n\n8.          if (e != null && e.get() == null) {  \n\n9.              n = len;  \n\n10.             removed = true;  \n\n11.             i = expungeStaleEntry(i);  \n\n12.         }  \n\n13.     } while ( (n >>>= 1) != 0);  \n\n14.     return removed;  \n\n15. }  \n```\n\n\n\n#### **7、ThreadLocal会引起OOM吗？**\n\n理论上是不会的，从上面ThreadLocal的内存回收可以看的出来，无论在线程执行后还是执行中都是会进行回收保障的，但是！如果这个线程一直不退出呢？\n\n没错，就是使用线程池的情况，比如固定线程池，线程一直存活，那么可想而知\n\n如果处理一次业务的时候存放到ThreadLocalMap中一个大对象，处理另一个业务的时候，又一个线程存放到ThreadLocalMap中一个大对象，但是这个线程由于是线程池创建的他会一直存在，不会被销毁，这样的话，以前执行业务的时候存放到ThreadLocalMap中的对象可能不会被再次使用，但是由于线程不会被关闭，因此无法释放Thread中的ThreadLocalMap对象，造成内存溢出。\n\n因此在线程池和ThreadLocal的使用下，是有可能出现OOM溢出的。\n\n\n\n但是ThreadLocal出现OOM的原因到底是什么呢？\n\n我们知道ThreadLocalMap threadlocals是Thread的全局变量，**它的生命周期和Thread是一样的**，虽然在ThreadLocalMap.Entry中的key是一个WeakReference，但是也只是在GC的时候清除这个key，然后key所在的Entry对象只会在当前ThreadLocal发生get、set方法后清除，所以如果当前**ThreadLocal在多线程set完大对象之后没有发生get/set行为**，那么这些key为null的Entry就一直存在！\n\n\n\nThreadLoca测试OOM溢出的代码如下：\n\n```\n1.  public class ThreadLocalOOM {  \n\n2.      public static void main(String[] args) {  \n\n3.          ExecutorService executorService = Executors.newFixedThreadPool(500);  \n\n4.          ThreadLocal<List<User>> threalLocal = new ThreadLocal<>();  \n\n5.          try {  \n\n6.              for(int i =0; i < 100; i++) {  \n\n7.                  executorService.execute(() ->{  \n\n8.                      threalLocal.set(new ThreadLocalOOM().addBigList());  \n\n9.                      System.out.println(Thread.currentThread().getName() + \"has executed!\");  \n\n10.                     threalLocal.remove();  \n\n11.                 });  \n\n12.             }  \n\n13.             Thread.sleep(1000L);  \n\n14.         } catch (Exception e) {  \n\n15.             e.printStackTrace();  \n\n16.         }  \n\n17.     }  \n\n\n18.     public List<User> addBigList(){  \n\n19.         List<User> list = new ArrayList<>(10000);  \n\n20.         for(int j = 0; j < 10000; j++) {  \n\n21.             list.add(new User(Thread.currentThread().getName(),\"this is a test User\" + j, 18884848, 25545454));  \n\n22.         }  \n\n23.         return list;  \n\n24.     }  \n\n25. }  \n\n\n26. class User {  \n\n27.     private String name;  \n\n28.     private String description;  \n\n29.     private int age;  \n\n30.     private int sex;  \n\n31.     public User(String name, String description, int age, int sex) {  \n\n32.         super();  \n\n33.         this.name = name;  \n\n34.         this.description = description;  \n\n35.         this.age = age;  \n\n36.         this.sex = sex;  \n\n37.     }  \n\n38. }  \n```\n\n\n\n这里将Eclipse的Run configuration的jvm参数为-Xms100M -Xmx100M\n\n报错的话是系统没办法在堆内存里面再给ArrayList分配内存了，因为每一个ArrayList都是大对象，然后放到ThreadLocal中又没有清除，所以OOM了。。。\n\n\n\n**解决办法就是在使用完ThreadLocal后手动触发回收，也就是ThreadLocal.remove()**\n\n当然这也是建立在业务的基础上的，如果希望ThreadLocal中set的值生命周期变长的话就不能随便remove了，但是要记住，不要给ThreadLocal里面set大对象！", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "36d08019dccf7efebedda9f6d62aef0b": {"id": "36d08019dccf7efebedda9f6d62aef0b", "item": "Java基础", "title": "TreeMap源码分析", "date": "2024-08-22", "summary": "TreeMap 是 Java 中的一种有序映射容器。它基于红黑树数据结构实现，能自动对键进行排序。在多线程环境下若要保证线程安全需额外同步措施。适用于需要按照特定顺序存储和检索键值对的场景，提供高效的查找、插入和删除操作。", "body": "\n#### 1. TreeMap特性\n\n1. 键值不允许重复，键不能为null\n2. 默认会对键进行排序，所以键必须实现Comparable接口或者使用外部比较器\n3. 查找、移除、添加操作的时间复杂度为log(n)\n4. 底层使用的数据结构是红黑树\n\n\n\n下面是TreeMap的常用操作示例：\n\n```\n1.  public static void main(String[] args){  \n\n2.      TreeMap<String, Integer> grades = new TreeMap<>();  \n\n3.      grades.put(\"Frank\", 100);  \n\n4.      grades.put(\"Alice\", 95);  \n\n5.      grades.put(\"Mary\", 90);  \n\n6.      grades.put(\"Bob\", 85);  \n\n7.      grades.put(\"Jack\", 90);  \n\n8.      System.out.println(grades);  \n\n9.      // 获取从\"Bob\"到\"Jack\"的子map，不包括头尾节点  \n\n10.     System.out.println(grades.subMap(\"Bob\", \"Jack\"));  \n\n11.     // 获取从\"Bob\"到\"Jack\"的子map，包括头尾节点      \n\n12.     System.out.println(grades.subMap(\"Bob\", true, \"Jack\", true));  \n\n13.     // 返回与大于或等于\"Bob\"的键值映射，如果没有此键，则 null   \n\n14.     System.out.println(grades.ceilingEntry(\"Bob\"));  \n\n15.     System.out.println(grades.ceilingKey(\"Bob\"));  \n\n16.     // 返回与大Bob的键值映射，如果没有此键，则 null   \n\n17.     System.out.println(grades.higherEntry(\"Bob\"));  \n\n18.     System.out.println(grades.higherKey(\"Bob\"));  \n\n19.     // 返回起点是map的最小值，终点是\"Bob\"的子map,不包括\"Bob\"  \n\n20.     System.out.println(grades.headMap(\"Bob\"));  \n\n21.     // 返回起点是map的最小值，终点是\"Bob\"的子map,包括\"Bob\"  \n\n22.     System.out.println(grades.headMap(\"Bob\", true));  \n\n23.     // 返回起点是\"Bob\"，终点是map的“最大值”,不包括\"Bob\"  \n\n24.     System.out.println(grades.tailMap(\"Bob\"));  \n\n25.     // 返回起点是\"Bob\"，终点是map的“最大值”, 包括\"Bob\"  \n\n26.     System.out.println(grades.tailMap(\"Bob\", true));  \n\n27.     System.out.println(grades.containsKey(\"Bob\"));  \n\n28.     System.out.println(grades.containsValue(90));  \n\n29.     // 返回当前map的反向排序视图，该视图的操作会影响原视图  \n\n30.     System.out.println(grades.descendingMap());  \n\n31.     System.out.println(grades.descendingKeySet());  \n\n32. }\n```\n\n\n\n注意：\n\n- 原Map的subMap(或者其他切割map的操作)以及descendingMap的操作（增删改）操作都会影响原视图\n- 对上述操作分割出来的map进行增删改的时候，会验证参数key值，如果key比原map最小值还小或者最大值还大将会报错。\n\n\n\n#### 2. TreeMap继承结构\n\n![img](http://pcc.huitogo.club/3e765bb091a4fee36ee75b039c953b7d)\n\n除了基本的接口外TreeMap主要继承的是NavigableMap接口，而NavigableMap接口继承的是SortedMap接口\n\n**SortedMap接口就是一个具有排序功能的接口**\n\nNavigableMap接口在SortedMap接口的基础上增加了导航（查询定位分割）功能，比如查询指定key的最近的一个比它大的节点是谁，在指定key和key之间的keyMap是什么，以及返回结果的时候包不包括参数key本身之类的等等，这些方法在TreeMap中都有实现。\n\n\n\nTreeMap的数据结构也就是红黑树由Entry组成\n\n```\n1.  static final class Entry<K,V> implements Map.Entry<K,V> {  \n\n2.      K key;  \n\n3.      V value;  \n\n4.      Entry<K,V> left;  \n\n5.      Entry<K,V> right;  \n\n6.      Entry<K,V> parent;  \n\n7.      boolean color = BLACK;  \n\n\n8.      /** \n\n9.       * 构造函数\n      \n10.      */  \n\n10.     Entry(K key, V value, Entry<K,V> parent) {  \n\n11.         this.key = key;  \n\n12.         this.value = value;  \n\n13.         this.parent = parent;  \n\n14.     }  \n\n15.     ...  \n\n16.   } \n```\n\n\n\nTreeMap的变量如下\n\n```\n1.  /** \n\n2.   * 外部比较器 \n\n3.   */  \n\n4.  private final Comparator<? super K> comparator;  \n\n5.  private transient Entry<K,V> root;  \n\n6.  /** \n\n7.   * 键值对数量 \n\n8.   */  \n\n9.  private transient int size = 0;  \n\n10. private transient int modCount = 0;  \n\n11. private static final boolean RED   = false;  \n\n12. private static final boolean BLACK = true;  \n\n13. /** \n\n14.  * 键值对集合 \n\n15.  */  \n\n16. private transient EntrySet entrySet;  \n\n17. /** \n\n18.  * 键的集合 \n\n19.  */  \n\n20. private transient KeySet<K> navigableKeySet;  \n\n21. /** \n\n22.  * 倒序Map \n\n23.  */  \n\n24. private transient NavigableMap<K,V> descendingMap;\n```\n\n\n\n#### 3. TreeMap是怎么实现排序的\n\n关于排序想到的是Comparable接口和Comparator比较器，所以对于put进TreeMap的key值如果是自定义类的话需要：\n\n- 自定义类实现**Comparable**\n- 自定义**Comrator**比较器，在实例化TreeMap时指定比较器\n\n\n\n由于TreeMap底层是**红黑树**的，所以需要根据**比较key**来决定存放元素的位置，在读取元素的时候通过比较key使用**二分法**很快比较出来\n\n\n\n相关代码类似以下（先查看有没有自定义比较器）：\n\n```\n1.  Comparator<? super K> cpr = comparator;  \n\n2.  if (cpr != null) {  \n\n3.      do {  \n\n4.          parent = t;  \n\n5.         cmp = cpr.compare(key, t.key); //比较一 \n\n6.          ... // 根据比较结果存取值或者覆盖值  \n\n7.      } while (t != null);  \n\n8.  }  \n\n9.  else {  \n\n10.     if (key == null)  \n\n11.         throw new NullPointerException();  \n\n12.      @SuppressWarnings(\"unchecked\")  \n\n13.         Comparable<? super K> k = (Comparable<? super K>) key;  \n\n14.     do {  \n\n15.         parent = t;  \n\n16.         cmp = k.compareTo(t.key);  // 比较二\n\n17.         ... // 根据比较结果存取值或者覆盖值  \n\n18.     } while (t != null);  \n\n19. }  \n```\n\n\n\n#### 4. TreeMap的主要方法\n\nTreeMap底层维护的一个数据结构就是红黑树，知道这个就很好理解TreeMap在增删改查时需要考虑的问题了，其中最重要的就是红黑树的平衡了，使用变色和旋转进行解决，关于这部分代码跟HashMap中同出一辙，详细可以看HashMap红黑树的部分。\n\n\n\n##### 4.1 put\n\n```\n1.  // 插入元素  \n\n2.  public V put(K key, V value) {  \n\n3.      TreeMap.Entry<K,V> t = root;  \n\n4.      if (t == null) {  \n\n5.           // 这里主要对key进行空值检测和类型检测  \n\n6.           compare(key, key); // type (and possibly null) check  \n\n7.          // 如果根节点不存在，则用传入的键值对信息生成一个根节点  \n\n8.          root = new TreeMap.Entry<>(key, value, null);  \n\n9.          size = 1;  \n\n10.         modCount++;  \n\n11.         return null;  \n\n12.     }  \n\n13.     int cmp;  \n\n14.     TreeMap.Entry<K,V> parent;  \n\n15.     Comparator<? super K> cpr = comparator;  \n\n16.     if (cpr != null) {  \n\n17.         do {  \n\n18.             // 如果外部比较器不为空，则依次与各节点进行比较  \n\n19.             parent = t;  \n\n20.             cmp = cpr.compare(key, t.key);  \n\n21.             if (cmp < 0)   \n\n22.                 // 小于则与左孩子比较  \n\n23.                 t = t.left;  \n\n24.             else if (cmp > 0)  \n\n25.                 // 大于则与右孩子比较  \n\n26.                 t = t.right;  \n\n27.             else  \n\n28.                 // 找到相等的key则替换其value  \n\n29.                 return t.setValue(value);  \n\n30.             // 一直循环，直到待比较的节点为null  \n\n31.         } while (t != null);  \n\n32.     }  \n\n33.     else {  \n\n34.         // 如果外部比较器为null  \n\n35.         // 如果key为null则抛出空指针  \n\n36.         if (key == null)  \n\n37.             throw new NullPointerException();  \n\n38.         // 如果key未实现comparable接口则会抛出异常  \n\n39.         @SuppressWarnings(\"unchecked\")  \n\n40.         Comparable<? super K> k = (Comparable<? super K>) key;  \n\n41.         do {  \n\n42.             // 跟上面逻辑类似，只是用key的compareTo方法进行比较，而不是用外部比较器的compare方法  \n\n43.             parent = t;  \n\n44.             cmp = k.compareTo(t.key);  \n\n45.             if (cmp < 0)  \n\n46.                 t = t.left;  \n\n47.             else if (cmp > 0)  \n\n48.                 t = t.right;  \n\n49.             else  \n\n50.                 return t.setValue(value);  \n\n51.         } while (t != null);  \n\n52.     }  \n\n53.     // 生成键值对  \n\n54.     TreeMap.Entry<K,V> e = new TreeMap.Entry<>(key, value, parent);  \n\n55.     // 连接到当前map的左孩子位置或者右孩子位置  \n\n56.     if (cmp < 0)  \n\n57.         parent.left = e;  \n\n58.     else  \n\n59.         parent.right = e;  \n\n60.     // 插入后的调整  \n\n61.     fixAfterInsertion(e); \n\n62.     size++;  \n\n63.     modCount++;  \n\n64.     return null;  \n\n65. }  \n```\n\n\n\n**fixAfterInsertion(e)代码**\n\n```\n1.  private void fixAfterInsertion(TreeMap.Entry<K,V> x) {  \n\n2.       // 将插入的节点初始化为红色节点  \n\n3.       x.color = RED;  \n\n4.       // 如果x不为null且x不是根节点，且x的父节点是红色，此时祖父节点一定为黑色  \n\n5.       while (x != null && x != root && x.parent.color == RED) {  \n\n6.           // 如果x的父节点为祖父节点的左孩子  \n\n7.           if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {  \n\n8.               // y指向x的叔叔节点  \n\n9.               TreeMap.Entry<K,V> y = rightOf(parentOf(parentOf(x)));  \n\n10.              // 如果叔叔节点也是红色，则进行变色处理  \n\n11.              if (colorOf(y) == RED) {  \n\n12.                  // 父节点变成黑色  \n\n13.                  setColor(parentOf(x), BLACK);  \n\n14.                  // 叔叔节点变成黑色  \n\n15.                  setColor(y, BLACK);  \n\n16.                  // 祖父节点变成黑色  \n\n17.                  setColor(parentOf(parentOf(x)), RED);  \n\n18.                  // 将x指向祖父节点，继续往上调整  \n\n19.                  x = parentOf(parentOf(x));  \n\n20.              } else {  \n\n21.                  // 如果叔叔节点是黑色节点  \n\n22.                  // 如果x是父节点的右孩子  \n\n23.                  if (x == rightOf(parentOf(x))) {  \n\n24.                      // 将x指向其父节点  \n\n25.                      x = parentOf(x);  \n\n26.                      // 左旋  \n\n27.                      rotateLeft(x);  \n\n28.                  }  \n\n29.                  // 将x的父节点置为黑色  \n\n30.                  setColor(parentOf(x), BLACK);  \n\n31.                  // 将x的祖父节点置为红色  \n\n32.                  setColor(parentOf(parentOf(x)), RED);  \n\n33.                  // 将祖父节点右旋  \n\n34.                  rotateRight(parentOf(parentOf(x)));  \n\n35.              }  \n\n36.          } else {  \n\n37.              // 这里类似操作  \n\n38.              TreeMap.Entry<K,V> y = leftOf(parentOf(parentOf(x)));  \n\n39.              if (colorOf(y) == RED) {  \n\n40.                  setColor(parentOf(x), BLACK);  \n\n41.                  setColor(y, BLACK);  \n\n42.                  setColor(parentOf(parentOf(x)), RED);  \n\n43.                  x = parentOf(parentOf(x));  \n\n44.              } else {  \n\n45.                  if (x == leftOf(parentOf(x))) {  \n\n46.                      x = parentOf(x);  \n\n47.                      rotateRight(x);  \n\n48.                  }  \n\n49.                  setColor(parentOf(x), BLACK);  \n\n50.                  setColor(parentOf(parentOf(x)), RED);  \n\n51.                  rotateLeft(parentOf(parentOf(x)));  \n\n52.              }  \n\n53.          }  \n\n54.      }  \n\n55.      root.color = BLACK;  \n\n56.  }  \n```\n\n这里的逻辑跟HashMap中TreeNode的插入逻辑十分类似，也是先找到要插入的位置，然后再进行结构调整。这里的结构调整即红黑树的结构调整\n\n\n\n##### 4.2 remove\n\n```\n1.  // 删除节点  \n\n2.  public V remove(Object key) {  \n\n3.      // 先找到该key对应的键值对  \n\n4.      TreeMap.Entry<K,V> p = getEntry(key);  \n\n5.      if (p == null)  \n\n6.          // 如果未找到则返回null  \n\n7.          return null;  \n\n8.      V oldValue = p.value;  \n\n9.      // 找到后删除该键值对  \n\n10.     deleteEntry(p);  \n\n11.     return oldValue;  \n\n12. }\n```\n\n\n\n**getEntry(key)：根据key获取Entry**\n\n```\n1.  final TreeMap.Entry<K,V> getEntry(Object key) {  \n\n2.      if (comparator != null)  \n\n3.          // 如果有自定义的比较器  代码和下面key实现了Comparator接口一样\n\n4.          return getEntryUsingComparator(key);  \n\n5.      if (key == null)  \n\n6.          throw new NullPointerException();  \n\n7.      @SuppressWarnings(\"unchecked\")  \n\n8.      Comparable<? super K> k = (Comparable<? super K>) key;  \n\n9.      TreeMap.Entry<K,V> p = root;  \n\n10.     // 使用compareTo方法进行查找  \n\n11.     while (p != null) {  \n\n12.         int cmp = k.compareTo(p.key);  \n\n13.         if (cmp < 0)  \n\n14.             p = p.left;  \n\n15.         else if (cmp > 0)  \n\n16.             p = p.right;  \n\n17.         else  \n\n18.             return p;  \n\n19.     }  \n\n20.     return null;  \n\n21. }  \n```\n\n\n\n**deleteEntry(p)：删除指定Entry，并调整红黑树以保持它的平衡**\n\n```\n1.  private void deleteEntry(TreeMap.Entry<K,V> p) {  \n\n2.      modCount++;  \n\n3.      size--;  \n\n4.      // 如果p的左右孩子均不为空，则找到p的后继节点，并且将p指向该后继节点  \n\n5.      if (p.left != null && p.right != null) {  \n\n6.          TreeMap.Entry<K,V> s = successor(p);  \n\n7.          p.key = s.key;  \n\n8.          p.value = s.value;  \n\n9.          p = s;  \n\n10.     }  // p has 2 children  \n\n11.     // 修复替补节点  \n\n12.     // 用替补节点替换待删除的节点后，需要对其原来所在位置结构进行修复  \n\n13.     TreeMap.Entry<K,V> replacement = (p.left != null ? p.left : p.right);  \n\n14.     if (replacement != null) {  \n\n15.         replacement.parent = p.parent;  \n\n16.         if (p.parent == null)  \n\n17.             root = replacement;  \n\n18.         else if (p == p.parent.left)  \n\n19.             p.parent.left  = replacement;  \n\n20.         else  \n\n21.             p.parent.right = replacement;  \n\n22.         p.left = p.right = p.parent = null;  \n\n23.         // 如果p的颜色是黑色，则进行删除后的修复  \n\n24.         if (p.color == BLACK)  \n\n25.             fixAfterDeletion(replacement);  \n\n26.     } else if (p.parent == null) {  \n\n27.         root = null;  \n\n28.     } else {  \n\n29.         if (p.color == BLACK)  \n\n30.             fixAfterDeletion(p); \n\n31.         if (p.parent != null) {  \n\n32.             if (p == p.parent.left)  \n\n33.                 p.parent.left = null;  \n\n34.             else if (p == p.parent.right)  \n\n35.                 p.parent.right = null;  \n\n36.             p.parent = null;  \n\n37.         }  \n\n38.     }  \n\n39. }  \n```\n\n\n\n**successor(p)：找到指定节点的后继节点，这个原理和predecessor一样，这里是在右子树中找最左的，如果没有右子树就在叔叔节点中去找最左的。**\n\n```\n1.  static <K,V> TreeMap.Entry<K,V> successor(TreeMap.Entry<K,V> t) {  \n\n2.      if (t == null)  \n\n3.          return null;  \n\n4.      else if (t.right != null) {  \n\n5.          TreeMap.Entry<K,V> p = t.right;  \n\n6.          // 如果右子树不为空，则找到右子树的最左节点作为后继节点  \n\n7.          while (p.left != null)  \n\n8.              p = p.left;  \n\n9.          return p;  \n\n10.     } else {  \n\n11.         TreeMap.Entry<K,V> p = t.parent;  \n\n12.         TreeMap.Entry<K,V> ch = t;  \n\n13.         // 如果右子树为空且当前节点为其父节点的左孩子，则直接返回  \n\n14.         // 如果为其父节点的右孩子，则一直往上找，直到找到根节点或者当前节点为其父节点的左孩子时，用其做为后继节点  \n\n15.         while (p != null && ch == p.right) {  \n\n16.             ch = p;  \n\n17.             p = p.parent;  \n\n18.         }  \n\n19.         return p;  \n\n20.     }  \n\n21. }  \n```\n\n\n\n**fixAfterDeletion(replacement)：进行删除后的结构修复**\n\n```\n1.  private void fixAfterDeletion(TreeMap.Entry<K,V> x) {  \n\n2.      while (x != root && colorOf(x) == BLACK) {  \n\n3.          // 如果x是父节点的左孩子  \n\n4.          if (x == leftOf(parentOf(x))) {  \n\n5.              // sib指向x的兄弟节点  \n\n6.              TreeMap.Entry<K,V> sib = rightOf(parentOf(x));  \n\n7.              // 如果sib是红色，则进行变色处理  \n\n8.              if (colorOf(sib) == RED) {  \n\n9.                  // 兄弟节点改为黑色  \n\n10.                 setColor(sib, BLACK);  \n\n11.                 // 父节点改为红色  \n\n12.                 setColor(parentOf(x), RED);  \n\n13.                 // 父节点左旋  \n\n14.                 rotateLeft(parentOf(x));  \n\n15.                 // sib指向x的父节点的右孩子  \n\n16.                 sib = rightOf(parentOf(x));  \n\n17.             }  \n\n18.             // 如果sib的左孩子和右孩子都是黑色，则进行变色处理  \n\n19.             if (colorOf(leftOf(sib))  == BLACK &&  \n\n20.                     colorOf(rightOf(sib)) == BLACK) {  \n\n21.                 // 将sib置为红色  \n\n22.                 setColor(sib, RED);  \n\n23.                 // x指向其父节点  \n\n24.                 x = parentOf(x);  \n\n25.             } else {  \n\n26.                 // 如果sib的右孩子是黑色而左孩子是红色，则变色右旋  \n\n27.                 if (colorOf(rightOf(sib)) == BLACK) {  \n\n28.                     setColor(leftOf(sib), BLACK);  \n\n29.                     setColor(sib, RED);  \n\n30.                     rotateRight(sib);  \n\n31.                     sib = rightOf(parentOf(x));  \n\n32.                 }  \n\n33.                 // 变色左旋  \n\n34.                 setColor(sib, colorOf(parentOf(x)));  \n\n35.                 setColor(parentOf(x), BLACK);  \n\n36.                 setColor(rightOf(sib), BLACK);  \n\n37.                 rotateLeft(parentOf(x));  \n\n38.                 x = root;  \n\n39.             }  \n\n40.         } else { // symmetric  \n\n41.             // 跟上面操作类似  \n\n42.             TreeMap.Entry<K,V> sib = leftOf(parentOf(x));  \n\n43.             if (colorOf(sib) == RED) {  \n\n44.                 setColor(sib, BLACK);  \n\n45.                 setColor(parentOf(x), RED);  \n\n46.                 rotateRight(parentOf(x));  \n\n47.                 sib = leftOf(parentOf(x));  \n\n48.             }  \n\n49.             if (colorOf(rightOf(sib)) == BLACK &&  \n\n50.                     colorOf(leftOf(sib)) == BLACK) {  \n\n51.                 setColor(sib, RED);  \n\n52.                 x = parentOf(x);  \n\n53.             } else {  \n\n54.                 if (colorOf(leftOf(sib)) == BLACK) {  \n\n55.                     setColor(rightOf(sib), BLACK);  \n\n56.                     setColor(sib, RED);  \n\n57.                     rotateLeft(sib);  \n\n58.                     sib = leftOf(parentOf(x));  \n\n59.                 }  \n\n60.                 setColor(sib, colorOf(parentOf(x)));  \n\n61.                 setColor(parentOf(x), BLACK);  \n\n62.                 setColor(leftOf(sib), BLACK);  \n\n63.                 rotateRight(parentOf(x));  \n\n64.                 x = root;  \n\n65.             }  \n\n66.         }  \n\n67.     }  \n\n68.     setColor(x, BLACK);  \n\n69. }  \n```\n\n\n\n##### 4.3 buildFromSorted\n\n这个方法可以将一个sortedMap转换成红黑树\n\n\n\n在TreeMap的putAll()和带Map的构造方法中都有使用，如下\n\n```\n1.  public TreeMap(SortedMap<K, ? extends V> m) {  \n\n2.      comparator = m.comparator();  \n\n3.      try {  \n\n4.          buildFromSorted(m.size(), m.entrySet().iterator(), null, null);  \n\n5.      } catch (java.io.IOException cannotHappen) {  \n\n6.      } catch (ClassNotFoundException cannotHappen) {  \n\n7.      }  \n\n8.  }  \n```\n\n\n\n**buildFromSorted(m.size(), m.entrySet().iterator(), null, null)**\n\n第一个参数是sortedMap的size\n\n第二个参数是sortedMap集合的迭代器，这里是entrySet的\n\n第三个参数是字符流，当迭代器为空的时候会从字符流中读取数据作为key\n\n第四个参数是默认值，当这个值不为空时，这个默认值作为所有entry的value\n\n```\n1.  private void buildFromSorted(int size, Iterator<?> it,  java.io.ObjectInputStream str, V defaultVal)  \n\n4.      throws  java.io.IOException, ClassNotFoundException {  \n\n5.      this.size = size;  \n\n6.      root = buildFromSorted(0, 0, size-1, computeRedLevel(size),  it, str, defaultVal); \n\n8.  }  \n```\n\n\n\n**buildFromSorted(0,  0,  size-1,  computeRedLevel(size),  it,  str, defaultVal)**\n\n第一参数是当前的level，可以想象成遍历sortedMap时的树的高度\n\n第二个参数是元素下标的最小值，就是start\n\n第三个参数是元素下标的最大值，就是end\n\n第四个参数是根据sortedMap的size计算出来的树的最大高度，对于通过sortedMap转过来的红黑树，这里原则是叶子节点全部必须是红色的，所以这里会在遍历中判断第一个参数是否等于第四个参数，也就是当前高度是否是最大高度\n\n后面的参数意义同上面\n\n\n\n这个方法返回的转换成红黑树的中间节点，所以如果需要全部转换成红黑树的话，这里就要用到递归了\n\n\n\n**思路**：如有序列 1,2,3,4,5,6,7,8 ,9,10,以最中间的数作为根结点，然后将序列分成两组，(1,2,3,4) (6,7,8,9,10)，以同理的方法\n\n在第一组序列中找出最中间的树作为根结点，建立一个子树，该子树作为整个树的左子树\n\n在第二个序列中找出最中间的树作为根结点，孩子子树作为整个树的右树\n\n以此递归下去最终形成的树是在叶子结点以上是一个满二叉树，所以满足红黑树的性质，叶子结点不满足，所以把叶子结点都染成红色\n\n```\n1.  private final Entry<K,V> buildFromSorted(int level, int lo, int hi,   int redLevel,  Iterator<?> it,  java.io.ObjectInputStream str,  V defaultVal)  \n\n6.      throws  java.io.IOException, ClassNotFoundException {  \n\n7.      if (hi < lo) return null;  \n\n8.      int mid = (lo + hi) >>> 1;  \n\n9.      Entry<K,V> left  = null;  \n\n10.     if (lo < mid)  \n\n11.         left = buildFromSorted(level+1, lo, mid - 1, redLevel,  it, str, defaultVal);  \n\n13.     // extract key and/or value from iterator or stream  \n\n14.     K key;  \n\n15.     V value;  \n\n16.     if (it != null) {  \n\n17.         if (defaultVal==null) {  \n\n18.             Map.Entry<?,?> entry = (Map.Entry<?,?>)it.next();  \n\n19.             key = (K)entry.getKey();  \n\n20.             value = (V)entry.getValue();  \n\n21.         } else {  \n\n22.             key = (K)it.next();  \n\n23.             value = defaultVal;  \n\n24.         }  \n\n25.     } else { // use stream  \n\n26.         key = (K) str.readObject();  \n\n27.         value = (defaultVal != null ? defaultVal : (V) str.readObject());  \n\n28.     }  \n\n29.     Entry<K,V> middle =  new Entry<>(key, value, null); // 创建以MId根的结点  \n\n30.     // color nodes in non-full bottommost level red  \n\n31.     if (level == redLevel)  \n\n32.         middle.color = RED;  \n\n33.     if (left != null) {  \n\n34.         middle.left = left;  \n\n35.         left.parent = middle;  \n\n36.     }  \n\n37.     if (mid < hi) {  \n\n38.         Entry<K,V> right = buildFromSorted(level+1, mid+1, hi, redLevel,  it, str, defaultVal); \n\n40.         middle.right = right;  \n\n41.         right.parent = middle;  \n\n42.     }  \n\n43.     return middle;  \n\n44. }  \n```\n\n\n\n**computeRedLevel(size)：计算sortedMap转换成红黑树后的最大高度**\n\n```\n1.  private static int computeRedLevel(int sz) {  \n\n2.      int level = 0;  \n\n3.      for (int m = sz - 1; m >= 0; m = m / 2 - 1)  \n\n4.          level++;  \n\n5.      return level;  \n\n6.  }  \n```", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "226bece86ea8b9abe6cad5a677f6280d": {"id": "226bece86ea8b9abe6cad5a677f6280d", "item": "Java基础", "title": "Vector和Stack源码解析", "date": "2024-08-22", "summary": "Vector 是同步的动态数组，可动态调整大小，适用于多线程环境。Stack 继承自 Vector，是一种后进先出（LIFO）的数据结构，用于存储和操作元素，提供了入栈、出栈等操作。", "body": "\n#### 1. Vector概述\n\n![img](http://pcc.huitogo.club/3e809b5c8dd4930d0705e12ebf1a81e0)\n\n\n\n通过API中可以知道：\n\n1. Vector是一个可变化长度的数组\n2. Vector增加长度通过的是capacity和capacityIncrement这两个变量\n3. Vector也可以获得iterator和listIterator这两个迭代器，并且他们发生的是fail-fast，而不是fail-safe\n4. Vector是一个线程安全的类，如果使用需要线程安全就使用Vector，如果不需要，就使用arrayList\n5. Vector和ArrayList很类似，就少许的不一样，从它继承的类和实现的接口来看，跟arrayList一模一样。\n\n**Verctor继承关系和ArrayList一模一样**\n\n\n\n#### 2. Vector构造方法\n\n##### 2.1 Vector() \n\n空构造\n\n\n\n##### 2.2 Vector(int) \n\n带初始大小的构造\n\n```\n4.  public Vector(int initialCapacity) {  \n\n5.      this(initialCapacity, 0);  \n\n6.  }  \n```\n\n\n\n##### 2.3 Vector(int，int) \n\n带初始大小和增长大小的构造\n\n```\n8.  public Vector(int initialCapacity, int capacityIncrement) {  \n\n9.      super();  \n\n10.     if (initialCapacity < 0) //小于0，会报非法参数异常  \n\n11.         throw new IllegalArgumentException(\"Illegal Capacity: \"+   initialCapacity);  \n\n13.     this.elementData = new Object[initialCapacity]; //初始化elementData数组  \n\n14.     this.capacityIncrement = capacityIncrement; // 初始化elementData的增长大小，为0时增长一倍  \n\n15. }  \n```\n\n\n\n##### 2.4 Vector(Collection<? extends E> c) \n\n带初始元素的构造\n\n```\n17. public Vector(Collection<? extends E> c) {  \n\n18.     elementData = c.toArray();  \n\n19.     elementCount = elementData.length;  \n\n20.     // c.toArray might (incorrectly) not return Object[] (see 6260652)  \n\n21.     if (elementData.getClass() != Object[].class)  \n\n22.         elementData = Arrays.copyOf(elementData, elementCount, Object[].class);  \n\n23. }  \n```\n\n\n\n#### 3. Vector核心方法\n\n##### 3.1 add方法\n\n```\n26. //在vector中的末尾追加元素，利用synchronized实现线程安全。  \n\n27. public synchronized boolean add(E e) {  \n\n28.     modCount++;  \n\n29.     //在增加元素前，检查容量是否够用  \n\n30.     ensureCapacityHelper(elementCount + 1);  \n\n31.     elementData[elementCount++] = e;  \n\n32.     return true;  \n\n33. }  \n```\n\n\n\nensureCapacityHelper(elementCount + 1)代码\n\n```\n1.  //注意，这个方法是异步的  \n\n2.  private void ensureCapacityHelper(int minCapacity) {  \n\n3.      // overflow-conscious code  \n\n4.      if (minCapacity - elementData.length > 0)  \n\n5.          // 扩增，核心方法  \n\n6.          grow(minCapacity);  \n\n7.  } \n```\n\n\n\ngrow(minCapacity)代码\n\n```\n1.  // 这个方法跟arrayList一样，唯一的不同就是扩增大小  \n\n2.  // 在capacityIncrement 为0时，在原有基础上扩展一倍  \n\n3.  // 在capacityIncrement 不为0时，在原有基础上增长capacityIncrement  \n\n4.  private void grow(int minCapacity) {  \n\n5.      // overflow-conscious code  \n\n6.      int oldCapacity = elementData.length;  \n\n7.      int newCapacity = oldCapacity + ((capacityIncrement > 0) ?    capacityIncrement : oldCapacity);  \n\n9.      if (newCapacity - minCapacity < 0)  \n\n10.         newCapacity = minCapacity;  \n\n11.     if (newCapacity - MAX_ARRAY_SIZE > 0)  \n\n12.         newCapacity = hugeCapacity(minCapacity);  \n\n13.     elementData = Arrays.copyOf(elementData, newCapacity);  \n\n14. }  \n```\n\n\n\n其他的方法跟ArrayList类似，可以参考ArrayList的源码分析，只是为了实现线程安全，在一些操作elementData数组的方法上加了synchronized关键字实现同步，核心就是对elementData进行同步操作，如下：\n\n```\n1.  public synchronized E get(int index) {  \n\n2.      if (index >= elementCount)  \n\n3.          throw new ArrayIndexOutOfBoundsException(index);  \n\n4.      return elementData(index);  \n\n5.  } \n```\n\n\n\n**Q1：vector是线程安全的，为什么在遍历中还可以进行增删操作？**\n\n**因为在迭代器跌代过程中没有使用增删改查的那些加锁的方法，自然可以在迭代的时候修改**\n\n\n\n**Q2：为什么不提倡使用Vector?**\n\n**Vector在你不需要进行线程安全的时候，也会给你加锁，也就导致了额外开销**，所以在jdk1.5之后就被弃用了，现在如果要用到线程安全的集合，都是从java.util.concurrent包下去拿相应的类。\n\n\n\n#### 4. Stack概述\n\n![img](http://pcc.huitogo.club/291b7b313658119043ff86a4f18fc20a)\n\n可以看出Stack是Vector的子类，相当于在Vector的基础上加了特有的方法，入栈、出栈等。\n\n**底层维护的也是一个数组，父类中的构造，跟父类一样的扩增方式，并且它的方法也是同步的，所以也是线程安全。**\n\n\n\n#### 5. 总结Vector和Stack\n\n##### 5.1 Vector总结\n\n1. Vector线程安全是因为它的方法都加了synchronized关键字\n2. Vector的本质是一个数组，特点能是能够自动扩增，扩增的方式跟capacityIncrement的值有关\n3. 它也会fail-fast\n\n\n\n##### 5.2 Stack的总结\n\n1. 对栈的一些操作，先进后出\n2. 底层也是用数组实现的，因为继承了Vector\n3. 也是线程安全的", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "078e266ab3ae83491a0be4c78721884d": {"id": "078e266ab3ae83491a0be4c78721884d", "item": "Java基础", "title": "WeakHashMap源码分析", "date": "2024-08-22", "summary": "WeakHashMap 是 Java 中的一种特殊的 Map 实现。它使用弱引用存储键，当键不再被强引用时，会被垃圾回收器自动回收，对应的键值对也会从 WeakHashMap 中移除。适用于需要自动清理不再使用的键值对的场景。", "body": "\n#### 1. weakHashMap的特性\n\n最重要的总结当然是放在前面啦~~~~\n\n1. weakHashMap是允许key为空\n2. weakHashMap是一个会自动清除Entry的Map\n3. weakHashMap的操作与HashMap完全一致\n4. WeakHashMap内部数据结构是数组+链表\n5. WeakHashMap常被用作缓存\n\nWeakHashMap 特殊之处在于 WeakHashMap 里的**entry可能会被垃圾回收器自动删除**，也就是说即使你没有调用remove()或者clear()方法，它的entry也可能会慢慢变少。所以多次调用比如isEmpty，containsKey，size等方法时可能会返回不同的结果。\n\n\n\n**Q1：为什么WeakHashMap的entry会被回收？**\n\n在HashMap中我们都知道entry并不会无缘无故的丢失，除非进行了remove操作。\n\n在weakHashMap中，关键在于**弱引用**，WeakHashMap中的key是间接保存在弱引用中的，所以当key没有被继续使用时，就可能会在GC的时候被回收掉。\n\n只有**key对象是使用弱引用保存**的，**value对象实际上仍旧是通过普通的强引用来保持的**，所以应该确保value不会直接或者间接的保持其对应key的强引用，因为这样会阻止key被回收。\n\n\n\n#### 2. weakHashMap的结构\n\nWeakHashMap并不是继承自HashMap，而是继承自AbstractMap，跟HashMap的继承结构差不多\n\n![img](http://pcc.huitogo.club/48a0005ebbf866a7f3223e36031052b2)\n\n\n\nWeakHashMap中的数据结构是数组+链表的形式，这一点跟HashMap也是一致的，但不同的是，在JDK8中，当发生较多key冲突的时候，HashMap中会由链表转为红黑树，而WeakHashMap则一直使用链表进行存储。\n\n![img](http://pcc.huitogo.club/a8601f03b839d8e92cac14012b78be25)\n\n\n\n#### 3. 成员变量\n\n```\n3.  private static final int DEFAULT_INITIAL_CAPACITY = 16;  \n\n4.  // 最大容量  \n\n5.  private static final int MAXIMUM_CAPACITY = 1 << 30;  \n\n6.  // 默认装载因子  \n\n7.  private static final float DEFAULT_LOAD_FACTOR = 0.75f;  \n\n8.  // Entry数组，长度必须为2的幂  \n\n9.  Entry<K,V>[] table;  \n\n10. // 元素个数  \n\n11. private int size;  \n\n12. // 阈值   \n\n13. private int threshold;  \n\n14. // 装载因子  \n\n15. private final float loadFactor;  \n\n16. // 引用队列  \n\n17. private final ReferenceQueue<Object> queue = new ReferenceQueue<>();  \n\n18. // 修改次数  \n\n19. int modCount; \n```\n\n这里主要是这个ReferenceQueue，用来存放那些已经被回收了的弱引用对象。\n\n\n\n#### 4. 构造方法\n\n##### 4.1 无参\n\n```\n3.  public WeakHashMap() {  \n\n4.      this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);  \n\n5.  }  \n```\n\n\n\n##### 4.2 带初始容量\n\n```\n7.  public WeakHashMap(int initialCapacity) {  \n\n8.      this(initialCapacity, DEFAULT_LOAD_FACTOR);  \n\n9.  } \n```\n\n\n\n##### 4.3 带初始容量和装载因子\n\n```\n11. public WeakHashMap(int initialCapacity, float loadFactor) {  \n\n12.     // 校验initialCapacity  \n\n13.     if (initialCapacity < 0)  \n\n14.         throw new IllegalArgumentException(\"Illegal Initial Capacity: \"+ initialCapacity);  \n\n16.     if (initialCapacity > MAXIMUM_CAPACITY)  \n\n17.         initialCapacity = MAXIMUM_CAPACITY;  \n\n18.     // 校验loadFactor  \n\n19.     if (loadFactor <= 0 || Float.isNaN(loadFactor))  \n\n20.         throw new IllegalArgumentException(\"Illegal Load factor: \"+ loadFactor);  \n\n22.     int capacity = 1;  \n\n23.     // 将容量设置为大于initialCapacity的最小2的幂  \n\n24.     while (capacity < initialCapacity)  \n\n25.         capacity <<= 1;  \n\n26.     table = newTable(capacity);  \n\n27.     this.loadFactor = loadFactor;  \n\n28.     threshold = (int)(capacity * loadFactor);  \n\n29. }  \n```\n\n\n\n##### 4.4 带集合\n\n```\n31. public WeakHashMap(Map<? extends K, ? extends V> m) {  \n\n32.     this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR);  \n\n35.     putAll(m);  \n\n36. } \n```\n\n\n\n#### 5. Entry源码\n\n上面我们知道weakHashMap的核心就是entry\n\nEntry继承自WeakReference，继承关系图如下：\n\n![img](http://pcc.huitogo.club/1bba1422eb4e9da669cc1f80cc844ff5)\n\n\n\n再来看下entry源码\n\n```\n1.  private static class Entry<K,V> extends WeakReference<Object> implements Map.Entry<K,V> {  \n\n2.      V value;  \n\n3.      final int hash;  \n\n4.      Entry<K,V> next;  \n\n5.      /** \n\n6.       * Creates new entry. \n\n7.       */  \n\n8.      Entry(Object key, V value, ReferenceQueue<Object> queue,  int hash, Entry<K,V> next) {  \n\n11.         super(key, queue); \n\n12.         this.value = value;  \n\n13.         this.hash  = hash;  \n\n14.         this.next  = next;  \n\n15.     }  \n\n16. }  \n```\n\n在entry的构造方法中我们可以发现对于形参key，被父类构造方法调用，在weakRefrence中指定refrent和queue。\n\n\n\n在entry中需要主要的方法是getKey()方法，获取entry的key值。\n\n```\n1.  public K getKey() {  \n\n2.      return (K) WeakHashMap.unmaskNull(get());  \n\n3.  }  \n```\n\n这个方法是获取之前构造方法中传入weakRefence中的refrent值，值得注意的是这里如果从weakRefrence中取到的regfrent为null的话会返回一个特殊变量，而不是直接返回null\n\n```\n1. private static final Object NULL_KEY = new Object();  \n```\n\n\n\n所以需要进行转换，当然也有对应的反转换，将null转换成new Object()的\n\n```\n1.  static Object unmaskNull(Object key) {  \n\n2.      return (key == NULL_KEY) ? null : key;  \n\n3.  }  \n\n\n4.   private static Object maskNull(Object key) {  \n\n5.      return (key == null) ? NULL_KEY : key;  \n\n6.  }  \n```\n\n\n\n可以看出在构建entry的时候就已经把key交给了weakRefrence保管，然后在遍历取值等操作的时候都会做一次清除操作，也就是消除key为null的entry。但是在weakHashMap不是直接遍历key为null的entry，而是**从refrenceQueue中取值**，前面我们知道**refrenceQueue存放的就是被回收的key**，所以这样效率更高一些，对应核心代码如下：\n\n```\n1.  private void expungeStaleEntries() {  \n\n2.      for (Object x; (x = queue.poll()) != null; ) {  \n\n3.  // 循环获取引用队列中的对象\n\n4.          synchronized (queue) {  \n\n5.              @SuppressWarnings(\"unchecked\")  \n\n6.               Entry<K,V> e = (Entry<K,V>) x;  \n\n7.              int i = indexFor(e.hash, table.length);  \n\n8.  // 找到之前的Entry\n\n9.              Entry<K,V> prev = table[i];  \n\n10.             Entry<K,V> p = prev;  \n\n11. // 在链表中寻找\n\n12.             while (p != null) {  \n\n13.                 Entry<K,V> next = p.next;  \n\n14.                 if (p == e) {  \n\n15.                     if (prev == e)  \n\n16.                         table[i] = next;  \n\n17.                     else  \n\n18.                         prev.next = next;  \n\n19.                     // 将对应的value置为null，帮助GC回收 \n\n20.                     e.value = null; // Help GC  \n\n21.                     size--;  \n\n22.                     break;  \n\n23.                 }  \n\n24.                 prev = p;  \n\n25.                 p = next;  \n\n26.             }  \n\n27.         }  \n\n28.     }  \n\n29. }  \n```\n\n\n\n#### 6. weakHashMap的主要方法\n\n这里我们主要感受以下weakHashMap在为key取hashCode的算法以及扩容策略跟hashMap有什么不同\n\n\n\n##### 6.1 put\n\n```\n2.  public V put(K key, V value) {  \n\n3.      // 处理null值  \n\n4.      Object k = maskNull(key);  \n\n5.      // 计算hash  \n\n6.      int h = hash(k);  \n\n7.      // 获取table  \n\n8.      Entry<K,V>[] tab = getTable();  \n\n9.      // 计算下标  \n\n10.     int i = indexFor(h, tab.length);  \n\n11.     // 查找Entry  \n\n12.     for (Entry<K,V> e = tab[i]; e != null; e = e.next) {  \n\n13.         if (h == e.hash && eq(k, e.get())) {  \n\n14.             V oldValue = e.value;  \n\n15.             if (value != oldValue)  \n\n16.                 e.value = value;  \n\n17.             return oldValue;  \n\n18.         }  \n\n19.     }  \n\n20.     modCount++;  \n\n21.     Entry<K,V> e = tab[i];  \n\n22.     tab[i] = new Entry<>(k, value, queue, h, e);  \n\n23.     // 如果元素个数超过阈值，则进行扩容  \n\n24.     if (++size >= threshold)  \n\n25.         resize(tab.length * 2);  \n\n26.     return null;  \n\n27. }  \n```\n\n\n\n这个方法里面已经有我们要的答案了。\n\n**hash(k)**：根据key计算hashCode\n\n```\n1.  final int hash(Object k) {  \n\n2.      int h = k.hashCode();  \n\n3.      // 这里做了二次散列，来扩大低位的影响  \n\n4.      h ^= (h >>> 20) ^ (h >>> 12);  \n\n5.      return h ^ (h >>> 7) ^ (h >>> 4);  \n\n6.  }  \n```\n\n在hashMap中计算hashCode直接将key的hashCode的高16位和低16位做了一次异或（散列）操作。\n\n然而在weakHashMap中显得复杂许多，在hash中作了两次散列操作，主要是为了扩大低位的影响，**因为Entry数组的大小是2的幂，在进行查找的时候，进行掩码处理，如果不进行二次散列，那么低位对index就完全没有影响了。**\n\n\n\n**indexFor(h, tab.length)**：计算下标\n\n```\n1.  private static int indexFor(int h, int length) {  \n\n2.      return h & (length-1);  \n\n3.  }  \n```\n\n这个和HashMap操作一样。\n\n\n\n**getTable()**：获取最新的table\n\n```\n1.  private Entry<K,V>[] getTable() {  \n\n2.      // 清除被回收的Entry对象  \n\n3.      expungeStaleEntries();  \n\n4.      return table;  \n\n5.  }  \n```\n\n这里就可以看到进行了清除操作，清除被回收的对象。\n\n\n\n**resize(tab.length \\* 2)**：扩容操作\n\n```\n1.  void resize(int newCapacity) {  \n\n2.      // 获取当前table  \n\n3.      Entry<K,V>[] oldTable = getTable();  \n\n4.      int oldCapacity = oldTable.length;  \n\n5.      if (oldCapacity == MAXIMUM_CAPACITY) {  \n\n6.          threshold = Integer.MAX_VALUE;  \n\n7.          return;  \n\n8.      }  \n\n9.      // 新建一个table  \n\n10.     Entry<K,V>[] newTable = **newTable**(newCapacity);  \n\n11.     // 将旧table中的内容复制到新table中  \n\n12.     transfer(oldTable, newTable);  \n\n13.     table = newTable;  \n\n14.     if (size >= threshold / 2) {  \n\n15.         threshold = (int)(newCapacity * loadFactor);  \n\n16.     } else {  \n\n17.         expungeStaleEntries();  \n\n18.         transfer(newTable, oldTable);  \n\n19.         table = oldTable;  \n\n20.     }  \n\n21. }  \n\n\n22. // 新建Entry数组  \n\n23. private Entry<K,V>[] newTable(int n) {  \n\n24.     return (Entry<K,V>[]) new Entry<?,?>[n];  \n\n25. }  \n\n\n26. private void transfer(Entry<K,V>[] src, Entry<K,V>[] dest) {  \n\n27.     for (int j = 0; j < src.length; ++j) {  \n\n28.         Entry<K,V> e = src[j];  \n\n29.         src[j] = null;  \n\n30.         while (e != null) {  \n\n31.             Entry<K,V> next = e.next;  \n\n32.             Object key = e.get();  \n\n33.             if (key == null) {  \n\n34.                 e.next = null;   \n\n35.                 e.value = null;   \n\n36.                 size--;  \n\n37.             } else {  \n\n38.                 int i = indexFor(e.hash, dest.length);  \n\n39.                 e.next = dest[i];  \n\n40.                 dest[i] = e;  \n\n41.             }  \n\n42.             e = next;  \n\n43.         }  \n\n44.     }  \n\n45. }  \n```\n\n这里和HashMap一样，也是扩充2的幂次方，但是有个有意思的地方就是，这里为了防止在扩容过程中，entry又进行了一轮回收导致释放了大量空间，所以在扩容后又进行了一次判断，如果size < threshold / 2的话就进行还原操作。\n\n\n\n##### 6.2 get\n\n```\n2.  public V get(Object key) {  \n\n3.      // 对null值特殊处理  \n\n4.      Object k = maskNull(key);  \n\n5.      // 取key的hash值  \n\n6.      int h = hash(k);  \n\n7.      // 取当前table  \n\n8.      Entry<K,V>[] tab = getTable();  \n\n9.      // 获取下标  \n\n10.     int index = indexFor(h, tab.length);  \n\n11.     Entry<K,V> e = tab[index];  \n\n12.     // 链表中查找元素  \n\n13.     while (e != null) {  \n\n14.         if (e.hash == h && **eq(k, e.get()**))  \n\n15.             return e.value;  \n\n16.         e = e.next;  \n\n17.     }  \n\n18.     return null;  \n\n19. }  \n```\n\n\n\n**eq(k, e.get())**：对比key值\n\n```\n1.  private static boolean eq(Object x, Object y) {  \n\n2.      return x == y || x.equals(y);  \n\n3.  }  \n```\n\n\n\n##### 6.3 remove\n\n```\n5.  public V remove(Object key) {  \n\n6.      // 对null值特殊处理  \n\n7.      Object k = maskNull(key);  \n\n8.      // 取key的hash  \n\n9.      int h = hash(k);  \n\n10.     // 取当前table  \n\n11.     Entry<K,V>[] tab = getTable();  \n\n12.     // 计算下标  \n\n13.     int i = indexFor(h, tab.length);  \n\n14.     Entry<K,V> prev = tab[i];  \n\n15.     Entry<K,V> e = prev;  \n\n16.     while (e != null) {  \n\n17.         Entry<K,V> next = e.next;  \n\n18.         // 查找对应Entry  \n\n19.         if (h == e.hash && eq(k, e.get())) {  \n\n20.             modCount++;  \n\n21.             size--;  \n\n22.             if (prev == e)  \n\n23.                 tab[i] = next;  \n\n24.             else  \n\n25.                 prev.next = next;  \n\n26.             // 如果找到，返回对应Entry的value  \n\n27.             return e.value;  \n\n28.         }  \n\n29.         prev = e;  \n\n30.         e = next;  \n\n31.     }  \n\n32.     return null;  \n\n33. }  \n```\n\n\n\n#### 7. weakHashMap的应用场景\n\n##### 7.1 用作缓存\n\n示例如下：\n\n```\n1.  public class MyWeakHashMap<K, V> {  \n\n2.      private int size;  \n\n3.      private ConcurrentHashMap<K, V> useMap;  \n\n4.      private WeakHashMap<K, V> cacheMap;  \n\n\n5.      public MyWeakHashMap(int size, ConcurrentHashMap<K, V> useMap, WeakHashMap<K, V> cacheMap) {  \n\n6.          super();  \n\n7.          this.size = size;  \n\n8.          this.useMap = useMap;  \n\n9.          this.cacheMap = cacheMap;  \n\n10.     }  \n\n\n11.     public void put(K k, V v) {  \n\n12.         if (useMap.size() >= size) {  \n\n13.             synchronized (cacheMap) {  \n\n14.                 **cacheMap.putAll(useMap);**  \n\n15.                 **cacheMap.clear(); ** \n\n16.             }  \n\n17.         }  \n\n18.         useMap.put(k, v);  \n\n19.     }  \n\n\n20.     public V get(K k) {  \n\n21.         V v = useMap.get(k);  \n\n22.         if (v == null) {  \n\n23.             synchronized (cacheMap) {  \n\n24.                 v = cacheMap.get(k);  \n\n25.             }  \n\n26.             if (v != null) {  \n\n27.                 **useMap.put(k, cacheMap.get(k));**  \n\n28.             }  \n\n29.         }  \n\n30.         return v;  \n\n31.     }  \n\n32. }  \n```\n\n这样设计的好处是，能将相对常用的对象都能在useMap中找到，**不常用的则存入cacheMap中缓存**，并且由于WeakHashMap能自动清除Entry，所以**不用担心cacheMap中键值对过多而导致OOM**。\n\n\n\n##### 7.2 配合事务\n\n配合事务进行使用，存储事务过程中的各类信息，可以使用如下结构：\n\n```\n1. WeakHashMap<String,Map<K,V>> transactionCache; \n```\n\n这里key为String类型，可以用来标志区分不同的事务，起到一个事务id的作用。value是一个map，可以是一个简单的HashMap或者LinkedHashMap，用来存放在事务中需要使用到的信息。\n\n在事务开始时创建一个事务id，并用它来作为key，事务结束后，将这个强引用消除掉，这样既能保证在事务中可以获取到所需要的信息，又能自动释放掉map中的所有信息。\n\n\n\n#### 8. WeakHashMap的注意事项\n\n**1）如果key是一个常量，即使将key置为null，对应的entry也不会被回收**\n\n\n\n举例说明，下面gc后不会清除已经为null的s1。\n\n```\n1.  WeakHashMap<Object, String> map = new WeakHashMap<>();  \n\n2.  Integer s1 = 118;  \n\n3.  String s2 = \"s2\";  \n\n4.  map.put(s1, \"s1\");  \n\n5.  map.put(s2, \"s2\");  \n\n6.  System.out.println(\"gc前，map=\" + map);  \n\n7.  s1 = null;  \n\n8.  System.out.println(s1);  \n\n9.  System.gc();  \n\n10. System.out.println(\"gc后，map=\" + map); \n```", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "a8b15ca09ba187705837cdf226804440": {"id": "a8b15ca09ba187705837cdf226804440", "item": "Java基础", "title": "线程池的工作原理分析", "date": "2024-08-22", "summary": "线程池是一种管理多线程的机制。它预先创建一定数量的线程，当有任务需要执行时，从池中分配线程去处理。可提高线程的复用率，减少线程创建和销毁的开销，同时能有效控制线程数量，避免系统资源过度消耗，提升系统性能。", "body": "\n先来看一下ThreadPoolExecutor中的重要成员，除了上面绑定线程池状态和线程数的ctl。\n\n```\n    //线程池任务队列，用于存放等待执行的任务  \n1.  private final BlockingQueue<Runnable>  workQueue;   \n\n    //用于线程池一些统计信息更新时的锁，e.g.如下的largestPoolSize，complectedTaskNum,ctl的状态和线程数更新时。\n2.   private final ReentrantLock mainLock = new ReentrantLock();\n    \n    //线程池工作集，Runnable的实现，里面封装了thread变量成员，用于执行任务  \n3.   private final HashSet<Worker> workers = new HashSet<Worker>();\n    \n    //客户端调用awaitTerminate()时，将阻塞与此，线程池处于terminate后，会调用condition.signalAll()通知（有time参数的另外考虑）。\n4.   private final Condition termination = mainLock.newCondition();\n   \n    //用于记录线程池运行过程曾出现过得最大线程数，不同于maximumPoolSize  \n6.   private int largestPoolSize;  \n\t\n    //用于动态记录线程池完成的任务数  \n7.   private long completedTaskCount;  \n\t\t\n    //用于创建新的线程,newThread(Runnable).  \n8.   private volatile ThreadFactory threadFactory; \n\t\t\n     //拒绝任务提交的处理器  \n9.   private volatile RejectedExecutionHandler handler; \n\t\t\n    //当线程数大于corePoolsize时，多出那部分线程处于idle状态时，最大保活时间。  \n10.  private volatile long keepAliveTime; \n\t\t\n    //当线程数小于corePoolsize时，是否允许其也运用保活时间限制。  \n11.  private volatile boolean allowCoreThreadTimeOut;  \n\n    //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）\n12.  private volatile int corePoolSize;   \n\n     //线程池运行的最大线程数。  \n13.  private volatile int maximumPoolSize;\n```\n\n\n因为threadPool.submit(thread)的底层也是threadPool.execute(thread)\n\n\n\n所以重点看**execute**()的源码\n\n```\n1.  public void execute(Runnable command) {  \n\n2.          if (command == null)  \n\n3.              throw new NullPointerException();  \n\n4.          int c = ctl.get();//读取ctl变量  \n\n5.          if (workerCountOf(c) < corePoolSize) {   //当前线程数和corePoolSize比较，当小于时：  \n\n6.              if (addWorker(command, true)) //addWorker一个new thread来处理该任务(true的情况)，直接返回；如果addWork返回false(线程池被shutdown or shutdownNow;或者同时又别的客户端提交任务，并且此时线程数大于corePoolSize);继续往下执行  \n\n9.                  return;  \n\n10.             c = ctl.get(); //重新读取ctl变量  \n\n11.         }  \n\n12.         if (isRunning(c) && workQueue.offer(command)) {//对addWorker返回false的情况进行判断,当线程池还运行着，说明是因为thread number 大于corePoolSize的情况，则&&操作第二个表达式把任务添加到workQueue队列中  \n\n15.             int recheck = ctl.get(); //再次读取ctl，防止并发\n\n16.             if (! isRunning(recheck) && remove(command))   //把任务加入队列的同时，pool被shutdown， 则从队列中删除task,并且调用rejectHandler的方法  \n\n17.                 reject(command);  \n\n18.             else if (workerCountOf(recheck) == 0)  //如果此时线程数为0（即设置了allowCorePoolSizeTimeOut为true的情况），则追加一个new thread(初始任务为null)  \n\n19.                 addWorker(null, false); \n\n20.         }  \n\n21.         else if (!addWorker(command, false)) //对于其他addWorker()为false的情况，即！isRunning和 workQueue.offer()失败的情况，再次尝试addWorker()添加new thread，如果为false,说明pool被关闭或者达到pool饱和，直接reject\n\n24.             reject(command);  \n\n25.     }\n```\n\n\n\nexecute的执行流程如下图：\n\n![img](http://pcc.huitogo.club/035041727e4daa9f76397ec32f4191cf)\n\nexecute的过程可以分三步\n\n第一步：当前工作线程数是否小于corePoolSize，即是否还能new线程去执行这个Runnable。\n\n第二步：没有足够线程处理了就放入workQueue中，等待corePoolSize下的线程执行完毕，在此过程中要考虑有其他任务加进来影响了当前工作线程数的值和判断线程池是否被强行关闭了，这时候需要从workQueue中移除且执行拒绝策略；如果设置了allowCorePoolSizeTimeOut为true，即不用等待从workQueue中去取Runnable了，直接new一个线程去处理当前这条Runnable。\n\n第三步：执行第三步是因为第二步中的workQueue满了或者执行第二步时线程池被关闭了这时候仍然努力去new一个线程执行这个Runnable，如果返回false则执行reject方法。\n\n\n\n#### 1. addWorker\n\n这里注意一下上面三次addWorker的不同含义\n\n1. addWorker(command, true)：正常范围内添加worker并指定firstTask\n2. addWorker(null, false)：由于允许线程池消除空闲worker的前提下，worker工作组没有线程了，那就起一个空的worker去执行吧\n3. addWorker(command, false)：向workQueue中添加task失败了，说明线程池太忙了，那么允许线程池在maximuxPoolSize的范围内新建Worker去分忧。如果这都失败了，那就只能执行reject策略了。\n\n\n\nexecute()中的**reject**方法\n\n```\n1.  final void reject(Runnable command) {  \n\n2.      handler.rejectedExecution(command, this); //调用rejectHander的处理方法处理。  \n\n3.  } \n```\n\n\n\nexecute()中的**addWorker**方法\n\n```\n1.  private boolean addWorker(Runnable firstTask, boolean core) {  \n\n2.      retry:  \n\n3.      for (;;) {  \n\n4.          int c = ctl.get();  \n\n5.          int rs = runStateOf(c);  \n\n6.          if (rs >= SHUTDOWN &&   ! (rs == SHUTDOWN &&   firstTask == null &&   ! workQueue.isEmpty()))   // 判断还有没有必要在新建worker去执行task  \n\n10.             return false;  \n\n11.         for (;;) {  \n\n12.             int wc = workerCountOf(c);  \n\n13.             if (wc >= CAPACITY ||  wc >= (core ? corePoolSize : maximumPoolSize)) // pool达到饱满，放弃新建worker  \n\n15.                 return false;  \n\n16.             if (compareAndIncrementWorkerCount(c)) // cas增加worker数量  \n\n17.                 break retry;  // 流程结束  \n\n18.             c = ctl.get();  // cas增加失败后  \n\n19.             if (runStateOf(c) != rs)  // 如果线程池状态发生变化，回到开始判断是否有必要新增worker的地方  \n\n20.                 continue retry;  \n\n21.         }  \n\n22.     }  \n\n23.     boolean workerStarted = false;  // worker是否已经启动  \n\n24.     boolean workerAdded = false; // worker是否已经加入了workers  \n\n25.     Worker w = null;  \n\n26.     try {  \n\n27.         w = new Worker(firstTask);  \n\n28.         final Thread t = w.thread;  \n\n29.         if (t != null) {  \n\n30.             final ReentrantLock mainLock = this.mainLock;   \n\n31.             mainLock.lock(); // 加锁处理  \n\n32.             try {  \n\n33.                 int rs = runStateOf(ctl.get());  \n\n34.                 if (rs < SHUTDOWN ||  (rs == SHUTDOWN && firstTask == null)) { // 这里一种是线程池还在运行，一种是线程池即将关闭了而且当前worker也没有task，那么就没有必要新增worker线程了  \n\n36.                     if (t.isAlive()) // 判断worker的线程状态  \n\n37.                         throw new IllegalThreadStateException();  \n\n38.                     workers.add(w); // 新增worker  \n\n39.                     int s = workers.size();  \n\n40.                     if (s > largestPoolSize) // 记录线程池运行过的最大的线程数  \n\n41.                         largestPoolSize = s;  \n\n42.                     workerAdded = true;  \n\n43.                 }  \n\n44.             } finally {  \n\n45.                 mainLock.unlock(); // 解锁  \n\n46.             }  \n\n47.             if (workerAdded) { // 启动worker  \n\n48.                 t.start(); // 这里有可能出现OOM，导致workerStarted=false  \n\n49.                 workerStarted = true;  \n\n50.             }  \n\n51.         }  \n\n52.     } finally {  \n\n53.         if (! workerStarted) // 如果出现OOM，进行失败处理  \n\n54.             addWorkerFailed(w);  \n\n55.     }  \n\n56.     return workerStarted;  \n\n57. }  \n```\n\n\n\n上述流程步骤\n\n1. 判断有没有必要去新建一个worker（线程）去执行firstTask和workQueue中的task\n2. 确实有必要就cas增加worker的数量\n3. 再实例化一个worker，将它加入workers工作组，启动这个worker\n4. 如果启动失败了，进行失败处理，失败处理代码看下面\n\n\n\naddWorker中的**addWorkerFailed**方法\n\n```\n1.  private void addWorkerFailed(Worker w) {  \n\n2.      final ReentrantLock mainLock = this.mainLock;  \n\n3.      mainLock.lock();  \n\n4.      try {  \n\n5.          if (w != null)  \n\n6.              workers.remove(w); // 从workers工作组移除失败的worker  \n\n7.          decrementWorkerCount(); // 减少workers的数量  \n\n8.          tryTerminate(); //检查线程池有没有terminate\n\n9.      } finally {  \n\n10.         mainLock.unlock();  \n\n11.     }  \n\n12. } \n```\n\n\n\n#### 2. tryTerminate\n\n失败处理的逻辑也分三步，这里看一下**tryTerminate**的方法\n\n```\n1.  final void tryTerminate() {  \n\n2.      for (;;) {  \n\n3.          int c = ctl.get();  \n\n4.          // 如果线程池在运行或者已经terminate了或者正在shutdown且还有task没完成 这些情况下不能强行terminate  \n\n5.          if (isRunning(c) ||  runStateAtLeast(c, TIDYING) ||   (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))  \n\n8.              return;  \n\n9.          if (workerCountOf(c) != 0) { // 将workers中的worker线程给interrupt掉  \n\n10.             interruptIdleWorkers(ONLY_ONE); // ONLY_ONE代表是否只interrupt掉一个worker  \n\n11.             return;  \n\n12.         }  \n\n13.         // 这里说明当前线程池没有线程运行，开始terminate掉线程池  \n\n14.         final ReentrantLock mainLock = this.mainLock;  \n\n15.         mainLock.lock();  \n\n16.         try {  \n\n17.             if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { // 线程池状态改为tidying，此时离terminate状态只差临门一脚  \n\n18.                 try {  \n\n19.                     terminated(); // 这就是临门一脚  \n\n20.                 } finally {  \n\n21.                     ctl.set(ctlOf(TERMINATED, 0)); // 线程池状态改为terminated  \n\n22.                     termination.signalAll(); // 通知那些阻塞awaitTerminate（）方法客户端。  \n\n23.                 }  \n\n24.                 return;  \n\n25.             }  \n\n26.         } finally {  \n\n27.             mainLock.unlock();  \n\n28.         }  \n\n29.         // 到这儿了说明没有cas更改线程池状态成功，那么下一次吧  \n\n30.     }  \n\n31. }  \n```\n\n上述过程分两步，先interrupt掉workers中的worker线程，再terminate线程池。\n\n\n\n#### 3. runWorker\n\n看完了addWorker中worker添加失败后的逻辑后，回头看一下在worker添加成功后发生了，也就是worker.run方法，实际调用的是**runWorker**方法，代码如下\n\n```\n1.  final void runWorker(Worker w) {  \n\n2.      Thread wt = Thread.currentThread();  \n\n3.      Runnable task = w.firstTask;  \n\n4.      w.firstTask = null;   \n\n5.      w.unlock(); // allow interrupts  \n\n6.      boolean completedAbruptly = true; // 这个代表worker执行任务中有没有意外暴毙  \n\n7.      try {  \n\n8.          while (task != null || (task = getTask()) != null) { // 如果worker自身接的任务是Null，就从workQueue中拿任务  \n\n9.              w.lock();  \n                   \n\t\t// 做任务之前，看看线程池是不是正在terminate，如果是的话就自我毁灭（interrupt）\n10.             if ((runStateAtLeast(ctl.get(), STOP) ||   (Thread.interrupted() &&   runStateAtLeast(ctl.get(), STOP))) &&   !wt.isInterrupted())  \n\n14.                 wt.interrupt();  \n\n15.             try {  \n\n16.                 beforeExecute(wt, task); // 这个方法用来覆盖  \n\n17.                 Throwable thrown = null;  \n\n18.                 try {  \n\n19.                     task.run();  \n\n20.                 } catch (RuntimeException x) {  \n\n21.                     thrown = x; throw x;  \n\n22.                 } catch (Error x) {  \n\n23.                     thrown = x; throw x;  \n\n24.                 } catch (Throwable x) {  \n\n25.                     thrown = x; throw new Error(x);  \n\n26.                 } finally {  \n\n27.                     afterExecute(task, thrown); // 这个方法用来覆盖  \n\n28.                 }  \n\n29.             } finally {  \n\n30.                 task = null;  \n\n31.                 w.completedTasks++; //worker完成任务数 + 1  \n\n32.                 w.unlock();  \n\n33.             }  \n\n34.         }  \n\n35.         completedAbruptly = false;  \n\n36.     } finally {  \n\n37.         processWorkerExit(w, completedAbruptly); // 收尾工作，根据当前的worker是否正常退出  \n\n38.     }  \n\n39. }  \n```\n\n上述过程就是\n\nworker线程执行自身任务以及从workerQueue中取出task去执行，直到没有任务可执行或者执行任务中出现异常时退出，退出会执行一次收尾工作。\n\n\n\n#### 4. getTask\n\n先看一下怎么从workerQueue中取出task，方法**getTask**代码如下\n\n```\n1.  private Runnable getTask() {  \n\n2.      boolean timedOut = false; // timedOut代表上一次循环取task的时候是否超时了  \n\n3.      for (;;) {  \n\n4.          int c = ctl.get();  \n\n5.          int rs = runStateOf(c);  \n\n6.          // 如果线程已经在terminate或者在stop中但是workQueue中没有任务的时候直接减少worker的数量  \n\n7.          if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {  \n\n8.              decrementWorkerCount();  \n\n9.              return null;  \n\n10.         }  \n\n11.         int wc = workerCountOf(c);  \n\n12.         // allowCoreThreadTimeOut 表示是否允许在worker数量没有达到corePoolSize的时候就消除空间worker  \n\n13.         // timed 的含义就是当前是否可以消除空闲worker  \n\n14.         boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;  \n\n15.         // 这里判断当前的worker是否有点多余  \n\n16.         // 如果当前工作的woker数量大于maximumPoolSize了，那肯定是多余了  \n\n17.         // 在当前worker没有任务，就是上一次没取到任务并且当前线程池允许消除空闲worker的前提下，如果workers工作组里面至少有一个线程了，或者没有任务了，那当前worker就是多余的  \n\n18.         if ((wc > maximumPoolSize || (timed && timedOut))  && (wc > 1 || workQueue.isEmpty())) {  \n\n20.             if (compareAndDecrementWorkerCount(c))  \n\n21.                 return null;  \n\n22.             continue;  \n\n23.         }  \n\n24.         // 开始接取任务，分两种  \n\n25.         // 一种是允许线程池消除空闲worker，那么如果这个worker在keepAliveTime时间内没有拿到task，说明现在线程池不忙，下一次循环考虑清除你  \n\n26.         // 另一种不允许的情况下也就是线程数没有限制（小于maximumPoolSize）的情况下，那无所谓了，你就一直等着吧，等到有task进workQueue了你就拿出来执行  \n\n27.         try {  \n\n28.             Runnable r = timed ?   workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :  workQueue.take();  \n\n31.             if (r != null)  \n\n32.                 return r;  \n\n33.             timedOut = true;  \n\n34.         } catch (InterruptedException retry) {  \n\n35.             timedOut = false;  \n\n36.         }  \n\n37.     }  \n\n38. }  \n```\n\n\n\n上述过程步骤如下\n\n1. 如果线程已经在stop或者在shutdown中但是workQueue中没有任务的时候直接减少worker的数量 \n\n2. 在线程池没有stop或者shutdown但是还有task需要执行的时候判断当前这个worker是不是多余的\n\n3. 如果当前工作的woker数量大于maximumPoolSize了，那肯定是多余了 \n\n4. 在当前worker没有任务，就是上一次没取到任务并且当前线程池允许消除空闲 worker的前提下，如果workers工作组里面至少有一个线程了，或者没有任务了，那当 前worker就是多余的 \n\n5. 开始接取任务，分两种\n\n   1）一种是允许线程池消除空闲worker，那么如果这个worker在keepAliveTime时间内没有拿到task，说明现在线程池不忙，下一次循环考虑辞退你 \n\n   2）另一种不允许的情况下也就是线程数没有限制（小于maximumPoolSize）的情况下，那无所谓了，你就一直等着吧，等到有task进workQueue了你就拿出来执行\n\n\n\n#### 5. processWorkerExit\n\n讲完woker线程怎么从workQueue中取task之后，再回到runWorker中看一下woker执行完成或者失败后的收尾工作\n\nrunWorker()中方法**processWorkerExit**代码如下\n\n```\n1.  private void processWorkerExit(Worker w, boolean completedAbruptly) {  \n\n2.      // 如果worker是暴毙的话，是不会调整workers的数量的，这里手动调整  \n\n3.      if (completedAbruptly)   \n\n4.          decrementWorkerCount();  \n\n5.      final ReentrantLock mainLock = this.mainLock;  \n\n6.      mainLock.lock();  \n\n7.      try {  \n\n8.          // 统计worker的工作量  \n\n9.          completedTaskCount += w.completedTasks;  \n\n10.         // 辞退worker  \n\n11.         workers.remove(w);  \n\n12.     } finally {  \n\n13.         mainLock.unlock();  \n\n14.     }  \n\n15.     // 看看线程池是不是在terminated中  \n\n16.     tryTerminate();  \n\n17.     // 辞退worker后开始考虑一个问题了，我这个线程池还有没有活干  \n\n18.     // 有活干得话，如果刚刚worker是暴毙得话，那我肯定要再雇一个wokrer来  \n\n19.     // 如果刚刚worker不是暴毙的，是下岗的话，那我要确认一下现在忙不忙，忙的话还得再请worker，不忙的话一个也够用了  \n\n20.     int c = ctl.get();  \n\n21.     if (runStateLessThan(c, STOP)) {  \n\n22.         if (!completedAbruptly) {  \n\n23.             int min = allowCoreThreadTimeOut ? 0 : corePoolSize;  \n\n24.             if (min == 0 && ! workQueue.isEmpty())  \n\n25.                 min = 1;  \n\n26.             if (workerCountOf(c) >= min)  \n\n27.                 return;  // replacement not needed  \n\n28.         }  \n\n29.         addWorker(null, false);  \n\n30.     }  \n\n31. } \n```\n\n\n\n上述过程如下\n\n1. 如果worker是暴毙的话那我要手动调整workers的数量\n2. 统计一下worker的工作（发放一下工资），再辞退它\n3. 辞退worker后开始考虑一个问题了，我这个线程池还有没有活干 \n4. 有活干的话，如果刚刚worker是暴毙得话，那我肯定要再雇一个wokrer来 \n5. 如果刚刚worker不是暴毙的，是下岗的话，那我要确认一下现在忙不忙，忙的话还得再请worker，不忙的话一个也够用了", "imgFile": "02.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}}, "源码解读": {"2a8821e1e222a0b708e12a9b329a940e": {"id": "2a8821e1e222a0b708e12a9b329a940e", "item": "源码解读", "title": "Disruptor源码分析", "date": "2024-08-22", "summary": "Disruptor 是一个高性能的异步处理框架。它通过环形缓冲区实现无锁并发，极大提高了数据处理效率。能在高并发场景下，让多个生产者和多个消费者高效协作，减少竞争和等待，是处理大规模数据和高并发任务的强大工具。", "body": "\n先看一下Disruptor中重要组件之间的协作关系\n\n\n\n![img](http://pcc.huitogo.club/5833b00a0505618b978df3ce9351ca24)\n\n\n\n**Ring Buffer（DataProvider）**\n\n如其名，环形的缓冲区。曾经 RingBuffer 是 Disruptor 中的最主要的对象，但从3.0版本开始，其职责被简化为仅仅负责对通过 Disruptor 进行交换的数据（事件）进行存储和更新。在一些更高级的应用场景中，Ring Buffer 可以由用户的自定义实现来完全替代。\n\n\n\nSequence 通过顺序递增的序号来编号管理通过其进行交换的数据（事件），对数据(事件)的处理过程总是沿着序号逐个递增处理。一个 Sequence 用于跟踪标识某个特定的事件处理者( RingBuffer/Consumer )的处理进度。虽然一个 AtomicLong 也可以用于标识进度，但定义 Sequence 来负责该问题还有另一个目的，那就是防止不同的Sequence 之间的CPU缓存伪共享(Flase Sharing)问题。\n\n\n\n**Sequencer**\n\n是 Disruptor 的真正核心。此接口有两个实现类 SingleProducerSequencer、MultiProducerSequencer ，它们定义在生产者和消费者之间快速、正确地传递数据的并发算法。\n\n\n\n**Sequence Barrier**\n\n用于保持对RingBuffer的 main published Sequence 和Consumer依赖的其它Consumer的 Sequence 的引用。 Sequence Barrier 还定义了决定 Consumer 是否还有可处理的事件的逻辑。\n\n\n\n**Wait Strategy**\n\n定义 Consumer 如何进行等待下一个事件的策略。 （注：Disruptor 定义了多种不同的策略，针对不同的场景，提供了不一样的性能表现）\n\n\n\n**Event**\n\n在 Disruptor 的语义中，生产者和消费者之间进行交换的数据被称为事件(Event)。它不是一个被 Disruptor 定义的特定类型，而是由 Disruptor 的使用者定义并指定。\n\n\n\n**EventProcessor**\n\nEventProcessor 持有特定消费者(Consumer)的 Sequence，并提供用于调用事件处理实现的事件循环(Event Loop)。\n\n\n\n**EventHandler**\n\nDisruptor 定义的事件处理接口，由用户实现，用于处理事件，是 Consumer 的真正实现。\n\n\n\n**Producer**\n\n即生产者，只是泛指调用 Disruptor 发布事件的用户代码，Disruptor 没有定义特定接口或类型。\n\n\n\n\n\n#### **1、初始化**\n\n```\n/**\n * Create a new Disruptor. Will default to {@link com.lmax.disruptor.BlockingWaitStrategy} and\n * {@link ProducerType}.MULTI\n *\n * @param eventFactory   the factory to create events in the ring buffer.\n * @param ringBufferSize the size of the ring buffer.\n * @param threadFactory  a {@link ThreadFactory} to create threads to for processors.\n */\npublic Disruptor(final EventFactory<T> eventFactory, final int ringBufferSize, final ThreadFactory threadFactory)\n{\n    this(RingBuffer.createMultiProducer(eventFactory, ringBufferSize), new BasicExecutor(threadFactory));\n}\n```\n\n\n\n其中 EventFactory 即生产者，生产Event数据到RingBuffer中，ringBufferSize即环数组的长度限制，一般是 2的幂等方，方便做位运算，threadFactory 是构建线程池的线程工厂，这里线程池 是执行消费者线程的执行器\n\n\n\n生产者分两种，多生产者MultiProducerSequencer 和 单生产者 SingleProducerSequencerPad，这里以创建多生产者为例\n\n```\npublic final class MultiProducerSequencer extends AbstractSequencer{\n    \n    // availableBuffer tracks the state of each ringbuffer slot\n\n    private final int[] availableBuffer;\n    // 掩码 = ringBufferSize - 1，用于 和 sequence做位于运算 求下标\n    private final int indexMask;\n    // sequence 下标 index 的偏移量 = bufferSize 的 2的阶值\n    private final int indexShift;\n    \n     /**\n     * Construct a Sequencer with the selected wait strategy and buffer size.\n     *\n     * @param bufferSize   the size of the buffer that this will sequence over.\n     * @param waitStrategy for those waiting on sequences.\n     */\n    public MultiProducerSequencer(int bufferSize, final WaitStrategy waitStrategy)\n    {\n        super(bufferSize, waitStrategy);\n        availableBuffer = new int[bufferSize];\n        indexMask = bufferSize - 1;\n        // 比如 bufferSize为1024 则indexShift = 10\n        indexShift = Util.log2(bufferSize);\n        // 初始化 sequence 的下标的 flag值\n        initialiseAvailableBuffer();\n    }\n```\n\n\n\n这里waitStrategy 指的是消费者的等待策略，即当前没有可消费event消息时的 消费者线程的行为，有以下几种\n\n\n\n![img](http://pcc.huitogo.club/4beec8629c99c6903929b7edfc61f3a9)\n\n\n\navailableBuffer 有两种用处，一种用于多生产者情况下 避免重复写入同一个数组单元的安全缓冲地带，另一个也避免消费者 拿到还未生产成功的Event消息，原理就是无论你是读还是写 都需要在 availableBuffer 在指定sequence的位置将flag置为有效，创建Sequencer的时候会初始化availableBuffer数组中的所有元素flag值为-1\n\n```\n// 数组在内存中初始位置（偏移量）\nprivate static final long BASE = UNSAFE.arrayBaseOffset(int[].class);\n//一个数组元素占用的偏移量\nprivate static final long SCALE = UNSAFE.arrayIndexScale(int[].class);\n\nprivate void initialiseAvailableBuffer()\n{\n    for (int i = availableBuffer.length - 1; i != 0; i--)\n    {\n        setAvailableBufferValue(i, -1);\n    }\n    setAvailableBufferValue(0, -1);\n}\n\nprivate void setAvailableBufferValue(int index, int flag)\n{\n    long bufferAddress = BASE + (index * SCALE);\n    UNSAFE.putOrderedInt(availableBuffer, bufferAddress, flag);\n}\n```\n\n\n\nUNSAFE 里面是native方法，直接和jvm内存做交互，所以有更高的性能，但是使用它修改内存值的时候 得使用它的native方法，比如这里的UNSAFE.putOrderedInt，需要自己计算待修改值在内存中相对于对象的偏移量，比如这里计算修改index的元素位置是BASE + (index * SCALE)；\n\n\n\n创建好Sequencer之后，需要初始化 RingBuffer（DataProvider）\n\n```\nprivate static final int BUFFER_PAD;\nprivate static final long REF_ARRAY_BASE;\nprivate static final int REF_ELEMENT_SHIFT;\nprivate static final Unsafe UNSAFE = Util.getUnsafe();\n\nprivate final long indexMask;\n// 物理上是从entries中定位元素的 逻辑上借助Sequencer 获取元素的下标\nprivate final Object[] entries;\nprotected final int bufferSize;\nprotected final Sequencer sequencer;\n\nRingBufferFields(EventFactory<E> eventFactory, Sequencer sequencer)\n{\n    this.sequencer = sequencer;\n    this.bufferSize = sequencer.getBufferSize();\n\n    this.indexMask = bufferSize - 1;\n    // 实际数组长度  =  128 / scale * 2 + bufferSize\n    this.entries = new Object[sequencer.getBufferSize() + 2 * BUFFER_PAD];\n    // 将entries中 bufferSize 边界里的元素值填充默认值\n    fill(eventFactory);\n}\n\nstatic\n{\n    // 数组元素 占用精度（位数）\n    final int scale = UNSAFE.arrayIndexScale(Object[].class);\n    if (4 == scale)\n    {\n        REF_ELEMENT_SHIFT = 2;\n    }\n    else if (8 == scale)\n    {\n        REF_ELEMENT_SHIFT = 3;\n    }\n    else\n    {\n        throw new IllegalStateException(\"Unknown pointer size\");\n    }\n    BUFFER_PAD = 128 / scale;\n    // Including the buffer pad in the array base offset\n    REF_ARRAY_BASE = UNSAFE.arrayBaseOffset(Object[].class) + (BUFFER_PAD << REF_ELEMENT_SHIFT);\n}\n```\n\n\n\nRingBuffer 物理上存储Event消息的结构是 entries数组，但是数组是有界的，怎么让它循环存储元素达到一个无边界的效果呢，答案就是 使用Sequence做元素的 逻辑序列值，Sequence里面有个 value值，每次申请新的序列值都会新增\n\n\n\nSequence 存储的value值 为了避免 伪共享，使用了 行对齐的方式，即 前后各填充了 7个long值，当然获取 和 修改value值也使用了UNSAFE类\n\n```\nclass LhsPadding\n{\n    protected long p1, p2, p3, p4, p5, p6, p7;\n}\n\nclass Value extends LhsPadding\n{\n    protected volatile long value;\n}\n\nclass RhsPadding extends Value\n{\n    protected long p9, p10, p11, p12, p13, p14, p15;\n}\n\npublic class Sequence extends RhsPadding\n{\n    static final long INITIAL_VALUE = -1L;\n    private static final Unsafe UNSAFE;\n    private static final long VALUE_OFFSET;\n\n    static\n    {\n        UNSAFE = Util.getUnsafe();\n        try\n        {\n            VALUE_OFFSET = UNSAFE.objectFieldOffset(Value.class.getDeclaredField(\"value\"));\n        }\n        catch (final Exception e)\n        {\n            throw new RuntimeException(e);\n        }\n    }\n    \n    public void set(final long value)\n    {\n        UNSAFE.putOrderedLong(this, VALUE_OFFSET, value);\n    }\n}\n```\n\n\n\n初始化RingBuffer会初始化 entries数组中的Event消息默认值，这里就有个巧妙的设计了，正常生产 和 消费 都是基于空的队列 去塞/获取 数据，但是RingBuffer可是一开始就将数组塞满 默认Event事件，当然这个默认Event也是由用户自定义的EventFactory生成\n\n```\nprivate void fill(EventFactory<E> eventFactory)\n{\n    for (int i = 0; i < bufferSize; i++)\n    {\n        entries[BUFFER_PAD + i] = eventFactory.newInstance();\n    }\n}\n```\n\n\n\n实际entries的长度 = ringBufferSize + 2* BUFFER_PAD，这里赋值的时候是在中间一段 ringBufferSize的长度进行赋值，即前后都预留了 BUFFER_PAD长度的空白作为缓冲地带，BUFFER_PAD = 2^7 >>> 2 的长度，即2^5 的长度\n\n\n\n![img](http://pcc.huitogo.club/7b86163b13cc856ced3f8af4815da24a)\n\n\n\n\n\n#### **2、配置消费者组**\n\n\n\nRingBuffer初始化后，我们需要配置消费者组 - 实现EventHandler的消费者们，消息者也就是事件监听器\n\n```\npublic class SeckillEventConsumer implements EventHandler<SeckillEvent> {\n\n    @Override\n    public void onEvent(SeckillEvent seckillEvent, long seq, boolean bool) throws Exception {\n//        seckillService.doSeckill(seckillEvent.getSeckill_id());\n    }\n}\n\ndisruptor.handleEventsWith(new SeckillEventConsumer());\n\nEventProcessorInfo(消费者) = BatchEventProcessor（消费者监听线程） + EventHandler（消费事件执行器），多个消费者共用一个SequenceBarrier（序号屏障）\nprivate final ConsumerRepository<T> consumerRepository = new ConsumerRepository<>();\n\nEventHandlerGroup<T> createEventProcessors(\n    final Sequence[] barrierSequences,\n    final EventHandler<? super T>[] eventHandlers)\n{\n    checkNotStarted();\n\n    final Sequence[] processorSequences = new Sequence[eventHandlers.length];\n    final SequenceBarrier barrier = ringBuffer.newBarrier(barrierSequences);\n\n    // 每有一个 EventHandler 就新增一个消费者 ,假设有n个消费者\n    // 1 * SequenceBarrier + n * BatchEventProcessor + n * EventHandler = EventHandlerGroup\n    // SequenceBarrier ：序号屏障, 保证消费者和生产者，消费者和消费者之间的可见性和消费速度\n    // BatchEventProcessor：消费者线程，从RingBuffer里消费事件 交给EventHandler执行\n    // EventHandler：消费事件执行器\n    for (int i = 0, eventHandlersLength = eventHandlers.length; i < eventHandlersLength; i++)\n    {\n        final EventHandler<? super T> eventHandler = eventHandlers[i];\n\n        final BatchEventProcessor<T> batchEventProcessor =\n            new BatchEventProcessor<>(ringBuffer, barrier, eventHandler);\n\n        if (exceptionHandler != null)\n        {\n            batchEventProcessor.setExceptionHandler(exceptionHandler);\n        }\n\n        consumerRepository.add(batchEventProcessor, eventHandler, barrier);\n        processorSequences[i] = batchEventProcessor.getSequence();\n    }\n    // 更新消费者的 消费序列到 sequenceGroup中\n    updateGatingSequencesForNextInChain(barrierSequences, processorSequences);\n\n    return new EventHandlerGroup<>(this, consumerRepository, processorSequences);\n}\n```\n\n\n\n消费者线程 执行的任务 我们在读数据的时候再认真看下，这里主要看一下 消费者各自的消费序列是怎么维护的\n\n```\nprivate void updateGatingSequencesForNextInChain(final Sequence[] barrierSequences, final Sequence[] processorSequences)\n{\n    if (processorSequences.length > 0)\n    {\n        ringBuffer.addGatingSequences(processorSequences);\n        for (final Sequence barrierSequence : barrierSequences)\n        {\n            ringBuffer.removeGatingSequence(barrierSequence);\n        }\n        consumerRepository.unMarkEventProcessorsAsEndOfChain(barrierSequences);\n    }\n}\n...\nclass SequenceGroups\n{\n    static <T> void addSequences(\n        final T holder,\n        final AtomicReferenceFieldUpdater<T, Sequence[]> updater,\n        final Cursored cursor,\n        final Sequence... sequencesToAdd)\n    {\n        long cursorSequence;\n        Sequence[] updatedSequences;\n        Sequence[] currentSequences;\n\n        do\n        {\n            currentSequences = updater.get(holder);\n            // updatedSequences = currentSequences + sequencesToAdd\n            updatedSequences = copyOf(currentSequences, currentSequences.length + sequencesToAdd.length);\n            cursorSequence = cursor.getCursor();\n\n            int index = currentSequences.length;\n            // sequencesToAdd 的Sequence 赋 当前生产者的消费指针位置 然后添加到 updatedSequences中\n            for (Sequence sequence : sequencesToAdd)\n            {\n                sequence.set(cursorSequence);\n                updatedSequences[index++] = sequence;\n            }\n        }\n        while (!updater.compareAndSet(holder, currentSequences, updatedSequences));\n\n        cursorSequence = cursor.getCursor();\n        for (Sequence sequence : sequencesToAdd)\n        {\n            sequence.set(cursorSequence);\n        }\n    }\n```\n\n\n\n最终会再SequenceGroups中进行存储，在初始化 和 更新的时候 会将原数组 进行 System.copyof一份，然后借助AtomicReferenceFieldUpdater 和 CAS进行原子性 和 可见性的更新\n\n\n\n消费者最终会存储到ConsumerRepository 中，可迭代访问\n\n```\n/**\n * Provides a repository mechanism to associate {@link EventHandler}s with {@link EventProcessor}s\n *\n * @param <T> the type of the {@link EventHandler}\n */\nclass ConsumerRepository<T> implements Iterable<ConsumerInfo>\n{\n    private final Map<EventHandler<?>, EventProcessorInfo<T>> eventProcessorInfoByEventHandler =\n        new IdentityHashMap<>();\n    private final Map<Sequence, ConsumerInfo> eventProcessorInfoBySequence =\n        new IdentityHashMap<>();\n    private final Collection<ConsumerInfo> consumerInfos = new ArrayList<>();\n\n    public void add(\n        final EventProcessor eventprocessor,\n        final EventHandler<? super T> handler,\n        final SequenceBarrier barrier)\n    {\n        final EventProcessorInfo<T> consumerInfo = new EventProcessorInfo<>(eventprocessor, handler, barrier);\n        eventProcessorInfoByEventHandler.put(handler, consumerInfo);\n        eventProcessorInfoBySequence.put(eventprocessor.getSequence(), consumerInfo);\n        consumerInfos.add(consumerInfo);\n    }\n}\n```\n\n\n\n\n\n#### **3、写数据**\n\n\n\n现在我们看一下生产者是怎么输出数据的，前面我们已经知道RingBuffer中其实每个元素都已经被我们使用EventFactory初始化了Event，那么生产者要做的事就不是new一个Event，而是定位到可生产元素的有效位置然后 塞入事件消息\n\n```\npublic void publishEvent(EventTranslatorVararg<E> translator, Object... args)\n{    \n    // 找到有效位置\n    final long sequence = sequencer.next();\n    // 塞入值\n    translateAndPublish(translator, sequence, args);\n}\n```\n\n\n\n我们基于多生产者 MultiProducerSequencer 来看如何找到有效位置\n\n```\n/**\n * @see Sequencer#next(int)\n */\n@Override\npublic long next(int n)\n{\n    if (n < 1)\n    {\n        throw new IllegalArgumentException(\"n must be > 0\");\n    }\n\n    long current;\n    long next;\n\n    do\n    {\n        current = cursor.get();\n        next = current + n;\n\n        // 相对于当前 cursor 的 数组起点\n        long wrapPoint = next - bufferSize;\n        // gatingSequenceCache 最小的消费序列\n        long cachedGatingSequence = gatingSequenceCache.get();\n\n        // 限制生产者能不能继续生产，Max(待生效的序列) - Min(消费序列) 不能大于 bufferSize\n        if (wrapPoint > cachedGatingSequence || cachedGatingSequence > current)\n        {\n            // 寻找消费者组 和 当前生产游标的 最小值\n            long gatingSequence = Util.getMinimumSequence(gatingSequences, current);\n\n            // 生产太快了 需要等一等消费者\n            if (wrapPoint > gatingSequence)\n            {\n                LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy?\n                continue;\n            }\n\n            gatingSequenceCache.set(gatingSequence);\n        }\n        else if (cursor.compareAndSet(current, next))\n        {\n            break;\n        }\n    }\n    while (true);\n\n    return next;\n}\n```\n\n这里有两个地方需要注意的是\n\n1）多个生产者申请的区间是不一样的，使用CAS操作保证线程安全\n\n2）最快的生产者 和 最慢的消费者之间相差的序列值不能大于RingBufferSize的长度，否则生产者会一直在自旋加锁（park 1ns），这也就是生产者的等待策略\n\n\n\n生产者申请好写入区间之后，塞入值操作 也就是一个translate操作，使用Translator将原entries中的元素值 装配成带有 事件的元素\n\n```\nprivate void translateAndPublish(EventTranslatorVararg<E> translator, long sequence, Object... args)\n{\n    try\n    {\n        //translate操作\n        translator.translateTo(get(sequence), sequence, args);\n    }\n    finally\n    {\n        sequencer.publish(sequence);\n    }\n}\n```\n\n\n\nTranslator是用于自定义的，需要实现EventTranslatorVararg 接口\n\n\n\n这里有个重要点就是怎么根据 sequence下标 在entires中寻找到实际的元素，即get(sequence)方法\n\n```\npublic E get(long sequence)\n{\n    return elementAt(sequence);\n}\n\n/**\n * 根据 序列 获取 在entries数组中的实际元素\n * @param sequence\n * @return\n */\n@SuppressWarnings(\"unchecked\")\nprotected final E elementAt(long sequence)\n{\n    // 基于 sequence 获取 实际 entries 中的对象 为什么要偏移  scale 的 对阶值？\n    // 求的是内存的偏移量 而不仅仅只是一个下标，数据起始地址 + 元素下标 * 单个元素占用位置 = 实际数组元素在对象中的偏移量\n    return (E) UNSAFE.getObject(entries, REF_ARRAY_BASE + ((sequence & indexMask) << REF_ELEMENT_SHIFT));\n}\n```\n\n\n\n定位的算法就是 使用sequnce & ringBufferSize -1 寻找下标 * 数据元素的精度（偏移量） + 数组起始偏移量\n\n\n\n塞入值之后 有个通知消费者的操作，比如消息者线程在wait的情况下 给他sign\n\n```\n/**\n * @see Sequencer#publish(long)\n */\n@Override\npublic void publish(final long sequence)\n{\n    setAvailable(sequence);\n    // 通知阻塞 的消费线程 有消息来了\n    waitStrategy.signalAllWhenBlocking();\n}\n\nprivate void setAvailable(final long sequence)\n{\n    // calculateIndex(sequence) 取 sequence & bufferSize -1 的值\n    // calculateAvailabilityFlag(sequence)  计算 sequence 溢出 bufferSize 外的 高位值，用于存储 ringBuffer的环数（轮次）\n    setAvailableBufferValue(calculateIndex(sequence), calculateAvailabilityFlag(sequence));\n}\n\nprivate void setAvailableBufferValue(int index, int flag)\n{\n    long bufferAddress = BASE + (index * SCALE);\n    UNSAFE.putOrderedInt(availableBuffer, bufferAddress, flag);\n}\n```\n\n\n\navailableBuffer 也是之前讲的用于 生产者 和 消费者的一个 缓存数组，这里生产者发布完事件后也需要在 availableBuffer 中设置有效值，这里的算法是 将 sequence & rinfBufferSize-1 的值做下标，将sequence 偏移 ringBufferSize长度的溢出值 做flag值，这个flag值也就是 当前RingBuffer的轮次\n\n\n\nwaitStrategy 我们以BlockingWaitStrategy 为例，将消费者线程 从wait状态唤醒 继续消费\n\n```\n@Override\npublic void signalAllWhenBlocking()\n{\n    lock.lock();\n    try\n    {\n        processorNotifyCondition.signalAll();\n    }\n    finally\n    {\n        lock.unlock();\n    }\n}\n```\n\n\n\n\n\n#### **4、读数据**\n\n\n\n读数据 我们回过头来看 配置消费者组的时候 消费者线程BatchEventProcessor的行为，首先看下消费者线程是怎么启动的\n\n```\npublic RingBuffer<T> start()\n{\n    checkOnlyStartedOnce();\n    for (final ConsumerInfo consumerInfo : consumerRepository)\n    {\n        consumerInfo.start(executor);\n    }\n\n    return ringBuffer;\n}\n```\n\n\n\n在Distruptor启动的时候 就会执行，执行器就是我们初始化RingBuffer的时候 配置的Executor线程池\n\n\n\n消费者线程的行为如下，这里有一些钩子函数的处理 ，比如Lifestyle，类比Spring里面的，我们就跳过了\n\n```\n/**\n * It is ok to have another thread rerun this method after a halt().\n *\n * @throws IllegalStateException if this object instance is already running in a thread\n */\n@Override\npublic void run()\n{\n    if (!running.compareAndSet(IDLE, RUNNING))\n    {\n        if (running.get() == RUNNING)\n        {\n            throw new IllegalStateException(\"Thread is already running\");\n        }\n    }\n    sequenceBarrier.clearAlert();\n\n    notifyStart();\n\n    try\n    {\n        if (running.get() == HALTED)\n        {\n            return;\n        }\n\n        T event = null;\n        // 获取当前待消费的下一个序列\n        long nextSequence = sequence.get() + 1L;\n\n        while (true)\n        {\n            try\n            {\n                // 返回生产者 生产的最大有效序列\n                final long availableSequence = sequenceBarrier.waitFor(nextSequence);\n                if (batchStartAware != null)\n                {\n                    batchStartAware.onBatchStart(availableSequence - nextSequence + 1);\n                }\n\n                while (nextSequence <= availableSequence)\n                {\n                    event = dataProvider.get(nextSequence);\n                    eventHandler.onEvent(event, nextSequence, nextSequence == availableSequence);\n                    nextSequence++;\n                }\n\n                sequence.set(availableSequence);\n            }\n            catch (final TimeoutException e)\n            {\n                notifyTimeout(sequence.get());\n            }\n            catch (final AlertException ex)\n            {\n                if (running.get() != RUNNING)\n                {\n                    break;\n                }\n            }\n            catch (final Throwable ex)\n            {\n                exceptionHandler.handleEventException(ex, nextSequence, event);\n                sequence.set(nextSequence);\n                nextSequence++;\n            }\n        }\n    }\n    finally\n    {\n        notifyShutdown();\n        running.set(IDLE);\n    }\n}\n```\n\n\n\n消费者线程 也是分为两步走，第一步 取可消费的序列值 第二步 根据序列值找到实际元素进行消费\n\n\n\n消费者是使用SequenceBarrier序列屏障 来保障 消费者 和 生产者的序列冲突 和 一致性，取可消费的序列值即sequenceBarrier.waitFor(nextSequence)\n\n```\npublic long waitFor(final long sequence)\n        throws AlertException, InterruptedException, TimeoutException {\n    checkAlert();\n\n    long availableSequence = waitStrategy.waitFor(sequence, cursorSequence, dependentSequence, this);\n\n    if (availableSequence < sequence) {\n        return availableSequence;\n    }\n\n    /*\n     * 查询 nextSequence-availableSequence 区间段之间连续发布的最大序号。多生产者模式下可能是不连续的\n     *     多生产者模式下{@link Sequencer#next(int)} next是预分配的，因此可能部分数据还未被填充。\n     */\n    return sequencer.getHighestPublishedSequence(sequence, availableSequence);\n}\n```\n\n\n\n虽然你希望消费nextSequence序列，但还是得按实际的可消费序列来，这里还是以BlockingWaitStrategy 为例\n\n```\n@Override\npublic long waitFor(long sequence, Sequence cursorSequence, Sequence dependentSequence, SequenceBarrier barrier)\n\tthrows AlertException, InterruptedException\n{\nlong availableSequence;\nif (cursorSequence.get() < sequence)\n{\n\tlock.lock();\n\ttry\n\t{\n\t\t// 如果当前 待消费序列 一直小于当前生产的序列值 则一直 await\n\t\twhile (cursorSequence.get() < sequence)\n\t\t{\n\t\t\tbarrier.checkAlert();\n\t\t\tprocessorNotifyCondition.await();\n\t\t}\n\t}\n\tfinally\n\t{\n\t\tlock.unlock();\n\t}\n}\n// dependentSequence 当前消费者 消费序列时 所依赖的 序列\n// 正常是 生产者的序列   当有消费者消费优先关系时 则是 其他消费者的消费队列\nwhile ((availableSequence = dependentSequence.get()) < sequence)\n{\n\tbarrier.checkAlert();\n\t// 自旋\n\tThreadHints.onSpinWait();\n}\nreturn availableSequence;\n}\n```\n\n\n\n这里可以看出消费者 可消费的序列 和 两个序列值有关，一个是生产者的游标、另一个是 依赖的序列。\n\n第一个好理解，如果你希望消费的序列值大于我生产者所在的游标，那么说明 队列中无可消费Event，就需要按WaitStategy来等待；\n\n第二个依赖的序列分两种，正常情况下也是依赖生产者的游标，如果消费者出现层级关系的时候，也就是依赖其他消费者先执行后才能执行，则需要依赖其他消费者的消费序列，不能比他们大，如果大的话就需要自旋进行原地等待\n\n\n\n获取到可消费序列值后，还需要验证它的有效性，即利用我们之前提到的availableBuffer\n\n```\n@Override\npublic long getHighestPublishedSequence(long lowerBound, long availableSequence)\n{\n    for (long sequence = lowerBound; sequence <= availableSequence; sequence++)\n    {\n        if (!isAvailable(sequence))\n        {\n            return sequence - 1;\n        }\n    }\n\n    return availableSequence;\n}\n\npublic boolean isAvailable(long sequence)\n{\n    int index = calculateIndex(sequence);\n    int flag = calculateAvailabilityFlag(sequence);\n    long bufferAddress = (index * SCALE) + BASE;\n    return UNSAFE.getIntVolatile(availableBuffer, bufferAddress) == flag;\n}\n```\n\n\n\n这里会验证 从期望消费序列sequence到 可消费序列availableSequence之间 元素的有效性，有的元素可能生产者还未来得及更改flag值，则暂时不能消费，最后会返回最大的可消费序列值\n\n\n\n\n\n#### **5、总结**\n\n\n\n这里简单基于源码总结下 Distruptor高效的原因\n\n1）无锁 多线程情况下 CAS操作 性能优于 加锁\n\n2）UNSAFE，基于UNSAFE的内存操作，大大减少了 更新值的操作时间\n\n3）位运算，也是在计算环节取得了优势\n\n4）采用了数组的底层存储结构，RingBuffer内对数组都是查找和修改操作，大大发挥了数组的优势", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 4}, "ccf23638cf6ea96777a2969ea75d1b5b": {"id": "ccf23638cf6ea96777a2969ea75d1b5b", "item": "源码解读", "title": "Nacos的NameService实现原理", "date": "2024-08-22", "summary": "Nacos 的 NameService通过维护服务名与服务实例列表的映射关系，采用心跳机制检测服务实例的健康状态。客户端向 Nacos 服务端注册服务实例信息，服务端接收并存储，在请求服务时能快速准确地返回可用服务实例列表。", "body": "\n#### 1. NameService组件说明\n\nNacos服务注册表结构：Map<namespace, Map<group::serviceName, Service>>\n\n![img](http://pcc.huitogo.club/9479eb688d234d6306add441c41b00cb)\n\n\n\n举例说明\n\n![img](http://pcc.huitogo.club/5bcdbeb6a6bc8661d9dbac6b5b0a3e5a)\n\n\n\n其中有几个概念：\n\n\n\n##### 1.1 Service\n\n在服务发现领域中，服务指的是由应用程序提供的⼀个或⼀组软件功能的⼀种抽象概念（例如登录服务 和 支付服务）。|\n\n![img](http://pcc.huitogo.club/e4a46dbe1e0f4bfab79c3327bfd3789e)\n\n\n\n在 Nacos 中，服务的定义包括以下几个内容\n\n- Namespace（命名空间）：Nacos 数据模型中最顶层、也是包含范围最广的概念，用于在类似 环境或租户等需要强制隔离的场景中定义。\n- Group（分组）：Nacos 数据模型中次于命名空间的⼀种隔离概念，区别于命名空间的强制隔离 属性，分组属于⼀个弱隔离概念。\n- Name（服务名）：服务实际的名字，⼀般用于描述该服务提供了某种功能或能力。\n\n除了服务之间区别的字段之外，还有服务元数据；服务的定义只是为服务设置了⼀些基本的信息，用于描述服务以及方便快速的找到服务，而服务的 元数据是进⼀步定义了 Nacos 中服务的细节属性和描述信息。主要包含：\n\n- ProtectThreshold（健康保护阈值）：为了防止因过多实例故障，导致所有流量全部流入剩余实 例，继而造成流量压力将剩余实例被压垮形成的雪崩效应。应将健康保护阈值定义为⼀个 0 到 1 之间的浮点数。当域名健康实例数占总服务实例数的比例小于该值时，无论实例是否健康，都会 将这个实例返回给客户端。这样做虽然损失了⼀部分流量，但是保证了集群中剩余健康实例能正常工作。\n- Selector（实例选择器）：用于在获取服务下的实例列表时，过滤和筛选实例。该选择器也被称 为路由器，目前 Nacos 支持通过将实例的部分信息存储在外部元数据管理 CMDB 中，并在发现 服务时使用 CMDB 中存储的元数据标签来进行筛选的能力。\n- extendData（拓展数据）：用于用户在注册实例时自定义扩展的元数服务中拓展服务的元数据信息，方便用户实现自己的自定义逻辑。\n\n\n\n##### 1.2. Instance\n\n服务实例是某个服务的具体提供能力的节点，⼀个实例仅从属于⼀个服务，而 ⼀个服务可以包含⼀个或多个实例。\n\n![img](http://pcc.huitogo.club/dab377eb6fb9a1372aa1a721fe044366)\n\n\n\n由于服务实例是具体提供服务的节点，因此 Nacos 在设计实例的定义时，主要需要存储该实例的 ⼀些网络相关的基础信息，主要包含以下内容：\n\n- 网络 IP 地址：该实例的 IP 地址，在 Nacos2.0 版本后支持设置为域名。\n- 网络端口：该实例的端口信息。\n- 健康状态（Healthy）：用于表示该实例是否为健康状态，会在 Nacos 中通过健康检查的手段进 行维护，具体内容将在 Nacos 健康检查机制章节中详细说明，读者目前只需要该内容的含义即 可。\n- 集群（Cluster）：用于标示该实例归属于哪个逻辑集群，有关于集群的相关内容，将在后文详细 说明。\n- 拓展数据(extendData)：用于用户自定义扩展的元数据内容，形式为 K-V。可以在实例中拓展该 实例的元数据信息，方便用户实现自己的自定义逻辑和标示该实例。\n\n\n\n和服务元数据不同，实例的元数据主要作用于实例运维相关的数据信息。主要包含：\n\n- Weight（权重）：实例级别的配置。权重为浮点数，范围为 0-10000。权重越大，分配给该实例 的流量越大。\n- Enabled（上线状态）：标记该实例是否接受流量，优先级大于权重和健康状态。用于运维人员 在不变动实例本身的情况下，快速地手动将某个实例从服务中移除。\n- extendData（拓展数据）：不同于实例定义中的拓展数据，这个拓展数据是给予运维人员在不变动 实例本身的情况下，快速地修改和新增实例的扩展数据，从而达到运维实例的作用。\n\n\n\n##### 1.**3. Cluster**\n\n集群是 Nacos 中⼀组服务实例的⼀个逻辑抽象的概念，它介于服务和实例之间，是⼀部分服务属性的下沉和实例属性的抽象。\n\n![img](http://pcc.huitogo.club/f8918125ed938c7a94ad7bff4416662f)\n\n\n\n在 Nacos 中，集群中主要保存了有关健康检查的⼀些信息和数据：\n\n- 健康检查类型（HealthCheckType）：使用哪种类型的健康检查方式，MySQL；设置为 NONE 可以关闭健康检查。\n- 健康检查端口（HealthCheckPort）：设置用于健康检查的端口。\n- 是否使用实例端口进行健康检查（UseInstancePort）：如果使用实例使用实例定义中的网络端口进行健康检查，而不再使用上述设置的健康\n- 拓展数据(extendData)：用于用户自定义扩展的元数据内容，形式为 K群的元数据信息，方便用户实现自己的自定义逻辑和标示该集群。\n\n\n\n**NacosNamingService源码分析（看源码的思路）**\n\n```\nNacosNamingService\n\n服务端 和 监听者（其他服务端、客户端或者第三方监听服务）\n\nPublish | Subscriber    发布订阅\n\t\tNotifyCenter    服务注册 | 注销 | 订阅 | 取消订阅\n\t\t\t\tEventPublisher\n\t\t\t\t\t\tDefaultSharePublisher  多个事件类型 共享一个事件队列   shareBufferSize\n\t\t\t\t\t\tDefaultPublisher    每个事件类型对应一个 事件队列 ringBufferSize\n\n\t\t\t\tSubscriber\n\t\t\t\t\t\tSmartSubscriber\n\t\t\t\t\t\t\t\tClientServiceIndexesManager  客户端事件处理  通常会回调一个 监听客户端同步事件\n\t\t\t\t\t\t\t\tDistroClientDataProcessor  nacos 集群同步信息 \n\t\t\t\t\t\t\t\t\t\tDistroProtocol  真正执行同步\n\t\t\t\t\t\t\t\tNamingMetadataManager\n\t\t\t\t\t\t\t\tNamingSubscriberServiceV2Impl  监听的客户端同步信息 处理\n\t\t\t\t\t\t\t\t\t\tNacosDelayTaskExecuteEngine  merge 多个客户端监听事件 并执行\n\t\t\t\t\t\t\t\t\t\t\t\tNacosTaskProcessor  process  真正执行同步\n```\n\n\n\n客户端 和 服务端通信\n\n```\nNamingClientProxy  实际执行\n\t\tNamingHttpClientProxy 长连接\n\t\t\t\tBeatReactor  心跳机制\n\t\t\t\t\n\t\tNamingGrpcClientProxy 短连接\n\t\t\t\tGrpcRequestAcceptor\n\t\t\t\tRequestHandler\n\t\t\t\t\t\tDistroDataRequestHandler\n\t\t\t\t\t\tHealthCheckRequestHandler\n\t\t\t\t\t\tInstanceRequestHandler   注册节点\n\t\t\t\t\t\tServerLoaderInfoRequestHandler\n\t\t\t\t\t\tServerReloaderRequestHandler\n\t\t\t\t\t\tServiceListRequestHandler\n\t\t\t\t\t\tServiceQueryRequestHandler\n\t\t\t\t\t\tSubscribeServiceRequestHandler   服务订阅  =  服务获取  + 发布订阅事件\n```\n\n\n\n获取 全部 Service Instance\n\n```\nServiceInfoHolder  本地service缓存\n\t\tFailoverReactor   失败兜底机制\n\nserviceDataIndexes  缓存\nsingletonRepository 缓存实例工厂\npublisherIndexes 实际存放数据\nserviceClusterIndex nacos集群数据\n\n获取单个Service Instance\n\nBalancer 负载均衡\n```\n\n\n\n以下进入源码分析\n\n\n\n#### 2. 初始化NamingService\n\n```\nprivate void init(Properties properties) throws NacosException {\n        ValidatorUtils.checkInitParam(properties);\n        // 命名空间\n        this.namespace = InitUtils.initNamespaceForNaming(properties);\n        InitUtils.initSerialization();\n        InitUtils.initWebRootContext(properties);\n        initLogName(properties);\n        this.changeNotifier = new InstancesChangeNotifier();\n        // 注册服务变更事件（触发器）\n        NotifyCenter.registerToPublisher(InstancesChangeEvent.class, 16384);\n        // 注册服务变更订阅（监听器）\n        NotifyCenter.registerSubscriber(changeNotifier);\n        // 本地服务缓存器初始化\n        this.serviceInfoHolder = new ServiceInfoHolder(namespace, properties);\n        // 和 nacos server发起通信\n        this.clientProxy = new NamingClientProxyDelegate(this.namespace, serviceInfoHolder, properties, changeNotifier);\n    }\n```\n\n\n\n#### 3. 服务端 和 客户端 通信\n\n```\nNamingClientProxy  实际执行\n\n\t\tNamingHttpClientProxy 长连接(HTTP1.0)\n\t\t\n\t\t\t\tBeatReactor  心跳机制\n\t\t\t\t\n\t\tNamingGrpcClientProxy 短连接(HTTP2.0)\n```\n\n\n\n#### 4. 服务注册\n\n##### 4.1 客户端\n\n```\n@Override\npublic void registerInstance(String serviceName, String groupName, String ip, int port, String clusterName)\n\t\tthrows NacosException {\n\tInstance instance = new Instance();\n\tinstance.setIp(ip);\n\tinstance.setPort(port);\n\tinstance.setWeight(1.0);\n\tinstance.setClusterName(clusterName);\n\tregisterInstance(serviceName, groupName, instance);\n}\n\npublic void registerService(String serviceName, String groupName, Instance instance) throws NacosException {\n\n\tInstanceRequest request = new InstanceRequest(namespaceId, serviceName, groupName,\n\t\t\tNamingRemoteConstants.REGISTER_INSTANCE, instance);\n\trequestToServer(request, Response.class);\n\tnamingGrpcConnectionEventListener.cacheInstanceForRedo(serviceName, groupName, instance);\n}\n```\n\n\n\n##### 4.2 服务端\n\nInstanceRequestHandler\n\n```\npublic void registerInstance(Service service, Instance instance, String clientId) {\n\tService singleton = ServiceManager.getInstance().getSingleton(service);\n\tClient client = clientManager.getClient(clientId);\n\tInstancePublishInfo instanceInfo = getPublishInfo(instance);\n\tclient.addServiceInstance(singleton, instanceInfo);\n\tclient.setLastUpdatedTime();\n\t// 发布客户端注册事件\n\tNotifyCenter.publishEvent(new ClientOperationEvent.ClientRegisterServiceEvent(singleton, clientId));\n\t// 服务服务实例元数据 变更事件\n\tNotifyCenter.publishEvent(new MetadataEvent.InstanceMetadataEvent(singleton, instanceInfo.getMetadataId(), false));\n}\n```\n\n\n\n##### 4.3 事件发布器\n\n看下**NotifyCenter**的 publishEvent方法\n\n```\nprivate static boolean publishEvent(final Class<? extends Event> eventType, final Event event) {\n        if (ClassUtils.isAssignableFrom(SlowEvent.class, eventType)) {\n            return INSTANCE.sharePublisher.publish(event);\n        }\n        \n        final String topic = ClassUtils.getCanonicalName(eventType);\n        // 根据事件类型获取不同的事件发布器\n        EventPublisher publisher = INSTANCE.publisherMap.get(topic);\n        if (publisher != null) {\n            return publisher.publish(event);\n        }\n       \n        return false;\n    }\n```\n\n\n\n事件发布器有两种\n\n- DefaultSharePublisher 多个事件类型 共享一个事件队列 shareBufferSize = 1024\n- DefaultPublisher 每个事件类型对应一个 事件队列 ringBufferSize = 16384\n\n```\nvoid receiveEvent(Event event) {\n\tfinal long currentEventSequence = event.sequence();\n\n\tif (!hasSubscriber()) {\n\n\t\treturn;\n\t}\n\n// 通知事件的订阅者       \n\tfor (Subscriber subscriber : subscribers) {\n\t\t// Whether to ignore expiration events\n\t\tif (subscriber.ignoreExpireEvent() && lastEventSequence > currentEventSequence) {\n\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Because unifying smartSubscriber and subscriber, so here need to think of compatibility.\n\t\t// Remove original judge part of codes.\n\t\tnotifySubscriber(subscriber, event);\n\t}\n}\n```\n\n\n\n这里事件发布器最终调用的 是 Subscriber 的 onEvent事件，Subscriber 有以下几类\n\n- ClientServiceIndexesManager 客户端事件处理，通常会回调一个 监听客户端同步事件\n- DistroClientDataProcessor nacos 集群同步信息\n- DistroProtocol 真正执行同步\n- NamingMetadataManager\n- NamingSubscriberServiceV2Impl 监听的客户端同步信息 处理\n- NacosDelayTaskExecuteEngine merge 多个客户端监听事件 并执行\n- NacosTaskProcessor process 真正执行同步\n\n\n\n这里看下服务注册 的订阅者 也就是 ClientServiceIndexesManager 怎么处理注册节点的\n\n```\n private void addPublisherIndexes(Service service, String clientId) {\n        publisherIndexes.computeIfAbsent(service, (key) -> new ConcurrentHashSet<>());\n        publisherIndexes.get(service).add(clientId);\n        NotifyCenter.publishEvent(new ServiceEvent.ServiceChangedEvent(service, true));\n }\n```\n\n可以看到 最终Sercice的信息会存储在publisherIndexes 中，同时发布了一条服务变更的事件 通知到 监听该服务的所有客户端\n\n\n\n#### 5. 服务发现\n\n##### 5.1 客户端\n\n```\nif (subscribe) {\n            serviceInfo = serviceInfoHolder.getServiceInfo(serviceName, groupName, clusterString);\n            if (null == serviceInfo) {\n                serviceInfo = clientProxy.subscribe(serviceName, groupName, clusterString);\n            }\n        } else {\n            serviceInfo = clientProxy.queryInstancesOfService(serviceName, groupName, clusterString, 0, false);\n        }\n}  \n\npublic ServiceInfo getServiceInfo(final String serviceName, final String groupName, final String clusters) {\n       \n        String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName);\n        String key = ServiceInfo.getKey(groupedServiceName, clusters);\n        if (failoverReactor.isFailoverSwitch()) {\n            return failoverReactor.getService(key);\n        }\n        return serviceInfoMap.get(key);\n}    \n```\n\n\n\n可以看到它先在Client端本地缓存中尝试获取\n\n在查询不到的情况下会向Server端发起请求\n\n```\npublic ServiceInfo subscribe(String serviceName, String groupName, String clusters) throws NacosException {\n        SubscribeServiceRequest request = new SubscribeServiceRequest(namespaceId, groupName, serviceName, clusters,\n                true);\n        SubscribeServiceResponse response = requestToServer(request, SubscribeServiceResponse.class);\n        namingGrpcConnectionEventListener\n                .cacheSubscriberForRedo(NamingUtils.getGroupedName(serviceName, groupName), clusters);\n        return response.getServiceInfo();\n    }\n```\n\n\n\n这里区分是否需要订阅，需要的话 可以先注册订阅监听事件，然后获取服务实例，这里以需要订阅为例\n\n\n\n##### 5.2 服务端\n\nSubscribeServiceRequestHandler\n\n```\n   public SubscribeServiceResponse handle(SubscribeServiceRequest request, RequestMeta meta) throws NacosException {\n        String namespaceId = request.getNamespace();\n        String serviceName = request.getServiceName();\n        String groupName = request.getGroupName();\n        String app = request.getHeader(\"app\", \"unknown\");\n        String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName);\n        // 请求订阅 / 查询 服务信息\n        Service service = Service.newService(namespaceId, groupName, serviceName, true);\n        // 订阅者信息\n        Subscriber subscriber = new Subscriber(meta.getClientIp(), meta.getClientVersion(), app,\n                meta.getClientIp(), namespaceId, groupedServiceName, 0, request.getClusters());\n        // 获取服务实例        \n        ServiceInfo serviceInfo = handleClusterData(serviceStorage.getData(service),\n                metadataManager.getServiceMetadata(service).orElse(null),\n                subscriber);\n        if (request.isSubscribe()) {\n            clientOperationService.subscribeService(service, subscriber, meta.getConnectionId());\n        } else {\n            clientOperationService.unsubscribeService(service, subscriber, meta.getConnectionId());\n        }\n        return new SubscribeServiceResponse(ResponseCode.SUCCESS.getCode(), \"success\", serviceInfo);\n    }\n```\n\n\n\n这里重点看下获取服务实例\n\n```\npublic ServiceInfo getData(Service service) {\n\treturn serviceDataIndexes.containsKey(service) ? serviceDataIndexes.get(service) : getPushData(service);\n}\n\npublic ServiceInfo getPushData(Service service) {\n\tServiceInfo result = emptyServiceInfo(service);\n\tif (!ServiceManager.getInstance().containSingleton(service)) {\n\t\treturn result;\n\t}\n\tresult.setHosts(getAllInstancesFromIndex(service));\n\tserviceDataIndexes.put(service, result);\n\treturn result;\n}  \n```\n\n\n\n所以这里可以得出获取全部服务实例的流程就是\n\n1. ServiceInfoHolder 本地service缓存\n\n   FailoverReactor 失败兜底机制\n\n2. serviceDataIndexes 缓存\n\n3. singletonRepository 缓存实例工厂\n\n4. publisherIndexes 实际存放数据\n\n5. serviceClusterIndex nacos集群数据\n\n\n\n假如是从全部服务实例中获取其中一个的话，这里有个负载均衡策略，即选择一个最优的\n\n```\nString clusterString = StringUtils.join(clusters, \",\");\n\tif (subscribe) {\n\t\tServiceInfo serviceInfo = serviceInfoHolder.getServiceInfo(serviceName, groupName, clusterString);\n\t\tif (null == serviceInfo) {\n\t\t\tserviceInfo = clientProxy.subscribe(serviceName, groupName, clusterString);\n\t\t}\n\t\treturn Balancer.RandomByWeight.selectHost(serviceInfo);\n\t} else {\n\t\tServiceInfo serviceInfo = clientProxy\n\t\t\t\t.queryInstancesOfService(serviceName, groupName, clusterString, 0, false);\n\t\treturn Balancer.RandomByWeight.selectHost(serviceInfo);\n\t}\n```\n\n\n\n具体负载策略见 Balancer\n\n\n\n#### 6. 答疑时间\n\n关于服务注册还有一些问题\n\n**Q1：如何支持高并发注册（异步任务与内存队列设计原理及源码剖析）**\n\n答案：**采用内存队列的方式进行服务注册**\n\n也就是说客户端在把自己的信息注册到Nacos Server的时候，并不是同步把信息写入到注册表中的，而且采取了先写入内存队列中，然后用独立的线程池来消费队列进行注册的。\n\n从源码可看出最终会执行listener.onChange()这个方法，并把Instances传入，然后进行真正的注册逻辑，这里的设计就是为了提高Nacos Server的并发注册量。这里再提一下，在进行队列消费的时候其实最终也是采用的JDK的线程池。\n\n\n\n**Q2：注册表如何防止多节点读写并发冲突**\n\n答案：**Copy on write 思想**\n\nupdateIps方法中传入了一个List<Instance> ips，然后用ips跟之前注册表中的Instances进行比较，分别得出需要添加、更新、和删除的实例，然后做一些相关的操作，比如Instance的一些属性设置、启动心跳、删除心跳等等，最后把处理后的List<Instance> ips，直接替换内存注册表，这样如果同时有读的请求，其实读取是之前的老注册表的信息，这样就很好的控制了并发读写冲突问题，这个思想就是Copy On Write思想，在JDK源码中并发包里也有一些相关的实现，比如：CopyOnWriteArrayList", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 2}, "ed8095211e143af68235a3da9517ccec": {"id": "ed8095211e143af68235a3da9517ccec", "item": "源码解读", "title": "Nacos的ConfigService实现原理", "date": "2024-08-22", "summary": "Nacos 的 ConfigService 通过客户端与服务端交互。服务端存储配置信息，客户端发起请求获取配置。服务端采用一致性协议保证数据可靠，同时提供监听机制，当配置变更时及时通知客户端，实现动态配置管理。", "body": "\n#### 1. 初始化NacosConfigService\n\n```\npublic NacosConfigService(Properties properties) throws NacosException {\n\tValidatorUtils.checkInitParam(properties);\n\n\tinitNamespace(properties);\n\tthis.configFilterChainManager = new ConfigFilterChainManager(properties);\n\tServerListManager serverListManager = new ServerListManager(properties);\n\tserverListManager.start();\n\n\tthis.worker = new ClientWorker(this.configFilterChainManager, serverListManager, properties);\n\t// will be deleted in 2.0 later versions\n\tagent = new ServerHttpAgent(serverListManager);\n\n}\n```\n\n\n\nNacosConfigService 包含：\n\n1. IConfigFilterChain --- 拦截链\n\n   IConfigFilter\n\n2. ServerListManager ---获取 和 更新 nacos server 服务集群\n\n3. ClientWorker --- 保持 nacos server的登录有效状态、定期更新本地config 缓存\n\n   securityProxy.login\n\n   cacheMap\n\n   agent.notifyListenConfig();\n\n4. ServerHttpAgent --- 远程ConfigServer调用\n\n\n\n#### 2. 获取Config\n\n![img](http://pcc.huitogo.club/c0a9cfa35c8250b0112677bb9cadd0b7)\n\n\n\n##### 2.1 客户端\n\n```\nprivate String getConfigInner(String tenant, String dataId, String group, long timeoutMs) throws NacosException {\n\tgroup = blank2defaultGroup(group);\n\tParamUtils.checkKeyParam(dataId, group);\n\tConfigResponse cr = new ConfigResponse();\n\n\tcr.setDataId(dataId);\n\tcr.setTenant(tenant);\n\tcr.setGroup(group);\n\n\t// 优先使用本地配置\n\tString content = LocalConfigInfoProcessor.getFailover(worker.getAgentName(), dataId, group, tenant);\n\tif (content != null) {\n\n\t\tcr.setContent(content);\n\t\tString encryptedDataKey = LocalEncryptedDataKeyProcessor\n\t\t\t\t.getEncryptDataKeyFailover(agent.getName(), dataId, group, tenant);\n\t\tcr.setEncryptedDataKey(encryptedDataKey);\n\t\tconfigFilterChainManager.doFilter(null, cr);\n\t\tcontent = cr.getContent();\n\t\treturn content;\n\t}\n\n\ttry {\n\t\t// 从ServerList中 获取远程nacos server 地址\n\t\tConfigResponse response = worker.getServerConfig(dataId, group, tenant, timeoutMs, false);\n\t\tcr.setContent(response.getContent());\n\t\tcr.setEncryptedDataKey(response.getEncryptedDataKey());\n\t\tconfigFilterChainManager.doFilter(null, cr);\n\t\tcontent = cr.getContent();\n\n\t\treturn content;\n\t} \n\t...\n\t}\n```\n\n\n\n优先从本地用户文件夹缓存下获取，比如 C:\\Users\\huizhang43\\nacos\\config\\fixed-127.0.0.1_8848-dev_nacos\\snapshot-tenant\\dev\\DEFAULT_GROUP\n\n\n\n从远程Server端获取\n\n```\nConfigQueryRequest request = ConfigQueryRequest.build(dataId, group, tenant);\n            request.putHeader(\"notify\", String.valueOf(notify));\n            ConfigQueryResponse response = (ConfigQueryResponse) requestProxy(getOneRunningClient(), request,\n                    readTimeouts);\n\n            ConfigResponse configResponse = new ConfigResponse();\n```\n\n\n\n##### 2.2 服务端\n\n```\n        int lockResult = tryConfigReadLock(groupKey);\n        \n        boolean isBeta = false;\n        boolean isSli = false;\n        if (lockResult > 0) {\n            //FileInputStream fis = null;\n            try {\n                String md5 = Constants.NULL;\n                long lastModified = 0L;\n                // 尝试从缓存中获取                \n                CacheItem cacheItem = ConfigCacheService.getContentCache(groupKey);\n                if (cacheItem != null) {\n                    if (cacheItem.isBeta()) {\n                        if (cacheItem.getIps4Beta().contains(clientIp)) {\n                            isBeta = true;\n                        }\n                    }\n                    String configType = cacheItem.getType();\n                    response.setContentType((null != configType) ? configType : \"text\");\n                }\n                File file = null;\n                ConfigInfoBase configInfoBase = null;\n                PrintWriter out = null;\n                if (isBeta) {\n                    md5 = cacheItem.getMd54Beta();\n                    lastModified = cacheItem.getLastModifiedTs4Beta();\n                    // 如果nacos server是单机 且 是内嵌的数据库 则直接从数据库中读取\n                    if (PropertyUtil.isDirectRead()) {\n                        configInfoBase = persistService.findConfigInfo4Beta(dataId, group, tenant);\n                    } else {\n                    // 否则 从 文件缓存中获取，避免直穿数据库\n                        file = DiskUtil.targetBetaFile(dataId, group, tenant);\n                    }\n                    response.setBeta(true);\n               ...     \n```\n\n\n\n这里对于config文件的存储结构如下：\n\n![img](http://pcc.huitogo.club/7490626b76c4498ecac56e8ac14f2396)", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "78f4399c2054cd72324328d73092ad13": {"id": "78f4399c2054cd72324328d73092ad13", "item": "源码解读", "title": "SpringBoot-plugin原理分析", "date": "2024-08-22", "summary": "SpringBoot-plugin插件化目标在于SpringBoot项目上开发出用于扩展项目的插件，实现在原有项目基础上集成动态的功能模块，框架实现的功能可以类比Java SPI机制。", "body": "\n#### **1、什么是插件化？**\n\n\n\n##### （1） 插件化定义\n\n\n\n插件化目标在于SpringBoot项目上开发出用于扩展项目的插件，实现在原有项目基础上集成动态的功能模块。\n\n框架实现的功能可以类比Java SPI机制。\n\n\n\n##### （2） 插件化模块\n\n\n\n在下面介绍插件化框架的过程中，我们划分成三个模块，分别是**主版本**、**插件版本**和**插件扩展**。它们三者关系如下：\n\n\n\n![img](http://pcc.huitogo.club/57d6dce63717b3867b63d82da2764b47)\n\n\n\n##### （3） 插件化支持功能\n\n\n\n我们的框架是基于以下项目：\n\n\n\nhttps://gitee.com/starblues/springboot-plugin-framework-parent/tree/2.4.0/\n\n\n\n所以支持的功能也是类似的：\n\n\n\n1）在springboot上可以进行插件式开发, 扩展性极强, 可以针对不同项目开发不同插件, 进行不同插件jar包的部署。\n\n2）无需重启主程序, 动态的启用插件、停止插件。\n\n3）在插件应用模块上可以使用Spring注解定义组件, 进行依赖注入。\n\n4）支持在插件中开发Rest接口。\n\n5）支持自定义扩展开发接口, 使用者可以在预留接口上扩展额外功能。\n\n6）支持插件之间的通信。\n\n7）支持插件接口文档: Swagger、SpringDoc。\n\n\n\n#### **2、插件化怎么使用？**\n\n\n\n入门使用可以参考原框架文档：\n\n\n\nhttps://gitee.com/starblues/springboot-plugin-framework-parent/wikis/pages?sort_id=1693478&doc_id=343010\n\n\n\n#### **3、插件化的原理是什么？**\n\n\n\n##### **（1）插件和主版本**\n\n\n\n首先从Spring容器的角度来看一下主版本和插件版本的Resource装配过程，简图如下：\n\n\n\n![img](http://pcc.huitogo.club/9f65c0403334340a2ae32a626bd0dcfc)\n\n\n\n所以，我们可以看出\n\n\n\n1） 对于主版本，它是由SpringBoot自动装配的，并会将最终解析的结果（包括bean和configuration）放到mainApplicationContext中，所以这一步我们是不需要考虑的。\n\n2） 对于插件版本，它的pluginApplicationContext需要我们主动去填充，比如bean和configuration，你可以把这个pluginApplicationContext想象成一个空房间，它里面有什么取决于我们往里面放什么。所以这个是我们插件化主要考虑的内容。\n\n3） 对于插件版本和主版本之间的交互过程，因为在我们的框架设计中，mainApplicationContext和pluginApplicationContext是相互独立的spring上下文，但是在有的场景，比如插件中RequestMappingInfo（Controller的Mapping映射）， 是需要放到主版本的HandlerMapping中，从而实现插件的Controller层可以被Http访问的。\n\n\n\n##### **（2）插件生命周期**\n\n\n\n其次我们简单的分析插件版本的生命周期，下图所示\n\n\n\n![img](http://pcc.huitogo.club/d23257df1e0cec4fcd4383e97590dc09)\n\n\n\n其中各个阶段的解释：\n\n\n\n1） init\n\n插件版本程序初始化。\n\n\n\n2） plugin registry\n\n启动插件版本。\n\n\n\n3） 解析Resource\n\n对插件版本中的Resource进行解析，在dev环境下是target/下的文件，在deploy环境下是jar包中的文件，其中解析的内容大致分为class文件和配置文件（.resource文件和.yaml文件）\n\n\n\n4） Resource分类\n\n对上一步解析出来的Class类进行分组，分组的目的是用于下一步装配Resource时针对不同的Class分组进行不同的装配过程，目前框架中将Class分为Caller、Supplier、Component、ConfigBean、ConfigDefinition、Controller、OneselfListener、Repository。\n\n\n\n5） 装配Resource\n\n将上一步不同分组的Class类装配到插件版本的pluginApplicationContext，也就是插件的Spring上下文中。\n\n\n\n6） plugin unRegistry\n\n停止插件版本。\n\n\n\n7） 释放Resource\n\n这个阶段发生于用户动态的停止插件的过程，用于移除插件在程序中的缓存Resource。\n\n\n\n8） destroy\n\n插件版本程序关闭，这一部分暂时没有设计。\n\n\n\n##### **（3）插件源码分析**\n\n\n\n最后我们从源码的角度看一下插件生命周期的实现过程\n\n\n\n在主版本中\n\n\n\n```\n1. @Configuration \n\n2. public class PluginBeanConfig { \n\n3.  \n\n4.   @Bean \n\n5.   public PluginApplication pluginApplication() { \n\n6.     PluginApplication pluginApplication = new AutowiredPluginApplication(); \n\n7.     return pluginApplication; \n\n8.   } \n\n9. } \n```\n\n\n\n在插件化版本中\n\n\n\n```\n1. public class AutowiredPluginApplication extends DefaultPluginApplication implements PluginApplication, ApplicationContextAware, InitializingBean { \n\n2.  \n\n3.   private ApplicationContext applicationContext; \n\n4.   private PluginInitializerListener pluginInitializerListener; \n\n5.  \n\n6.   @Override \n\n7.   public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { \n\n8.     this.applicationContext = applicationContext; \n\n9.   } \n\n10.  \n\n11.   @Override \n\n12.   public void afterPropertiesSet() throws Exception { \n\n13.     super.initialize(applicationContext,pluginInitializerListener); \n\n14.   } \n\n15.  \n\n16.   public void setPluginInitializerListener(PluginInitializerListener pluginInitializerListener) { \n\n17.     this.pluginInitializerListener = pluginInitializerListener; \n\n18.   } \n\n19. } \n```\n\n\n\n插件版本是借助InitializingBean随主版本启动而初始化的，核心是调用了PluginApplication.Initialize方法，如下：\n\n\n\n```\n1. @Override \n\n2. public void initialize(ApplicationContext applicationContext, PluginInitializerListener listener) { \n\n3.   Objects.requireNonNull(applicationContext,\"参数 [applicationContext] 不能为空\"); \n\n4.  // 判断当前插件环境是否已经初始化了\n\n5.   if(isInitial.get()){ \n\n6.     throw new MainContextRuntimeException(\"主版本已经初始化，不要重复初始化\"); \n\n7.   } \n\n8.  \n\n9.   // 获取主版本对插件的配置 \n\n10.   IntegrationConfiguration configuration = getConfiguration(applicationContext); \n\n11.   if(pf4jApplicationContext == null) { \n\n12.     pf4jApplicationContext = new DefaultPf4jApplicationContext(configuration); \n\n13.   } \n\n14.    \n\n15.   PluginManager pluginManager = pf4jApplicationContext.getPluginManager(); \n\n16.   pluginOperator = createPluginOperator(applicationContext,pluginManager,configuration); \n\n17.  \n\n18.   try { \n\n19.     // 插件初始化（核心） \n\n20.     pluginOperator.initPlugins(listener); \n\n21.   } catch (Exception e) { \n\n22.     throw new PluginContextRuntimeException(\"插件初始化异常：[\" +e.getMessage()+ \"]\",e); \n\n23.   } \n\n24.  \n\n25.   isInitial.set(true); \n\n26. } \n```\n\n\n\n在解释以上的插件初始化流程之前，我们要先了解一下**pf4j**，以下是官方文档地址：\n\n\n\nhttps://github.com/pf4j/pf4j\n\n\n\n借助官方对它的一段介绍：\n\n\n\n```\n1. A plugin is a way for a third party to extend the functionality of an application. A plugin implements extension points declared by application or other plugins. Also a plugin can define extension points. \n```\n\n\n\n简单来说就是一个开源的Java Plugin Framework，我们开发的框架也是基于它去实现的。在pf4j中有4个重要组件，也在我们插件初始化流程中起到重要作用：\n\n\n\n###### 1） Plugin\n\n\n\n最基本的插件组件，是我们开发插件版本的实体代表。\n\n\n\n```\n1. Plugin is the base class for all plugins types. Each plugin is loaded into a separate class loader to avoid conflicts \n```\n\n\n\n###### 2） PluginWrapper\n\n\n\n对Plugin的包装类，从中可以拿到一个插件的很多信息，比如PluginClassLoader和PluginManager，可以理解成一个工具类。\n\n\n\n###### 3） PluginClassLoader\n\n\n\n插件环境的类加载器，用来加载插件中的所有Resource。\n\n\n\n```\n1. PluginLoader loads all information (classes) needed by a plugin \n```\n\n\n\n###### 4） PluginManager\n\n\n\n针对所有插件的插件管理器，除了对所有PluginWrapper的操作外，还包括重要的对插件生命周期的功能。\n\n\n\n```\n1. PluginManager is used for all aspects of plugins management (loading, starting, stopping). You can use a builtin implementation as JarPluginManager, ZipPluginManager, DefaultPluginManager (it's a JarPluginManager + ZipPluginManager) or you can implement a custom plugin manager starting from AbstractPluginManager (implement only factory methods) \n```\n\n在介绍完pf4j之后，再回到PluginApplication. Initialize方法中来，我们根据当前的插件运行环境（ dev和deploy）构建了自定义的PluginManager\n\n\n\n```\n1. // 开发环境下的插件配置 \n\n2. if (RuntimeMode.DEVELOPMENT == environment) { \n\n3.   Path path = Paths.get(getDevPluginDir(integrationConfiguration)); \n\n4.   return createDevPluginManager(path, sortedPluginIds); \n\n5. } else { \n\n6.   Path path = Paths.get(getProdPluginDir(integrationConfiguration)); \n\n7.   return createProdPluginManager(path, sortedPluginIds); \n\n8. } \n```\n\n\n\n而在构建PluginManager过程中，这里以dev环境为例\n\n\n\n```\n1. private PluginManager createDevPluginManager(Path devPath, List<String> sortedPluginIds){ \n\n2.   return new DefaultPluginManager(devPath) { \n\n3.  \n\n4.     @Override \n\n5.     protected void initialize() { \n\n6.       super.initialize(); \n\n7.       dependencyResolver = new SortDependencyResolver(sortedPluginIds,versionManager); \n\n8.     } \n\n9.  \n\n10.     // 设置当前插件的运行模式 \n\n11.     @Override \n\n12.     public RuntimeMode getRuntimeMode() { \n\n13.       System.setProperty(\"pf4j.mode\", RuntimeMode.DEVELOPMENT.toString()); \n\n14.       return RuntimeMode.DEVELOPMENT; \n\n15.     } \n\n16.  \n\n17.     // PluginDescriptorFinder：根据插件版本中的plugin.resources文件读取Plugin信息 \n\n18.     @Override \n\n19.     protected PluginDescriptorFinder createPluginDescriptorFinder() { \n\n20.       return DefaultPf4jApplicationContext.getPluginDescriptorFinder(RuntimeMode.DEVELOPMENT); \n\n21.     } \n\n22.  \n\n23.     //PluginStatusProvider：判断哪些插件是启用，哪些插件是禁用 \n\n24.     @Override \n\n25.     protected PluginStatusProvider createPluginStatusProvider() { \n\n26.       return new ConfigPluginStatusProvider( \n\n27.           integrationConfiguration.enablePluginIds(), \n\n28.           integrationConfiguration.disablePluginIds()); \n\n29.     } \n\n30.  \n\n31.     //PluginLoader：插件类信息加载器 \n\n32.     @Override \n\n33.     protected PluginLoader createPluginLoader() { \n\n34.       return new CompoundPluginLoader() \n\n35.           .add(new DevelopmentPluginLoader(this),this::isDevelopment); \n\n36.     } \n\n37.  \n\n38.   }; \n\n39. } \n```\n\n\n\n我们为PluginManager配置了一些可以用来正确读取Plugin信息的功能，配置好PluginManager之后就是插件初始化过程中最重要的一个方法PluginOperator.initPlugins\n\n\n\n```\n1. public synchronized boolean initPlugins(PluginInitializerListener pluginInitializerListener) throws Exception { \n\n2.   // 判断当前插件环境是否已经初始化了 \n\n3.   if (isPluginInitial.get()) { \n\n4.     throw new PluginContextRuntimeException(\"当前插件的环境已经初始化了\"); \n\n5.   } \n\n6.   pluginInitializerListenerManager.addPluginInitializerListeners(pluginInitializerListener); \n\n7.  \n\n8.   try { \n\n9.     // 插件初始化事件监听器 开始 \n\n10.     pluginInitializerListenerManager.before(); \n\n11.     if (!configuration.enable()) { \n\n12.       pluginInitializerListenerManager.complete(); \n\n13.       return false; \n\n14.     } \n\n15.     // 清理配置插件目录下的空文件（夹） \n\n16.     PluginFileHelper.cleanEmptyFile(pluginManager.getPluginsRoot()); \n\n17.     // 插件加工厂环境初始化 \n\n18.     pluginFactory.initialize(); \n\n19.  \n\n20.     // 装载插件环境信息和资源到内存中 \n\n21.     pluginManager.loadPlugins(); \n\n22.     // 启动插件（更新插件状态） \n\n23.     pluginManager.startPlugins(); \n\n24.     List<PluginWrapper> pluginWrappers = pluginManager.getStartedPlugins(); \n\n25.     if (pluginWrappers == null || pluginWrappers.isEmpty()) {  \n\n26.       return false; \n\n27.     } \n\n28.     // 插件在registry过程中是否出现异常 \n\n29.     boolean ifRegistryException = false; \n\n30.     for (PluginWrapper pluginWrapper : pluginWrappers) { \n\n31.       String pluginId = pluginWrapper.getPluginId(); \n\n32.       // 记录插件的操作状态 \n\n33.       addOperatorPluginInfo(pluginId, PluginOperateInfo.OperateType.INSTALL, false); \n\n34.  \n\n35.       try { \n\n36.         // 插件加工厂 注册单个插件信息\n\n37.         pluginFactory.registry(PluginRegistryInfo.build(pluginWrapper, pluginManager, mainApplicationContext,true)); \n\n38.       } catch (Exception e) { \n\n39.         ifRegistryException = true; \n\n40.       } \n\n41.     } \n\n42.     // 插件加工厂 启动前对插件的操作 \n\n43.     pluginFactory.build(); \n\n44.     isPluginInitial.set(true); \n\n45.  \n\n46.     if (ifRegistryException) { \n\n47.       return false; \n\n48.     } else { \n\n49.       // 插件初始化事件监听器 完成 \n\n50.       pluginInitializerListenerManager.complete(); \n\n51.       return true; \n\n52.     } \n\n53.   } catch (Exception e) { \n\n54.     // 插件初始化事件监听器 异常 \n\n55.     pluginInitializerListenerManager.failure(e); \n\n56.     throw new PluginContextRuntimeException(\"插件初始化异常:\" + e.getMessage()); \n\n57.   } \n\n58. } \n```\n\n\n\n对于以上插件初始化的过程大致可以分成三个过程：\n\n\n\n1） 准备阶段\n\n\n\n pluginInitializerListenerManager.before() ：插件初始化事件监听器\n\n\n\n pluginFactory.initialize() : 插件环境初始化（关于PluginFactory后面再介绍）\n\n\n\n pluginManager.loadPlugins() ：解析插件里的配置信息，可以理解成将pluginPath路径下的带有plugin.properties配置文件的插件 转换成Plugin 放到PluginManager中\n\n\n\n2） 注册阶段\n\n\n\npluginManager.startPlugins() : 启动所有插件（更新插件状态）\n\npluginFactory.registry() : 注册单个插件信息\n\n\n\n3） 结束阶段\n\n\n\npluginFactory.build() ： 对所有插件进行构建\n\npluginInitializerListenerManager.complete() ：插件注册完成事件监听器\n\n\n\n在上述步骤中，插件事件监听器和PluginManager的相关操作这里不作赘述，主要看一下PluginFactory下的initialize和registry方法\n\n\n\n```\n1. @Override \n\n2. public void initialize() throws Exception { \n\n3.   // 添加默认的插件事件监听器，可扩展 \n\n4.   addDefaultPluginListener(); \n\n5.   pluginPreProcessorManager.initialize(); \n\n6.   pluginPostProcessorManager.initialize(); \n\n7. } \n\n8.  \n\n9. @Override \n\n10. public synchronized PluginFactory registry(PluginRegistryInfo pluginRegistryInfo) throws Exception { \n\n11.   String pluginId = pluginRegistryInfo.getPluginWrapper().getPluginId(); \n\n12.   if(PluginContextHelper.getPluginRegistryInfo(pluginId) != null){ \n\n13.     throw new PluginContextRuntimeException(\"插件\" + pluginId + \"已经注册，无须重复注册\"); \n\n14.   } \n\n15.   // 只有当插件生命周期为BUILD或者REGISTER的时候才允许注册插件 \n\n16.   if(!buildPluginRegistryList.isEmpty() && buildType == BuildType.UNINSTALL){ \n\n17.     throw new PluginContextRuntimeException(\"插件\" + pluginId + \"注册失败，当前非插件的注册周期\"); \n\n18.   } \n\n19.   try { \n\n20.     pluginPreProcessorManager.registry(pluginRegistryInfo); \n\n21.  \n\n22.     PluginContextHelper.addPluginPluginRegistryInfo(pluginId,pluginRegistryInfo); \n\n23.     buildPluginRegistryList.add(pluginRegistryInfo); \n\n24.     return this; \n\n25.   } catch (Exception e) { \n\n26.     pluginListenerManager.failure(pluginId,e); \n\n27.     throw e; \n\n28.   }finally { \n\n29.     buildType = BuildType.REGISTER; \n\n30.   } \n\n31. } \n```\n\n\n\n这里有两个重要的类，**PluginPreProcessorManager**和**PluginPostProcessorManager**，PluginPreProcessorManager是一堆**PluginPreProcessor**的集合，相应PluginPostProcessorManager是一堆**PluginPostProcessor**的集合。\n\n对PluginFactory的initialize和registry其实也就是调用PluginPreProcessorManager和PluginPostProcessorManager的initialize和registry，\n\n\n\n先看一下PluginPreProcessorManager.initialize\n\n\n\n```\n1. public void initialize(){ \n\n2.   // Resource加载 \n\n3.   pluginPreProcessors.add(new PluginResourceLoaderPreProcessor()); \n\n4.   // Resouce分类 \n\n5.   pluginPreProcessors.add(new PluginClassResolvePreProcessor()); \n\n6.   // Resource装配 \n\n7.   pluginPreProcessors.add(new PluginApplicationContextPreProcessor(mainApplicationContext)); \n\n8.   // Resource 自定义Bean装配 \n\n9.   pluginPreProcessors.add(new PluginConfigBeanPreProcessor()); \n\n10.  \n\n11.   pluginPreProcessors.forEach(PluginPreProcessor::initialize); \n\n12. } \n```\n\n\n\n在这里可以看到我们之前在插件生命周期中介绍的一些阶段，对于PluginPreProcessor和PluginPostProcessor的设计来说，是类似于Spring的BeanPostProcessor，Spring中的bean实例化和初始化阶段经历一系列前置器和后置器会增强，这里插件的初始化也是如此。\n\nPluginPreProcessorManager和PluginPostProcessorManager的作用都是在插件registry或者unRegistry的时候对插件的一些操作。不同的是PluginPreProcessorManager是**针对单个插件**进行操作，而PluginPostProcessorManager是需要等 PluginPreProcessorManager执行完后**针对所有的插件**进行操作。\n\n\n\n接下来详细介绍一下PluginPreProcessor和PluginPostProcessor的功能和它们的源码\n\n\n\n1） PluginResourceLoaderPreProcessor：对插件Resource的加载\n\n\n\n当有插件registry的时候，会使用所有的PluginResourceLoader从PluginRegistryInfo中加载出ResourceWrapper\n\n\n\n```\n1. @Override \n\n2. public void registry(PluginRegistryInfo pluginRegistryInfo) { \n\n3.   resourceLoaderList.forEach(resourceLoader ->{ \n\n4.     if(StringUtils.isNull(resourceLoader.key())){ \n\n5.       log.warn(\"插件加载器 [{}] 未配置key，直接跳过\",resourceLoader.getClass().getName()); \n\n6.       return; \n\n7.     } \n\n8.     try { \n\n9.       ResourceWrapper resourceWrapper = resourceLoader.load(pluginRegistryInfo); \n\n10.       if(resourceWrapper != null) { \n\n11.         pluginRegistryInfo.addPluginLoadResource(resourceLoader.key(), resourceWrapper); \n\n12.       } \n\n13.     } catch (IOException e) { \n\n14.       log.error(\"插件加载器 [{}] 加载插件 [{}] 异常\",resourceLoader.getClass().getName(),pluginRegistryInfo.getPluginWrapper().getPluginId()); \n\n15.     } \n\n16.   }); \n\n17. } \n```\n\n\n\n2） PluginClassResolvePreProcessor：插件Class分类\n\n\n\n遍历ResourceWrapper下的所有Class，在满足对应的PluginClassGroup的条件后会加入到对应的PluginClassGroup中；在Class没有匹配到任何PluginClassGroup后会进入缺省的Group。\n\n\n\n```\n1. @Override \n\n2. public void registry(PluginRegistryInfo pluginRegistryInfo) throws ClassNotFoundException { \n\n3.   BasePlugin basePlugin = pluginRegistryInfo.getBasePlugin(); \n\n4.   ResourceWrapper resourceWrapper = pluginRegistryInfo.getPluginLoadResource(PluginResourceLoader.DEFAULT_PLUGIN_RESOURCE_LOADER_KEY); \n\n5.   // 插件里没有class \n\n6.   if (resourceWrapper == null) { \n\n7.     return; \n\n8.   } \n\n9.   List<Resource> resources = resourceWrapper.getResources(); \n\n10.   // 插件没有配置文件（插件属性） \n\n11.   if (resources == null) { \n\n12.     return; \n\n13.   } \n\n14.  \n\n15.   pluginClassGroups.forEach(pluginClassGroup -> { \n\n16.     pluginClassGroup.initialize(basePlugin); \n\n17.   }); \n\n18.  \n\n19.   Set<String> pluginPackageClasses = resourceWrapper.getClassPackageNames(); \n\n20.   ClassLoader pluginClassLoader = basePlugin.getWrapper().getPluginClassLoader(); \n\n21.  \n\n22.   for (String className : pluginPackageClasses) { \n\n23.     Class pluginClass = Class.forName(className, false, pluginClassLoader); \n\n24.     if (pluginClass == null) { \n\n25.       continue; \n\n26.     } \n\n27.     boolean isMatchGroup = false; \n\n28.  \n\n29.     for (PluginClassGroup pluginClassGroup : pluginClassGroups) { \n\n30.       if (pluginClassGroup == null || StringUtils.isNull(pluginClassGroup.groupId())) { \n\n31.         return; \n\n32.       } \n\n33.       if (pluginClassGroup.filter(pluginClass)) { \n\n34.         pluginRegistryInfo.addClassInGroup(pluginClassGroup.groupId(), pluginClass); \n\n35.         isMatchGroup = true; \n\n36.       } \n\n37.     } \n\n38.     if(!isMatchGroup){ \n\n39.       pluginRegistryInfo.addClassInGroup(UNMATCH_GROUP_ID, pluginClass); \n\n40.     } \n\n41.     //添加进容器中 \n\n42.     pluginRegistryInfo.addPluginClass(pluginClass); \n\n43.   } \n\n44.  \n\n45.  \n\n46. } \n```\n\n\n\n3） PluginApplicationContextPreProcessor：插件Resource装配\n\n\n\n简单的说就是将上述每个PluginClassGroup中的Class转换成BeanDefinition放到插件Spring上下文pluginApplicationContext中，在所有的PluginClassGroup下的Class装配完之后会对pluginApplicationContext进行refresh操作。\n\n\n\n```\n1. @Override \n\n2. public void registry(PluginRegistryInfo pluginRegistryInfo) throws Exception { \n\n3.   for(PluginBeanRegistrar pluginBeanRegistrar : pluginBeanRegistrars){ \n\n4.     // 对不同PluginClassGroup采用不同的装配方式 \n\n5.     pluginBeanRegistrar.registry(pluginRegistryInfo); \n\n6.   } \n\n7.  \n\n8.   addPluginExtension(pluginRegistryInfo); \n\n9.   GenericApplicationContext pluginApplicationContext = pluginRegistryInfo.getPluginApplicationContext(); \n\n10.  \n\n11.   ClassLoader mainContextClassLoader = Thread.currentThread().getContextClassLoader(); \n\n12.   ClassLoader pluginContextClassLoader = pluginRegistryInfo.getDefaultPluginClassLoader(); \n\n13.  \n\n14.   try{ \n     // 切换当前线程类加载器，用于插件Spring上下文的refresh\n\n15.     Thread.currentThread().setContextClassLoader(pluginContextClassLoader); \n\n16.     // 刷新插件spring上下文环境 \n\n17.     pluginApplicationContext.refresh(); \n\n18.   }finally { \n\n19.     Thread.currentThread().setContextClassLoader(mainContextClassLoader); \n\n20.   } \n\n21.   String pluginId = pluginRegistryInfo.getPluginWrapper().getPluginId(); \n\n22.   PluginContextHelper.addPluginApplicationContext(pluginId,pluginApplicationContext); \n\n23. } \n```\n\n\n\n4） PluginControllerPostProcessor：对插件中Controller层的装配\n\n\n\n首先，为什么插件的Controller类需要单独装配?\n\n因为我们需要将插件中的RequestMappingInfo（Controller的RequestMapping）注册到主版本的HandlerMapping中，这样我们插件的Controller才能正常的通过Http访问。\n\n\n\n在此之前，我们从插件ResourceWrapper中解析的类都是直接装配到插件的Spring上下文中，和主版本是没有什么关系的。\n\n\n\n```\n1. @Override \n\n2. public void registry(List<PluginRegistryInfo> pluginRegistryInfos) throws Exception { \n\n3.   pluginRegistryInfos.forEach(pluginRegistryInfo -> { \n\n4.     List<Class> groupClasses = pluginRegistryInfo.getClassesFromGroup(ControllerGroup.GROUP_ID); \n\n5.     if (groupClasses == null || groupClasses.isEmpty()) { \n\n6.       return; \n\n7.     } \n\n8.     String pluginId = pluginRegistryInfo.getPluginWrapper().getPluginId(); \n\n9.     List<ControllerWrapper> controllerWrapperList = Lists.newArrayList(); \n\n10.     for (Class controllerClass : groupClasses) { \n\n11.       if (controllerClass == null) { \n\n12.         continue; \n\n13.       } \n\n14.       // 注册当前Controller类到主版本的mvc环境中 \n\n15.       ControllerWrapper controllerWrapper = doRegistry(pluginRegistryInfo, controllerClass); \n\n16.       if (controllerWrapper != null) { \n\n17.         controllerWrapperList.add(controllerWrapper); \n\n18.       } \n\n19.     } \n\n20.     pluginRegistryInfo.addControllerWrappers(controllerWrapperList); \n\n21.  \n\n22.   }); \n\n23. } \n```\n\n\n\n到此，其实插件的初始化流程已经完成了，现在回顾一下整个插件初始化的过程，时序图如下：\n\n\n\n![img](http://pcc.huitogo.club/6901ac3c27c3ebb618daa8de6c24566f)\n\n\n\n#### **4、插件扩展功能原理**\n\n\n\n在上述插件版本初始化后，我们在此主版本的基础上可以对插件调用的功能有：\n\n\n\n1）主版本通过Http访问插件的Controller层，在Controller中可以使用插件pluginApplicationContext中装配的bean和其他资源。\n\n2）主版本直接使用PluginUtils类获取pluginApplicationContext从而直接调用插件中装配的bean和其他资源。\n\n\n\n那怎么在插件中实现更多的功能呢？\n\n\n\n比如在插件中支持数据库操作，Mybatis、MybatisPlus或者TkMybatis？\n\n比如在插件中访问静态资源，js、css、html呢？\n\n\n\n因此我们需要对插件功能进行扩展，同时这些扩展功能相对于插件来说应该也是可插拔的。\n\n那什么是插件扩展功能，说白了就是向PluginApplicationContext中放入更多的东西，让它可以支持更加复杂的功能调用，比如说支持Mybatis的话，你需要将*Mapper.class解析成MapperFactoryBean放到PluginApplicationContext中，这样在调用*Mapper.class里方法时，会通过MapperFactoryBean生成MapperProxy去调用SqlSession执行sql语句。\n\n\n\n那怎么向PluginApplicationContext中放入更多的东西呢？\n\n\n\n通过参考插件的生命周期，如下图所示：\n\n\n\n![img](http://pcc.huitogo.club/62f33085fb8a7706baf132076191bb2a)\n\n\n\n 我们通过AbstractPluginExtension抽象类提供更多的Resource解析器、Resource分组器和Resource装配器，在插件的生命周期中解析更多的Resource和Resource分组，最终在装配Resource阶段为pluginApplicationContext装配更多的资源，从而支撑更多的功能。\n\n\n\n首先看一下AbstractPluginExtension的源码：\n\n\n\n```\n1. public abstract class AbstractPluginExtension { \n\n2.  \n\n3.   /** \n\n4.   * 扩展标识 唯一key \n\n5.   * \n\n6.   * @return \n\n7.   */ \n\n8.   public abstract String key(); \n\n9.  \n\n10.  \n\n11.   /** \n\n12.   * 该扩展初始化的操作 \n\n13.   * 主要是在插件初始化阶段被调用 \n\n14.   * \n\n15.   * @param mainApplicationContext 主版本ApplicationContext \n\n16.   * @throws Exception 初始化异常 \n\n17.   */ \n\n18.   public void initialize(ApplicationContext mainApplicationContext) throws Exception{ \n\n19.   } \n\n20.  \n\n21.   /** \n\n22.   * 返回插件的资源加载器 \n\n23.   * 主要是加载插件中的某些资源，比如文件、图片等 \n\n24.   * \n\n25.   * @return List PluginResourceLoader \n\n26.   */ \n\n27.   public List<PluginResourceLoader> getPluginResourceLoaders(){ \n\n28.     return null; \n\n29.   } \n\n30.  \n\n31.  \n\n32.   /** \n\n33.   * 返回扩展的插件中的类分组器。 \n\n34.   * 该扩展主要是对插件中的Class文件分组，然后供 PluginPreProcessor、PluginPostProcessor 阶段使用。 \n\n35.   * \n\n36.   * @param mainApplicationContext 主程序ApplicationContext \n\n37.   * @return List PluginClassGroup \n\n38.   */ \n\n39.   public List<PluginClassGroup> getPluginClassGroups(ApplicationContext mainApplicationContext){ \n\n40.     return null; \n\n41.   } \n\n42.  \n\n43.  \n\n44.   /** \n\n45.   * 返回扩展的插件前置处理者。 \n\n46.   * 该扩展会对每一个插件进行处理 \n\n47.   * \n\n48.   * @param mainApplicationContext 主程序ApplicationContext \n\n49.   * @return List PluginPreProcessor \n\n50.   */ \n\n51.   public List<PluginPreProcessor> getPluginPreProcessors(ApplicationContext mainApplicationContext){ \n\n52.     return null; \n\n53.   } \n\n54.  \n\n55.   /** \n\n56.   * 返回扩展的bean定义注册者扩展 \n\n57.   * 该扩展会对每一个插件进行处理 \n\n58.   * \n\n59.   * @param mainApplicationContext 主程序ApplicationContext \n\n60.   * @return List PluginBeanRegistrar \n\n61.   */ \n\n62.   public List<PluginBeanRegistrar> getPluginBeanRegistrars(ApplicationContext mainApplicationContext){ \n\n63.     return null; \n\n64.   } \n\n65.  \n\n66.   /** \n\n67.   * 返回扩展的插件后置处理者。 \n\n68.   * 该扩展会对全部插件进行处理。 \n\n69.   * \n\n70.   * @param mainApplicationContext 主程序ApplicationContext \n\n71.   * @return List PluginPostProcessor \n\n72.   */ \n\n73.   public List<PluginPostProcessor> getPluginPostProcessors(ApplicationContext mainApplicationContext){ \n\n74.     return null; \n\n75.   } \n\n76.  \n\n77.   /** \n\n78.   * 返回扩展的插件后置处理者。 \n\n79.   * 该扩展会对每一个插件进行处理 \n\n80.   * \n\n81.   * @param mainApplicationContext 主程序ApplicationContext \n\n82.   * @return List PluginAfterPreProcessor \n\n83.   */ \n\n84.   public List<PluginAfterPreProcessor> getPluginAfterPreProcessors(ApplicationContext mainApplicationContext){ \n\n85.     return null; \n\n86.   } \n\n87. } \n```\n\n\n\n我们的插件扩展功能需要继承AbstractPluginExtension，通过覆写里面的方法来实现功能扩展。下面分别介绍Mybatis扩展和静态资源扩展下对AbstractPluginExtension的继承。\n\n\n\n##### **（1）Mybatis扩展**\n\n\n\n```\n1. public class SpringBootMybatisPluginExtension extends AbstractPluginExtension { \n\n2.  \n\n3.   private static final String KEY = \"springBootMabtisPluginExtension\"; \n\n4.  \n\n5.   private final LoadType loadType; \n\n6.  \n\n7.   public SpringBootMybatisPluginExtension() { \n\n8.   } \n\n9.  \n\n10.   @Override \n\n11.   public String key() { \n\n12.     return KEY; \n\n13.   } \n\n14.  \n\n15.   @Override \n\n16.   public List<PluginClassGroup> getPluginClassGroups(ApplicationContext mainApplicationContext) { \n\n17.     final List<PluginClassGroup> classGroups = Lists.newArrayList(); \n\n18.     // Mybatis的配置类分组 \n\n19.     classGroups.add(newMybatisConfigGroup()); \n\n20.     // 数据库实体类和别名分组 \n\n21.     classGroups.add(newPluginEntityAliasGroup()); \n\n22.     // 数据库Mapper访问分组 \n\n23.     classGroups.add(newPluginMapperGroup()); \n\n24.     return classGroups; \n\n25.   } \n\n26.  \n\n27.   @Override \n\n28.   public List<PluginBeanRegistrar> getPluginBeanRegistrars(ApplicationContext mainApplicationContext) { \n\n29.     final List<PluginBeanRegistrar> beanRegistrars = Lists.newArrayList(); \n\n30.     beanRegistrars.add(newMybatisBeanRegistrar()); \n\n31.     return beanRegistrars; \n\n32.   } \n\n33.  \n\n34. } \n```\n\n\n\n可以看到Mybatis扩展增加了3个Resource分组器和1和Resource装配器\n\n3个Resource分组器分别是Mybatis的配置类分组、数据库实体类和别名分组 和 数据库Mapper访问分组。\n\n\n\n重点看一下Resource装配器MybatisBeanRegistrar，当插件初始化或者有新的插件启用的时候：\n\n\n\n```\n1. @Override \n\n2. public void registry(PluginRegistryInfo pluginRegistryInfo) throws Exception { \n\n3.   List<Object> configFileObjects = pluginRegistryInfo.getConfigFileObjects(); \n\n4.   SpringBootMybatisConfig springBootMybatisConfig = getMybatisConfig(configFileObjects); \n\n5.   if (springBootMybatisConfig == null) { \n\n6.     return; \n\n7.   } \n\n8.  \n\n9.   SqlSessionFactoryBean sqlSessionFactoryBean =newSqlSessionFactoryBean(); \n\n10.  \n\n11.   if (springBootMybatisConfig.enableOneselfConfig()) { \n\n12.     // 自己配置SqlSessionFactoryBean \n\n13.     springBootMybatisConfig.oneselfConfig(sqlSessionFactoryBean); \n\n14.   }  else {\n\n15.       // 使用主版本里的SqlSession\n\n16.       ApplicationContext mainApplicationContext = pluginRegistryInfo.getMainApplicationContext();\n\n17.       PluginMybatisCoreConfig pluginMybatisCoreConfig = new PluginMybatisCoreConfig(mainApplicationContext);\n\n18. \n\n19.       DataSource dataSource = pluginMybatisCoreConfig.getDataSource();\n\n20.       if (dataSource != null) {\n\n21.         // 设置数据库连接池     sqlSessionFactoryBean.setDataSource(pluginMybatisCoreConfig.getDataSource());\n\n22.       }\n\n23. \n\n24.       Configuration configuration = pluginMybatisCoreConfig.getMybatisConfiguration();\n\n25.       // 设置Mybatis配置信息\n\n26.       sqlSessionFactoryBean.setConfiguration(configuration);\n\n27. \n\n28.       Interceptor[] interceptors = pluginMybatisCoreConfig.getInterceptors();\n\n29.       if (interceptors != null && interceptors.length > 0) {\n\n30.         // 设置Mybatis自定义插件拦截器信息\n\n31.         sqlSessionFactoryBean.setPlugins(interceptors);\n\n32.       }\n\n33. \n\n34.       DatabaseIdProvider databaseIdProvider = pluginMybatisCoreConfig.getDatabaseIdProvider();\n\n35.       if (databaseIdProvider != null) {\n\n36.         // 设置数据库唯一标识生成器信息\n\n37.     sqlSessionFactoryBean.setDatabaseIdProvider(databaseIdProvider);\n\n38.       }\n\n39. \n\n40.       LanguageDriver[] languageDrivers = pluginMybatisCoreConfig.getLanguageDrivers();\n\n41.       if (languageDrivers != null && languageDrivers.length > 0) {\n\n42.         for (LanguageDriver languageDriver : languageDrivers) {\n\n43.           // 注册Mybatis的自定义sql解析\n\n44.     configuration.getLanguageRegistry().register(languageDriver);\n\n45.         }\n\n46.       }\n\n47.     }\n\n48. \n\n49.     PluginResourceFinder pluginResourceFinder = new PluginResourceFinder(pluginRegistryInfo);\n\n50.     Class<?>[] aliasesClasses = pluginResourceFinder.getAliasesClasses(springBootMybatisConfig.entityPackages());\n\n51.     // 设置数据库实体和别名\n\n52.     sqlSessionFactoryBean.setTypeAliases(aliasesClasses);\n\n53. \n\n54.     Resource[] xmlResources = pluginResourceFinder.getXmlResources(springBootMybatisConfig.xmlLocationsMatch());\n\n55.     // 设置数据库访问xml资源\n\n56.     sqlSessionFactoryBean.setMapperLocations(xmlResources);\n\n57. \n\n58.     // 保存原有的ClassLoader用于后期还原\n\n59.     ClassLoader defaultClassLoader = Resources.getDefaultClassLoader();\n\n60. \n\n61.     try {\n\n  Resources.setDefaultClassLoader(pluginRegistryInfo.getDefaultPluginClassLoader());\n\n62. \n\n63.       SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBean.getObject();\n\n64.       Objects.requireNonNull(sqlSessionFactory);\n\n65. \n\n66.       SqlSessionTemplate sqlSessionTemplate = new SqlSessionTemplate(sqlSessionFactory);\n\n67.       MapperHandler mapperHandler = new MapperHandler();\n\n68.       // 对单个Mapper操作\n\n69.       mapperHandler.processMapper(pluginRegistryInfo, sqlSessionFactory, sqlSessionTemplate);\n\n70. \n\n71.     } finally {\n\n72.       Resources.setDefaultClassLoader(defaultClassLoader);\n\n73.     }\n\n74. } \n```\n\n\n\n这里Mybatis的装配过程中配置或生成了一个SqlSessionFactoryBean用来生成SqlSessionFactory，SqlSessionFactoryBean里的信息来源于mainApplicationContext或者插件配置中。\n\n最后基于数据库Mapper访问分组获取插件中的*Mapper.class，将*Mapper.class转换成MapperFactoryBean注入到pluginApplicationContext中。\n\n\n\n```\n1. private void doInjectProperties(BeanDefinitionHolder holder, \n\n2.                 Class<?> mapperClass, \n\n3.                 SqlSessionFactory sqlSessionFactory, \n\n4.                 SqlSessionTemplate sqlSessionTemplate) { \n\n5.   GenericBeanDefinition beanDefinition = (GenericBeanDefinition) holder.getBeanDefinition(); \n\n6.   beanDefinition.getConstructorArgumentValues().addGenericArgumentValue(mapperClass); \n\n7.   beanDefinition.setBeanClass(org.mybatis.spring.mapper.MapperFactoryBean.class); \n\n8.   beanDefinition.getPropertyValues().add(\"addToConfig\", true); \n\n9.   beanDefinition.getPropertyValues().add(\"sqlSessionFactory\", sqlSessionFactory); \n\n10.   beanDefinition.getPropertyValues().add(\"sqlSessionTemplate\", sqlSessionTemplate); \n\n11.   beanDefinition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); \n\n12. } \n```\n\n\n\n##### **（2）静态资源扩展**\n\n\n\n```\n1. public class SpringBootStaticResourceExtension extends AbstractPluginExtension { \n\n2.  \n\n3.   private final static String STATIC_RESOURCE_PLUGIN_EXTENSION = \"staticResourcePluginExtension\"; \n\n4.   \n\n5.   // 静态资源访问前缀\n\n6.   private static String pluginResourcePrefix = \"static-plugin\"; \n\n7.  \n\n8.   /** \n\n9.   * 对resource资源的访问缓存，设置缓存时间为1小时 \n\n10.   */ \n\n11.   private static CacheControl pluginStaticResourceCacheControl = CacheControl.maxAge(1, TimeUnit.HOURS).cachePublic(); \n\n12.  \n\n13.   @Override \n\n14.   public String key() { \n\n15.     return STATIC_RESOURCE_PLUGIN_EXTENSION; \n\n16.   } \n\n17.  \n\n18.   @Override \n\n19.   public void initialize(ApplicationContext mainApplicationContext) throws Exception { \n\n20.     List<WebMvcConfigurer> webMvcConfigurers = Lists.newArrayList(new ResourceWebMvcConfigurer()); \n\n21.     // webMvc的处理委托类 \n\n22.     DelegatingWebMvcConfiguration delegatingWebMvcConfiguration = mainApplicationContext.getBean(DelegatingWebMvcConfiguration.class); \n\n23.     delegatingWebMvcConfiguration.setConfigurers(webMvcConfigurers); \n\n24.   } \n\n25.  \n\n26.   @Override \n\n27.   public List<PluginPostProcessor> getPluginPostProcessors(ApplicationContext mainApplicationContext) { \n\n28.     final List<PluginPostProcessor> pluginPostProcessors = Lists.newArrayList(); \n\n29.     pluginPostProcessors.add(newPluginResourceResolvePostProcessor()); \n\n30.     return pluginPostProcessors; \n\n31.   } \n\n32.  \n\n33.   @Override \n\n34.   public List<PluginAfterPreProcessor> getPluginAfterPreProcessors(ApplicationContext mainApplicationContext) { \n\n35.     final List<PluginAfterPreProcessor> pluginAfterPreProcessors = Lists.newArrayList(); \n\n36.     pluginAfterPreProcessors.add(newPluginThymeleafResourceAfterProcessor()); \n\n37.     return pluginAfterPreProcessors; \n\n38.   } \n\n39. } \n```\n\n\n\n这里将静态资源扩展的功能分为两部分\n\n\n\n###### 1） 插件准备阶段\n\n\n\n自定义Spring MVC的拦截配置类ResourceWebMvcConfigurer。\n\nResourceWebMvcConfigurer拦截配置类会拦截指定的资源访问路径前缀pathPattern，然后交由PluginResourceResolver解析出Resource。\n\n\n\n```\n1. public class ResourceWebMvcConfigurer implements WebMvcConfigurer { \n\n2.  \n\n3.   @Override\n\n4.   public void addResourceHandlers(ResourceHandlerRegistry registry) {\n\n5.     String pathPattern = \"/\" + SpringBootStaticResourceExtension.getPluginResourcePrefix() + \"/**\";\n\n6.     // 设置资源请求拦截路径的前缀\n\n7.     ResourceHandlerRegistration resourceHandlerRegistration = registry.addResourceHandler(pathPattern);\n\n8. \n\n9.     // 设置对资源的缓存\n\n10.     CacheControl cacheControl = SpringBootStaticResourceExtension.getCacheControl();\n\n11.     if(cacheControl != null){\n\n12.       resourceHandlerRegistration.setCacheControl(cacheControl);\n\n13.     }else{\n\n14.       resourceHandlerRegistration.setCacheControl(CacheControl.noStore());\n\n15.     }\n\n16.     resourceHandlerRegistration.resourceChain(false).addResolver(new PluginResourceResolver());\n\n17.   }  \n\n18. } \n```\n\n\n\n最后获取主版本中SpringMVC委托处理类DelegatingWebMvcConfiguration，并将我们自定义的ResourceWebMvcConfigurer 注册到DelegatingWebMvcConfiguration中。\n\n\n\n```\n1. @Override \n\n2. public void initialize(ApplicationContext mainApplicationContext) throws Exception { \n\n3.   List<WebMvcConfigurer> webMvcConfigurers = Lists.newArrayList(new ResourceWebMvcConfigurer()); \n\n4.   // webMvc的处理委托类 \n\n5.   DelegatingWebMvcConfiguration delegatingWebMvcConfiguration = mainApplicationContext.getBean(DelegatingWebMvcConfiguration.class); \n\n6.   delegatingWebMvcConfiguration.setConfigurers(webMvcConfigurers); \n\n7. } \n```\n\n\n\n###### 2） 插件registry阶段\n\n\n\n```\n1. @Override \n\n2. public void registry(List<PluginRegistryInfo> pluginRegistryInfos) throws Exception { \n\n3.     for(PluginRegistryInfo pluginRegistryInfo : pluginRegistryInfos){\n\n4. \n\n5.       List<Object> configFileObjects = pluginRegistryInfo.getConfigFileObjects();\n\n6.       SpringBootStaticResourceConfig staticResourceConfig = null;\n\n7. \n\n8.       for(Object configFileObject : configFileObjects){\n\n9.         Class<?>[] interfaces = configFileObject.getClass().getInterfaces();\n\n10.         if(interfaces.length > 0 && Arrays.asList(interfaces).contains(SpringBootStaticResourceConfig.class)){\n\n11.           staticResourceConfig = (SpringBootStaticResourceConfig) configFileObject;\n\n12.         }\n\n13.       }\n\n14. \n\n15.       if(staticResourceConfig == null){\n\n16.         continue;\n\n17.       }\n\n18. \n\n19.       PluginResourceResolver.parse(pluginRegistryInfo,staticResourceConfig);\n\n20.     }   \n\n21. }\n```\n\n\n\n当插件初始化或者插件启用的时候，首先会读取插件版本中对静态资源的相关配置，比如资源的保存路径；其次会分别从ClassPath和File两个维度去读取指定路径下的Resource信息并保存在本地。\n\n最后当我们在插件准备阶段定义的WebMvcConfigurer拦截到用户的访问请求时，直接从本地查找对应的Resource信息。\n\n\n\n#### **5、主版本修改了什么部分？**\n\n\n\n截止到目前为止，作为我们正在使用的主线版本基于以上框架作出了4处修改：\n\n\n\n##### **（1）删除pluginApplicationContext**\n\n\n\n```\n1. public String register(String pluginId, Class<?> aClass, \n\n2.            Consumer<AnnotatedGenericBeanDefinition> consumer) { \n\n3.        AnnotatedGenericBeanDefinition beanDefinition = new\n\n4.         AnnotatedGenericBeanDefinition(aClass);\n\n5. \n\n6.     BeanNameGenerator beanNameGenerator =\n\n7.         new AnnotationBeanNameGenerator();\n\n8.     String beanName = beanNameGenerator.generateBeanName(beanDefinition, applicationContext);\n\n9.     if(PluginInfoContainer.existRegisterBeanName((beanName))){\n\n10.       String error = MessageFormat.format(\"Bean name {0} already exist of {1}\",\n\n11.           beanName, aClass.getName());\n\n12.       logger.debug(error);\n\n13.       return beanName;\n\n14.     }\n\n15.     if(consumer != null){\n\n16.       consumer.accept(beanDefinition);\n\n17.     }\n\n18.     applicationContext.registerBeanDefinition(beanName, beanDefinition);\n\n19.     PluginInfoContainer.addRegisterBeanName(pluginId, beanName);\n\n20.     return beanName;\n\n21. } \n```\n\n\n\n其中applicaitonContext是mainApplicationContext，也就是说插件中解析出的所有Bean全部装配到主版本的Spring上下文中。\n\n这在无形于解决了插件中事务的问题，在原始框架中插件是不支持事务的，因为插件中没有事务管理器，更不会为对象生成代理类去实现事务。\n\n\n\n##### **（2）增加PluginMapper分组类**\n\n\n\n在解析被PluginMapper注解的Mapper类后会放到主版本的ApplicationContext中，覆盖原有的Mapper。\n\n\n\n```\n1. public class PluginMapperGroup implements PluginClassGroupExtend { \n\n2.  \n\n3.   public static final String GROUP_ID = \"plugin_mybatis_mapper\"; \n\n4.  \n\n5.   @Override \n\n6.   public String groupId() { \n\n7.     return GROUP_ID; \n\n8.   } \n\n9.  \n\n10.   @Override \n\n11.   public void initialize(BasePlugin basePlugin) { \n\n12.  \n\n13.   } \n\n14.  \n\n15.   @Override \n\n16.   public boolean filter(Class<?> aClass) { \n\n17.     return AnnotationsUtils.haveAnnotations(aClass, false, PluginMapper.class, Mapper.class); \n\n18.   } \n\n19. } \n```\n\n\n\n##### **（3）tkMybatis 直接用主线SqlSessionFactory中的Configuration**\n\n\n\n对于tkMybatis构建的SqlSessionFactoryBean中关于Mybatis的配置Configuration直接从主版本的SqlSessionFactory中获取。\n\n\n\n```\n1. public Configuration getConfiguration(SpringBootMybatisExtension.Type type){ \n\n2.   if(type == SpringBootMybatisExtension.Type.TK_MYBATIS){ \n\n3.     SqlSessionFactory sqlSessionFactory = applicationContext.getBean(SqlSessionFactory.class); \n\n4.     configuration = sqlSessionFactory.getConfiguration(); \n\n5.   } \n\n6.   return configuration; \n\n7. } \n```", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "4bac3907564180300a4f001767b4efec": {"id": "4bac3907564180300a4f001767b4efec", "item": "源码解读", "title": "SpringBoot的启动流程", "date": "2024-08-22", "summary": "Spring Boot 的启动流程如下：首先创建 SpringApplication 对象，进行初始化操作。接着加载应用的启动类，扫描并加载相关的 Bean。然后进行环境准备，创建并启动嵌入式的 Servlet 容器。最后启动应用的业务逻辑，开始处理请求。", "body": "\nspringBoot启动大致需要完成以下步骤\n\n1. 准备环境\n2. 创建一个 合适的 ApplicationContext\n3. 将命令行参数 注入到 spring properties 中\n4. Refresh applicationContext\n5. 调用启动回调接口（ComandLineRunner）\n\n其中穿插了很多监听器的动作，并且很多逻辑都是靠各种监听器的实现类执行的。\n\n\n\nSpringBootApplication.run源码：\n\n```\n/**\n * Run the Spring application, creating and refreshing a new\n * {@link ApplicationContext}.\n * @param args the application arguments (usually passed from a Java main method)\n * @return a running {@link ApplicationContext}\n */\npublic ConfigurableApplicationContext run(String... args) {\n   //开启时钟计时\n   StopWatch stopWatch = new StopWatch();\n   stopWatch.start();\n   //spirng 上下文\n   ConfigurableApplicationContext context = null;\n   //启动异常报告容器\n   Collection<SpringBootExceptionReporter> exceptionReporters = new ArrayList<>();\n   //开启设置，让系统模拟不存在io设备\n   configureHeadlessProperty();\n   // 1 初始化SpringApplicationRunListener 监听器，并进行封装\n   SpringApplicationRunListeners listeners = getRunListeners(args);\n   listeners.starting();\n   try {\n      ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);\n     //2 Environment 的准备 \n      ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);\n      configureIgnoreBeanInfo(environment);\n      Banner printedBanner = printBanner(environment); // 打印标语 彩蛋\n     //3 创建上下文实例\n      context = createApplicationContext();\n     //异常播报器，默认有org.springframework.boot.diagnostics.FailureAnalyzers\n      exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class,\n            new Class[] { ConfigurableApplicationContext.class }, context);\n     //4 容器初始化\n      prepareContext(context, environment, listeners, applicationArguments, printedBanner);\n     //5 刷新上下文容器 \n      refreshContext(context);\n     //给实现类留的钩子，这里是一个空方法。\n      afterRefresh(context, applicationArguments);\n      stopWatch.stop();\n      if (this.logStartupInfo) {\n         new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);\n      }\n      listeners.started(context);\n      callRunners(context, applicationArguments);\n   }\n   catch (Throwable ex) {\n      handleRunFailure(context, ex, exceptionReporters, listeners);\n      throw new IllegalStateException(ex);\n   }\n\n   try {\n      listeners.running(context);\n   }\n   catch (Throwable ex) {\n      handleRunFailure(context, ex, exceptionReporters, null);\n      throw new IllegalStateException(ex);\n   }\n   return context;\n}\n```\n\n\n\nSpringBoot启动流程图：\n\n![spring_running.png](https://pcc.huitogo.club/z0/6ba8bf5c8177430b8f462f35948d1c74~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)\n\n\n\n#### 1. SpringApplicationRunListener使用\n\n首先通过getSpringFactoriesInstances 获取到所有实现SpringApplicationRunListener  接口的实例，默认情况下该接口的实现类只有 EventPublishingRunListener  他的主要作用是作为Springboot 的一个广播器\n\n```\npublic interface SpringApplicationRunListener {\n  /**EventPublishingRunListener 前期采用 SimpleApplicationEventMulticaster.multicastEvent(ApplicationEvent) 进行广播\n  **/\n   default void starting() {} \n   default void environmentPrepared(ConfigurableEnvironment environment) {}\n   default void contextPrepared(ConfigurableApplicationContext context) {}\n   default void contextLoaded(ConfigurableApplicationContext context) {}\n  /**\n  EventPublishingRunListener 后期采用 context.publishEvent(ApplicationEvent)\n  **/\n   default void started(ConfigurableApplicationContext context) {}\n   default void running(ConfigurableApplicationContext context) {}\n   default void failed(ConfigurableApplicationContext context, Throwable exception) {}\n}\n```\n\n-  starting 准备启动\n-  environmentPrepared 环境准备就绪\n-  contextPrepared 上下文准备就绪\n-  contextLoaded 上下文环境加载完毕\n-  started 启动完毕 \n-  running 正在运行\n-  failed 异常事件\n\n\n\n#### 2. 准备 Enviroment\n\n```\nSpringApplication. prepareEnvironment\n    SpringApplication.getOrCreateEnvironment()  初始化环境\n          WebApplicationType. deduceFromClasspath() 从上下文推理当前环境                                       SERVLET -> StandardServletEnvironment\n                  REACTIVE -> StandardReactiveWebEnvironment\n                  DEFAULT -> StandardEnvironment\n     SpringApplication. configureEnvironment()  配置环境\n          configurePropertySources()  配置命令行参数 到 Enviroment中                                                 （SimpleCommandLinePropertySource）\n          configureProfiles()  配置命令行模板到Enviroment 中\n     ConfigurationPropertySources.attach() 适配Enviroment 的MutablePropertySources 到                                         SpringConfigurationPropertySources\n     SpringApplication. bindToSpringApplication() 将 enviroment 属性 bind到当前上下文\n          Binder.bind()\n```\n\n- SpringApplication. configureIgnoreBeanInfo() 配置是否允许搜索自定义BeanInfo\n- SpringApplication. printBanner() 打印启动日志中的Banner ~\n\n\n\n答疑时间\n\n***Q1：StandardEnvironment？***\n\n- StandardServletEnvironment：对应SERVLET模式（阻塞的）\n\n- StandardReactiveWebEnvironment：对应REACTIVE模式（非阻塞的）\n\n\n\n\n***Q2：Binder.bind***？\n\nspring 2.0 中绑定属性的用法\n\n```\nBinder.get(environment).bind(\"spring.main\", Bindable.ofInstance(this));\n```\n\n上面的代码意思是 将environment中 spring.main开头的相关属性 装配到 SpringApplication类中\n\n\n\n如下是spring.main 的相关\n\n![img](http://pcc.huitogo.club/77f118b3124f6e90bad4a2c9e37257b3)\n\n\n\n底层实现有：\n\nValueObjectBinder. bind() 利用构造函数 进行传值\n\nJavaBeanBinder.bind() 利用bean 的 getter / setter 进行传值\n\n\n\n**Q3：spring.beaninfo.ignore -> Introspector -> BeanInfo？**\n\nIntrospector 是 javaBean 的内省工具（内省会按照类继承关系一层层向上内省）\n\n```\n1.    // 在Object类时候停止检索，可以选择在任意一个父类停止 \n\n2.    BeanInfo beanInfo = Introspector.getBeanInfo(JavaBeanDemo.class,Object.class); \n```\n\n\n\ngetBeanInfo流程\n\n![img](http://pcc.huitogo.club/da87413fd178a7d30347e014ed7bc111)\n\n\n\nBeanInfo只是一个内省结果的接口，Java中对该接口的实现有以下四种：\n\n-  ApplicationBeanInfo：Apple desktop相关的JavaBean内省结果\n-  ComponentBeanInfo：Java Awt组件的内省结果，如按钮等\n-  GenericBeanInfo：通用的内省结果，JEE开发中的内省结果都为该类型\n-  ExtendedBeanInfo：Spring自定义的内省结果类型，主要用于识别返回值不为空的Setter方法\n\n\n\nspring.beaninfo.ignore = true 表示 禁止对自定义的BeanInfo 类的搜索（除上述BeanInfo接口的实现类之外的BeanInfo实现）\n\nSpring的BeanUtils.copyProperties底层就是使用的javaBean的内省，通过内省得到拷贝源对象和目的对象属性的读方法和写方法，然后调用对应的方法进行属性的复制\n\n![img](http://pcc.huitogo.club/1e7e34ca56d6acbcd7bcfbc02aade958)\n\n\n\n#### 3. 创建 ApplicationContext\n\n```\n SpringApplication. createApplicationContext() 创建ApplicationContext （webApplicationType）\n     SERVLET -> AnnotationConfigServletWebServerApplicationContext\n     REACTIVE –> AnnotationConfigReactiveWebServerApplicationContext\n     DEFAULT –> AnnotationConfigApplicationContext\n\t \n\t SpringApplication. prepareContext() \n         SpringApplication. postProcessApplicationContext()\n              beanNameGenerator 注入 beanNameGenerator\n              resourceLoader  配置 ResourceLoader\n              resourceLoader.getClassLoader()  配置 ClassLoader\n              sharedInstance 添加 ApplicationConversionService\n         SpringApplication. applyInitializers()  applicationcontext 初始化事件\n              ApplicationContextInitializer. initialize\n```\n\n- SpringApplication.load() 注入 source （这里将我们的SpringBootApplication注入进去，开启SpringBoot 欢乐时光）\n\n\n\n\n其中`#prepareContext()`初始化ApplicationContext上下文\n\n```\nprivate void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment,\n      SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) {\n  //绑定环境\n   context.setEnvironment(environment);\n  //如果application有设置beanNameGenerator、resourceLoader就将其注入到上下文中，并将转换工具也注入到上下文中\n  postProcessApplicationContext(context);\n  //调用初始化的切面\n   applyInitializers(context);\n  //发布ApplicationContextInitializedEvent事件\n   listeners.contextPrepared(context);\n  //日志\n   if (this.logStartupInfo) {\n      logStartupInfo(context.getParent() == null);\n      logStartupProfileInfo(context);\n   }\n   // Add boot specific singleton beans\n   ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();\n   beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments);\n   if (printedBanner != null) {\n      beanFactory.registerSingleton(\"springBootBanner\", printedBanner);\n   }\n   if (beanFactory instanceof DefaultListableBeanFactory) {\n     //如果bean名相同的话是否允许覆盖，默认为false，相同会抛出异常\n      ((DefaultListableBeanFactory) beanFactory)\n            .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding);\n   }\n   if (this.lazyInitialization) {\n      context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor());\n   }\n   // Load the sources\n  // 这里获取到的是BootstrapImportSelectorConfiguration这个class，而不是自己写的启动来，这个class是在之前注册的BootstrapApplicationListener的监听方法中注入的\n   Set<Object> sources = getAllSources();\n   Assert.notEmpty(sources, \"Sources must not be empty\");\n  //加载sources 到上下文中\n   load(context, sources.toArray(new Object[0]));\n  //发布ApplicationPreparedEvent事件\n   listeners.contextLoaded(context);\n}\n```\n\n\n\n#### 4. 刷新 ApplicationContext\n\n```\nSpringApplication. refreshContext() \n\n  AbstractApplicationContext. refresh() 更新 Spring 上下文 \n\n  ConfigurableApplicationContext. registerShutdownHook() 设置 spring 关闭 钩子函数\n```\n\n\n\n其中`#AbstractApplicationContext.refresh`的核心可以看Spring的refesh源码\n\n```\npublic void refresh() throws BeansException, IllegalStateException {\n    synchronized (this.startupShutdownMonitor) {\n        //记录启动时间、状态，web容器初始化其property，复制listener\n        prepareRefresh();\n        //这里返回的是context的BeanFactory\n        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n        //beanFactory注入一些标准组件，例如ApplicationContextAwareProcessor，ClassLoader等\n        prepareBeanFactory(beanFactory);\n        try {\n            //给实现类留的一个钩子，例如注入BeanPostProcessors，这里是个空方法\n            postProcessBeanFactory(beanFactory);\n\n            // 调用切面方法\n            invokeBeanFactoryPostProcessors(beanFactory);\n\n            // 注册切面bean\n            registerBeanPostProcessors(beanFactory);\n\n            // Initialize message source for this context.\n            initMessageSource();\n\n            // bean工厂注册一个key为applicationEventMulticaster的广播器\n            initApplicationEventMulticaster();\n\n            // 给实现类留的一钩子，可以执行其他refresh的工作，这里是个空方法\n            onRefresh();\n\n            // 将listener注册到广播器中\n            registerListeners();\n\n            // 实例化未实例化的bean\n            finishBeanFactoryInitialization(beanFactory);\n\n            // 清理缓存，注入DefaultLifecycleProcessor，发布ContextRefreshedEvent\n            finishRefresh();\n        }\n\n        catch (BeansException ex) {\n            if (logger.isWarnEnabled()) {\n                logger.warn(\"Exception encountered during context initialization - \" +\n                        \"cancelling refresh attempt: \" + ex);\n            }\n\n            // Destroy already created singletons to avoid dangling resources.\n            destroyBeans();\n\n            // Reset 'active' flag.\n            cancelRefresh(ex);\n\n            // Propagate exception to caller.\n            throw ex;\n        }\n\n        finally {\n            // Reset common introspection caches in Spring's core, since we\n            // might not ever need metadata for singleton beans anymore...\n            resetCommonCaches();\n        }\n    }\n}\n```\n\n\n\n#### 5. 回调\n\nSpringApplication. afterRefresh() 自定义 未实现（备用）\n\n```\nSpringApplication. callRunners() 回调事件处理\n     ApplicationRunner. run() 应用回调\n     CommandLineRunner. run() 命令行事件回调\n```\n\n\n\n#### 6. 其他问题\n\n***Q1：SpringBootApplication自动配置?***\n\n```\n@SpringBootConfiguration  =  @Configuration 不过在SpringBoot项目中只能有一个\n \n @EnableAutoConfiguration 自动装配springBoot 上下文*\n     @AutoConfigurationPackage \n          // 将BasePackage（有启动类目录信息） 作为bean装载到spring中\n          AutoConfigurationPackages. register\n\n     // 获取bean 用于装配到spring中\n     AutoConfigurationImportSelector. selectImports()  \n          AutoConfigurationImportSelector. getAutoConfigurationEntry() \n               AutoConfigurationImportSelector. getCandidateConfigurations()\n                   SpringFactoriesLoader.loadFactoryNames()                           //从spring环境中的加载META-INF/spring.factories，获取EnableAutoConfiguration下的类\n                        SpringFactoriesLoader. loadSpringFactories()\n```\n\n![img](http://pcc.huitogo.club/8140542aa852198755f97b104f0e99e5)\n\n\n\n@EnableAutoConfiguration 适合 和 @Conditional 在一起食用\n\n对于自动装配的bean 如果缺少必要的依赖 和 属性值则没有装配进spring的必要\n\n\n\n当然 加载完之后会有去重、排除项（在@SpringBootApplication中配置）、过滤（AutoConfigurationImportFilter），最后是调用自动装配完成的监听器（AutoConfigurationImportListener）\n\n\n\n**BasePackage的 bean什么时候被用？**\n\n其他功能组件 需要扫描 当前上下文Bean 的时候，比如jpa扫描Entiry\n\n```\n EntityScanner.scan()\n     EntityScanner. getPackages()\n          AutoConfigurationPackages. getBean(BEAN, BasePackages.class)\n```\n\n\n\n***Q2：yaml是怎么解析的？***\n\n**第一种被绑定到ConfigurationProperties上（@ConfigurationProperties）**\n\n入口\n\n```\n@EnableConfigurationProperties \n     // 将@ConfigurationProperties 注解的类装配到spring中 \n     EnableConfigurationPropertiesRegistrar. registerBeanDefinitions() \n\n     // 注入绑定ConfigurationProperties的 处理器\n    ConfigurationPropertiesBindingPostProcessor.register()\n```\n\n\n\n处理器\n\n```\n ConfigurationPropertiesBindingPostProcessor. postProcessBeforeInitialization()\n     // 核心绑定逻辑\n     ConfigurationPropertiesBinder.bind()\n          // 基于 bean 绑定 或者 构造器绑定 这里对于属性绑定肯定是bean\n          Binder.bind() \n```\n\n\n\n**第二种被SPEL表达式解析给属性赋值（@Value）**\n\n入口\n\n```\nPropertyPlaceholderAutoConfiguration\n// 加载environmentProperties 和 localProperties\n PropertySourcesPlaceholderConfigurer. postProcessBeanFactory()\n     // 解析 SPEL 表达式\n     PropertySourcesPlaceholderConfigurer. processProperties()\n          // 对每个 BeanDefinition 的 属性进行解析\n          BeanDefinitionVisitor. visitBeanDefinition()\n               ConfigurablePropertyResolver. resolvePlaceholders()\n                   // 将SPEL表达式替换成实际值的核心方法\n                   PropertyPlaceholderHelper. parseStringValue() \n```", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "469328f6fe06ae755c2a5d11fecf1573": {"id": "469328f6fe06ae755c2a5d11fecf1573", "item": "源码解读", "title": "Spring核心 - Aop", "date": "2024-08-22", "summary": "Spring AOP 即面向切面编程，它通过预编译方式和运行期动态代理实现程序功能的统一维护。可以在不修改原有代码的情况下，对方法进行增强，如日志记录、性能监控等。增强了代码的可维护性和可扩展性，让开发更加高效便捷。", "body": "\n#### 1. AOP使用\n\n1. 创建Advisor，用注解@Aspect标注，用@Pointcut指定切点，再用@Before、@After、@Test等注解标注方法在切点附近的执行时机\n2. 在配置文件中声明aop:aspectj-autoproxy标签，并添加bean和测试类\n3. 执行切点方法，查看Advisor中的方法是否执行\n   \n\n\n\n接下来从源码角度解读Aop\n\n#### 2. 开始\n\n![img](http://pcc.huitogo.club/9472548801489f5357f172fc5453fd2a)\n\n\n\n##### 2.1 注册aop标签解析器\n\nAopNamespaceHandler 对 `<aop:/>` 命名空间的处理器，主要是注册AspectJAutoProxyBeanDefinitionParser解析器\n\n```\npublic void init() {\n\t\t// In 2.0 XSD as well as in 2.1 XSD.\n\t\tregisterBeanDefinitionParser(\"config\", new ConfigBeanDefinitionParser());\n\t\tregisterBeanDefinitionParser(\"aspectj-autoproxy\", new AspectJAutoProxyBeanDefinitionParser());\n\t\tregisterBeanDefinitionDecorator(\"scoped-proxy\", new ScopedProxyBeanDefinitionDecorator());\n\n\t\t// Only in 2.0 XSD: moved to context namespace as of 2.1\n\t\tregisterBeanDefinitionParser(\"spring-configured\", new SpringConfiguredBeanDefinitionParser());\n\t}\n```\n\n- AspectJAutoProxyBeanDefinitionParser \n- ScopedProxyBeanDefinitionDecorator\n- ConfigBeanDefinitionParser\n- SpringConfiguredBeanDefinitionParser\n\n\n\n##### 2.2 注册ProxyCreator\n\nAspectJAutoProxyBeanDefinitionParser 的parse方法会注册AbstractAutoProxyCreator\n\n核心代码在AopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary中：\n\n1. 注册或升级AbstractAutoProxyCreator，它可以根据@Point注解去定义切点，自动代理相匹配的bean。\n\n2. 调用useClassProxyingIfNecessary方法，处理proxy-target-class以及expose-proxy属性。\n\n   \n\n注意：这里AbstractAutoProxyCreator是个抽象类，具体是环境中注册的是它的实现类\n\n- 在<aop->配置环境中注册的是AnnotationAwareAspectJAutoProxyCreator\n- 在SpringBoot启动下注册的是InfrastructureAdvisorAutoProxyCreator\n\n\n\n#### 3. 创建AOP代理\n\nAbstractAutoProxyCreator实现了BeanPostProcessor接口，当这个bean被加载的时候，会自动调用postProcessAfterInitialization方法。在该方法中，会根据bean是否需要被代理，决定是否需要封装指定的bean，该操作在wrapIfNecessary方法中执行。\n\n1. 判断bean是否已经处理过，如果在targetSourcedBeans中包含这个bean的名字，则说明已处理过，直接return\n2. 判断bean是否需要处理，如果nonAdvisedBeans中包含这个bean的名字，则说明无需处理，直接return\n3. 判断bean是否需要设置代理，如果该bean代表一个基础设施类，则不应设置代理，如果在配置中指定了这个bean不需要代理，则将其添加到nonAdvisedBeans中并直接return\n4. 尝试通过getAdvicesAndAdvisorsForBean方法获取当前bean的增强方法，如果获取到了增强方法，则针对增强创建代理。创建代理的过程在createProxy方法中完成\n\n![img](http://pcc.huitogo.club/86b2c42fed20357de0ff9d5132ec60b7)\n\n\n\n##### 3.1 获取Adivsor\n\n获取增强器的功能在findEligibleAdvisors方法中完成，通过注解实现AOP时，这个方法的实现是由AnnotationAwareAspectJAutoProxyCretor完成的，该方法间接继承了AbstractAdvisorAutoProxyCreator，在实现获取增强的方法中除了保留父类的获取配置文件中定义的增强外，同时添加了获取bean的注解增强的功能。其大致过程包括：获取所有的beanName、遍历所有beanName，找出声明AspectJ注解的类、对标记为AspectJ注解的类进行增强器提取(getAdvisors)，最后将提取结果存入缓存中。\n\n\n\n- advisorFactory.getAdvisors\n\n增强器的提取在getAdvisors方法中完成，具体有两个步骤：获取切点的注解以及根据注解信息生成增强\n\n​\t\t\t\ta）切点信息获取：获取指定注解的表达式信息，如注解类型、注解内的表达式等\n\n​\t\t        b）根据切点信息，调用Advisor类的InstantiationModelAwarePointcutAdvisorImpl方法，根据不同的注解类型封装不同的增强器\n\n- SyntheticInstantiationAdvisor\n\n如果寻找的增强器不为空，而且又配置了增强的延迟初始化，那么需要在首位加入同步实例化增强器\n\n- getDeclareParentsAdvisor\n\n用于获取DeclareParents注解，DeclareParents主要用于引介增强的注解形式的实现，而其实现方式与普通增强类似，但会使用DeclareParentsAdvisor对功能进行封装\n\n\n\n##### 3.2 过滤Advisor\n\n针对于每个bean，要挑选出适合当前bean的增强器，即满足我们配置的通配符的增强器，该过程在AopUtil.findAdvisorsThatCanApply方法中实现，其主要功能是寻找所有适用于当前bean的增强器，并分开处理引介增强和普通增强。对于是否适用。\n\n\n\n##### 3.3 Advisor排序\n\nAnnotationAwareOrderComparator\n\n\n\n***Q1：为什么ExposeInvocationInterceptor放在所有MethodInterceptor的前面？***\n\nExposeInvocationInterceptor 会将当前代理类的 MethodInvocation 放在 ThreadLocal中 以备使用，为什么放在第一位就是 希望后面所有的MethodInterceptor都能访问到 这个全局的MethodInvocation\n\n```\n1.    ExposeInvocationInterceptor.invoke()\n\n2.     \n\n3.    public Object invoke(MethodInvocation mi) throws Throwable { \n\n4.      MethodInvocation oldInvocation = invocation.get(); \n\n5.      invocation.set(mi); \n\n6.      try { \n\n7.       // 在代理类的 advice chain 执行期间 都能用ExposeInvocationInterceptor.currentInvocation() 拿到 mi 的信息 \n\n8.        return mi.proceed(); \n\n9.      } \n\n10.     finally { \n\n11.       invocation.set(oldInvocation); \n\n12.     } \n\n13.   } \n\n14.    \n\n15.   使用案例\n\n16.    @Around(\"printSysLog()\") \n\n17.    public Object saveSysLog(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { \n\n18.      MethodInvocation invocation = ExposeInvocationInterceptor.currentInvocation(); \n\n19.      ...... \n\n20.   } \n```\n\n![img](http://pcc.huitogo.club/1fae6cfdf98dd6eafa8e1d6a82c5c6ac)\n\n\n\n##### 3.3 创建代理\n\ncreateProxy过程：\n\n1. 获取当前类中的相关属性\n2. 添加代理接口\n3. 封装Advisor并加入ProxyFactory中\n4. 设置要代理的类\n5. 根据需要定制代理类\n6. 进行获取代理的操作，调用proxyFactroy的getProxy方法获取代理\n\n\n\ngetProxy：\n\n```\npublic Object getProxy(ClassLoader classLoader){\n    return createAopProxy().getProxy(classLoader);\n}\n```\n\n\n\n创建代理核心方法：AopProxyFactory.createAopProxy\n\n主要是根据一些条件来确定创建JDKProxy还是CglibProxy。根据if条件，有三个方面的因素：\n\n1. optimize：用来控制通过CGLIB创建的代理是否使用激进优化策略，只推荐在完全了解AOP代理的优化的情况下使用。对JDK动态代理无效。\n\n2. proxyTargetClass：这个属性为true时，目标本身被代理而不是目标类的接口，此时CGLIB代理将被创建。设置方式:\n\n   ```\n   <aop:aspextj-autoproxy proxy-target-class = “true” />\n   ```\n\n3. hasNoUserSuppliedProxyInterfaces：是否存在代理接口\n\n   \n\nJDK与Cglib方式的总结：\n\n1. 如果目标对象实现了接口，默认情况下采用JDK的动态代理实现AOP\n2. 如果目标对象实现了接口，可采用添加CGLIB库或指定proxy-target-class的方法强制使用CGLIB实现AOP\n3. 如果没有实现接口，则必须采用CGLIB库，Spring会自动在两者之间转换\n\n\n\n两者的区别：\n\n- JDK动态代理只能对实现了接口的类生成代理，而不能针对类\n\n- CGLIB时针对类实现代理，主要是对指定的类生成子类，覆盖其中的方法。因为这个实现过程本质上是继承，所以类或方法最好不声明为final的\n  \n  \n\n#### 4. 链式执行\n\nAdvice -> 对应 MethodInterceptor 怎么执行 Advisor -> Advice 的适配器 什么时候执行（切入点） + 怎么执行 Advised -> 代理类容器 = Interceptors + other advice + Advisors + the proxied interfaces\n\nAdvisedSupport.getInterceptorsAndDynamicInterceptionAdvice 获取代理方法上 真正执行的 拦截器链 （一堆Advisor）\n\nAdvisorAdapter. getInterceptor(Advisor advisor) 转换Advisor 到对应的 MethodInteceptor AdvisorAdapterRegistry. registerAdvisorAdapter 注册AdvisorAdapter （so 可以自定义）\n\n![img](http://pcc.huitogo.club/015795c232e14e34a0b92805cc9197cf)\n\n\n\n最后执行的时候是执行 Advisor 所对应的 MethodInteceptor\n\nBeforeAdvice、AfterAdvice、AbstractAspectJAdvice\n\n![img](http://pcc.huitogo.club/843e5a56e8a4bf51cbb54107aa926c9c)\n\n\n\n#### 5. 扩展\n\n##### 5.1 DynamicDataSourceAnnotationAdvisor 动态数据源 \n\n![img](http://pcc.huitogo.club/ea8f4fbd1c883670e77b451abfbd088a)\n\n\n\n1）定义切面（拦截哪些类 或 方法）\n\n也就是带DS 注解的\n\n```\nDynamicDataSourceAnnotationAdvisor. buildPointcut()\n          AnnotatedElementUtils.hasAnnotation(clazz,DS.class)\n          AnnotatedElementUtils.hasAnnotation(method,DS.class)\n```\n\n\n\n2）定义通知（拦截之后做什么）\n\n```\nDynamicDataSourceAnnotationInterceptor.invoke()\n     DynamicDataSourceContextHolder. LOOKUP_KEY_HOLDER  将ds放到threadlocal中\n```\n\n\n\n3）谁要用ds\n\n```\n DynamicRoutingDataSource. determineDataSource()  确定当前线程使用哪个数据源\n     dataSourceMap.get(ds)  \n```\n\n\n\n4）dataSourceMap怎么来？\n\n```\n   DynamicRoutingDataSource. afterPropertiesSet()  extends InitialBean覆盖\n        DynamicDataSourceProvider. loadDataSources()\n             AbstractJdbcDataSourceProvider. loadDataSources() jdbc数据源\n             YmlDynamicDataSourceProvider. loadDataSources() 从yaml文件中加载数据源\n        DynamicDataSourceProvider. addDataSource()\n```\n\n\n\n##### 5.2 BeanFactoryTransactionAttributeSourceAdvisor事务\n\n1）切入点pointcut（拦截什么）\n\n```\nTransactionAttributeSourcePointcut\n     TransactionAttributeSourceClassFilter.match()\n          TransactionAttributeSource. isCandidateClass()\n               TransactionAnnotationParser. isCandidateClass() \n                   AnnotationUtils.isCandidateClass(targetClass, Transactional.class) \n```\n\n从spring jpa 的接口实现 类或方法要带有 @Transactional 注解\n\n\n\n2）事务信息\n\n```\nTransactionDefinition 事务定义\n\n     TransactionAttribute 事务属性\n\n          TransactionAttributeSource\n\n              AnnotationTransactionAttributeSource\n```\n\n\n\n3）通知 advice（做什么）\n\n```\n TransactionInterceptor\n     TransactionAspectSupport. invokeWithinTransaction()\n          TransactionAspectSupport. invokeWithinTransaction() \n               TransactionAspectSupport.invokeWithinTransaction() \n                   定义协议 交给 各数据库层实现 \n```\n\n\n\n4）开始\n\nAbstractSingletonProxyFactoryBean\n\n```\n AbstractSingletonProxyFactoryBean. afterPropertiesSet()\n     ProxyFactory. addAdvisor()\n          AbstractSingletonProxyFactoryBean.preInterceptors 事务执行前置函数 \n          TransactionProxyFactoryBean. createMainInterceptor()核心返回TransactionInterceptor\n          AbstractSingletonProxyFactoryBean. postInterceptors 事务执行后置函数\n```", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "ca2bdf95edb8870eb39212d38811bf82": {"id": "ca2bdf95edb8870eb39212d38811bf82", "item": "源码解读", "title": "Tomcat源码分析", "date": "2024-08-22", "summary": "Tomcat 是一个开源的 Web 应用服务器。它实现了 Java Servlet 和 JavaServer Pages 等技术规范，能高效处理 HTTP 请求。具有易部署、性能稳定等特点，广泛应用于开发和部署 Java Web 应用，是 Java 生态中重要的组成部分。", "body": "\n#### **1、tomcat 的启动流程**\n\n\n\n下图是tomcat 的启动时序图\n\n![img](http://pcc.huitogo.club/92eeecfa6b461721c5696f00dd7b7971)\n\n\n\n由图中我们可以看到从Bootstrap类的main方法开始, tomcat会以链的方式逐级调用各个模块的init()方法进行初始化, 待各个模块都初始化后, 又会逐级调用各个模块的start()方法启动各个模块\n\n\n\n下面通过源码的调用层级来看一下：\n\n```\nCatilna\n\n\t\tBootstrap\n\t\t\n\t\t\t\tServer --- StandardServer                tomcat           \n\t\t\t\t\n\t\t\t\t\t\tService --- StandardService\n\t\t\t\t\t\t\n\t\t\t\t\t\tEngine --- StandardEngine、EngineConfig          \n\t\t\t\t\t\t\n\t\t\t\t\t\tContainer --- ContainerBase          webApps                   \n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tConnector(8080、443)  -> ProtocolHandler -> EndPoint  --- NIOEndPoint、NIO2EndPoint、APREndPoint\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tHost  --- StandardHost、HosConfig                               \n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\tContext --- StandardContext、ContextConfig                        webApp       \n\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tWrapper  ---   StandardWrapper                                 servlet         \n```\n\n\n\n主要分成两个大接口，Lifeclycle 和 LifecycleListener，Lifeclycle 进行 init 和 start 控制生命周期，变更状态的时候 触发LifecycleListener事件，执行lifecycleEvent\n\nLifeclycle ---> LifeclycleMBeanBase：ContainerBase（StandardEngine、StandardHost、StandardContext）、StandardServer、StandardService\n\nLifecycleListener：EngineConfig、HosConfig、ContextConfig\n\n\n\n\n\n#### **2、tomcat 的组件**\n\n\n\ntomcat 的组件 和 组件之间的交互主要如下\n\n\n\n![img](http://pcc.huitogo.club/5fc5d76298edbf10a46aa8369fac7df5)\n\n\n\n**server**：整个servlet容器，一个tomcat对应一个server，一个server包含多个service，Server就掌管着多个Service的死活\n\nserver在tomcat中的实现类是：StandardServer\n\n**service**：service是对外提供服务的， 一个service包含多个connector（接受请求的协议），和一个container（容器），多个connector共享一个container容器，\n\nservice在tomcat中的实现类是：StandardService\n\n**connector**：connector主要用来接收请求，解析请求内容，封装request和response，然后将准备好的数据交给Container处理\n\n**executor**：线程池\n\n**container**：Container就是我们常说的容器，里面可以有多个Host,一个host表示一个虚拟主机，就是一个对应一个WebApps. 最后Container处理完请求之后会将响应内容返回给Connecter,再由Connecter返回给客户端包含engine，host，context，wrapper等组件\n\n**engine**：Container（容器/引擎）， 用来管理多个站点，一个Service最多只能有一个Engine\n\nengine在tomcat中的实现类是：StandardEngine\n\n**host**：engine容器的子容器，一个host对应一个网络域名，一个host包含多个context\n\nhost在tomcat中的实现类是：StandardHost\n\n**context**：host容器的子容器，表示一个web应用\n\ncontext在tomcat中的实现类是：StandardContext\n\n**wrapper**：tomcat中最小的容器单元，表示web应用中的servlet\n\nwrapper在tomcat中的实现类是：StandardWrapper  \n\n\n\n\n\n\n\n其中组件中最核心的是Connector 和 Container；Connector负责 请求和响应，Container 负责 处理请求 两者交互如下：\n\n\n\n![img](http://pcc.huitogo.club/5dcf290e5aa65422ed2687f06ff4001c)\n\n\n\n##### 2.1 Connector\n\n\n\nconnector架构：最底层使用的是Socket进行连接的，Request和Response是按照Http协议来封装的，所以Connector同时需要实现TCP/IP协议和Http协议\n\nConnector中具体用事件处理器来处理请求【ProtocoHandler】，不同的ProtocoHandler代表不同的连接类型【所以一个Service中可以有多个Connector】 例如：Http11Protocol使用普通的Socket来连接的，Http11NioProtocol使用NioSocket连接。 Endpoint用于处理底层Socket的网络连接，用来实现Tcp/Ip协议。\n\nAcceptor:用于监听和接收请求。\n\nHandler：请求的初步处理，并且调用Processor\n\nAsynTimeout:检查异步的Request请求是否超时 Processor用于将Endpoint接收Socket封装成Request，用来实现HTTP协议\n\nAdapter 用于将Request交给Container 进行具体处理，即将请求适配到Servlet容器\n\n\n\n##### 2.2 Container\n\n\n\n![img](http://pcc.huitogo.club/729b44dc8f59d6aadf5efc9465e472ac)\n\n\n\nContainer 架构：Container就是一个Engine。Container用于封装和管理Servlet，以及具体处理Request请求\n\n\n\n\n\n#### **3、CoyoteAdapter**\n\n\n\n这里需要着重说一下 Connector 和 Container的细节\n\n\n\n![img](http://pcc.huitogo.club/a8b78a1b823d55f60128420d931605a5)\n\n\n\n1）Endpoint接收Socket连接，生成一个SocketProcessor任务提交到线程池去处理\n\n2）SocketProcessor的run方法会调用Processor组件去解析应用层协议，Processor通过解析生成Request对象后，会调 用Adapter的service方法。\n\n\n\n其中：\n\n##### 3.1 **EndPoint**\n\n提供字节流给Processor\n\n监听通信端口，是对传输层的抽象，用来实现 TCP/IP 协议的。 对应的抽象类为AbstractEndPoint，有很多实现类，比如NioEndPoint，JIoEndPoint等。在其中有两个组件，一个 是Acceptor，另外一个是SocketProcessor。 Acceptor用于监听Socket连接请求，SocketProcessor用于处理接收到的Socket请求。\n\n\n\n##### 3.2 **Processor**\n\n提供Tomcat Request对象给Adapter\n\nProcessor是用于实现HTTP协议的，也就是说Processor是针对应用层协议的抽象。 Processor接受来自EndPoint的Socket，然后解析成Tomcat Request和Tomcat Response对象，最后通过Adapter 提交给容器。 对应的抽象类为AbstractProcessor，有很多实现类，比如AjpProcessor、Http11Processor等。\n\n\n\n##### 3.3 **Adapter**\n\n提供ServletRequest给容器\n\nProtocolHandler接口负责解析请求并生成 Tomcat Request 类。 需要把这个 Request 对象转换成 ServletRequest。 Tomcat 引入CoyoteAdapter，这是适配器模式的经典运用，连接器调用 CoyoteAdapter 的 sevice 方法，传入的是 Tomcat Request 对象，CoyoteAdapter 负责将 Tomcat Request 转成 ServletRequest，再调用容器的 service 方 法。\n\n\n\n所以 CoyoteAdapter 是 Connector 请求的 处理适配器， 将 HttpRequest 转换成 ServletRequest 交由 Container 处理\n\n\n\n\n\n#### **4、web.xml 和 web-fragment.xml**\n\n\n\nweb.xml 是 javaWeb项目的配置根文件（万恶之源）\n\nServlet 3.0 引入了称之为“Web 模块部署描述符片段”的 web-fragment.xml 部署描述文件，该文件必须存放在 JAR 文件的 META-INF 目录下，该部署描述文件可以包含一切可以在 web.xml 中定义的内容。JAR 包通常放在 WEB-INF/lib 目录下，除此之外，所有该模块使用的资源，包括 class 文件、配置文件等，只需要能够被容器的类加载器链加载的路径上，比如 classes 目录等。可以说这个新特性还是很实用的，不用把之前臃肿的配置全部放在web.xml文件中了，可以把一些初始化的配置全部配置到web-fragment.xml文件中，比如在分布式项目中，spring的包扫描，在一些公司中都会有相应的规范约束，就连controller和service等等都要求包名都要遵守规范，这样我们就可以提取出来一个工程，统一加载spring的配置文件，在web-fragment.xml中加载这些spring的配置文件，这样在其他开发者工作中，不用每次都要配置spring的几乎重复的配置，直接引用相应的jar包即可完成配置，这样可以大大提高效率。\n\n最终 web.xml 和 web-fragment.xml 都会被加载到 WebXml中，多个文件会被merge，优先是 web.xml，后面的web-fragment.xml 按 order顺序加载\n\n\n\n\n\n#### **5、GlobalNamingResources**\n\n定义了服务器的全局JNDI资源\n\n\n\n\n\n#### **6、MapperListener**\n\nContainer 资源变更时引发的刷新事件\n\n\n\n\n\n#### **7、源码鉴赏**\n\n\n\n1）服务包扫描 + 添加Servlet映射\n\n\n\n```\nHosConfig.deployDirectory()\n\n\tWebAppLoader.start()\n\t\n\t\tContextConfig.configureStart()\n```\n\n\n\n2）http请求处理\n\n```\nAbstractProtocol.start()\n\n\tAbstractEndpoint.start()\n\t\n\t\tPoller.run()\n\t\t\n\t\t\tAbstractProtocol.process()\n\t\t\t\n\t\t\t\tAbstractProcessorLight.process()\n\t\t\t\t\n\t\t\t\t\tAbstractProcessorLight.service()\n\t\t\t\t\t\n\t\t\t\t\t\tHttp11Processor.service()   --- getAdapter().service(request, response)\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tCoyoteAdapter.service()   ---   connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);\n```", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "60438f2facca83685769500144869958": {"id": "60438f2facca83685769500144869958", "item": "源码解读", "title": "Zookeeper源码分析", "date": "2024-08-22", "summary": "Zookeeper 是一个分布式协调服务。它主要用于维护配置信息、命名服务、分布式同步等。具有高可靠性和高性能，通过选举机制保证服务的可用性。能有效协调分布式系统中各个节点，确保系统稳定高效运行，是分布式架构中的重要组件。", "body": "\n#### **1、zk的启动**\n\n\n\n![img](http://pcc.huitogo.club/ec2d54ec357814640817a5414b1964ba)\n\n\n\n重点看一下ZookeeperServerMain的main方法，主要包含三大块\n\n\n\n```\nAdminServer.start()   \n\n\tDummyAdminServer：什么都不做\n\tJettyAdminServer： 内嵌Servlet容器，用于访问ZookeeperServer支持的接口（命令行）\n\nServerCnxnFactory.startup(ZookeeperServer) 初始化 和 客户端之间的连接处理，分 加密模式 和 非加密模式\n\n\tNettyServerCnxnFactory：和客户端之间使用Netty传输\n\tNIOServerCnxnFactory：使用Http的NIO模式进行传输\n\t\n\t\t start工作线程：\n\t\t \n\t\t\t\t1 accept thread：接收新的连接 并委派给Selector Thread\n\t\t\t\t1-N selector threads: 实际select 请求的线程，哪个channel有流传输则进行select，支持多线程用于大量客户端发起请求的场景，避免selector thread变成性能瓶颈\n\t\t\t\t0-M socket I/O worker threads：实际工作线程，执行RequestProcessor，如果配置为0的话则直接在selector thread中执行\n\t\t\t\t1 connection expiration thread：根据会话时间（心跳）关闭空闲的客户端连接\n\t\t\t\t\n\t\t装配Zookeeper 服务端配置信息\n\t\t\t\tstartdata()：加载磁盘数据（dataTree）到内存中，并获取最后一次有效的 zxid（节点序列号）\n\t\t\t\tstartup()\n\t\t\t\t\t\tstartSessionTracker()： 启动session会话跟踪管理器，leader 和 standalone模式下的 共用一个，其他的follow 服务 则关联到 leader上\n\t\t\t\t\t\tsetupRequestProcessors()：配置请求链式处理器  PrepRequestProcessor -> SyncRequestProcessor -> FinalRequestProcessor\n\t\t\t\t\t\tregisterJMX()：注册了一个 Zk的服务信息 和 数据信息\n\nContainerManager.start()：管理 和 清理 zk的数据节点\n\t\tcheckContainers()：清理无子节点 和 ttl到期的叶子节点\n```\n\n\n\n简单的总结就是Zookeeper本质上就是管理它的数据节点（DataTree）\n\n\n\n详细看下各子部分的代码\n\n\n\nNIOServerCnxnFactory.start() 初始化 和 客户端之间的连接处理\n\n```\npublic void start() {\n    stopped = false;\n    // 真正执行客户端的请求\n    if (workerPool == null) {\n        workerPool = new WorkerService(\n                \"NIOWorker\", numWorkerThreads, false);\n    }\n    // epoll 模型\n    // 都是damon 线程\n    // 处理 和 验证请求，更新客户端连接状态，主要是讲请求体 转交给 Worker去执行\n    for (SelectorThread thread : selectorThreads) {\n        if (thread.getState() == Thread.State.NEW) {\n            thread.start();\n        }\n    }\n    // ensure thread is started once and only once\n    // acceptThread 将 连接请求 ClientSocketChannerl加入 acceptQueue中\n    if (acceptThread.getState() == Thread.State.NEW) {\n        acceptThread.start();\n    }\n    // 关闭 过期的（失活）的客户端连接\n    if (expirerThread.getState() == Thread.State.NEW) {\n        expirerThread.start();\n    }\n}\n```\n\n\n\n可以看出这是一块典型的NIO的epoll模式设计，一个Accept Thread拖着多个Selector Thread，然后Selector Thread将读取的客户端连接通道的流信息报文请求分发到WorkPool中 等待Worker执行，最后是一个Exipirer Thread负责 心跳检查\n\n\n\n**Accept Thread**\n\n```\nprivate boolean doAccept() {\n    boolean accepted = false;\n    SocketChannel sc = null;\n    try {\n        sc = acceptSocket.accept();\n        accepted = true;\n        InetAddress ia = sc.socket().getInetAddress();\n        int cnxncount = getClientCnxnCount(ia);\n\n        if (maxClientCnxns > 0 && cnxncount >= maxClientCnxns) {\n            throw new IOException(\"Too many connections from \" + ia\n                    + \" - max is \" + maxClientCnxns);\n        }\n\n        LOG.debug(\"Accepted socket connection from \"\n                + sc.socket().getRemoteSocketAddress());\n        sc.configureBlocking(false);\n\n        // Round-robin assign this connection to a selector thread\n        if (!selectorIterator.hasNext()) {\n            selectorIterator = selectorThreads.iterator();\n        }\n        SelectorThread selectorThread = selectorIterator.next();\n        if (!selectorThread.addAcceptedConnection(sc)) {\n            throw new IOException(\n                    \"Unable to add connection to selector queue\"\n                            + (stopped ? \" (shutdown in progress)\" : \"\"));\n        }\n        acceptErrorLogger.flush();\n    } catch (IOException e) {\n        // accept, maxClientCnxns, configureBlocking\n        acceptErrorLogger.rateLimitLog(\n                \"Error accepting new connection: \" + e.getMessage());\n        fastCloseSock(sc);\n    }\n    return accepted;\n}\n```\n\n\n\n**Selector Thread**\n\n```\nprivate void select() {\n    try {\n        selector.select();\n\n        Set<SelectionKey> selected = selector.selectedKeys();\n        ArrayList<SelectionKey> selectedList =\n                new ArrayList<SelectionKey>(selected);\n        Collections.shuffle(selectedList);\n        Iterator<SelectionKey> selectedKeys = selectedList.iterator();\n        while (!stopped && selectedKeys.hasNext()) {\n            SelectionKey key = selectedKeys.next();\n            selected.remove(key);\n\n            if (!key.isValid()) {\n                cleanupSelectionKey(key);\n                continue;\n            }\n            if (key.isReadable() || key.isWritable()) {\n                handleIO(key);\n            } else {\n                LOG.warn(\"Unexpected ops in select \" + key.readyOps());\n            }\n        }\n    } catch (IOException e) {\n        LOG.warn(\"Ignoring IOException while selecting\", e);\n    }\n}\n```\n\n\n\nExpire Thread\n\n```\npublic void run() {\n    try {\n        while (!stopped) {\n            long waitTime = cnxnExpiryQueue.getWaitTime();\n            if (waitTime > 0) {\n                Thread.sleep(waitTime);\n                continue;\n            }\n            for (NIOServerCnxn conn : cnxnExpiryQueue.poll()) {\n                conn.close();\n            }\n        }\n\n    } catch (InterruptedException e) {\n        LOG.info(\"ConnnectionExpirerThread interrupted\");\n    }\n}\n```\n\n\n\nNIOServerCnxnFactory.startdata() 加载磁盘数据（dataTree）到内存中，并获取最后一次有效的 zxid（节点序列号）\n\n```\n/**\n *  Restore sessions and data\n */\npublic void loadData() throws IOException, InterruptedException {\n    /*\n     * When a new leader starts executing Leader#lead, it \n     * invokes this method. The database, however, has been\n     * initialized before running leader election so that\n     * the server could pick its zxid for its initial vote.\n     * It does it by invoking QuorumPeer#getLastLoggedZxid.\n     * Consequently, we don't need to initialize it once more\n     * and avoid the penalty of loading it a second time. Not \n     * reloading it is particularly important for applications\n     * that host a large database.\n     * \n     * The following if block checks whether the database has\n     * been initialized or not. Note that this method is\n     * invoked by at least one other method: \n     * ZooKeeperServer#startdata.\n     *  \n     * See ZOOKEEPER-1642 for more detail.\n     */\n    if(zkDb.isInitialized()){\n        setZxid(zkDb.getDataTreeLastProcessedZxid());\n    }\n    else {\n        setZxid(zkDb.loadDataBase());\n    }\n    \n    // Clean up dead sessions\n    LinkedList<Long> deadSessions = new LinkedList<Long>();\n    for (Long session : zkDb.getSessions()) {\n        if (zkDb.getSessionWithTimeOuts().get(session) == null) {\n            deadSessions.add(session);\n        }\n    }\n\n    for (long session : deadSessions) {\n        // XXX: Is lastProcessedZxid really the best thing to use?\n        killSession(session, zkDb.getDataTreeLastProcessedZxid());\n    }\n\n    // Make a clean snapshot\n    takeSnapshot();\n}\n```\n\n\n\n总结下就是 如果内存有的话直接获取最近一次的zxid，没有则从磁盘（zkdb）中获取，可以是本地文件 也可以是数据库，硬盘存储是以log的形式存储的，映射到内存中的快照则是DataTree结构\n\n\n\nNIOServerCnxnFactory.startup()\n\n```\npublic synchronized void startup() {\n    if (sessionTracker == null) {\n        createSessionTracker();\n    }\n    // 启动session会话跟踪管理器，leader 和 standalone模式下的 共用一个，其他的follow 服务 则关联到 leader上\n    // 处理主从之间的 会话，清除过期会话\n    startSessionTracker();\n    // 启动请求链式处理器  PrepRequestProcessor -> SyncRequestProcessor -> FinalRequestProcessor\n    // 有点类似于Netty 的 Processor模式\n    setupRequestProcessors();\n\n    // 通常使用JMX来监控系统的运行状态或管理系统的某些方面，比如清空缓存、重新加载配置文件等\n    // 注册了一个 ZooKeeperServerBean 和 DataTreeBean\n    // ZooKeeperServerBean : zk的服务信息\n    // DataTreeBean： zk的内存数据信息，DataTree，一个hashtable保存数据信息，用于存取，一个Tree 用于磁盘序列化（快照）\n    registerJMX();\n\n    setState(State.RUNNING);\n    notifyAll();\n}\n```\n\n\n\nsetupRequestProcessors()\n\n```\nprotected void setupRequestProcessors() {\n    RequestProcessor finalProcessor = new FinalRequestProcessor(this);\n    RequestProcessor syncProcessor = new SyncRequestProcessor(this,\n            finalProcessor);\n    ((SyncRequestProcessor)syncProcessor).start();\n    firstProcessor = new PrepRequestProcessor(this, syncProcessor);\n    ((PrepRequestProcessor)firstProcessor).start();\n}\n```\n\n\n\n可以看出请求处理链的先后顺序是PrepRequestProcessor -> SyncRequestProcessor -> FinalRequestProcessor，跟Netty里面配置的SocketProcessor有点像，比如先读取字符流转码 -> 请求处理 -> 输出字符流编码\n\n\n\nContainerManager.start() 管理 和 清理 zk的数据节点\n\n```\n/**\n * Manually check the containers. Not normally used directly\n */\npublic void checkContainers()\n        throws InterruptedException {\n    long minIntervalMs = getMinIntervalMs();\n    for (String containerPath : getCandidates()) {\n        long startMs = Time.currentElapsedTime();\n\n        ByteBuffer path = ByteBuffer.wrap(containerPath.getBytes());\n        Request request = new Request(null, 0, 0,\n                ZooDefs.OpCode.deleteContainer, path, null);\n        try {\n            LOG.info(\"Attempting to delete candidate container: {}\",\n                    containerPath);\n            requestProcessor.processRequest(request);\n        } catch (Exception e) {\n            LOG.error(\"Could not delete container: {}\",\n                    containerPath, e);\n        }\n\n        long elapsedMs = Time.currentElapsedTime() - startMs;\n        long waitMs = minIntervalMs - elapsedMs;\n        if (waitMs > 0) {\n            Thread.sleep(waitMs);\n        }\n    }\n}\n```\n\n\n\n就是清理无效的 数据节点，这里主要看下哪些是无效的数据节点\n\n\n\ngetCandidates()\n\n```\nprotected Collection<String> getCandidates() {\n    Set<String> candidates = new HashSet<String>();\n    for (String containerPath : zkDb.getDataTree().getContainers()) {\n        DataNode node = zkDb.getDataTree().getNode(containerPath);\n        /*\n            cversion > 0: keep newly created containers from being deleted\n            before any children have been added. If you were to create the\n            container just before a container cleaning period the container\n            would be immediately be deleted.\n         */\n        if ((node != null) && (node.stat.getCversion() > 0) &&\n                (node.getChildren().size() == 0)) {\n            candidates.add(containerPath);\n        }\n    }\n    for (String ttlPath : zkDb.getDataTree().getTtls()) {\n        DataNode node = zkDb.getDataTree().getNode(ttlPath);\n        if (node != null) {\n            Set<String> children = node.getChildren();\n            if ((children == null) || (children.size() == 0)) {\n                if ( EphemeralType.get(node.stat.getEphemeralOwner()) == EphemeralType.TTL ) {\n                    long elapsed = getElapsed(node);\n                    long ttl = EphemeralType.TTL.getValue(node.stat.getEphemeralOwner());\n                    if ((ttl != 0) && (getElapsed(node) > ttl)) {\n                        candidates.add(ttlPath);\n                    }\n                }\n            }\n        }\n    }\n    return candidates;\n}\n```\n\n\n\n无效的叶子节点即 没有子节点的节点 或者 ttl到期的 叶子节点\n\n\n\n\n\n#### **2、zkclient 和 zkserver 的请求机制**\n\n\n\n这里重点看下 Worker的工作范围\n\n\n\n```\n/**\n * Schedule work to be done by the thread assigned to this id. Thread\n * assignment is a single mod operation on the number of threads.  If a\n * worker thread pool is not being used, work is done directly by\n * this thread.\n */\npublic void schedule(WorkRequest workRequest, long id) {\n    if (stopped) {\n        workRequest.cleanup();\n        return;\n    }\n\n    ScheduledWorkRequest scheduledWorkRequest =\n        new ScheduledWorkRequest(workRequest);\n\n    // If we have a worker thread pool, use that; otherwise, do the work\n    // directly.\n    int size = workers.size();\n    if (size > 0) {\n        try {\n            // make sure to map negative ids as well to [0, size-1]|\n            // 随机挑选一个幸运工人，线程池的最大数 在0~size-1之间\n            int workerNum = ((int) (id % size) + size) % size;\n            ExecutorService worker = workers.get(workerNum);\n            worker.execute(scheduledWorkRequest);\n        } catch (RejectedExecutionException e) {\n            LOG.warn(\"ExecutorService rejected execution\", e);\n            workRequest.cleanup();\n        }\n    } else {\n        // When there is no worker thread pool, do the work directly\n        // and wait for its completion\n        scheduledWorkRequest.run();\n    }\n}\n\n// 工人开始工作了\nprivate class ScheduledWorkRequest implements Runnable {\n    \n    @Override\n    public void run() {\n        try {\n            // Check if stopped while request was on queue\n            if (stopped) {\n                workRequest.cleanup();\n                return;\n            }\n            workRequest.doWork();\n        } catch (Exception e) {\n            LOG.warn(\"Unexpected exception\", e);\n            workRequest.cleanup();\n        }\n    }\n}\n```\n\n\n\n从 workRequest.doWork() 可追踪到 zkServer.processPacket(this, incomingBuffer)\n\n```\nZookeeperServer.processPacket(ServerCnxn, ByteBuffer)  处理请求报文\npublic void processPacket(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException {\n    // We have the request, now process and setup for next\n    InputStream bais = new ByteBufferInputStream(incomingBuffer);\n    BinaryInputArchive bia = BinaryInputArchive.getArchive(bais);\n    RequestHeader h = new RequestHeader();\n    h.deserialize(bia, \"header\");\n    // Through the magic of byte buffers, txn will not be\n    // pointing\n    // to the start of the txn\n    incomingBuffer = incomingBuffer.slice();\n    // 授权认证请求\n    if (h.getType() == OpCode.auth) {\n       //... 不关心的内容\n    } else {\n        // ssl请求\n        if (h.getType() == OpCode.sasl) {\n            // ... 不关心的内容\n        } // 正文处理\n        else {\n            Request si = new Request(cnxn, cnxn.getSessionId(), h.getXid(),\n              h.getType(), incomingBuffer, cnxn.getAuthInfo());\n            si.setOwner(ServerCnxn.me);\n            // Always treat packet from the client as a possible\n            // local request.\n            setLocalSessionFlag(si);\n            // 提交请求\n            submitRequest(si);\n        }\n    }\n    cnxn.incrOutstandingRequests(h);\n}\n```\n\n\n\nsubmitRequest(Request）\n\n```\npublic void submitRequest(Request si) {\n    // zk 服务端正在启动，稍等片刻\n    if (firstProcessor == null) {\n        synchronized (this) {\n            try {\n                // Since all requests are passed to the request\n                // processor it should wait for setting up the request\n                // processor chain. The state will be updated to RUNNING\n                // after the setup.\n                while (state == State.INITIAL) {\n                    wait(1000);\n                }\n            } catch (InterruptedException e) {\n                LOG.warn(\"Unexpected interruption\", e);\n            }\n            if (firstProcessor == null || state != State.RUNNING) {\n                throw new RuntimeException(\"Not started\");\n            }\n        }\n    }\n    try {\n        // 客户端有请求来了，说明它是活的\n        touch(si.cnxn);\n        boolean validpacket = Request.isValid(si.type);\n        if (validpacket) {\n            firstProcessor.processRequest(si);\n            if (si.cnxn != null) {\n                // 请求数 + 1，因为zk服务端会作一个等待处理的最大请求数量的限制\n                incInProcess();\n            }\n        } else {\n            LOG.warn(\"Received packet at server of unknown type \" + si.type);\n            new UnimplementedRequestProcessor().processRequest(si);\n        }\n    } catch (MissingSessionException e) {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Dropping request: \" + e.getMessage());\n        }\n    } catch (RequestProcessorException e) {\n        LOG.error(\"Unable to process request:\" + e.getMessage(), e);\n    }\n}\n```\n\n\n\n可以看到有我们熟悉的 FirstProcessor，根据我们之前配置的Processor链来看，第一个应该是PrepRequestProcessor\n\n```\nLinkedBlockingQueue<Request> submittedRequests = new LinkedBlockingQueue<Request>();\n\npublic void processRequest(Request request) {\n    submittedRequests.add(request);\n}\n```\n\n往阻塞队列里面加了一个任务处理，这里用一个队列 缓冲任务，可以实现异步操作\n\n\n\n真正的处理在PrepRequestProcessor 的 线程任务中\n\n```\npublic void run() {\n    try {\n        while (true) {\n            Request request = submittedRequests.take();\n            long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK;\n            if (request.type == OpCode.ping) {\n                traceMask = ZooTrace.CLIENT_PING_TRACE_MASK;\n            }\n            // 日志追踪，看是客户端请求日志还是心跳包日志\n            if (LOG.isTraceEnabled()) {\n                ZooTrace.logRequest(LOG, traceMask, 'P', request, \"\");\n            }\n            if (Request.requestOfDeath == request) {\n                break;\n            }\n            // 实际执行\n            pRequest(request);\n        }\n}\n\n/**\n * This method will be called inside the ProcessRequestThread, which is a\n * singleton, so there will be a single thread calling this code.\n *\n * @param request\n */\nprotected void pRequest(Request request) throws RequestProcessorException {\n    // LOG.info(\"Prep>>> cxid = \" + request.cxid + \" type = \" +\n    // request.type + \" id = 0x\" + Long.toHexString(request.sessionId));\n    request.setHdr(null);\n    request.setTxn(null);\n\n    try {\n        switch (request.type) {\n        case OpCode.createContainer:\n        case OpCode.create:\n        case OpCode.create2:\n            CreateRequest create2Request = new CreateRequest();\n            pRequest2Txn(request.type, zks.getNextZxid(), request, create2Request, true);\n            break;\n        case OpCode.createTTL:\n            CreateTTLRequest createTtlRequest = new CreateTTLRequest();\n            pRequest2Txn(request.type, zks.getNextZxid(), request, createTtlRequest, true);\n            break;\n        case OpCode.deleteContainer:\n        case OpCode.delete:\n            DeleteRequest deleteRequest = new DeleteRequest();\n            pRequest2Txn(request.type, zks.getNextZxid(), request, deleteRequest, true);\n            break;\n        case OpCode.setData:\n            SetDataRequest setDataRequest = new SetDataRequest();                \n            pRequest2Txn(request.type, zks.getNextZxid(), request, setDataRequest, true);\n            break;\n}\n```\n\n\n\n这里我们以createNode指令为例看看流程怎么执行的\n\n```\nprivate void pRequest2TxnCreate(int type, Request request, Record record, boolean deserialize) throws IOException, KeeperException {\n    if (deserialize) {\n        ByteBufferInputStream.byteBuffer2Record(request.request, record);\n    }\n\n    int flags;\n    String path;\n    List<ACL> acl;\n    byte[] data;\n    long ttl;\n    if (type == OpCode.createTTL) {\n        CreateTTLRequest createTtlRequest = (CreateTTLRequest)record;\n        flags = createTtlRequest.getFlags();\n        path = createTtlRequest.getPath();\n        acl = createTtlRequest.getAcl();\n        data = createTtlRequest.getData();\n        ttl = createTtlRequest.getTtl();\n    } else {\n        CreateRequest createRequest = (CreateRequest)record;\n        flags = createRequest.getFlags();\n        path = createRequest.getPath();\n        acl = createRequest.getAcl();\n        data = createRequest.getData();\n        ttl = -1;\n    }\n    // 节点类型\n    CreateMode createMode = CreateMode.fromFlag(flags);\n    validateCreateRequest(path, createMode, request, ttl);\n    String parentPath = validatePathForCreate(path, request.sessionId);\n\n    List<ACL> listACL = fixupACL(path, request.authInfo, acl);\n    // 我理解的 是修正操作（事务），状态介于准备修改 和 修改完成之间\n    ChangeRecord parentRecord = getRecordForPath(parentPath);\n\n    checkACL(zks, parentRecord.acl, ZooDefs.Perms.CREATE, request.authInfo);\n    int parentCVersion = parentRecord.stat.getCversion();\n    if (createMode.isSequential()) {\n        path = path + String.format(Locale.ENGLISH, \"%010d\", parentCVersion);\n    }\n    validatePath(path, request.sessionId);\n    try {\n        // 节点有 修改操作，即不为空\n        if (getRecordForPath(path) != null) {\n            throw new KeeperException.NodeExistsException(path);\n        }\n    } catch (KeeperException.NoNodeException e) {\n        // ignore this one\n    }\n    // 判断父节点是否叶子节点\n    boolean ephemeralParent = EphemeralType.get(parentRecord.stat.getEphemeralOwner()) == EphemeralType.NORMAL;\n    if (ephemeralParent) {\n        throw new KeeperException.NoChildrenForEphemeralsException(path);\n    }\n    // 修改父节点的 版本号\n    int newCversion = parentRecord.stat.getCversion() + 1;\n    if (type == OpCode.createContainer) {\n        request.setTxn(new CreateContainerTxn(path, data, listACL, newCversion));\n    } else if (type == OpCode.createTTL) {\n        request.setTxn(new CreateTTLTxn(path, data, listACL, newCversion, ttl));\n    } else {\n        request.setTxn(new CreateTxn(path, data, listACL, createMode.isEphemeral(),\n                newCversion));\n    }\n    StatPersisted s = new StatPersisted();\n    if (createMode.isEphemeral()) {\n        s.setEphemeralOwner(request.sessionId);\n    }\n    //写时复制\n    parentRecord = parentRecord.duplicate(request.getHdr().getZxid());\n    parentRecord.childCount++;\n    parentRecord.stat.setCversion(newCversion);\n    addChangeRecord(parentRecord);\n    addChangeRecord(new ChangeRecord(request.getHdr().getZxid(), path, s, 0, listACL));\n}\n```\n\n\n\n这里在校验完 新增节点 和 新增节点的父节点有效性后 使用 写时复制 的方式 修改父节点的信息（版本号、子节点数量），添加了 新增节点的修改记录，addChangeRecord操作 向事件队列中 添加新增事件信息\n\n```\nprivate void addChangeRecord(ChangeRecord c) {\n    synchronized (zks.outstandingChanges) {\n        // 事件队列（双端）\n        zks.outstandingChanges.add(c);\n        // 修改事件内容（非安全的）\n        zks.outstandingChangesForPath.put(c.path, c);\n    }\n}\n```\n\n\n\n按照我们之前整理的调用链的顺序，下一个是 SyncRequestProcessor，这个处理器是将节点事件生成snapshot 存入磁盘，我们后面再看\n\n\n\n最后一个处理器是 FinalRequestProcessor，也就是真正对数据进行操作的地方，看一下 processRequest 方法\n\n```\nsynchronized (zks.outstandingChanges) {\n    // Need to process local session requests\n    // 修改本地内存（DataTree）中的节点信息\n    rc = zks.processTxn(request);\n\n    // request.hdr is set for write requests, which are the only ones\n    // that add to outstandingChanges.\n    if (request.getHdr() != null) {\n        TxnHeader hdr = request.getHdr();\n        Record txn = request.getTxn();\n        long zxid = hdr.getZxid();\n        while (!zks.outstandingChanges.isEmpty()\n               && zks.outstandingChanges.peek().zxid <= zxid) {\n            // 移除事务id 小的       \n            ChangeRecord cr = zks.outstandingChanges.remove();\n            if (cr.zxid < zxid) {\n                LOG.warn(\"Zxid outstanding \" + cr.zxid\n                         + \" is less than current \" + zxid);\n            }\n            // 重复操作同一 path 进行移除，已最新的操作为准\n            if (zks.outstandingChangesForPath.get(cr.path) == cr) {\n                zks.outstandingChangesForPath.remove(cr.path);\n            }\n        }\n    }\n\n    // do not add non quorum packets to the queue.\n    // 新增日志记录（时间轴的形式），用于从节点之间的数据同步\n    if (request.isQuorum()) {\n        zks.getZKDatabase().addCommittedProposal(request);\n    }\n}\nif (request.cnxn == null) {\n    return;\n}\nServerCnxn cnxn = request.cnxn;\n\nString lastOp = \"NA\";\n// zk客户端连接数减 1\nzks.decInProcess();\nCode err = Code.OK;\n// 根据事件节点类型 返回 响应报文\nRecord rsp = null;\n...\n//审计操作\n}\n对事件缓冲队列进行弹出操作，先写入内存再写入磁盘，最后返回响应报文。\n```\n\n\n\n\n\n#### **3、zk的数据怎么持久化？**\n\n\n\n先总结一下，数据 分别存在内存 和 磁盘中，通常 对节点的 CRUD发生在内存中（不难理解，快嘛），以DataTree（TreeNode）的数据结构进行存储； 持久化入磁盘的以l snapshot 文件的方式进行存储，可用于 初始化数据、数据恢复等后台耗时操作；还有一种内存数据用于主从节点的数据同步，基于 log 的数据结构；\n\n\n\n对数据的操作都在ZkDatabase中\n\n```\npublic class ZKDatabase {\n\n    private static final Logger LOG = LoggerFactory.getLogger(ZKDatabase.class);\n\n    /**\n     * make sure on a clear you take care of all these members.\n     */\n    protected DataTree dataTree;\n    protected ConcurrentHashMap<Long, Integer> sessionsWithTimeouts;\n    //FileTxnSnapLog是管理日志文件和持久化文件的对象\n    protected FileTxnSnapLog snapLog;\n    protected long minCommittedLog, maxCommittedLog;\n\n    /**\n     * Default value is to use snapshot if txnlog size exceeds 1/3 the size of snapshot\n     */\n    public static final String SNAPSHOT_SIZE_FACTOR = \"zookeeper.snapshotSizeFactor\";\n    public static final double DEFAULT_SNAPSHOT_SIZE_FACTOR = 0.33;\n    private double snapshotSizeFactor;\n\n    public static final int commitLogCount = 500;\n    protected static int commitLogBuffer = 700;\n    protected LinkedList<Proposal> committedLog = new LinkedList<Proposal>();\n    protected ReentrantReadWriteLock logLock = new ReentrantReadWriteLock();\n    volatile private boolean initialized = false;\n    ...    \n}\n```\n\n\n\n数据节点的类型有以下几种\n\n```\n/**\n * The znode will not be automatically deleted upon client's disconnect.\n */\nPERSISTENT (0, false, false, false, false),\n/**\n* The znode will not be automatically deleted upon client's disconnect,\n* and its name will be appended with a monotonically increasing number.\n*/\nPERSISTENT_SEQUENTIAL (2, false, true, false, false),\n/**\n * The znode will be deleted upon the client's disconnect.\n */\nEPHEMERAL (1, true, false, false, false),\n/**\n * The znode will be deleted upon the client's disconnect, and its name\n * will be appended with a monotonically increasing number.\n */\nEPHEMERAL_SEQUENTIAL (3, true, true, false, false),\n/**\n * The znode will be a container node. Container\n * nodes are special purpose nodes useful for recipes such as leader, lock,\n * etc. When the last child of a container is deleted, the container becomes\n * a candidate to be deleted by the server at some point in the future.\n * Given this property, you should be prepared to get\n */\nCONTAINER (4, false, false, true, false),\n/**\n * The znode will not be automatically deleted upon client's disconnect.\n * However if the znode has not been modified within the given TTL, it\n * will be deleted once it has no children.\n */\nPERSISTENT_WITH_TTL(5, false, false, false, true),\n/**\n * The znode will not be automatically deleted upon client's disconnect,\n * and its name will be appended with a monotonically increasing number.\n * However if the znode has not been modified within the given TTL, it\n * will be deleted once it has no children.\n */\nPERSISTENT_SEQUENTIAL_WITH_TTL(6, false, true, false, true);\n```\n\n\n\n还是以创建节点为例，先看一下内存中怎么 插入节点的，内存的核心操作类是DataTree，看一下DataTree.createNode()\n\n```\n/**\n * Add a new node to the DataTree.\n * @param path\n *             Path for the new node.\n * @param data\n *            Data to store in the node.\n * @param acl\n *            Node acls\n * @param ephemeralOwner\n *            the session id that owns this node. -1 indicates this is not\n *            an ephemeral node.\n * @param zxid\n *            Transaction ID\n * @param time\n * @param outputStat\n *             A Stat object to store Stat output results into.\n * @throws NodeExistsException\n * @throws NoNodeException\n * @throws KeeperException\n */\npublic void createNode(final String path, byte data[], List<ACL> acl,\n        long ephemeralOwner, int parentCVersion, long zxid, long time, Stat outputStat)\n        throws KeeperException.NoNodeException,\n        KeeperException.NodeExistsException {\n    int lastSlash = path.lastIndexOf('/');\n    String parentName = path.substring(0, lastSlash);\n    String childName = path.substring(lastSlash + 1);\n    StatPersisted stat = new StatPersisted();\n    stat.setCtime(time);\n    stat.setMtime(time);\n    stat.setCzxid(zxid);\n    stat.setMzxid(zxid);\n    stat.setPzxid(zxid);\n    stat.setVersion(0);\n    stat.setAversion(0);\n    stat.setEphemeralOwner(ephemeralOwner);\n    DataNode parent = nodes.get(parentName);\n    if (parent == null) {\n        throw new KeeperException.NoNodeException();\n    }\n    synchronized (parent) {\n        Set<String> children = parent.getChildren();\n        if (children.contains(childName)) {\n            throw new KeeperException.NodeExistsException();\n        }\n\n        if (parentCVersion == -1) {\n            parentCVersion = parent.stat.getCversion();\n            parentCVersion++;\n        }\n        // 1. 修改父节点\n        parent.stat.setCversion(parentCVersion);\n        parent.stat.setPzxid(zxid);\n        // 根据acl 转换成引用数量值\n        // acl是节点的权限信息\n        Long longval = aclCache.convertAcls(acl);\n        DataNode child = new DataNode(data, longval, stat);\n        parent.addChild(childName);\n        // 2. 添加新增节点\n        nodes.put(path, child);\n        // 3. 将新增节点分类\n        EphemeralType ephemeralType = EphemeralType.get(ephemeralOwner);\n        if (ephemeralType == EphemeralType.CONTAINER) {\n            containers.add(path);\n        } else if (ephemeralType == EphemeralType.TTL) {\n            ttls.add(path);\n        } else if (ephemeralOwner != 0) {\n            HashSet<String> list = ephemerals.get(ephemeralOwner);\n            if (list == null) {\n                list = new HashSet<String>();\n                ephemerals.put(ephemeralOwner, list);\n            }\n            synchronized (list) {\n                list.add(path);\n            }\n        }\n        // 4. 复制出新增节点 状态信息 （用于返回）\n        if (outputStat != null) {\n           child.copyStat(outputStat);\n        }\n    }\n    // now check if its one of the zookeeper node child\n    // 5. 判断是否到系统节点下（比如手动添加引用信息）\n    if (parentName.startsWith(quotaZookeeper)) {\n        // now check if its the limit node\n        if (Quotas.limitNode.equals(childName)) {\n            // this is the limit node\n            // get the parent and add it to the trie\n            pTrie.addPath(parentName.substring(quotaZookeeper.length()));\n        }\n        if (Quotas.statNode.equals(childName)) {\n            updateQuotaForPath(parentName\n                    .substring(quotaZookeeper.length()));\n        }\n    }\n    // also check to update the quotas for this node\n    // 6. 修改节点的引用数\n    String lastPrefix = getMaxPrefixWithQuota(path);\n    if(lastPrefix != null) {\n        // ok we have some match and need to update\n        updateCount(lastPrefix, 1);\n        updateBytes(lastPrefix, data == null ? 0 : data.length);\n    }\n    // 触发节点 watch事件\n    dataWatches.triggerWatch(path, Event.EventType.NodeCreated);\n    childWatches.triggerWatch(parentName.equals(\"\") ? \"/\" : parentName,\n            Event.EventType.NodeChildrenChanged);\n}\n```\n\n\n\n看下第二种写入内存中的 log 格式，用于主从之间的数据同步\n\n```\n/**\n * maintains a list of last <i>committedLog</i>\n *  or so committed requests. This is used for\n * fast follower synchronization.\n * @param request committed request\n */\npublic void addCommittedProposal(Request request) {\n    // 读写锁\n    WriteLock wl = logLock.writeLock();\n    try {\n        wl.lock();\n        // 现在最大提交日志记录大小默认为500\n        if (committedLog.size() > commitLogCount) {\n            committedLog.removeFirst();\n            // 挤出一个后取最小的\n            minCommittedLog = committedLog.getFirst().packet.getZxid();\n        }\n        if (committedLog.isEmpty()) {\n            minCommittedLog = request.zxid;\n            maxCommittedLog = request.zxid;\n        }\n\n        byte[] data = SerializeUtils.serializeRequest(request);\n        // 定制日志包信息\n        QuorumPacket pp = new QuorumPacket(Leader.PROPOSAL, request.zxid, data, null);\n        Proposal p = new Proposal();\n        p.packet = pp;\n        p.request = request;\n        // 新增一条提议 = 定制日志包 + request信息\n        committedLog.add(p);\n        // 修改最大提交日志偏移量\n        maxCommittedLog = p.packet.getZxid();\n    } finally {\n        wl.unlock();\n    }\n}\n```\n\n\n\ncommittedLog 默认最多可以存储500条日志记录，超出时 则删除最老一条数据\n\n\n\n在看磁盘操作时，我们先回过头看一下 请求数据处理的第二条处理链 SyncRequestProcessor.processRequest()\n\n```\npublic void processRequest(Request request) {\n    queuedRequests.add(request);\n}\n```\n\n\n\n这里同样使用一条队列实现异步操作，实际执行代码在SyncRequestProcessor.run()中\n\n```\npublic void run() {\n    try {\n        // 生成快照数量\n        int logCount = 0;\n\n        // we do this in an attempt to ensure that not all of the servers\n        // in the ensemble take a snapshot at the same time\n        int randRoll = r.nextInt(snapCount/2);\n        while (true) {\n            Request si = null;\n            if (toFlush.isEmpty()) {\n                si = queuedRequests.take();\n            } else {\n                si = queuedRequests.poll();\n                if (si == null) {\n                    flush(toFlush);\n                    continue;\n                }\n            }\n            if (si == requestOfDeath) {\n                break;\n            }\n            if (si != null) {\n                // track the number of records written to the log\n                // 追加日志记录 .log.21212\n                if (zks.getZKDatabase().append(si)) {\n                    logCount++;\n                    // 生成快照数量过多过快时，进行rollback\n                    if (logCount > (snapCount / 2 + randRoll)) {\n                        randRoll = r.nextInt(snapCount/2);\n                        // roll the log\n                        zks.getZKDatabase().rollLog();\n                        // take a snapshot\n                        // 生成快照的快照线程\n                        if (snapInProcess != null && snapInProcess.isAlive()) {\n                            LOG.warn(\"Too busy to snap, skipping\");\n                        } else {\n                            snapInProcess = new ZooKeeperThread(\"Snapshot Thread\") {\n                                    public void run() {\n                                        try {\n                                            zks.takeSnapshot();\n                                        } catch(Exception e) {\n                                            LOG.warn(\"Unexpected exception\", e);\n                                        }\n                                    }\n                                };\n                            snapInProcess.start();\n                        }\n                        logCount = 0;\n                    }\n                } else if (toFlush.isEmpty()) {\n                    // optimization for read heavy workloads\n                    // iff this is a read, and there are no pending\n                    // flushes (writes), then just pass this to the next\n                    // processor\n                    if (nextProcessor != null) {\n                        nextProcessor.processRequest(si);\n                        if (nextProcessor instanceof Flushable) {\n                            ((Flushable)nextProcessor).flush();\n                        }\n                    }\n                    continue;\n                }\n                toFlush.add(si);\n                // 追加记录达到1000条进行落盘（刷入磁盘）\n                if (toFlush.size() > 1000) {\n                    // 落盘 即 \n                    flush(toFlush);\n                }\n            }\n        }\n    } catch (Throwable t) {\n        handleException(this.getName(), t);\n    } finally{\n        running = false;\n    }\n    LOG.info(\"SyncRequestProcessor exited!\");\n}\n```\n\n\n\n实际存储磁盘有两种形式，一种是追加日志记录 .log ；一种是以快照 snapshot 的方式 存储，相关操作在 FileTxnSnapLog 中\n\n\n\n追加日志记录 FileTxnSnapLog.append()\n\n```\npublic synchronized boolean append(TxnHeader hdr, Record txn)\n    throws IOException\n{\n    if (hdr == null) {\n        return false;\n    }\n    if (hdr.getZxid() <= lastZxidSeen) {\n        LOG.warn(\"Current zxid \" + hdr.getZxid()\n                + \" is <= \" + lastZxidSeen + \" for \"\n                + hdr.getType());\n    } else {\n        lastZxidSeen = hdr.getZxid();\n    }\n    if (logStream==null) {\n       if(LOG.isInfoEnabled()){\n            LOG.info(\"Creating new log file: \" + Util.makeLogName(hdr.getZxid()));\n       }\n\n       logFileWrite = new File(logDir, Util.makeLogName(hdr.getZxid()));\n       fos = new FileOutputStream(logFileWrite);\n       logStream=new BufferedOutputStream(fos);\n       oa = BinaryOutputArchive.getArchive(logStream);\n       FileHeader fhdr = new FileHeader(TXNLOG_MAGIC,VERSION, dbId);\n       fhdr.serialize(oa, \"fileheader\");\n       // Make sure that the magic number is written before padding.\n       logStream.flush();\n       filePadding.setCurrentSize(fos.getChannel().position());\n       streamsToFlush.add(fos);\n    }\n    filePadding.padFile(fos.getChannel());\n    byte[] buf = Util.marshallTxnEntry(hdr, txn);\n    if (buf == null || buf.length == 0) {\n        throw new IOException(\"Faulty serialization for header \" +\n                \"and txn\");\n    }\n    Checksum crc = makeChecksumAlgorithm();\n    crc.update(buf, 0, buf.length);\n    oa.writeLong(crc.getValue(), \"txnEntryCRC\");\n    Util.writeTxnBytes(oa, buf);\n\n    return true;\n}\n```\n\n\n\n追加记录的 输出流会预先保存在streamsToFlush中，等待toFlush的队列数量达到1000条即可刷入磁盘，即FileTxnSnapLog.commit()\n\n```\n/**\n * commit the logs. make sure that everything hits the\n * disk\n */\npublic synchronized void commit() throws IOException {\n    if (logStream != null) {\n        logStream.flush();\n    }\n    for (FileOutputStream log : streamsToFlush) {\n        log.flush();\n        if (forceSync) {\n            long startSyncNS = System.nanoTime();\n\n            FileChannel channel = log.getChannel();\n            channel.force(false);\n\n            syncElapsedMS = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startSyncNS);\n            if (syncElapsedMS > fsyncWarningThresholdMS) {\n                if(serverStats != null) {\n                    serverStats.incrementFsyncThresholdExceedCount();\n                }\n                LOG.warn(\"fsync-ing the write ahead log in \"\n                        + Thread.currentThread().getName()\n                        + \" took \" + syncElapsedMS\n                        + \"ms which will adversely effect operation latency. \"\n                        + \"File size is \" + channel.size() + \" bytes. \"\n                        + \"See the ZooKeeper troubleshooting guide\");\n            }\n        }\n    }\n    while (streamsToFlush.size() > 1) {\n        streamsToFlush.removeFirst().close();\n    }\n}\n```\n\n\n\n再看一下快照文件的生成方式，快照是由snapInProcess线程异步执行的，有新增追加记录的时候进行触发，生成快照的代码如下\n\n```\npublic void takeSnapshot(){\n    try {\n        txnLogFactory.save(zkDb.getDataTree(), zkDb.getSessionWithTimeOuts());\n    } catch (IOException e) {\n        LOG.error(\"Severe unrecoverable error, exiting\", e);\n        // This is a severe error that we cannot recover from,\n        // so we need to exit\n        System.exit(10);\n    }\n}\n\n/**\n * save the datatree and the sessions into a snapshot\n * @param dataTree the datatree to be serialized onto disk\n * @param sessionsWithTimeouts the session timeouts to be\n * serialized onto disk\n * @throws IOException\n */\npublic void save(DataTree dataTree,\n        ConcurrentHashMap<Long, Integer> sessionsWithTimeouts)\n    throws IOException {\n    long lastZxid = dataTree.lastProcessedZxid;\n    File snapshotFile = new File(snapDir, Util.makeSnapshotName(lastZxid));\n    LOG.info(\"Snapshotting: 0x{} to {}\", Long.toHexString(lastZxid),\n            snapshotFile);\n    snapLog.serialize(dataTree, sessionsWithTimeouts, snapshotFile);\n}\n```\n\n\n\n快照文件生成过快（不一定可以全部同步到子节点）时会触发一个rollback操作，也是调用FileTxnSnapLog.rollLog()\n\n```\n/**\n * rollover the current log file to a new one.\n * @throws IOException\n */\npublic synchronized void rollLog() throws IOException {\n    if (logStream != null) {\n        this.logStream.flush();\n        this.logStream = null;\n        oa = null;\n    }\n}\n```\n\n\n\n最后顺便看一下 磁盘里的log文件怎么恢复成 内存中的 DataTree结构，这里调用了FileTxnSnapLog.restore()方法\n\n```\n/**\n * this function restores the server\n * database after reading from the\n * snapshots and transaction logs\n * @param dt the datatree to be restored\n * @param sessions the sessions to be restored\n * @param listener the playback listener to run on the\n * database restoration\n * @return the highest zxid restored\n * @throws IOException\n */\npublic long restore(DataTree dt, Map<Long, Integer> sessions,\n                    PlayBackListener listener) throws IOException {\n    // 1. 选取100条快照文件，找出最有效最新的一条，将文件的后缀名（二进制）转十进制即最近的一次事务id\n    long deserializeResult = snapLog.deserialize(dt, sessions);\n    FileTxnLog txnLog = new FileTxnLog(dataDir);\n\n    // 快速的 根据日志记录 文件（列表） 获取\n    RestoreFinalizer finalizer = () -> {\n        long highestZxid = fastForwardFromEdits(dt, sessions, listener);\n        return highestZxid;\n    };\n    if (-1L == deserializeResult) {\n        /* this means that we couldn't find any snapshot, so we need to\n         * initialize an empty database (reported in ZOOKEEPER-2325) */\n        // 2. 从日志追加记录里面获取最近的一次事务id\n        if (txnLog.getLastLoggedZxid() != -1) {\n            // ZOOKEEPER-3056: provides an escape hatch for users upgrading\n            // from old versions of zookeeper (3.4.x, pre 3.5.3).\n            if (!trustEmptySnapshot) {\n                throw new IOException(EMPTY_SNAPSHOT_WARNING + \"Something is broken!\");\n            } else {\n                LOG.warn(\"{}This should only be allowed during upgrading.\", EMPTY_SNAPSHOT_WARNING);\n                return finalizer.run();\n            }\n        }\n        // 3. 对DataTree 进行一次快照\n        save(dt, (ConcurrentHashMap<Long, Integer>)sessions);\n        /* return a zxid of zero, since we the database is empty */\n        return 0;\n    }\n\n    return finalizer.run();\n}\n```\n\n\n\n\n\n#### **4、zk怎么保证线程安全 和 数据的一致性**\n\n\n\n##### 1）zxid 的原子性，每一个客户端请求会带上xid（事务id）已经服务端会生成全局zxid，执行请求的时候会校验zxid的时效性\n\n\n\n客户端发起请求时，Zookeeper服务端会自动生成唯一的递增的zxid 作为事务id，生成途径如下：\n\n```\nprotected void pRequest(Request request) throws RequestProcessorException \n    try {\n        switch (request.type) {\n            case OpCode.createContainer:\n            case OpCode.create:\n            case OpCode.create2:\n                CreateRequest create2Request = new CreateRequest();\n                pRequest2Txn(request.type, zks.getNextZxid(), request, create2Request, true);\n                //... 不重要省略了\n    }\n}\nprivate final AtomicLong hzxid = new AtomicLong(0);\n\nlong getNextZxid() {\n    return hzxid.incrementAndGet();\n}\n```\n\n\n\n这个zxid在很多场景都会用到，作为单次客户端发起事务的唯一标识，可作为日志追加记录的文件名（转二进制）；也可以作为zk执行时参考的依据，比如worker执行某个zxid的时候，从事件队列中弹出事件（ChangeRecord）时可以比较zxid的大小，如果小的话说明已经过时了，可以remove掉\n\n```\nwhile (!zks.outstandingChanges.isEmpty()\n       && zks.outstandingChanges.peek().zxid <= zxid) {\n    ChangeRecord cr = zks.outstandingChanges.remove();\n    if (cr.zxid < zxid) {\n        LOG.warn(\"Zxid outstanding \" + cr.zxid\n                 + \" is less than current \" + zxid);\n    }\n    if (zks.outstandingChangesForPath.get(cr.path) == cr) {\n        zks.outstandingChangesForPath.remove(cr.path);\n    }\n}\n```\n\n\n\n另外存放 节点修改事件的 数据结构是 HashMap，可以保证针对某一个path 的修改操作只会存在最新的一条\n\n```\n// this data structure must be accessed under the outstandingChanges lock\nfinal HashMap<String, ChangeRecord> outstandingChangesForPath =\n    new HashMap<String, ChangeRecord>();\n```\n\n\n\n##### 2）修改 DataNode 的操作，写时复制\n\n\n\n有修改事件需要修改父节点时 会 duplicate 一下父节点的最新操作（如果没有则从DataTree中新建一个），写时复制，避免直接修改原事件信息\n\n```\n// 获取最近一次针对父节点的操作 如果没有 则新建一个\nChangeRecord parentRecord = getRecordForPath(parentPath);\nChangeRecord nodeRecord = getRecordForPath(path);\n// ... 不重要省略了\nparentRecord = parentRecord.duplicate(request.getHdr().getZxid());\nparentRecord.childCount--;\naddChangeRecord(parentRecord);\naddChangeRecord(new ChangeRecord(request.getHdr().getZxid(), path, null, -1, null));\n```\n\n\n\n##### 3）加锁\n\n\n\n典型的例子是需要修改 outstandingChangesForPath 的数据时，都需要进行加锁\n\n```\nprivate ChangeRecord getRecordForPath(String path) throws KeeperException.NoNodeException {\n    ChangeRecord lastChange = null;\n    synchronized (zks.outstandingChanges) {\n        lastChange = zks.outstandingChangesForPath.get(path);\n        //...\n}\n\npublic void processRequest(Request request) {\n    synchronized (zks.outstandingChanges) {\n        // Need to process local session requests\n        // 修改本地内存（DataTree）中的节点信息\n        rc = zks.processTxn(request);\n        //...\n}\n```\n\n\n\n##### 4）数据 有快照 + 日志文件保证数据安全\n\n\n\n数据可以从日志追加记录中 或者 快照文件 进行恢复，见FileTxnSnapLog.restore() 中的 fastForwardFromEdits方法\n\n```\n/**\n * This function will fast forward the server database to have the latest\n * transactions in it.  This is the same as restore, but only reads from\n * the transaction logs and not restores from a snapshot.\n * @param dt the datatree to write transactions to.\n * @param sessions the sessions to be restored.\n * @param listener the playback listener to run on the\n * database transactions.\n * @return the highest zxid restored.\n * @throws IOException\n */\npublic long fastForwardFromEdits(DataTree dt, Map<Long, Integer> sessions,\n                                 PlayBackListener listener) throws IOException {\n    TxnIterator itr = txnLog.read(dt.lastProcessedZxid+1);\n    long highestZxid = dt.lastProcessedZxid;\n    TxnHeader hdr;\n    try {\n        // 按事务日志的zxid顺序解析所有文件\n        while (true) {\n            // iterator points to\n            // the first valid txn when initialized\n            hdr = itr.getHeader();\n            if (hdr == null) {\n                //empty logs\n                return dt.lastProcessedZxid;\n            }\n            // 更新zxid并处理事务\n            if (hdr.getZxid() < highestZxid && highestZxid != 0) {\n                LOG.error(\"{}(highestZxid) > {}(next log) for type {}\",\n                        highestZxid, hdr.getZxid(), hdr.getType());\n            } else {\n                highestZxid = hdr.getZxid();\n            }\n            try {\n                processTransaction(hdr,dt,sessions, itr.getTxn());\n            } catch(KeeperException.NoNodeException e) {\n               throw new IOException(\"Failed to process transaction type: \" +\n                     hdr.getType() + \" error: \" + e.getMessage(), e);\n            }\n            // 监听器监听事务日志恢复信息\n            listener.onTxnLoaded(hdr, itr.getTxn());\n            if (!itr.next())\n                break;\n        }\n    } finally {\n        if (itr != null) {\n            itr.close();\n        }\n    }\n    return highestZxid;\n}\n```\n\n\n\n##### 5）acl 权限安全\n\n\n\n每个节点都会有对应的权限，新节点是ALL权限\n\n```\npublic interface Perms {\n    int READ = 1 << 0;\n\n    int WRITE = 1 << 1;\n\n    int CREATE = 1 << 2;\n\n    int DELETE = 1 << 3;\n\n    int ADMIN = 1 << 4;\n\n    int ALL = READ | WRITE | CREATE | DELETE | ADMIN;\n}\n```\n\n\n\n执行相应的事件操作时会检查节点权限\n\n```\n// 校验父节点是否有创建节点的权限\ncheckACL(zks, parentRecord.acl, ZooDefs.Perms.CREATE, request.authInfo);\n\n/**\n * Grant or deny authorization to an operation on a node as a function of:\n *\n * @param zks: not used.\n * @param acl:  set of ACLs for the node\n * @param perm: the permission that the client is requesting\n * @param ids:  the credentials supplied by the client\n */\nstatic void checkACL(ZooKeeperServer zks, List<ACL> acl, int perm,\n                     List<Id> ids) throws KeeperException.NoAuthException {\n    if (skipACL) {\n        return;\n    }\n    if (acl == null || acl.size() == 0) {\n        return;\n    }\n    for (Id authId : ids) {\n        if (authId.getScheme().equals(\"super\")) {\n            return;\n        }\n    }\n    for (ACL a : acl) {\n        Id id = a.getId();\n        if ((a.getPerms() & perm) != 0) {\n            if (id.getScheme().equals(\"world\")\n                    && id.getId().equals(\"anyone\")) {\n                return;\n            }\n            AuthenticationProvider ap = ProviderRegistry.getProvider(id\n                    .getScheme());\n            if (ap != null) {\n                for (Id authId : ids) {\n                    if (authId.getScheme().equals(id.getScheme())\n                            && ap.matches(authId.getId(), id.getId())) {\n                        return;\n                    }\n                }\n            }\n        }\n    }\n    throw new KeeperException.NoAuthException();\n}\n```\n\n\n\n\n\n#### **5、zk的Watch机制？**\n\n\n\n##### 1）watch的数据存储\n\n\n\nwatcher的关联path存储在WatchManager中的两个HashMap中，watchTable 是 path 和 watcher的一对多关系，watch2Paths 是 watcher和path的一对多关系，两者在不同的场景下搭配使用\n\n```\nprivate final HashMap<String, HashSet<Watcher>> watchTable =\n    new HashMap<String, HashSet<Watcher>>();\n\nprivate final HashMap<Watcher, HashSet<String>> watch2Paths =\n    new HashMap<Watcher, HashSet<String>>();\n```\n\n\n\n添加Watcher的核心方法见WatcherManager.addWatch方法，核心也就分别向watchTable 和 watch2Paths中填充内容\n\n```\nsynchronized void addWatch(String path, Watcher watcher) {\n    HashSet<Watcher> list = watchTable.get(path);\n    if (list == null) {\n        // don't waste memory if there are few watches on a node\n        // rehash when the 4th entry is added, doubling size thereafter\n        // seems like a good compromise\n        list = new HashSet<Watcher>(4);\n        watchTable.put(path, list);\n    }\n    list.add(watcher);\n\n    HashSet<String> paths = watch2Paths.get(watcher);\n    if (paths == null) {\n        // cnxns typically have many watches, so use default cap here\n        paths = new HashSet<String>();\n        watch2Paths.put(watcher, paths);\n    }\n    paths.add(path);\n}\n```\n\n\n\n添加Watcher的场景有很多种，常见的比如 获取节点数据（getData）、获取节点状态（statNode）、获取子节点（getChildern） 和 直接对节点添加Watch，除直接对节点添加Watch行为外，其他操作均有客户端有选择性的发起，比如我希望实时获取节点数据，即节点数据能在修改的时候通知到我，这一点可以用作 全局配置项 或者 服务发现 的场景中；\n\n直接添加Watch的行为 我们常见于分布式锁，分布式锁会在zk上创建临时有序节点（EPHEMERAL_SEQUENTIAL），当客户端断开连接时节点会自动删除（放弃锁），较大的临时节点存在时（锁占有）可以对该节点进行Watch，该临时节点主动或被动删除后会通知到我（获取锁），这个可以实现公平锁；非公平锁 即直接对父节点进行 Watch，当子节点发生Delete操作时获取到通知 进行抢占锁；当然在并发的情况下由zk保证并发操作的有序性 和 线程安全；\n\n\n\n看下的相关代码，以获取节点数据为例\n\n```\ncase OpCode.getData: {\n    lastOp = \"GETD\";\n    GetDataRequest getDataRequest = new GetDataRequest();\n    // 将客户端request里的请求 内容 赋给 GetDataRequest\n    ByteBufferInputStream.byteBuffer2Record(request.request,\n            getDataRequest);\n    DataNode n = zks.getZKDatabase().getNode(getDataRequest.getPath());\n    if (n == null) {\n        throw new KeeperException.NoNodeException();\n    }\n    PrepRequestProcessor.checkACL(zks, zks.getZKDatabase().aclForNode(n),\n            ZooDefs.Perms.READ,\n            request.authInfo);\n    Stat stat = new Stat();\n    // 加入 客户端请求中带有watch参数，则将当前的serer连接视为watcher进行注册\n    byte b[] = zks.getZKDatabase().getData(getDataRequest.getPath(), stat,\n            getDataRequest.getWatch() ? cnxn : null);\n    rsp = new GetDataResponse(b, stat);\n    break;\n```\n\n\n\n这里的cnxn代表当前连接zkServer的连接信息，如果是NIO模式下就是一条Select socket连接\n\n```\nprivate void readRequest() throws IOException {\n    // NIO模式下 this代指NIOServerCnxn\n    zkServer.processPacket(this, incomingBuffer);\n}\n```\n\n\n\n##### 2）哪些情况下会触发watch？\n\n\n\n触发watch的场景大致分成两种，节点自身变化 和 节点数据变化，分别对应DataTree中的childWatches 和 dataWatches\n\n```\n// 关心节点数据变化\nprivate final WatchManager dataWatches = new WatchManager();\n\n// 关心节点自身变化\nprivate final WatchManager childWatches = new WatchManager();\n```\n\n\n\n正常watch事件触发是在内存中的DataTree修改完成后发生。以删除节点为例，见DataTree.deleteNode()\n\n```\npublic void deleteNode(String path, long zxid)\n        throws KeeperException.NoNodeException {\n    //...不重要\n    // 数据变化 触发DataWatch的process方法\n    Set<Watcher> processed = dataWatches.triggerWatch(path,EventType.NodeDeleted);\n    // 节点变化 触发ChildWatch的process方法，这里剔除了数据变化触发的Watcher\n    childWatches.triggerWatch(path, EventType.NodeDeleted, processed);\n    childWatches.triggerWatch(\"\".equals(parentName) ? \"/\" : parentName,EventType.NodeChildrenChanged);\n}\n```\n\n\n\ntriggerWatch即查询 对节点感兴趣的Watchers，发一条短信（WatchedEvent）通知他们，通知的内容仅包括 通知状态、事件类型 和 节点path\n\n```\npublic class WatchedEvent {\n    // 通知状态\n    final private KeeperState keeperState;\n    // 事件类型\n    final private EventType eventType;\n    // 节点path\n    private String path;\n}\n\nSet<Watcher> triggerWatch(String path, EventType type, Set<Watcher> supress) {\n    WatchedEvent e = new WatchedEvent(type,\n            KeeperState.SyncConnected, path);\n    HashSet<Watcher> watchers;\n    synchronized (this) {\n        watchers = watchTable.remove(path);\n        if (watchers == null || watchers.isEmpty()) {\n            if (LOG.isTraceEnabled()) {\n                ZooTrace.logTraceMessage(LOG,\n                        ZooTrace.EVENT_DELIVERY_TRACE_MASK,\n                        \"No watchers for \" + path);\n            }\n            return null;\n        }\n        for (Watcher w : watchers) {\n            HashSet<String> paths = watch2Paths.get(w);\n            if (paths != null) {\n                paths.remove(path);\n            }\n        }\n    }\n    for (Watcher w : watchers) {\n        if (supress != null && supress.contains(w)) {\n            continue;\n        }\n        w.process(e);\n    }\n    return watchers;\n}\n```\n\n\n\n##### 3）触发watch后怎么反馈到监听的客户端？\n\n\n\n这里以NIO模式下的服务端为例，对应Watcher（NIOServerCnxn）的WatchEvent通知行为\n\n```\npublic void process(WatchedEvent event) {\n    ReplyHeader h = new ReplyHeader(-1, -1L, 0);\n    if (LOG.isTraceEnabled()) {\n        ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK,\n                                 \"Deliver event \" + event + \" to 0x\"\n                                 + Long.toHexString(this.sessionId)\n                                 + \" through \" + this);\n    }\n\n    // Convert WatchedEvent to a type that can be sent over the wire\n    WatcherEvent e = event.getWrapper();\n\n    sendResponse(h, e, \"notification\");\n}\n\nsendResponse会将响应信息放到outgoingBuffer缓冲队列中\nprivate final Queue<ByteBuffer> outgoingBuffers =\n    new LinkedBlockingQueue<ByteBuffer>();\n\n/**\n * sendBuffer pushes a byte buffer onto the outgoing buffer queue for\n * asynchronous writes.\n */\npublic void sendBuffer(ByteBuffer bb) {\n    if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Add a buffer to outgoingBuffers, sk \" + sk\n                  + \" is valid: \" + sk.isValid());\n    }\n    outgoingBuffers.add(bb);\n    // 有响应信息了，唤醒selector线程，让它工作（假如不在工作）\n    requestInterestOpsUpdate();\n}\n```\n\n\n\n接下的事情就交给Selector线程 和 Worker线程了，Selector线程select出内容后 交给Worker线程处理，Worker 会将outgoingBuffer的内容进行输出\n\n\n\n\n\n#### **6、zk的会话机制？**\n\n\n\n##### 1）客户端连接数限制\n\n\n\n先简单总结 最大客户端连接数为60，超过60则拒绝连接；对存在的客户端连接有会话时间限制（默认10s），10s内无任何消息处理（select）则被ExpireThread清理掉；当客户端有消息处理（select）时则给它续命（默认10s）\n\n```\nprotected int maxClientCnxns = 60;\n```\n\n\n\n客户端连接数过大时则拒绝连接，被AcceptThread拒绝\n\n```\nprivate boolean doAccept() {\n    boolean accepted = false;\n    SocketChannel sc = null;\n    try {\n        sc = acceptSocket.accept();\n        accepted = true;\n        InetAddress ia = sc.socket().getInetAddress();\n        int cnxncount = getClientCnxnCount(ia);\n        // 默认为60\n        if (maxClientCnxns > 0 && cnxncount >= maxClientCnxns) {\n            throw new IOException(\"Too many connections from \" + ia\n                    + \" - max is \" + maxClientCnxns);\n        }\n//...\n}\n```\n\n\n\nSelectorThread有新客户端连接请求时封装成NIOServerCnxn 进行管理，并关联（attach）到SelectKey上\n\n```\n/**\n * Iterate over the queue of accepted connections that have been\n * assigned to this thread but not yet placed on the selector.\n */\nprivate void processAcceptedConnections() {\n    SocketChannel accepted;\n    while (!stopped && (accepted = acceptedQueue.poll()) != null) {\n        // 选择键维护了通道和选择器之间的关联，可以通过选择键获取Channel或Selector，键对象表示一种特殊的关联关系\n        SelectionKey key = null;\n        try {\n            key = accepted.register(selector, SelectionKey.OP_READ);\n            NIOServerCnxn cnxn = createConnection(accepted, key, this);\n            key.attach(cnxn);\n            // 添加进 cnxns中\n            addCnxn(cnxn);\n        } catch (IOException e) {\n            // register, createConnection\n            cleanupSelectionKey(key);\n            fastCloseSock(accepted);\n        }\n    }\n}\n```\n\n\n\nExpireThread清理掉过期会话，关闭客户端连接\n\n```\nprivate class ConnectionExpirerThread extends ZooKeeperThread {\n\n    public void run() {\n        try {\n            while (!stopped) {\n                long waitTime = cnxnExpiryQueue.getWaitTime();\n                if (waitTime > 0) {\n                    Thread.sleep(waitTime);\n                    continue;\n                }\n                for (NIOServerCnxn conn : cnxnExpiryQueue.poll()) {\n                    conn.close();\n                }\n            }\n\n        } catch (InterruptedException e) {\n            LOG.info(\"ConnnectionExpirerThread interrupted\");\n        }\n    }\n}\n```\n\n\n\nSelectorTrhead有客户端请求时修改客户端的会话时间（状态）\n\n```\n/**\n * Schedule I/O for processing on the connection associated with\n * the given SelectionKey. If a worker thread pool is not being used,\n * I/O is run directly by this thread.\n */\nprivate void handleIO(SelectionKey key) {\n    IOWorkRequest workRequest = new IOWorkRequest(this, key);\n    NIOServerCnxn cnxn = (NIOServerCnxn) key.attachment();\n\n    // Stop selecting this key while processing on its\n    // connection\n    cnxn.disableSelectable();\n    key.interestOps(0);\n    //更新客户端的连接状态\n    touchCnxn(cnxn);\n    workerPool.schedule(workRequest);\n}\n\n/**\n * Add or update cnxn in our cnxnExpiryQueue\n * @param cnxn\n */\npublic void touchCnxn(NIOServerCnxn cnxn) {\n    //默认session有效时长为10s\n    cnxnExpiryQueue.update(cnxn, cnxn.getSessionTimeout());\n}\n```\n\n\n\n##### 2）客户端会话跟踪\n\n\n\n会话管理 和 上面客户端连接管理的区别在于 出发点不一样，客户端连接管理 是出于服务端性能考虑，关闭不必要 或 空闲的客户端连接，直接从socket层面给它close掉；会话管理是 出于业务安全考虑，更多的偏向于一种权限管理，比如验证会话的有效性，会话是否超时等；两者的共同之处在于都借助于使用ExpiryQueue来清理失效连接，当连接有活跃请求时又会touch连接（续费）。\n\n\n\nSession是 ZooKeeper中的会话实体,代表了一个客户端会话。其包含以下4个基本属性。\n\nsessionID:会话ID,用来唯一标识一个会话,每次客户端创建新会话的时候,ZooKeeper都会为其分配一个全局唯一的 sessionID。\n\nTimeOut:会话超时时间。客户端在构造 ZooKeeper实例的时候,会配置一个sessiontimeout参数用于指定会话的超时时间。ZooKeeper客户端向服务器发送这个超时时间后,服务器会根据自己的超时时间限制最终确定会话的超时时间。\n\nTickTime:下次会话超时时间点。为了便于 ZooKeeper对会话实行“分桶策略”管理,同时也是为了高效低耗地实现会话的超时检查与清理, ZooKeeper会为每个会话标记一个下次会话超时时间点。 TickTime是一个13位的long型数据,其值接近于当前时间加上 Time Out,但不完全相等。关于 TickTime的计算方式,将在“分桶策略”部分做详细讲解。\n\nisClosing:该属性用于标记一个会话是否已经被关闭。通常当服务端检测到一个会话已经超时失效的时候,会将该会话的 isClosing属性标记为“已关闭”,这样就能确保不再处理来自该会话的新请求了。\n\n\n\n这里分桶策略就是将 会话 根据 expireTime进行分桶管理，然后Leader服务器在运行期间会定时地对不同的分桶进行会话超时检査。\n\n\n\n![img](http://pcc.huitogo.club/7aae462cff2f5041d2bf75e628e6d134)\n\n\n\n**session的创建**\n\n服务端对于客户端的“会话创建”请求的处理,大体可以分为四大步骤,分别是处理ConnectRequest请求、会话创建、处理器链路处理和会话响应。在 ZooKeeper服务端,首先将会由NI0 Servercnxn来负责接收来自客户端的“会话创建”请求,并反序列化出ConnectRequest请求,然后根据 ZooKeeper服务端的配置完成会话超时时间的协商。随后, Session tracker将会为该会话分配一个 sessionID,并将其注册到sessionsById和 sessionsWithTimeout中去,同时进行会话的激活。之后,该“会话请求”还会在 ZooKeeper服务端的各个请求处理器之间进行顺序流转,最终完成会话的创建。\n\n```\npublic void processConnectRequest(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException {\n    BinaryInputArchive bia = BinaryInputArchive.getArchive(new ByteBufferInputStream(incomingBuffer));\n    ConnectRequest connReq = new ConnectRequest();\n    connReq.deserialize(bia, \"connect\");\n    //...\n    int sessionTimeout = connReq.getTimeOut();\n    byte passwd[] = connReq.getPasswd();\n    int minSessionTimeout = getMinSessionTimeout();\n    if (sessionTimeout < minSessionTimeout) {\n        sessionTimeout = minSessionTimeout;\n    }\n    int maxSessionTimeout = getMaxSessionTimeout();\n    if (sessionTimeout > maxSessionTimeout) {\n        sessionTimeout = maxSessionTimeout;\n    }\n    cnxn.setSessionTimeout(sessionTimeout);\n    // We don't want to receive any packets until we are sure that the\n    // session is setup\n    cnxn.disableRecv();\n    long sessionId = connReq.getSessionId();\n    if (sessionId == 0) {\n        long id = createSession(cnxn, passwd, sessionTimeout);\n    } else {\n        long clientSessionId = connReq.getSessionId();\n        if (serverCnxnFactory != null) {\n            serverCnxnFactory.closeSession(sessionId);\n        }\n        if (secureServerCnxnFactory != null) {\n            secureServerCnxnFactory.closeSession(sessionId);\n        }\n        cnxn.setSessionId(sessionId);\n        reopenSession(cnxn, sessionId, passwd, sessionTimeout);\n    }\n}\n```\n\n\n\n主要关注sessionId的生成，在客户端没有提供的情况下 且是初始化连接则需要zk服务端自行创建唯一会话id，默认采用的是自增的方式，但自增的初始值是 serverId + 时间戳的组合方式\n\n```\nprivate final AtomicLong nextSessionId = new AtomicLong();\n\n/**\n * Generates an initial sessionId. High order byte is serverId, next 5\n * 5 bytes are from timestamp, and low order 2 bytes are 0s.\n */\npublic static long initializeNextSession(long id) {\n    long nextSid;\n    nextSid = (Time.currentElapsedTime() << 24) >>> 8;\n    nextSid =  nextSid | (id <<56);\n    if (nextSid == EphemeralType.CONTAINER_EPHEMERAL_OWNER) {\n        ++nextSid;  // this is an unlikely edge case, but check it just in case\n    }\n    return nextSid;\n}\n\npublic long createSession(int sessionTimeout) {\n    // 自增\n    long sessionId = nextSessionId.getAndIncrement();\n    addSession(sessionId, sessionTimeout);\n    return sessionId;\n}\n```\n\n\n\n存储session的是两个数据结构，sessionsWithTimeout 和 sessionsById，前者记录session的超时时间，后者记录session的详细信息，添加session如下：\n\n```\npublic synchronized boolean addSession(long id, int sessionTimeout) {\n    sessionsWithTimeout.put(id, sessionTimeout);\n\n    boolean added = false;\n\n    SessionImpl session = sessionsById.get(id);\n    if (session == null){\n        session = new SessionImpl(id, sessionTimeout);\n    }\n\n    // findbugs2.0.3 complains about get after put.\n    // long term strategy would be use computeIfAbsent after JDK 1.8\n    SessionImpl existedSession = sessionsById.putIfAbsent(id, session);\n\n    if (existedSession != null) {\n        session = existedSession;\n    } else {\n        added = true;\n        LOG.debug(\"Adding session 0x\" + Long.toHexString(id));\n    }\n\n    if (LOG.isTraceEnabled()) {\n        String actionStr = added ? \"Adding\" : \"Existing\";\n        ZooTrace.logTraceMessage(LOG, ZooTrace.SESSION_TRACE_MASK,\n                \"SessionTrackerImpl --- \" + actionStr + \" session 0x\"\n                + Long.toHexString(id) + \" \" + sessionTimeout);\n    }\n    // 激活session（充值）\n    updateSessionExpiry(session, sessionTimeout);\n    return added;\n}\n```\n\n\n\n这里session激活也是利用ExpiryQueue，同样session失效会话的清理也是类似借助线程完成\n\n```\n@Override\npublic void run() {\n    try {\n        while (running) {\n            long waitTime = sessionExpiryQueue.getWaitTime();\n            if (waitTime > 0) {\n                Thread.sleep(waitTime);\n                continue;\n            }\n\n            for (SessionImpl s : sessionExpiryQueue.poll()) {\n                setSessionClosing(s.sessionId);\n                expirer.expire(s);\n            }\n        }\n    } catch (InterruptedException e) {\n        handleException(this.getName(), e);\n    }\n    LOG.info(\"SessionTrackerImpl exited loop!\");\n}\n```\n\n\n\nsession创建完之后会发起一条CreateSession的请求交给处理器链处理\n\n```\nlong createSession(ServerCnxn cnxn, byte passwd[], int timeout) {\n    if (passwd == null) {\n        // Possible since it's just deserialized from a packet on the wire.\n        passwd = new byte[0];\n    }\n    // 自增的sessionId\n    long sessionId = sessionTracker.createSession(timeout);\n    Random r = new Random(sessionId ^ superSecret);\n    // 加密密码\n    r.nextBytes(passwd);\n    ByteBuffer to = ByteBuffer.allocate(4);\n    to.putInt(timeout);\n    cnxn.setSessionId(sessionId);\n    Request si = new Request(cnxn, sessionId, 0, OpCode.createSession, to, null);\n    setLocalSessionFlag(si);\n    submitRequest(si);\n    return sessionId;\n}\n```\n\n\n\n其中预处理器 和 最终处理器均执行的addSession()方法\n\n```\ncase OpCode.createSession:\n    request.request.rewind();\n    int to = request.request.getInt();\n    request.setTxn(new CreateSessionTxn(to));\n    request.request.rewind();\n    if (request.isLocalSession()) {\n        // This will add to local session tracker if it is enabled\n        zks.sessionTracker.addSession(request.sessionId, to);\n    } else {\n        // Explicitly add to global session if the flag is not set\n        zks.sessionTracker.addGlobalSession(request.sessionId, to);\n    }\n    zks.setOwner(request.sessionId, request.getOwner());\n    break;\n```\n\n\n\n这里我的理解是 为了让session保持最佳有效时长，避免因为连接请求处理时间过长导致会话失效，毕竟客户端发起ping请求也得是 连接建立完之后\n\n\n\nrequest的owner 指的是发起请求来源，这里来源是 客户端请求即ServerCnxn.me，还可能是follwer发起的请求\n\n```\n// setowner as the leader itself, unless updated\n// via the follower handlers\nsetOwner(sessionId, ServerCnxn.me);\n```\n\n\n\n当客户端有发起请求的时候会对重新激活会话\n\n```\npublic void submitRequest(Request si) {\n    //...\n    // 客户端有请求来了，激活会话\n    touch(si.cnxn);\n    //...\n}\n\nvoid touch(ServerCnxn cnxn) throws MissingSessionException {\n    if (cnxn == null) {\n        return;\n    }\n    long id = cnxn.getSessionId();\n    int to = cnxn.getSessionTimeout();\n    if (!sessionTracker.touchSession(id, to)) {\n        throw new MissingSessionException(\n                \"No session with sessionid 0x\" + Long.toHexString(id)\n                + \" exists, probably expired and removed\");\n    }\n}\n```\n\n\n\n重新激活会话 更新expiryQueue 中会话的下次失效时间，默认3s\n\n```\nsynchronized public boolean touchSession(long sessionId, int timeout) {\n    SessionImpl s = sessionsById.get(sessionId);\n\n    if (s == null) {\n        logTraceTouchInvalidSession(sessionId, timeout);\n        return false;\n    }\n\n    if (s.isClosing()) {\n        logTraceTouchClosingSession(sessionId, timeout);\n        return false;\n    }\n\n    updateSessionExpiry(s, timeout);\n    return true;\n}\n```\n\n\n\n会话一个重要的使用场景就是对客户端发起的请求进行校验，比如在预处理器中处理Delete操作之前\n\n```\ncase OpCode.delete:\n    zks.sessionTracker.checkSession(request.sessionId, request.getOwner());\n```\n\n\n\n校验会话一方面判断sessionId是否存在（存活），另一方面判断请求来源是否正确\n\n```\npublic synchronized void checkSession(long sessionId, Object owner)\n        throws KeeperException.SessionExpiredException,\n        KeeperException.SessionMovedException,\n        KeeperException.UnknownSessionException {\n    LOG.debug(\"Checking session 0x\" + Long.toHexString(sessionId));\n    SessionImpl session = sessionsById.get(sessionId);\n\n    if (session == null) {\n        throw new KeeperException.UnknownSessionException();\n    }\n\n    if (session.isClosing()) {\n        throw new KeeperException.SessionExpiredException();\n    }\n\n    if (session.owner == null) {\n        session.owner = owner;\n    } else if (session.owner != owner) {\n        throw new KeeperException.SessionMovedException();\n    }\n}\n```", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "e4e000d0fba20eddfb2933fa8c05a89d": {"id": "e4e000d0fba20eddfb2933fa8c05a89d", "item": "源码解读", "title": "Mybatis源码分析", "date": "2024-08-22", "summary": "MyBatis 是一种优秀的 Java 持久化框架。它通过 XML 或注解将 SQL 语句与 Java 对象映射起来。易于理解和使用，让开发者能灵活控制 SQL，提高数据库操作效率。支持多种数据库，在 Java 开发中广泛应用于数据持久化层的实现。", "body": "\n#### 1. 怎么解析的？\n\n查找mybatis-config.xml文件，解析 标签中的子节点 到Configuration中\n\n```\n// 配置常量\npropertiesElement(root.evalNode(\"properties\")); \n// 配置别名\ntypeAliasesElement(root.evalNode(\"typeAliases\"));\n// 配置插件（拦截器）\npluginElement(root.evalNode(\"plugins\"));\n// 配置查询结果 转成对象的生成工厂（通过MetaObject）\nobjectFactoryElement(root.evalNode(\"objectFactory\"));\nobjectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n// 常规配置（如配置列表 通过驼峰+下划线转换到 字段名）\nsettingsElement(root.evalNode(\"settings\"));\n// 环境变量\nenvironmentsElement(root.evalNode(\"environments\"));\ndatabaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n// 出入参数类型转换\ntypeHandlerElement(root.evalNode(\"typeHandlers\"));\n// 核心 解析 *Mapper.xml 到MapperStatement\nmapperElement(root.evalNode(\"mappers\"));\n```\n\n\n\nConfiguration中对应的属性\n\n```\nprotected Environment environment;\nprotected Properties variables = new Properties();\nprotected ObjectFactory objectFactory = new DefaultObjectFactory();\nprotected ObjectWrapperFactory objectWrapperFactory = new DefaultObjectWrapperFactory();\nprotected MapperRegistry mapperRegistry = new MapperRegistry(this);\nprotected final InterceptorChain interceptorChain = new InterceptorChain();\nprotected final TypeHandlerRegistry typeHandlerRegistry = new TypeHandlerRegistry();\nprotected final TypeAliasRegistry typeAliasRegistry = new TypeAliasRegistry();\nprotected final LanguageDriverRegistry languageRegistry = new LanguageDriverRegistry();\nprotected final Map<String, MappedStatement> mappedStatements = new StrictMap<MappedStatement>(\"Mapped Statements collection\");\nprotected final Map<String, Cache> caches = new StrictMap<Cache>(\"Caches collection\");\nprotected final Map<String, ResultMap> resultMaps = new StrictMap<ResultMap>(\"Result Maps collection\");\nprotected final Map<String, ParameterMap> parameterMaps = new StrictMap<ParameterMap>(\"Parameter Maps collection\");\nprotected final Map<String, KeyGenerator> keyGenerators = new StrictMap<KeyGenerator>(\"Key Generators collection\");\n```\n\n\n\n重点看一下怎么将*Mapper.xml 解析到 MapperStatements\n\n```\nString namespace = context.getStringAttribute(\"namespace\");\nif (namespace.equals(\"\")) {\n throw new BuilderException(\"Mapper's namespace cannot be empty\");\n}\nbuilderAssistant.setCurrentNamespace(namespace);\n// MapperStatement缓存\ncacheRefElement(context.evalNode(\"cache-ref\"));\ncacheElement(context.evalNode(\"cache\"));\n// 入参映射\nparameterMapElement(context.evalNodes(\"/mapper/parameterMap\"));\n// 出参映射\nresultMapElements(context.evalNodes(\"/mapper/resultMap\"));\n// sql 节点\nsqlElement(context.evalNodes(\"/mapper/sql\"));\n// 封装MapperStatement\nbuildStatementFromContext(context.evalNodes(\"select|insert|update|delete\"));\n```\n\n    \n- <parameterMap>标签会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。\n\n- <resultMap>标签会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。\n- <insert>、<select>、<update>、<delete>标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。\n\n\n\n在buildStatementFromContext过程中，也就是组装成下面的MapperStatement对象\n\n```\n// 原始 *Mapper.xml资源\nprivate String resource;\nprivate Configuration configuration;\nprivate String id;\n// fetchsize决定了每批次可以传输的记录条数，但同时，也决定了内存的大小\nprivate Integer fetchSize;\nprivate Integer timeout;\n// 语句执行类型\nprivate StatementType statementType;\n// 返回结果集类型\nprivate ResultSetType resultSetType;\n// 待执行数据\nprivate SqlSource sqlSource;\n// 语句缓存\nprivate Cache cache;\nprivate ParameterMap parameterMap;\nprivate List<ResultMap> resultMaps;\nprivate boolean flushCacheRequired;\nprivate boolean useCache;\nprivate boolean resultOrdered;\nprivate SqlCommandType sqlCommandType;\nprivate KeyGenerator keyGenerator;\nprivate String[] keyProperties;\nprivate String[] keyColumns;\nprivate boolean hasNestedResultMaps;\nprivate String databaseId;\nprivate Log statementLog;\nprivate LanguageDriver lang;\nprivate String[] resultSets;\n```\n\n\n\n在生成MapperStatement中，有几个重要点\n\nmybatis 最终执行的sql字符串就是由SqlSource提供的，而mybatis是支持动态标签的，比如<where><foreach><trim>等，这部分标签会被解析成SqlNode\n\n![img](http://pcc.huitogo.club/f0a2fe8d140bf15cb8ff99c39f4e8ac5)\n\n\n\n这里LangugeDriver就是基于 静态sql 或者 动态 生成 SqlSource，目前支持XmlLanguageDriver 和 RawLanguageDriver\n\n- XMLLanguageDriver:用于创建动态、静态SqlSource。\n\n- RawLanguageDriver：在确保只有静态sql时，可以使用，不得含有任何动态sql的内容，否则，请使用XMLLanguageDriver。它其实是对XMLLanguageDriver创建的结果进行唯静态sql检查而已，发现有动态sql的内容，就抛异常。\n\n\n\n\n解析的底层是使用Dom4j 把XML解析成一个个子节点，在通过 XMLScriptBuilder 遍历这些子节点最后生成对应的SqlSource。\n\n![img](http://pcc.huitogo.club/1f787e20a09ae5e54c620d50931fbf32)\n\n\n\n#### 2. 怎么执行的？\n\n这里先说一点 ，mybatis 不具备执行sql 语句的能力，它只是对接 Jbdc规范（Connection、Statement、Transaction、ResultSet），然后 由各数据库产商去实现Jdbc 规范，所以mybatis 的目标是 包装成 Jdbc的规范\n\n```\nStatement stmt = null;\ntry {\n  Configuration configuration = ms.getConfiguration();\n  // 添加 Statement的 Plugin Handler\n  StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);\n  stmt = prepareStatement(handler, ms.getStatementLog());\n  // 执行 statement.execute()\n  return handler.<E>query(stmt, resultHandler);\n} finally {\n  closeStatement(stmt);\n}\n```\n\n\n\n这里我们先回顾下MyBatis 编程步骤：\n\n1. 创建 SqlSessionFactory 对象。\n2. 通过 SqlSessionFactory 获取 SqlSession 对象。\n3. 通过 SqlSession 获得 Mapper 代理对象。\n4. 通过 Mapper 代理对象，执行数据库操作。\n5. 执行成功，则使用 SqlSession 提交事务。\n6. 执行失败，则使用 SqlSession 回滚事务。\n7. 最终，关闭会话。\n\n\n\n再从源码看一下mybatis 的三个组件的执行规则\n\n```\nSqlSessionFactoryBuilder  --合成-  Configuration ---解析- mybatis.config \n\n\t生成（MappedStatement）XMLMapperBuilder.configurationElement() ---> XMLStatementBuilder.parseStatementNode\n\n\tKeyGenerator、StatementType、LanguageDriver（处理动态标签）、ParameterMap、ResultMap、ResultType\n\t\n\nSqlSessionFactory\n\n\tDataSource、Transaction\n\t\n\nSqlSession（执行sql 语句  ）\n\n\tExecutor（SimpleExecutor、ReuseExecutor、BatchExecutor、ClosedExecutor）\n\n\tStatement.execute -- SimpleStatement、PrepareStatement、CallableStatement(支持调用存储过程,提供了对输出和输入/输出参数(INOUT)的支持; )\n\n\tTypeHandler ResultHandler  InterceptorChain（Plugin）\n    \n\tRowBounds（分页）\n\n    语句缓存  CacheKey\n```\n\n\n\n##### 2.1 Executor（语句执行器）\n\n- **SimpleExecutor**：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。\n\n- **ReuseExecutor**：执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map<String, Statement>内，供下一次使用。简言之，就是重复使用 Statement 对象。\n\n\n```\nBoundSql boundSql = handler.getBoundSql();\nString sql = boundSql.getSql();\n// 如果有 就不会重复创建Statement\nif (hasStatementFor(sql)) {\n  stmt = getStatement(sql);\n} else {\n  Connection connection = getConnection(statementLog);\n  stmt = handler.prepare(connection);\n  putStatement(sql, stmt);\n}\n```\n\n- **BatchExecutor**：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。**实际上，整个过程与 JDBC 批处理是相同**。\n\n\n```\nConnection connection = getConnection(ms.getStatementLog());\nstmt = handler.prepare(connection);\ncurrentSql = sql;\ncurrentStatement = ms;\nstatementList.add(stmt);\nbatchResultList.add(new BatchResult(ms, sql, parameterObject));\n```\n\n- **CachingExecutor** ：在上述的三个执行器之上，增加**二级缓存**的功能。\n\n> 通过设置 `<setting name=\"defaultExecutorType\" value=\"\">` 的 `\"value\"` 属性，可传入 SIMPLE、REUSE、BATCH 三个值，分别使用 SimpleExecutor、ReuseExecutor、BatchExecutor 执行器。\n>\n> 通过设置 `<setting name=\"cacheEnabled\" value=\"\"` 的 `\"value\"` 属性为 `true` 时，创建 CachingExecutor 执行器。\n\n\n\n##### 2.2 PerpetualCache（语句缓存）\n\n在执行sql 语句的时候，会有一个缓存机制，保证下次遇到相同的 Statement 不需要 在从数据库查询，这个是sqlSession级别的缓存，数据库层面也是有缓存的，基于PrepareStatement的缓存，如果预参数 相同，则不需要对sql进行二次校验 + 优化，直接执行\n\n\n\n大概逻辑代码如下：\n\n```\n// 不需要对结果处理 可以试试先从缓存处理\nlist = resultHandler == null ? (List<E>) localCache.getObject(key) : null;\nif (list != null) {\n  handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);\n} else {\n  list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);\n}\n```\n\n\n\n这里的localCache就是PerpetualCache，缓存key的重要组成部分 包括 MapperStatement的Id、分页参数、实际执行sql语句 和 经过TypeHandler转换之后的入参\n\n```\nCacheKey cacheKey = new CacheKey();\ncacheKey.update(ms.getId());\ncacheKey.update(rowBounds.getOffset());\ncacheKey.update(rowBounds.getLimit());\ncacheKey.update(boundSql.getSql());\n...\n else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) {\n     cacheKey.update(parameterObject);\n }\n```\n\n\n\n这里语句执行的话 有一个延迟加载机制，是使用 DeferredLoad 实现的，先看一下 queryFromDatabase语句\n\n```\nprivate <E> List<E> queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {\n  List<E> list;\n  // 执行之前先放入占位\n  localCache.putObject(key, EXECUTION_PLACEHOLDER);\n  try {\n    list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);\n  } finally {\n    localCache.removeObject(key);\n  }\n  // 执行之后再放入真实数据\n  localCache.putObject(key, list);\n  if (ms.getStatementType() == StatementType.CALLABLE) {\n    localOutputParameterCache.putObject(key, parameter);\n  }\n  return list;\n}\n```\n\n\n\n可以看出在实际执行sql语句之前，是有个伪返回值的，这个设计防止多个线程同时执行相同的Statement语句的时候，只会有一个线程和数据库交互进行真实获取，其他线程得到的是伪返回值，那这么伪返回值怎么赋真实值呢，就需要看DeferredLoad.load()\n\n```\npublic void load() {\n  @SuppressWarnings( \"unchecked\" ) // we suppose we get back a List\n  List<Object> list = (List<Object>) localCache.getObject(key);\n  // 替换返回结果集\n  Object value = resultExtractor.extractObjectFromList(list, targetType);\n  resultObject.setValue(property, value);\n}\n```\n\n\n\n##### 2.3 Plugin（插件）\n\nMybatis仅可以编写针对ParameterHandler、ResultSetHandler、StatementHandler、Executor这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是InvocationHandler的invoke()方法，当然，只会拦截那些你指定需要拦截的方法。\n\n\n\n使用很简单，继承Inteceptor即可\n\n```\npublic static class AlwaysMapPlugin implements Interceptor {\n  public Object intercept(Invocation invocation) throws Throwable {\n    return \"Always\";\n  }\n\n  public Object plugin(Object target) {\n    return Plugin.wrap(target, this);\n  }\n\n  public void setProperties(Properties properties) {\n  }\n}\n```\n\n\n\n在解析mybatis-config.xml 会 将这些Interceptor 装入到 Configuration中，在doQuery执行语句的时候会依次执行 ParameterHandler、StatementHandler、ResultSetHandler\n\n```\nprotected BaseStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) {\n  this.configuration = mappedStatement.getConfiguration();\n  this.executor = executor;\n  this.mappedStatement = mappedStatement;\n  this.rowBounds = rowBounds;\n  ...\n  this.parameterHandler = configuration.newParameterHandler(mappedStatement, parameterObject, boundSql);\n  this.resultSetHandler = configuration.newResultSetHandler(executor, mappedStatement, rowBounds, parameterHandler, resultHandler, boundSql);\n}\n\npublic ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) {\n  ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql);\n  parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler);\n  return parameterHandler;\n}\n\npublic ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler,\n    ResultHandler resultHandler, BoundSql boundSql) {\n  ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds);\n  resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler);\n  return resultSetHandler;\n}\n```\n\n\n\n#### 3. Spring中怎么运行的\n\n**MapperProxy** 和 **MapperProxyFactory**\n\n\n\n在Spring中 需要借助 Spring 的 扫描机制 将 Mybatis的特定注解 注册到BeanFactory中，比如@Mapper\n\n![img](http://pcc.huitogo.club/8509fea79dfaae019bdfc9bc2a890526)\n\n```\nMapperScanConfigurer.postProcessBeanDefinitionRegistry     #spring的BeanPostProcessor\n\n\tClassPathBeanDefinitionScanner.scan\n\t\n\t\tClassPathMapperScanner.doScan\n```\n\n\n\n最终 将指定dao包 路径下的Mapper 转换成BeanDefinition 存储在BeanFactory中\n\n```\nprivate void processBeanDefinitions(Set<BeanDefinitionHolder> beanDefinitions) {\n  for (BeanDefinitionHolder holder : beanDefinitions) {\n    definition = (GenericBeanDefinition) holder.getBeanDefinition();\n    String beanClassName = definition.getBeanClassName();\n    definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); \n    definition.setBeanClass(this.mapperFactoryBeanClass);\n    definition.getPropertyValues().add(\"addToConfig\", this.addToConfig);\n    definition.getPropertyValues().add(\"sqlSessionFactory\",\n    definition.getPropertyValues().add(\"sqlSessionTemplate\",\n    definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n    definition.setLazyInit(lazyInitialization);\n  }\n}\n```\n\n\n\n每个BeanDefinition存储了 SqlSessionFactory的里面（可以找到数据源信息 和 MapperStatement），这里需要注意的是BeanClass 其实已经变成了 MapperFactoryBean\n\n相当于你实际使用的时候，拿到的是一个MapperProxy，由MapperProxyFactory生成的，而MapperProxy 会帮助你去使用SqlSessionFactoty 生成SqlSession，从MapperStament中获取SqlSource 进行执行\n\n```\npublic <T> T getMapper(Class<T> type) {\n  return getConfiguration().getMapper(type, this);\n}\n\npublic <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    final MybatisMapperProxyFactory<T> mapperProxyFactory = (MybatisMapperProxyFactory<T>) knownMappers.get(type);\n    return mapperProxyFactory.newInstance(sqlSession);\n}\n\npublic T newInstance(SqlSession sqlSession) {\n    final MybatisMapperProxy<T> mapperProxy = new MybatisMapperProxy<>(sqlSession, mapperInterface, methodCache);\n    return return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[]{mapperInterface}, mapperProxy);\n}\n```\n\n\n\n最终执行流程图如下：\n\n![流程](https://pcc.huitogo.club/z0/02.png)\n\n\n\n#### 4. SpringBoot中怎么运行的\n\n运用了SpringBoot的自动装配\n\n![img](http://pcc.huitogo.club/2d90ea145fa45e124f67bcdddca6e0a4)\n\n\n\n引入了 MybatisAutoConfiguration（这里以MybatisPlus为例），原理是一样的\n\n```\n@Configuration\n@ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class})\n@ConditionalOnSingleCandidate(DataSource.class)\n@EnableConfigurationProperties({MybatisPlusProperties.class})\n@AutoConfigureAfter({DataSourceAutoConfiguration.class, MybatisPlusLanguageDriverAutoConfiguration.class})\npublic class MybatisPlusAutoConfiguration implements InitializingBean {\n}\n\n@Configuration\n@Import({MybatisPlusAutoConfiguration.AutoConfiguredMapperScannerRegistrar.class})\n@ConditionalOnMissingBean({MapperFactoryBean.class, MapperScannerConfigurer.class})\npublic static class MapperScannerRegistrarNotFoundConfiguration implements InitializingBean {\n}\n```", "imgFile": "01.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 10}}, "机器学习": {"685453220c86511c425b3a4c6043abd7": {"id": "685453220c86511c425b3a4c6043abd7", "item": "机器学习", "title": "tess4j训练字库步骤", "date": "2024-08-22", "summary": "记录一次tess4j训练字库的步骤", "body": "\n使用tess4j做文字识别的时候，如果只用它自带的中文语言包“chi_sim”对中文手写字体或者环境比较复杂的图片，识别正确率不高，因此需要针对特定情况用自己的样本进行训练，提高识别率，通过训练，也可以形成自己的语言库。\n\n\n\n怎么训练自己的语言库呢\n\n\n\n首先我们需要\n\n1）安装tesseract-ocr 4.0，地址https://digi.bib.uni-mannheim.de/tesseract/\n\n2）下载jTessBoxEditor2.0，地址https://sourceforge.net/projects/vietocr/files/jTessBoxEditor/\n\n3）安装Tess4J-3.4.8 ，地址 [https://sourceforge.net/projects/tess4j/files/tess4j/](https://links.jianshu.com/go?to=https://sourceforge.net/projects/tess4j/files/tess4j/)\n\n\n\n接下来，开始\n\n\n\n#### **1、准备样本图片**\n\n\n\n进行训练的样本图片数量越多越好\n\n\n\n#### **2、使用jTessBoxEditor生成训练样本的的合并tif图片**\n\n\n\n打开jTessBoxEditor，选择Tools->Merge TIFF，进入训练样本所在文件夹，选中要参与训练的样本图片\n\n点击 “打开” 后弹出保存对话框，选择保存在当前路径下，文件命名为 “zwp.test.exp0.tif” ，格式只有一种 “TIFF” 可选。\n\n\n\ntif文面命名格式[lang].[fontname].exp[num].tif\n\nlang是语言，fontname是字体，num为自定义数字。\n\n比如我们要训练自定义字库 zwp，字体名test，那么我们把图片文件命名为 zwp.test.exp0.tif\n\n\n\n#### **3、使用tesseract生成.box文件**\n\n\n\n执行如下命令 ： tesseract zwp.test.exp0.tif zwp.test.exp0 batch.nochop makebox\n\n\n\n#### **4、使用jTessBoxEditor矫正.box文件的错误**\n\n\n\n**.box文件记录了每个字符在图片上的位置和识别出的内容，训练前需要使用jTessBoxEditor调整字符的位置和内容。**\n\n\n\n打开jTessBoxEditor点击Box Editor ->Open，打开步骤2中生成的“zwp.test.exp0.tif”，会自动关联到“zwp.test.exp0.box”文件，这两文件要求在同一目录下。调整完点击“save”保存修改。\n\n\n\n![img](http://pcc.huitogo.club/99e234c2e01bad909923214863dcdf55)\n\n\n\n注意这里自定义文字可能是乱码，解决方法： jtessboxeditor的setting ---> Font 里改字体为宋体，regular就可以了。\n\n还需要注意的是修改文字必须是白底黑字，要不然训练时会出现错误\n\n\n\n#### **5、生成font_properties文件**\n\n\n\n1）执行如下命令： echo test 0 0 0 0 0 >font_properties\n\n\n\n2）也可以手工新建一个名为font_properties的文本文件，输入内容 “test 0 0 0 0 0” 表示字体test的粗体、倾斜等共计5个属性。这里的“test”必须与“zwp.test.exp0.box”中的“test”名称一致。\n\n\n\n#### **6、使用tesseract生成.tr训练文件**\n\n\n\n执行下面命令，执行完之后，会在当前目录生成zwp.test.exp0.tr文件。\n\n\n\ntesseract zwp.test.exp0.tif zwp.test.exp0 nobatch box.train\n\n\n\n#### **7、生成字符集文件**\n\n\n\n执行下面命令：执行完之后会在当前目录生成一个名为“unicharset”的文件。\n\n\n\nunicharset_extractor zwp.test.exp0.box\n\n\n\n#### **8、生成shape文件**\n\n\n\n执行下面命令，执行完之后，会生成 shapetable 和 zwp.unicharset 两个文件。\n\n\n\nshapeclustering -F font_properties -U unicharset -O zwp.unicharset zwp.test.exp0.tr\n\n\n\n#### **9、生成聚字符特征文件**\n\n\n\n执行下面命令，会生成 inttemp、pffmtable、shapetable和zwp.unicharset四个文件。\n\n\n\nmftraining -F font_properties -U unicharset -O zwp.unicharset zwp.test.exp0.tr\n\n\n\n#### **10、生成字符正常化特征文件**\n\n\n\n执行下面命令，会生成 normproto 文件。\n\n\n\ncntraining zwp.test.exp0.tr\n\n\n\n#### **11、文件重命名**\n\n\n\n重新命名inttemp、pffmtable、shapetable和normproto这四个文件的名字为[lang].xxx。\n\n\n\n这里修改为zwp.inttemp、zwp.pffmtable、zwp.shapetable和zwp.normproto\n\n\n\n执行下面命令：\n\n\n\nrename normproto zwp.normproto\n\nrename inttemp zwp.inttemp\n\nrename pffmtable zwp.pffmtable\n\nrename shapetable zwp.shapetable\n\n\n\n#### **12、合并训练文件**\n\n\n\n执行下面命令，会生成zwp.traineddata文件。\n\n\n\ncombine_tessdata zwp.\n\n\n\nLog输出中的Offset 1、3、4、5、13这些项不是-1，表示新的语言包生成成功。\n\n将生成的“zwp.traineddata”语言包文件复制到Tesseract-OCR 安装目录下的tessdata文件夹中，就可以使用训练生成的语言包进行图像文字识别了。\n\n\n\n#### **13、测试**\n\n\n\n测试代码如下\n\n\n\n```\n1. public static void main(String[] args) throws TesseractException { \n\n2.   //加载待读取图片 \n\n3.   File imageFile = new File(\"D:\\\\develop\\\\tess4J\\\\img\\\\1.png\"); \n\n4.   //创建tess对象 \n\n5.   ITesseract instance = new Tesseract(); \n\n6.   //设置训练文件目录 \n\n7.   instance.setDatapath(System.getProperty(\"user.dir\") + \"\\\\src\\\\main\\\\resources\\\\tessdata\"); \n\n8.   //设置训练语言 \n\n9.   instance.setLanguage(\"zwp\"); \n\n10.   //执行转换 \n\n11.   String result = instance.doOCR(imageFile); \n\n12.  \n\n13.   System.out.println(result); \n\n14. } \n```", "imgFile": "04.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}}, "大前端": {"ca661a93ee4f93470c6f03591dee4ba0": {"id": "ca661a93ee4f93470c6f03591dee4ba0", "item": "大前端", "title": "Vue入门扫盲总结", "date": "2024-08-22", "summary": "Vue 是一款流行的前端 JavaScript 框架。它采用数据驱动视图的方式，通过简洁的模板语法将数据与页面进行绑定。Vue 易于上手，具有高效的响应式系统，能自动更新页面。同时，它还支持组件化开发，提升代码复用性和可维护性。", "body": "\n### 1、vue实例的生命周期\n\n\n\n![img](http://pcc.huitogo.club/cbdce8588b13c236cf993a71de9fd33c)\n\n\n\nvue生命周期分为四个阶段\n\n第一阶段（创建阶段）：beforeCreate，created\n\n第二阶段（挂载阶段）：beforeMount（render），mounted\n\n第三阶段（更新阶段）：beforeUpdate，updated\n\n第四阶段（销毁阶段）：beforeDestroy，destroyed\n\n\n\n1）beforeCreate\n\n官网：在实例初始化之后,进行数据侦听和事件/侦听器的配置之前同步调用。\n\n详细：在这个阶段，数据是获取不到的，并且真实dom元素也是没有渲染出来的\n\n\n\n2）created\n\n官网：在实例创建完成后被立即同步调用。在这一步中，实例已完成对选项的处理，意味着以下内容已被配置完毕：数据侦听、计算属性、方法、事件/侦听器的回调函数。然而，挂载阶段还没开始，且 $el property 目前尚不可用。\n\n详细：在这个阶段，可以访问到数据了，但是页面当中真实dom节点还是没有渲染出来，在这个钩子函数里面，可以进行相关初始化事件的绑定、发送请求操作\n\n\n\n3）beforeMount\n\n官网：在挂载开始之前被调用：相关的 render 函数首次被调用。\n\n详细：代表dom马上就要被渲染出来了，但是却还没有真正的渲染出来，这个钩子函数与created钩子函数用法基本一致，可以进行相关初始化事件的绑定、发送ajax操作\n\n\n\n4）mounted\n\n官网：实例被挂载后调用，这时 el 被新创建的 vm.$el 替换了。如果根实例挂载到了一个文档内的元素上，当 mounted 被调用时 vm.$el 也在文档内。 注意 mounted 不会保证所有的子组件也都被挂载完成。如果你希望等到整个视图都渲染完毕再执行某些操作，可以在 mounted 内部使用 vm.$nextTick：\n\n详细：挂载阶段的最后一个钩子函数,数据挂载完毕，真实dom元素也已经渲染完成了,这个钩子函数内部可以做一些实例化相关的操作\n\n\n\n5）beforeUpdate\n\n官网：在数据发生改变后，DOM 被更新之前被调用。这里适合在现有 DOM 将要被更新之前访问它，比如移除手动添加的事件监听器。\n\n详细：这个钩子函数初始化的不会执行,当组件挂载完毕的时候，并且当数据改变的时候，才会立马执行,这个钩子函数获取dom的内容是更新之前的内容\n\n\n\n6）updated\n\n官网：在数据更改导致的虚拟 DOM 重新渲染和更新完毕之后被调用。 当这个钩子被调用时，组件 DOM 已经更新，所以你现在可以执行依赖于 DOM 的操作。然而在大多数情况下，你应该避免在此期间更改状态。如果要相应状态改变，通常最好使用计算属性或 watcher 取而代之。\n\n详细：这个钩子函数获取dom的内容是更新之后的内容生成新的虚拟dom，新的虚拟dom与之前的虚拟dom进行比对，差异之后，就会进行真实dom渲染。在updated钩子函数里面就可以获取到因diff算法比较差异得出来的真实dom渲染了。\n\n\n\n7）beforeDestroy\n\n官网：实例销毁之前调用。在这一步，实例仍然完全可用。\n\n详细：当组件销毁的时候，就会触发这个钩子函数代表销毁之前，可以做一些善后操作,可以清除一些初始化事件、定时器相关的东西。\n\n\n\n8）destroyed\n\n官网：实例销毁后调用。该钩子被调用后，对应 Vue 实例的所有指令都被解绑，所有的事件监听器被移除，所有的子实例也都被销毁。\n\n详细：Vue实例失去活性，完全丧失功能\n\n\n\n问题：\n\n1）created和mouted\n\ncreated:在模板渲染成html前调用，即通常初始化某些属性值，然后再渲染成视图。\n\nmounted:在模板渲染成html后调用，通常是初始化页面完成后，再对html的dom节点进行一些需要的操作。\n\n\n\n2）computed 和 data\n\ndata 和 computed 最核心的区别在于 data 中的属性并不会随赋值变量的改动而改动，而computed 会\n\n\n\n### 2、项目结构\n\n\n\n![img](http://pcc.huitogo.club/bbad268d08cead7dfc8bf0527f3d4a64)\n\n\n\n### 3、数组操作\n\n\n\nsplice(x，y,z)：在x位置 删除y个元素 再添加z元素进去\n\n\n\n... 变量\n\n扩展语法。对数组和对象而言，就是将运算符后面的变量里东西每一项拆下来。\n\n\n\n### 4、slot、slot-scope、v-slot\n\n\n\nslot用于绑定传入内容的插槽，slot-scope获取插槽的作用域对象\n\n1）slot 占位符 子组件放占用符 父组件填充 分为匿名和具名 ，匿名只有一个\n\n2）slot-scope 传递数据的占位符 子组件放占用符 并绑定数据 父组件使用数据 填充样式\n\n\n\nv-slot（2.6版本之后加入）\n\n结合上述两个指令的新指令\n\n1）v-slot:slotName绑定传入的插槽，缩写为#slotName 等价于slot=“slotName”\n\n2）v-slot:slotName=“scope”,获取插槽的作用域对象并赋值给scope,等价于slot-scope=“scope”。同时可以使用ES6的解构语法获取指定的特性v-slot=“{ footer }”\n\n3）当插槽为默认插槽时，v-slot可以不带修饰符，直接在组件上使用，并且将默认插槽的作用域赋给v-slot声明的变量\n\n\n\n### 5、$refs 和 ref属性\n\n\n\nref被用来给元素或子组件注册引用信息。引用信息将会注册在父组件的 $refs对象上。如果在普通的 DOM 元素上使用，引用指向的就是 DOM 元素；如果用在子组件上，引用就指向该子组件实例\n\n通俗的讲，ref特性就是为元素或子组件赋予一个ID引用,通过this.$refs.refName来访问元素或子组件的实例。\n\n\n\n```\n   this.$refs.p\n   this.$refs.children\n```\n\n\n\nthis.$refs是一个对象，持有当前组件中注册过 ref特性的所有 DOM 元素和子组件实例\n\n注意： $refs只有在组件渲染完成后才填充，在初始渲染的时候不能访问它们，并且它是非响应式的，因此不能用它在模板中做数据绑定\n\n\n\n### 6、.native\n\n\n\n.native 可以在某组件的根元素上监听一个原生事件\n\n一般情况下，父组件要监听子组件的事件，可以通过$emit的方式。但是如果父组件要监听子组件的原生事件，比如：input的focus事件。此时可以通过使用v-on的.native修饰符达到目的。\n\n\n\n```\n<button @click=\"add(this)\">普通的html标签，不包含native的按钮</button>  // 生效\n<button @click.native=\"add(this)\">普通的html标签，包含native的按钮</button> // 不生效\n<myself-button @click=\"add(this)\"/></myself-button> //不生效\n<myself-button @click.native=\"add(this.id)\"/></myself-button>  //生效\n```\n\n但是如果目标预监听的元素不是根元素，那么.native可能会失效，此时可以利用emit 的 方·法 ， 通 过 使 用 emit的方法，通过使用emit的方法，通过使用‘listeners来获得父组件在子组件上加上的除.native的事件。 子组件则监听这些事件，当事件发生通知父组件 这个时候就不需要使用.native修饰符就可以监听原生事件的实例。\n\n\n\n### 7、scoped\n\n\n\n解决多页面应用中不同组件中的样式隔离问题\n\n原理：vue通过在DOM结构以及css样式上加上唯一的标记 data-v-469af010，保证唯一\n\n1）父组件无scoped属性，子组件带有scoped，父组件是无法操作子组件的样式的（原因在原理中可知），虽然我们可以在全局中通过该类标签的标签选择器设置样式，但会影响到其他组件\n\n2）父组件有scoped属性，子组件无，父组件也无法设置子组件样式，因为父组件的所有标签都会带有data-v-469af010唯一标志，但子组件不会带有这个唯一标志属性，与1同理，虽然我们可以在全局中通过该类标签的标签选择器设置样式，但会影响到其他组件\n\n3）父子组建都有，同理也无法设置样式，更改起来增加代码量\n\n\n\n副作用\n\n\n\n![img](http://pcc.huitogo.club/33061e374b10a760acf5bcb4ef609a6b)\n\n\n\n我们自己写的样式却被拼接了这个唯一的标识，我们再怎么操作也是没法命中这个元素的，也就是说Vue并没有给这个input加上这个标识，但是却在我们的样式中加上了这个标识\n\n\n\n解决办法：样式穿透\n\n\n\n```\n<style scoped>\n\n.my-Txt ::v-deep input {\n  background-color: pink;\n}\n</style>\n```\n\n\n\n![img](http://pcc.huitogo.club/26e2d3b34b739e9a29cb3a34de33e0b0)\n\n\n\n可以看到这个唯一标识从input后面跑到了my-Txt的后面了。\n\n\n\n### 8、el\n\n\n\n简单来说el的作用就是表明我们要将当前vue组件生成的实例插入到页面的哪个元素中，el属性的值可以是css选择器的字符串，或者直接就是对应的元素对象。并且只能在使用new生成实例时才能配置el属性，而我们在组件中只是export一个配置对象，如果设置了el则会报错。\n\n\n\n```\nnew Vue({\n  el: '#app',\n  router,\n  render: h => h(App)\n})\n```\n\n\n\n### 9、$emit 和 $on\n\n\n\n组件通信\n\n$emit 触发 $on 监听\n\n\n\n### 10、watch 监控事件\n\n观察数据变化\n\n$route：路由事件\n\n\n\n### 11、vue-router\n\n\n\nthis.$router.push()可在组件中控制路由跳转\n\n<router-link/>可在组件模板中设定超链接进行挑战，在Sidebar组件中也已实现\n\nbeforeEach 路由鉴权\n\n\n\n### 12、v-show与v-if区别\n\n\n\nv-show隐藏则是为该元素添加css--display:none，dom元素依旧还在。v-if显示隐藏是将dom元素整个添加或删除\n\n\n\n### 13、过渡\n\n\n\n动画过渡事件\n\n\n\n![img](http://pcc.huitogo.club/e2b8ddea36e76fc9a10cac22c8d79ceb)\n\n\n\n钩子函数\n\n```\n<transition\n  v-on:before-enter=\"beforeEnter\"\n  v-on:enter=\"enter\"\n  v-on:after-enter=\"afterEnter\"\n  v-on:enter-cancelled=\"enterCancelled\"\n  v-on:before-leave=\"beforeLeave\"\n  v-on:leave=\"leave\"\n  v-on:after-leave=\"afterLeave\"\n  v-on:leave-cancelled=\"leaveCancelled\"\n>\n```\n\n\n\n### 14、实用的组件\n\n\n\niCheck：基于jQuery的表单选项插件\n\nswitchery：把默认的HTML复选框转换成漂亮iOS7样式\n\ndaterangepicker：基于bootstrap的日历插件\n\ndatatables：jquery表格插件 tooltip（根据需求生成内容和标记）\n\n\n\n### 15、实用的模板网站\n\n\n\nGentelella\n\n\n\n### 16、export 和 export default\n\n\n\nexport与export default均可用于导出常量、函数、文件、模块等\n\n在一个文件或模块中，export、import可以有多个，export default仅有一个\n\n通过export方式导出，在导入时要加{ }，export default则不需要，并可以起任意名称\n\n\n\n### 17、vuex\n\n\n\n本地存储 刷新失效\n\nsessionStorage 会话存储\n\n\n\n### 18、Promise\n\n\n\n是一个容器（对象），里面是异步事件，用于解决异步回调地狱的问题\n\n\n\n### 19、Vue.directive\n\n\n\n自定义指令", "imgFile": "05.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 3}}, "实践原理": {"7854ca73e801c8a0633caba94bc78d67": {"id": "7854ca73e801c8a0633caba94bc78d67", "item": "实践原理", "title": "Mybatis缓存策略", "date": "2024-08-22", "summary": "MyBatis 有一级缓存和二级缓存策略。一级缓存是 SqlSession 级别的，默认开启，存储同一次会话中的查询结果。二级缓存是 Mapper 级别的，可配置开启，多个 SqlSession 可共享，能提高数据查询效率，减少数据库访问压力。", "body": "\nMybatis缓存机制示意图\n\n![img](http://pcc.huitogo.club/e74159071534c8226f75077016f5aeeb)\n\n\n\n#### 1. 一级缓存\n\n在应用运行过程中，我们有可能在一次数据库会话中，执行多次查询条件完全相同的 SQL， MyBatis 提供了一级缓存的方案优化这部分场景，如果是相同的 SQL 语句，会优先命中一级缓存， 避免直接对数据库进行查询，提高性能。具体执行过程如下：\n\n![img](http://pcc.huitogo.club/9bf9363503a4075d9aa7bfe076541e10)\n\n\n\n每个 SqlSession 中持有了 Executor，每个 Executor 中有一个 LocalCache。当用户发起查询时， MyBatis 根据当前执行的语句生成 MappedStatement，在 Local Cache 进行查询，如果缓存命中 的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入 Local Cache，最后返回结果给用户。\n\n\n\n具体实现类的类关系图如下图所示：\n\n![img](https://pcc.huitogo.club/z0/d76ec5fe.jpg)\n\n一级缓存执行的时序图：\n\n![img](https://pcc.huitogo.club/z0/bb851700.png)\n\n总结：\n\n1. MyBatis 一级缓存的生命周期和 SqlSession 一致。\n2. MyBatis 一级缓存内部设计简单，只是一个没有容量限定的 HashMap，在缓存的功能性上有所欠缺。\n3. MyBatis 的一级缓存最大范围是 SqlSession 内部，有多个 SqlSession 或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为 Statement。\n\n\n\n下面我们来验证一下：\n\n先准备一下mybatis-config文件（配置数据库、映射关系、实体别名等）\n\n```\n1.  <configuration>  \n\n2.      <properties resource=\"dbconfig.properties\" />  \n\n3.      <settings>  \n\n5.          <setting name=\"useGeneratedKeys\" value=\"true\" />  \n\n6.          <setting name=\"defaultExecutorType\" value=\"REUSE\" />  \n\n7.          <setting name=\"logImpl\" value=\"STDOUT_LOGGING\" />  \n\n8.      </settings>  \n\n9.      <typeAliases>  \n\n10.         <typeAlias type=\"cn.ictt.entity.system.User\" alias=\"User\" />  \n\n11.         <typeAlias type=\"cn.ictt.util.page.Page\" alias=\"Page\" />  \n\n12.     </typeAliases>  \n\n17.     <plugins>  \n\n18.         <plugin interceptor=\"cn.ictt.plugin.PagePlugin\">  \n\n19.             <property name=\"dialect\" value=\"mysql\" />  \n\n20.             <property name=\"pageSqlId\" value=\".*listPage.*\" />  \n\n21.         </plugin>  \n\n22.     </plugins>  \n\n23.     <environments default=\"mysql_developer\">  \n\n24.         <environment id=\"mysql_developer\">  \n\n25.             <transactionManager type=\"jdbc\" />  \n\n26.             <dataSource type=\"pooled\">  \n\n27.                 <property name=\"driver\" value=\"${driverClassName}\" />  \n\n28.                 <property name=\"url\" value=\"${url}\" />  \n\n29.                 <property name=\"username\" value=\"${username}\" />  \n\n30.                 <property name=\"password\" value=\"${password}\" />  \n\n31.             </dataSource>  \n\n32.         </environment>  \n\n33.     </environments>  \n\n34.     <mappers>  \n\n35.         <mapper resource=\"system/UserMapper.xml\" />  \n\n36.     </mappers>  \n\n37. </configuration>\n```\n\n\n\n配置要注意先后关系，UserMapper.xml和UserMapper.java这里不写上了。\n\n测试：\n\n```\n1.          InputStream resourceAsStream = Resources.getResourceAsStream(\"mybatis-config2.xml\");  \n\n2.          SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream);  \n\n3.          SqlSession sqlSession = sqlSessionFactory.openSession();  \n\n4.          UserMapper userMapper =sqlSession.getMapper(UserMapper.class);  \n\n5.          User user1 = userMapper.getById(1);  \n\n6.          System.out.println(user1);  \n\n7.  //      userMapper.editById(new User(1, \"张辉\", \"123\", 2));  \n\n8.  //      userMapper.save(new User(2, \"张辉\", \"123\", 2));  \n\n9.  //      sqlSession.commit();  \n\n10. //      userMapper.deleteById(12);  \n\n11.         User user2 = userMapper.getById(2);  \n\n12.         System.out.println(user2);  \n\n13.         sqlSession.close();  \n```\n\n\n\n总结一级缓存过程：\n\n第一次发出一个查询 sql，sql 查询结果写入 sqlsession 的一级缓存中，缓存使用的数据结构是一 个map。\n\n- key：MapperID+offset+limit+Sql+所有的入参\n- value：用户信息\n\n同一个 sqlsession 再次发出相同的 sql，就从缓存中取出数据。如果两次中间出现 **commit 操作** （修改、添加、删除），本 sqlsession 中的一级缓存区域全部清空，下次再去缓存中查询不到所以要从数据库查询，从数据库查询到再写入缓存，这样做的目的为了让缓存中存储的是最新的信息，**避免脏读**。\n\n\n\n#### 2. 二级缓存\n\n二级缓存是mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession可以共用二级缓存，也就是说多个sqlSession可以共享一个mapper中的二级缓存区域，并且如果两个mapper的namespace相同，即使是两个mapper，那么这两个mapper中执行sql查询到的数据也将存在相同的二级缓存区域中。\n\n\n\n具体的工作流程如下所示\n\n![img](http://pcc.huitogo.club/286fabffb6fae4a5a31d5474f44927f1)\n\n- mybatis的二级缓存是通过CacheExecutor实现的。\n\n- CacheExecutor其实是 Executor 的代理对象。所有的查询操作，在 CacheExecutor 中都会先匹配缓存中是否存 在，不存在则查询数据库。\n\n- key：MapperID+offset+limit+Sql+所有的入参\n\n\n\n\n##### 2.1 单服务器缓存\n\n在mybatis.config.xml中加入\n\n```\n1.  <!--开启二级缓存  -->  \n\n2.  <settings>  \n\n3.      <setting name=\"cacheEnabled\" value=\"true\"/>  \n\n4.  </settings> \n```\n\n\n\n在需要开启缓存的mapper.xml中加入\n\n```\n1.  <!-- 开启二级缓存 -->  \n\n2.  <cache></cache> \n```\n\n\n\n需要注意的是**需要将实体类（比如这里的User）进行序列化**\n\n为了将缓存数据取出执行反序列化操作，因为二级缓存数据存储介质多种多样，不一定只存在内存中，有可能存在硬盘中，如果我们要再取这个缓存的话，就需要反序列化了。所以mybatis中的pojo都去实现Serializable接口。\n\n\n\n下面是我的测试代码：\n\n```\n1.          InputStream resourceAsStream = Resources.getResourceAsStream(\"mybatis-config2.xml\");  \n\n2.          SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream);  \n\n3.          SqlSession sqlSession = sqlSessionFactory.openSession();  \n\n4.          UserMapper userMapper =sqlSession.getMapper(UserMapper.class);  \n\n5.          SqlSession sqlSession2 = sqlSessionFactory.openSession();  \n\n6.          UserMapper userMapper2 =sqlSession2.getMapper(UserMapper.class);  \n\n7.          SqlSession sqlSession3 = sqlSessionFactory.openSession();  \n\n8.          UserMapper userMapper3 =sqlSession2.getMapper(UserMapper.class);  \n\n9.          User user1 = userMapper.getById(2);  \n\n10.         System.out.println(user1);  \n\n11. //      userMapper.editById(new User(2, \"张辉\", \"123\", 2));  \n\n12.         sqlSession.commit();  \n\n13. //      sqlSession.close();  \n\n14. //      userMapper.editById(new User(1, \"张辉\", \"123\", 2));  \n\n15. //      userMapper3.save(new User(3, \"张辉\", \"123\", 2));  \n\n16. //        \n\n17. //      userMapper3.deleteById(1);  \n\n18.         userMapper3.editById(new User(1, \"张辉\", \"123\", 2));  \n\n19. //      sqlSession3.commit();  \n\n20.         User user2 = userMapper2.getById(2);  \n\n21.         System.out.println(user2);  \n\n22.         sqlSession2.close();\n```\n\n\n\n测试结果：\n\n1. 对于sqlSession1、sqlSession2，只有在sqlSession1.commit()或者sqlSession1.close()之后sqlSession2才能取到sqlSession1执行的缓存实体类。\n2. 就算sqlSession1.close()了，如果有sqlSession3或者其它的sqlSession执行了update或者delete方法（不需要commit()），当前实体的缓存就被清除了。\n\n\n\n总结：这种单服务器下的基于namespace的缓存，确实是对所以sqlSession都是可见的，**前提是提供缓存的sqlSession放弃对缓存的控制且在下一次做相同操作前都没有更新操作**。\n\n\n\n如果需要设置mapper.xml中某个方法不需要使用缓存时，可以设置useCache=\"false\"\n\n```\n1.  <select id=\"selectUserByUserId\" useCache=\"false\" resultType=\"com.ys.twocache.User\" parameterType=\"int\">  \n\n2.      select * from user where id=#{id}  \n\n3.  </select>  \n```\n\n\n\n如果希望某个方法执行完自动刷新缓存，可以设置flushCache=”true”\n\n```\n1.  <select id=\"selectUserByUserId\" flushCache=\"true\" resultType=\"com.ys.twocache.User\" parameterType=\"int\">  \n\n2.      select * from user where id=#{id}  \n\n3.  </select>  \n```\n\n默认commit后会执行一次flush操作。\n\n\n\n##### 2.2 多服务器(集群)下的缓存\n\n![img](http://pcc.huitogo.club/110899e8b9647d83684b120b35be6ce8)\n\n\n\nMyBatis默认有对ehcache的支持，启用流程如下：\n\n1）配置mybatis-ehcache的依赖。\n\n2）在mybatis-config.xml中配置全局缓存\n\n```\n<!--开启二级缓存  -->  \n<settings>  \n\n      <setting name=\"cacheEnabled\" value=\"true\"/>  \n\n  </settings>  \n```\n\n\n\n3）在UserMapper.xml中配置缓存类型\n\n```\n  <!-- 开启本mapper的namespace下的二级缓存   \n\n      type:指定cache接口的实现类的类型，不写type属性，mybatis默认使用PerpetualCache  \n\n     要和ehcache整合，需要配置type为ehcache实现cache接口的类型  \n\n -->  \n <cache type=\"org.mybatis.caches.ehcache.EhcacheCache\"></cache>  \n```\n\n\n\n4）在classpath下配置ehcache.xml的配置来配置缓存\n\n```\n14. <?xml version=\"1.0\" encoding=\"UTF-8\"?>  \n\n15. <ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"  \n\n16.     xsi:noNamespaceSchemaLocation=\"../config/ehcache.xsd\">  \n\n17.     <diskStore path=\"F:developehcache\"/>  \n\n18.     <defaultCache  \n\n19.             maxElementsInMemory=\"10000\"  \n\n20.             eternal=\"false\"  \n\n21.             timeToIdleSeconds=\"120\"  \n\n22.             timeToLiveSeconds=\"120\"  \n\n23.             maxElementsOnDisk=\"10000000\"  \n\n24.             diskExpiryThreadIntervalSeconds=\"120\"  \n\n25.             memoryStoreEvictionPolicy=\"LRU\">  \n\n26.         <persistence strategy=\"localTempSwap\"/>  \n\n27.     </defaultCache>  \n\n28. </ehcache> \n```\n\n上述配置中：\n\n- **diskStore**：指定数据在磁盘中的存储位置。\n- **defaultCache**：当借助CacheManager.add(\"demoCache\")创建Cache时，EhCache便会采用指定的的管理策略\n\n\n\n以下属性是必须的：\n\n- **maxElementsInMemory** ：在内存中缓存的element的最大数目\n- **maxElementsOnDisk** ：在磁盘上缓存的element的最大数目，若是0表示无穷大\n- eternal ：设定缓存的elements是否永远不过期。如果为true，则缓存的数据始终有效，如果为false那么还要根据timeToIdleSeconds，timeToLiveSeconds判断\n- **overflowToDisk** ： 设定当内存缓存溢出的时候是否将过期的element缓存到磁盘上\n\n\n\n以下属性是可选的：\n\n- **timeToIdleSeconds** ：当缓存在EhCache中的数据前后两次访问的时间超过timeToIdleSeconds的属性取值时，这些数据便会删除，默认值是0,也就是可闲置时间无穷大\n- **timeToLiveSeconds** ：缓存element的有效生命期，默认是0.,也就是element存活时间无穷大\n- **diskSpoolBufferSizeMB**：这个参数设置DiskStore(磁盘缓存)的缓存区大小.默认是30MB.每个Cache都应该有自己的一个缓冲区\n- **diskPersistent** ：在VM重启的时候是否启用磁盘保存EhCache中的数据，默认是false\n- **diskExpiryThreadIntervalSeconds** ：磁盘缓存的清理线程运行间隔，默认是120秒。每个120s，相应的线程会进行一次EhCache中数据的清理工作\n- **memoryStoreEvictionPolicy**：当内存缓存达到最大，有新的element加入的时候，移除缓存中element的策略。默认是LRU（最近最少使用），可选的有LFU（最不常使用）和FIFO（先进先出）\n\n\n\n#### 3. 缓存比较\n\n当开启缓存后，数据的查询执行的流程为：\n\n**二级缓存 -> 一级缓存 -> 数据库**\n\n1. MyBatis 的二级缓存相对于一级缓存来说，实现了 SqlSession 之间缓存数据的共享，同时粒度 更加细，能够到 namespace 级别，通过 Cache 接口实现类不同的组合，对 Cache 的可控性也更强。\n2. MyBatis 在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件 比较苛刻。\n3. 在分布式环境下，由于默认的 MyBatis Cache 实现都是基于本地的，分布式环境下必然会出现 读取到脏数据，需要使用集中式缓存将 MyBatis 的 Cache 接口实现，有一定的开发成本，直 接使用 Redis、Memcached 等分布式缓存可能成本更低，安全性也更高。\n\n\n\n#### 4. 总结\n\n对于访问多的查询请求且用户对查询结果实时性要求不高，此时可采用mybatis二级缓存技术降低数据库访问量，提高访问速度，业务场景比如：耗时较高的统计分析sql、电话账单查询sql等。\n\n实现方法如下：通过设置刷新间隔时间，由mybatis每隔一段时间自动清空缓存，根据数据变化频率设置缓存刷新间隔flushInterval，比如设置为30分钟、60分钟、24小时等，根据需求而定。\n\nmybatis二级缓存对细粒度的数据级别的缓存实现不好，比如如下需求：对商品信息进行缓存，由于商品信息查询访问量大，但是要求用户每次都能查询最新的商品信息，此时如果使用mybatis的二级缓存就无法实现当一个商品变化时只刷新该商品的缓存信息而不刷新其它商品的信息，因为mybaits的二级缓存区域以mapper为单位划分的，当一个商品信息变化会将所有商品信息的缓存数据全部清空。解决此类问题可能需要在业务层根据需求对数据有针对性缓存。", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 43}, "c5c73e12eb47b12416130125cb530328": {"id": "c5c73e12eb47b12416130125cb530328", "item": "实践原理", "title": "Nacos的配置热更新的原理", "date": "2024-08-22", "summary": "Nacos配置热更新的基本原理是通过客户端和Nacos Server之间的长连接实现的。当配置发生变化时，Nacos Server会向订阅了该配置的客户端发送通知，客户端接收到通知后会重新获取最新的配置并更新。", "body": "\n#### 1. Nacos配置热更新的基本原理\n\nNacos配置热更新的基本原理是通过客户端和Nacos Server之间的长连接实现的。当配置发生变化时，Nacos Server会向订阅了该配置的客户端发送通知，客户端接收到通知后会重新获取最新的配置并更新。 具体的步骤如下：\n\n1. Nacos Server：Nacos Server 是一个集中式的配置中心，负责管理所有的配置信息。\n2. Nacos Client：Nacos Client 是应用程序中的一个库，负责与 Nacos Server 进行通信。\n3. 配置注册：应用程序启动时，会使用 Nacos Client 将自己的配置注册到 Nacos Server 上，以便 Nacos Server 知道该应用程序的存在。\n4. 配置监听：应用程序可以通过 Nacos Client 注册一个监听器，用于监听配置的变化。当配置发生变化时，Nacos Server 会通知 Nacos Client，然后 Nacos Client 会触发监听器的回调方法。\n5. 配置更新：当 Nacos Client 接收到配置变化的通知后，会重新从 Nacos Server 获取最新的配置，并更新应用程序的配置。\n6. 配置缓存：为了提高性能，Nacos Client 会缓存配置信息。当配置发生变化时，Nacos Client 会先更新缓存中的配置，然后再触发监听器的回调方法。 \n\n通过上述步骤，Nacos 实现了配置的热更新。应用程序只需要注册监听器，当配置发生变化时，就能够自动获取最新的配置并更新。这样就可以实现应用程序在运行时动态调整配置，而不需要重启应用程序。\n\n\n\n#### 2.  配置热更新的实现细节\n\n- **长连接**\n\nNacos通过使用长连接的方式实现了与客户端的实时通信。通过长连接，Nacos Server能够主动向客户端发送配置变更的通知。\n\n- **订阅与通知**\n\nNacos提供了订阅和通知的机制，客户端可以通过订阅指定的配置来实现热更新。当配置发生变化时，Nacos Server会向订阅了该配置的客户端发送通知。\n\n- **配置的存储和管理**\n\nNacos将配置信息存储在自身的数据库中，并提供了管理接口供用户进行配置的创建、修改和删除等操作。当配置发生变化时，Nacos Server会将最新的配置信息发送给订阅者。\n\n- **配置的获取和更新**\n\n客户端可以通过向Nacos Server发送请求获取最新的配置信息。当配置发生变化时，客户端会收到Nacos Server的通知，并重新向Nacos Server请求最新的配置信息。\n\n\n\n#### 3. SpringBoot中怎么实现热更新？\n\n##### 3.1 实现热更新的两种方式\n\n- **@RefreshScope**\n\n通过 **@Value** 注入后，结合注解 **@RefreshScope** 刷新配置。\n\n过程是在要调用这些变化的配置的类中，通过注解 **@Value** 找到在 **nacos** 中配置的属性，然后在调用这些属性的类上加上注解 **@RefreshScope** 实现配置的自动更新。\n\n\n\n- **@ConfigurationProperties + @EnableConfigurationProperties**\n\n重新定义一个方法或者类(该注解使用于类和方法)，通过注解 **@ConfigurationProperties** 的属性 **prefix** 绑定配置文件中的配置，相当于捕捉到外部的配置信息，@EnableConfigurationProperties 注解实现把配置交给 **spring** 管理，实现配置文件的自动刷新。\n\n\n\n##### 3.2 @RefreshScope做了什么\n\n@RefreshScope主要就是基于@Scope注解的作用域代理的基础上进行扩展实现的，加了@RefreshScope注解的类，在被Bean工厂创建后会加入自己的refresh scope 这个Bean缓存中，后续会优先从Bean缓存中获取，当配置中心发生了变更，会把变更的配置更新到spring容器的Environment中，并且同时bean缓存就会被清空，从而就会从bean工厂中创建bean实例了，而这次创建bean实例的时候就会继续经历这个bean的生命周期，使得@Value属性值能够从Environment中获取到最新的属性值，这样整个过程就达到了动态刷新配置的效果。\n\n\n\n所以截止目前我们可以了解到下述大致流程：\n\n![img](https://pcc.huitogo.club/z0/1676278620132-6b06b93b-a48f-4b97-80b1-ebf437025221.jpeg)\n\n\n\n##### 3.3 @RefreshScope怎么做到的？\n\n基于上面我们知道，@Scope基于缓存失效，实现配置的热更新，我们继续看看它是如何做到的：\n\n![img](https://pcc.huitogo.club/z0/1676278632106-281bcaaf-8b97-4344-bd34-4ea0a57eccf5.png)\n\n- nacosClient和nacosServer通信，nacosClient订阅某个配置的事件，nacosServer在配置更新后会通知nacosClient\n- nacosClient会更新Enviroment并删除refreshScope的bean的缓存，具体是GenericScope\n- nacosClient会publish  RefreshEvent事件由业务方自行实现\n- @RefreshScope注解的Bean会被注册成FactoryBean，getObject获取代理，代理根据scope从GenericScope缓存中取值，如果缓存没有则doCreateBean\n- doCreateBean会根据最新的Enviroment创建Bean，则保证@Value值是最新的\n\n\n\n总结：对于@RefreshScope注解实现配置热更新的流程，实际是借助于缓存失效+Spring重新创建配置Bean解决\n\n\n\n", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 11}, "bcf8530af282a0d72679d1337629bb4a": {"id": "bcf8530af282a0d72679d1337629bb4a", "item": "实践原理", "title": "Seata的AT模式分析", "date": "2024-08-22", "summary": "Seata 的 AT 模式是一种分布式事务解决方案。它基于两阶段提交，一阶段业务数据和回滚日志记录一起提交，二阶段若全局事务成功则提交，失败则根据回滚日志自动回滚。提高了分布式系统中事务处理的效率和可靠性。", "body": "\n**client 端 (TM 和 RM) 和 server端 （TC）**\n\n\n\n1）初始化 client端 和 server端 通过服务发现（nacos、fille、zookeeper等） 发现对方地址 并建立 netty 连接 ，保持心跳连接\n\n\n\n2）TM 端 和 RM在初始化的时候上传自身信息到TC (registerRMChannel、registerTMChannel)\n\n![img](http://pcc.huitogo.club/4a30fe0ae2a30aca06154a956c2f5055)\n\n![img](http://pcc.huitogo.club/67c1dfe79744a3f8def648b2adb75497)\n\n\n\n3）client init 的时候 GlobalTransactionScanner 扫描 @GlobalTransaction 生成代理 AbstractAutoProxyCreator 添加了 GlobalTransactionalInterceptor 拦截逻辑\n\n\n\n**核心方法 TransactionalTemplate.execute**\n\n\n\n开始事务 -- sendRequest到 server端 保存 branch事务信息 （保存数据源信息、建立行锁）\n\n-  client 处理业务 没有发生异常 --> 通知到server端 --> 根据xid 查找关联的branch 事务信息 --> 进行 branch Commit （删除undo_log）\n-  client 处理业务 发生异常 --> 通知到server端 --> 根据xid 查找关联的branch 事务信息 --> 进行branch rollback（回滚并删除undo_log）\n\n![img](http://pcc.huitogo.club/1ffb48d8d2be2f716975ace9bb89d957)", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 2}, "9f7995984d242d9979a4ec52a37d8c23": {"id": "9f7995984d242d9979a4ec52a37d8c23", "item": "实践原理", "title": "SpringBoot-plugin功能扩展", "date": "2024-08-22", "summary": "基于SpringBoot-plugin项目的功能扩展。", "body": "\n#### **1、WebMvc的扩展**\n\n\n\n关键字：**WebMvcConfigurer、ResourceResolver、Resource、DelegatingWebMvcConfiguration**\n\n工具类：Files\n\n\n\n在springboot-plugin中有个静态资源扩展的需求：怎么访问到插件中的静态资源？\n\n具体思路就是先配置插件访问路径拦截规则，也就是声明什么样的请求可以视为对插件静态资源的访问。\n\n\n\n这里我们要实现**WebMvcConfigurer**，定义资源处理规则\n\n\n\n```\n1. public class ResourceWebMvcConfigurer implements WebMvcConfigurer { \n\n2.  \n\n3.   @Override\n\n4.   public void addResourceHandlers(ResourceHandlerRegistry registry) {\n\n5.     String pathPattern = \"/\" + SpringBootStaticResourceExtension.getPluginResourcePrefix() + \"/**\";\n\n6.     // 设置资源请求拦截路径的前缀\n\n7.     ResourceHandlerRegistration resourceHandlerRegistration = registry.addResourceHandler(pathPattern);\n\n8. \n\n9.     // 设置对资源的缓存\n\n10.     CacheControl cacheControl = SpringBootStaticResourceExtension.getCacheControl();\n\n11.     if(cacheControl != null){\n\n12.       resourceHandlerRegistration.setCacheControl(cacheControl);\n\n13.     }else{\n\n14.       resourceHandlerRegistration.setCacheControl(CacheControl.noStore());\n\n15.     }\n\n16.     resourceHandlerRegistration.resourceChain(false).addResolver(new PluginResourceResolver());\n\n17.   }  \n\n18. } \n```\n\n\n\n其次就是在拦截到对应请求后，怎么根据请求路径查找到它对应的资源呢？\n\n\n\n这里我们要实现**ResourceResolver**，定义资源解析规则\n\n\n\n```\n1. public class PluginResourceResolver implements ResourceResolver { \n\n2.  \n\n3.   @Override \n\n4.   public Resource resolveResource(HttpServletRequest request, String requestPath, List<? extends Resource> locations, ResourceResolverChain chain) { \n\n5.     int startIndex = requestPath.startsWith(\"/\") ? 1 : 0;\n\n6.     int endIndex = requestPath.indexOf(\"/\", 1);\n\n7. \n\n8.     if (endIndex != -1) {\n\n9.       String pluginId = requestPath.substring(startIndex, endIndex);\n\n10.       String partialPath = requestPath.substring(endIndex + 1);\n\n11. \n\n12.       PluginStaticResource pluginStaticResource = PLUGIN_STATIC_RESOURCE_MAP.get(pluginId);\n\n13.       if (pluginStaticResource == null) {\n\n14.         return null;\n\n15.       }\n\n16. \n\n17.       // 跟据pluginId计算缓存key\n\n18.       String cacheKey = computeKey(pluginId);\n\n19.       // 有缓存直接取缓存\n\n20.       if (pluginStaticResource.hasCacheResource(pluginId)) {\n\n21.         return pluginStaticResource.getCacheResource(pluginId);\n\n22.       }\n\n23. \n\n24.       Resource resource;\n\n25. \n\n26.       // 基于classpath路径解析出插件Resource\n\n27.       resource = resolveResourceFromClassPath(pluginStaticResource,partialPath);\n\n28.       if(resource != null){\n\n29.         pluginStaticResource.addCacheResourceIfAbsent(cacheKey,resource);\n\n30.         return resource;\n\n31.       }\n\n32. \n\n33.       // 基于File文件路径加载插件Resource\n\n34.       resource = resolveResourceFromFilePath(pluginStaticResource,partialPath);\n\n35.       if(resource != null){\n\n36.         pluginStaticResource.addCacheResourceIfAbsent(cacheKey,resource);\n\n37.         return resource;\n\n38.       }\n\n39. \n\n40.       return null;\n\n41.     }\n\n42.     // 责任链模式\n\n43.     return chain.resolveResource(request, requestPath, locations);\n\n44.   } \n\n45. } \n```\n\n\n\n这里会根据插件中对静态资源的配置（保存路径）PluginStaticResource，从File路径和ClassPath路径两个维度去查找用户需要访问的静态资源Resource。\n\n这里有一点需要说明的是，在MVC和Servlet中用的比较多的一种设计模式是责任链模式，比如说这里的\n\n\n\n```\nreturn chain.resolveResource(request, requestPath, locations);\n```\n\n\n\n也就是当前资源或者路径我加载不了或者匹配不上，可以交由下游去继续执行。\n\n\n\n最后也是最重要的一步就是将我们自定义的WebMvcConfigurer加入到主版本的MVC环境中，这里是**DelegatingWebMvcConfiguration**\n\n\n\n```\n1. @Override \n\n2. public void initialize(ApplicationContext mainApplicationContext) throws Exception { \n\n3.   List<WebMvcConfigurer> webMvcConfigurers = Lists.newArrayList(new ResourceWebMvcConfigurer()); \n\n4.   // webMvc的处理委托类 \n\n5.   DelegatingWebMvcConfiguration delegatingWebMvcConfiguration = mainApplicationContext.getBean(DelegatingWebMvcConfiguration.class); \n\n6.   delegatingWebMvcConfiguration.setConfigurers(webMvcConfigurers); \n\n7. } \n```\n\n\n\n到此WebMvc扩展结束\n\n\n\n#### **2、Mybatis的扩展**\n\n\n\n关键字：**SqlSessionFactoryBean**、**SqlSessionFactory**、**Configuration**、**SqSessionTemplate**、**SqlSession**、**MybatisFactoryBean**\n\n工具类：AnnotationConfigUtils、BeanDefinitionReaderUtils、ScopeMetadataResolver、ResourcePatternResolver、MetadataReaderFactory\n\n\n\n在springboot-plugin有个需求：需要让插件支持Mybatis对数据库操作\n\n前面springboot-plugin原理一节中我们了解到，pluginApplicationContext是个“空房子”，如果要让它支持Mybatis，首先我们需要知道Mybatis的原理是什么？\n\n\n\n正常我们在使用Mybatis的时候，有一个*Mapper.class刚好一个*Mapper.xml文件，然后在*Mapper.xml中写sql执行语句，最后将*Mapper.class类注入到我们待使用的类中。\n\n\n\n那背后的原理是什么呢？\n\n\n\n*Mapper.xml文件会被解析到一个重量级的类Configuration中，其中：\n\n <parameterMap>标签会被解析为 ParameterMap 对象，其中每个子元素会被解析成ParameterMapping对象。\n\n <resultMap>标签会被解析成ResultMap对象，其中每个子元素会被解析成ResultMapping对象。\n\n <select>、<insert>、<update>、<delete>标签都会被解析成MappedStatement对象，标签内的sql会被解析成BoundSql对象。\n\n\n\n*Mapper.class里面的select、insert、delete、update方法会通过*Mapper.xml的namespace标签值 + 方法名进行关联。\n\n\n\n*Mapper.class 真正注入到Spring中是一个MapperFactoryBean，通过getObject返回一个MapperProxy对象，在真正执行的时候，会通过MapperFactoryBean里的SqlSessionFactroy生成SqlSession对象，由SqlSession真正去执行MappedStatement里的SqlSource。\n\n\n\n综上所述，我们实现在插件中支持Mybatis的本质是将插件中的*Mapper.class以MapperFactoryBean的方式装配到pluginApplicationContext中\n\n\n\n首先我们需要SqlSessionFactoryBean去生成SqlSessionFactrory\n\n\n\n```\n1. @Override \n\n2. public void registry(PluginRegistryInfo pluginRegistryInfo) throws Exception { \n\n3.   List<Object> configFileObjects = pluginRegistryInfo.getConfigFileObjects(); \n\n4.   SpringBootMybatisConfig springBootMybatisConfig = getMybatisConfig(configFileObjects); \n\n5.   if (springBootMybatisConfig == null) { \n\n6.     return; \n\n7.   } \n\n8.  \n\n9.   SqlSessionFactoryBean sqlSessionFactoryBean =newSqlSessionFactoryBean(); \n\n10.  \n\n11.   if (springBootMybatisConfig.enableOneselfConfig()) { \n\n12.     // 自己配置SqlSessionFactoryBean \n\n13.     springBootMybatisConfig.oneselfConfig(sqlSessionFactoryBean); \n\n14.   }  else {\n\n15.       // 使用主版本里的SqlSession\n\n16.       ApplicationContext mainApplicationContext = pluginRegistryInfo.getMainApplicationContext();\n\n17.       PluginMybatisCoreConfig pluginMybatisCoreConfig = new PluginMybatisCoreConfig(mainApplicationContext);\n\n18. \n\n19.       DataSource dataSource = pluginMybatisCoreConfig.getDataSource();\n\n20.       if (dataSource != null) {\n\n21.         // 设置数据库连接池     sqlSessionFactoryBean.setDataSource(pluginMybatisCoreConfig.getDataSource());\n\n22.       }\n\n23. \n\n24.       Configuration configuration = pluginMybatisCoreConfig.getMybatisConfiguration();\n\n25.       // 设置Mybatis配置信息\n\n26.       sqlSessionFactoryBean.setConfiguration(configuration);\n\n27. \n\n28.       Interceptor[] interceptors = pluginMybatisCoreConfig.getInterceptors();\n\n29.       if (interceptors != null && interceptors.length > 0) {\n\n30.         // 设置Mybatis自定义插件拦截器信息\n\n31.         sqlSessionFactoryBean.setPlugins(interceptors);\n\n32.       }\n\n33. \n\n34.       DatabaseIdProvider databaseIdProvider = pluginMybatisCoreConfig.getDatabaseIdProvider();\n\n35.       if (databaseIdProvider != null) {\n\n36.         // 设置数据库唯一标识生成器信息\n\n37.     sqlSessionFactoryBean.setDatabaseIdProvider(databaseIdProvider);\n\n38.       }\n\n39. \n\n40.       LanguageDriver[] languageDrivers = pluginMybatisCoreConfig.getLanguageDrivers();\n\n41.       if (languageDrivers != null && languageDrivers.length > 0) {\n\n42.         for (LanguageDriver languageDriver : languageDrivers) {\n\n43.           // 注册Mybatis的自定义sql解析\n\n44.     configuration.getLanguageRegistry().register(languageDriver);\n\n45.         }\n\n46.       }\n\n47.     }\n\n48. \n\n49.     PluginResourceFinder pluginResourceFinder = new PluginResourceFinder(pluginRegistryInfo);\n\n50.     Class<?>[] aliasesClasses = pluginResourceFinder.getAliasesClasses(springBootMybatisConfig.entityPackages());\n\n51.     // 设置数据库实体和别名\n\n52.     sqlSessionFactoryBean.setTypeAliases(aliasesClasses);\n\n53. \n\n54.     Resource[] xmlResources = pluginResourceFinder.getXmlResources(springBootMybatisConfig.xmlLocationsMatch());\n\n55.     // 设置数据库访问xml资源\n\n56.     sqlSessionFactoryBean.setMapperLocations(xmlResources);\n\n57. \n\n58.     // 保存原有的ClassLoader用于后期还原\n\n59.     ClassLoader defaultClassLoader = Resources.getDefaultClassLoader();\n\n60. \n\n61.     try {\n\n  Resources.setDefaultClassLoader(pluginRegistryInfo.getDefaultPluginClassLoader());\n\n62. \n\n63.       SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBean.getObject();\n\n64.       Objects.requireNonNull(sqlSessionFactory);\n\n65. \n\n66.       SqlSessionTemplate sqlSessionTemplate = new SqlSessionTemplate(sqlSessionFactory);\n\n67.       MapperHandler mapperHandler = new MapperHandler();\n\n68.       // 对单个Mapper操作\n\n69.       mapperHandler.processMapper(pluginRegistryInfo, sqlSessionFactory, sqlSessionTemplate);\n\n70. \n\n71.     } finally {\n\n72.       Resources.setDefaultClassLoader(defaultClassLoader);\n\n73.     }\n```\n\n\n\n这里配置SqlSessionFactoryBean一部分是从主版本里Mybatis下的Configuration中取配值信息，比如Mybatis插件、数据源、sql解析器等，另一部分是从插件版本的配置中去取，比如数据库实体类和别名、\\mapper.xml资源。\n\n\n\n取*mapper.xml资源\n\n\n\n```\n1. /** \n\n2. * xmlLocationPath ： 插件配置*Mapper.xml路径 \n\n3. * resourcePatternResolver：PathMatchingResourcePatternResolver Spring的根据路径查找Resource的工具 \n\n4. */ \n\n5.Resource[] loadResources = resourcePatternResolver.getResources(xmlLocationPath); \n```\n\n\n\n取数据库实体类和别名\n\n\n\n```\n1. String resourcePath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + ClassUtils.convertClassNameToResourcePath(packagePattern) + \"/**/*.class\"; \n\n2.  \n\n3.Resource[] packageLoadResources = resourcePatternResolver.getResources(resourcePath); \n\n4. for(Resource resource : packageLoadResources){ \n\n5.   try { \n\n6.     // 读取Resource信息 \n\n7.     ClassMetadata classMetadata = metadataReaderFactory.getMetadataReader(resource).getClassMetadata(); \n\n8.     Class<?> clazz = classLoader.loadClass(classMetadata.getClassName()); \n\n9.     packageEntities.add(clazz); \n\n10.   } catch (ClassNotFoundException e) { \n\n11.     e.printStackTrace(); \n\n12.   } \n\n13. } \n```\n\n\n\n在配置好SqlSessionFactoryBean后，需要将我们的*Maper.class装配到pluginApplicationContext中\n\n\n\n```\n1. for (Class mapperClass : mapperGroupClasses) { \n\n2.   AnnotatedGenericBeanDefinition annotatedGenericBeanDefinition = new AnnotatedGenericBeanDefinition(mapperClass); \n\n3.   // 获取mapperClass中Bean的Scope \n\n4.   ScopeMetadata scopeMetadata = scopeMetadataResolver.resolveScopeMetadata(annotatedGenericBeanDefinition); \n\n5.   annotatedGenericBeanDefinition.setScope(scopeMetadata.getScopeName()); \n\n6.   // 生成BeanName \n\n7.   String mapperBeanName = beanNameGenerator.generateBeanName(annotatedGenericBeanDefinition, pluginApplicationContext); \n\n8.   BeanDefinitionHolder beanDefinitionHolder = new BeanDefinitionHolder(annotatedGenericBeanDefinition, mapperBeanName); \n\n9.  \n\n10.   AnnotationConfigUtils.processCommonDefinitionAnnotations(annotatedGenericBeanDefinition); \n\n11.   // 注册Mapper的BeanDefinition \n\n12.   BeanDefinitionReaderUtils.registerBeanDefinition(beanDefinitionHolder, pluginApplicationContext); \n\n13.  \n\n14.   // 修改BeanDefinition中的MapperClass 到 MapperFactoryBean \n\n15.   doInjectProperties(beanDefinitionHolder, mapperClass, sqlSessionFactory, sqlSessionTemplate); \n\n16.   mapperBeanNames.add(mapperBeanName); \n\n17. } \n```\n\n\n\n其中修改MapperBean的BeanDefinition从MapperClass到MapperFactoryBean\n\n\n\n```\n1. GenericBeanDefinition beanDefinition = (GenericBeanDefinition) holder.getBeanDefinition(); \n\n2. beanDefinition.getConstructorArgumentValues().addGenericArgumentValue(mapperClass); \n\n3.beanDefinition.setBeanClass(org.mybatis.spring.mapper.MapperFactoryBean.class); \n\n4. beanDefinition.getPropertyValues().add(\"addToConfig\", true); \n\n5.beanDefinition.getPropertyValues().add(\"sqlSessionFactory\", sqlSessionFactory); \n\n6. beanDefinition.getPropertyValues().add(\"sqlSessionTemplate\", sqlSessionTemplate); \n\n7. beanDefinition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); \n```\n\n\n\n到此Mybatis的扩展结束。\n\n\n\n#### **3、SpringMVC扩展**\n\n\n\n**关键字：RequestMappingHandlerMapping、RequestMappingInfo**\n\n工具类：ReflectionUtils\n\n\n\n在springboor-plugin有个需求：怎么让插件的Controller可以被外界访问到？\n\n\n\n首先还是说明一下，pluginApplicationContext是一个“空房子”，如果你不对Controller类做特别的处理，它只能作为一个bean躺在pluginApplicationContext里。\n\n而在说明需要做什么处理之前，我们先简单了解一下springMvc的原理，我们的controller是怎么被外界访问到的？\n\n\n\nspringMVC原理图如下：\n\n\n\n![img](http://pcc.huitogo.club/c944ccd15bc83b6703f66904326515d5)\n\n\n\n其中各个流程：\n\n\n\n1）客户端（浏览器）发送请求，直接请求到 DispatcherServlet。\n\n2）DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。\n\n3）解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。\n\n4）HandlerAdapter 会根据 Handler 来调用真正的处理器来处理请求，并处理相应的业务逻辑。\n\n5）处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。\n\n6）ViewResolver 会根据逻辑 View 查找实际的 View。\n\n7）DispaterServlet 把返回的 Model 传给 View（视图渲染）。\n\n8）把View返回给请求者。\n\n\n\n在了解完springMVC的原理后，接下来我们需要做的事情就很简单了，只要把插件版本Controller里的RequestMappingInfo（被@RequestMapping注解的）装配到主版本的HandlerMapping中，这样在外界访问的时候就可以根据HandlerMapping找到插件里的Handler，最后由HandlerAdapter调用插件Handler里的业务逻辑。\n\n\n\n这一部分的代码如下：\n\n\n\n```\n1. /** \n\n2. * 注册当前Controller类到主版本的mvc环境中 \n\n3. * \n\n4. * @param pluginRegistryInfo \n\n5. * @param controllerClass \n\n6. * @return \n\n7. */ \n\n8. private ControllerWrapper doRegistry(PluginRegistryInfo pluginRegistryInfo, Class<?> controllerClass) { \n\n9.   String pluginId = pluginRegistryInfo.getPluginWrapper().getPluginId(); \n\n10.   GenericApplicationContext pluginApplicationContext = pluginRegistryInfo.getPluginApplicationContext(); \n\n11.  \n\n12.   Object controllerBean = pluginApplicationContext.getBean(controllerClass); \n\n13.   ControllerWrapper controllerWrapper = new ControllerWrapper(); \n\n14.   controllerWrapper.setBeanClass(controllerClass); \n\n15.   Set<RequestMappingInfo> requestMappingInfos = Sets.newHashSet(); \n\n16.  \n\n17.   try { \n\n18.     //修改controllerClass中RequestMapping映射路径 \n\n19.     setPathPrefix(pluginId, controllerClass); \n\n20.   // 通过反射获取RequestMappingHandlerMapping的getMappingForMethod字段\n\n21.     Method getMappingForMethod = ReflectionUtils.findMethod(RequestMappingHandlerMapping.class, \"getMappingForMethod\",Method.class,Class.class); \n\n22.     getMappingForMethod.setAccessible(true); \n\n23.  \n\n24.     // 遍历controllerClass所有Method 过滤出被RequestMapping注释的方法 然后注册到主版本的RequestMapping上下文中去 \n\n25.     Method[] targetMethods = controllerClass.getMethods(); \n\n26.     for (Method targetMethod : targetMethods) { \n\n27.       if (isHaveRequestMapping(targetMethod)) { \n\n28.         RequestMappingInfo requestMappingInfo = (RequestMappingInfo) getMappingForMethod.invoke(requestMappingHandlerMapping, targetMethod, controllerClass);   \n\n29.         requestMappingHandlerMapping.registerMapping(requestMappingInfo, controllerBean, targetMethod); \n\n30.         requestMappingInfos.add(requestMappingInfo); \n\n31.       } \n\n32.     } \n\n33.   } catch (Exception e) { \n\n34.     e.printStackTrace(); \n\n35.   } \n\n36.   controllerWrapper.setRequestMappingInfos(requestMappingInfos); \n\n37.   return controllerWrapper; \n\n38. } \n```\n\n\n\n当指定插件被停用的时候，我们还要从版本中移除被停用插件中的RequestMappingInfo\n\n\n\n```\n1. /** \n\n2. * 从主版本的mvc环境中去除Controller \n\n3. */ \n\n4. private void doUnRegistry(ControllerWrapper controllerWrapper){ \n\n5.      Set<RequestMappingInfo> requestMappingInfos = controllerWrapper.getRequestMappingInfos();\n\n6.     if(requestMappingInfos != null && requestMappingInfos.size() > 0) {\n\n7.       requestMappingInfos.forEach(requestMappingHandlerMapping::unregisterMapping);\n\n8.     }\n\n9. } \n```\n\n\n\n到此SpringMVC扩展结束。\n\n\n\n#### **4、yml读取成对象**\n\n\n\n**关键字：YAMLParser、TreeTraversingParser、YAMLFactory**\n\n工具类：ObjectMapper\n\n\n\n在springboot-plugin中有个需求：解析被@ConfigDefinition注解的对象，将ConfigDefinition里value的配置文件的值赋给被@ConfigDefinition注解的对象。\n\n\n\n如下方：\n\n\n\n1. @ConfigDefinition(\"plugin1.yml\")\n2. public class Plugin1Config {\n3. \n4. private String name;\n5. }\n\n\n\n这个类似于这样：\n\n\n\n```\n1. @Configuration \n\n2. public class Plugin1Config { \n\n3.  \n\n4.   @Value(\"name\") \n\n5.   private String name; \n\n6. } \n```\n\n\n\n实现思路就是读取plugin1.yml文件的key-value成一个对象注入到pluginApplicationContext中。\n\n解析plugin.yml文件到对象的代码如下：\n\n\n\n```\n1. /** \n\n2. * 从resource中解析出configDefinitionClass的实体类 \n\n3. * \n\n4. * @param resource plugin.yml文件 \n\n5. * @param configDefinitionClass 被@ConfigDefinition注解的类 \n\n6. * @return \n\n7. * @throws Exception \n\n8. */ \n\n9. @Override \n\n10. protected Object parse(Resource resource, Class configDefinitionClass) throws Exception { \n\n11.   InputStream inputStream = null; \n\n12.   YAMLParser yamlParser = null; \n\n13.   TreeTraversingParser treeTraversingParser = null; \n\n14.  \n\n15.   try { \n\n16.     inputStream = resource.getInputStream(); \n\n17.     yamlParser = yamlFactory.createParser(inputStream); \n\n18.     final JsonNode root = objectMapper.readTree(yamlParser); \n\n19.     if(root == null){ \n\n20.       return configDefinitionClass.newInstance(); \n\n21.     } \n\n22.     treeTraversingParser = new TreeTraversingParser(root); \n\n23.     returnobjectMapper.readValue(treeTraversingParser,configDefinitionClass); \n\n24.   }finally { \n\n25.     if(treeTraversingParser != null){ \n\n26.       treeTraversingParser.close(); \n\n27.     } \n\n28.     if(yamlParser != null){ \n\n29.       yamlParser.close(); \n\n30.     } \n\n31.     if(inputStream != null){ \n\n32.       inputStream.close(); \n\n33.     } \n\n34.   } \n\n35.  \n\n36. } \n```\n\n\n\n注入到pluginApplicationContext的代码如下：\n\n\n\n```\n1. ConfigDefinition configDefinition = configDefinitionClass.getAnnotation(ConfigDefinition.class); \n\n2. if(configDefinition == null){ \n\n3.   return NULL_REGISTER_BEAN; \n\n4. } \n\n5. String fileName = getConfigFileName(configDefinition); \n\n6. Object parseObject; \n\n7. if(fileName == NULL_CONFIG_FILE_NAME){ \n\n8.   parseObject = configDefinitionClass.newInstance(); \n\n9. }else{ \n\n10.   PluginConfigDefinition pluginConfigDefinition = new PluginConfigDefinition(fileName,configDefinitionClass); \n\n11.   parseObject = configurationParser.parse(pluginRegistryInfo,pluginConfigDefinition); \n\n12. } \n\n13.  \n\n14. String beanName = configDefinition.beanName(); \n\n15. if(StringUtils.isNull(beanName)){ \n\n16.   beanName = configDefinitionClass.getName(); \n\n17. } \n\n18. beanName = beanName.concat(\"@\").concat(pluginRegistryInfo.getPluginWrapper().getPluginId()); \n\n19. // 注册到插件的Spring上下文中 \n\n20.super.registerSingleton(beanName,pluginRegistryInfo,parseObject); \n\n21. // 注册到插件信息中 \n\n22. pluginRegistryInfo.addConfigFileObject(parseObject); \n\n23. return beanName; \n```\n\n\n\nyaml读取成对象到此结束。\n\n\n\n#### **5、lambda函数**\n\n\n\n在springboot-plugin中有很多方法的参数是lambda函数，如果使用传统方法的话代码会繁杂和冗余，而使用lambda函数则显得很优雅\n\n\n\n##### （1）Supplier\n\n\n\n在第4节中将plugin.yml读取成对象的前提是找到plugin.yml并将它变成Resource以供下一步的解析操作。\n\n而这个查找操作是有多种方式的，比如从插件配置目录、插件classPath中、插件的根目录下等等。\n\n这个地方设计是可以采用Supplier的，只要一个方式返回了Resource，即认为找到plugin.yml文件。\n\n\n\n相关代码如下：\n\n\n\n```\n1. @Override \n\n2. public ResourceWrapper load(PluginRegistryInfo pluginRegistryInfo){ \n\n3.  \n\n4.   List<Supplier<Resource>> resolveResources = Lists.newArrayList(); \n\n5.   // 想方设法的加载fileName配置文件 \n\n6.   resolveResources.add(findInPluginConfigPath()); \n\n7.   resolveResources.add(findInPluginPath(pluginRegistryInfo)); \n\n8.   resolveResources.add(findInPluginClassPath(pluginRegistryInfo)); \n\n9.  \n\n10.   for (Supplier<Resource> resourceSupplier : resolveResources) { \n\n11.     Resource resource = resourceSupplier.get(); \n\n12.     if (resource.exists()) { \n\n13.       List<Resource> pluginResource = Lists.newArrayList(resource); \n\n14.       ResourceWrapper resourceWrapper = new ResourceWrapper(); \n\n15.       resourceWrapper.addResources(pluginResource); \n\n16.       return resourceWrapper; \n\n17.     } \n\n18.   } \n\n19.  \n\n20.   throw new PluginContextRuntimeException(\"找不到指定的插件配置文件：[\" + fileName + \"]\"); \n\n21. } \n```\n\n\n\n从插件配置目录下查找：\n\n\n\n```\n1. /** \n\n2. * 直接从传入的pluginConfigPath目录下查找fileName文件 \n\n3. * \n\n4. * @return \n\n5. */ \n\n6. private Supplier<Resource> findInPluginConfigPath() { \n\n7.   return () -> { \n\n8.     String filePath = pluginConfigPath + File.separator + fileName; \n\n9.     Resource resource = new FileSystemResource(filePath); \n\n10.     return resource; \n\n11.   }; \n\n12. } \n```\n\n\n\n从插件根目录下查找：\n\n\n\n```\n1. /** \n\n2. * 从加载的插件根目录下查找fileName文件 \n\n3. * \n\n4. * @return \n\n5. */ \n\n6. private Supplier<Resource> findInPluginPath(PluginRegistryInfo pluginRegistryInfo) { \n\n7.   return () -> { \n\n8.     BasePlugin basePlugin = pluginRegistryInfo.getBasePlugin(); \n\n9.     Path pluginPath = basePlugin.getWrapper().getPluginPath(); \n\n10.     String rootPath = pluginPath.getParent().toString(); \n\n11.     String filePath = rootPath + File.separator + fileName; \n\n12.     Resource resource = new FileSystemResource(filePath); \n\n13.     return resource; \n\n14.   }; \n\n15. } \n```\n\n\n\n从插件classPath下查找：\n\n\n\n```\n1. /** \n\n2. * 从插件的运行环境下的 \n\n3. * \n\n4. * @return \n\n5. */ \n\n6. private Supplier<Resource> findInPluginClassPath(PluginRegistryInfo pluginRegistryInfo) { \n\n7. return () -> {\n  ClassLoader pluginClassLoader = pluginRegistryInfo.getDefaultPluginClassLoader();\n  Resource resource = new ClassPathResource(\"/\" + fileName, pluginClassLoader);\n  return resource;\n}; \t\n\n8. } \n```\n\n\n\n##### （2）Function\n\n\n\n对插件初始化的时候会经过一些PluginPreProcessor进行处理，而这些PluginPreProcessor加载和处理是有顺序的，这个顺序是由OrderPriority决定的\n\n\n\n```\n1. public interface PluginPreProcessor { \n\n2.  \n\n3.   /** \n\n4.   * 优先级 \n\n5.   * \n\n6.   * @return \n\n7.   */ \n\n8.   default OrderPriority order(){ \n\n9.     return OrderPriority.getMiddlePriority(); \n\n10.   } \n\n11. } \n```\n\n\n\n我们在执行这些PluginPreProcessor的时候会对它们排序，而这个排序工具类方法则需要将PluginPreProcessor转换成OrderPriority进行处理，这个时候用Function完成转换对代码设计来说是很优雅的\n\n\n\n```\n1. public static <T> Comparator<T> orderPriority(final Function<T, OrderPriority> order){ \n\n2.      return Comparator.comparing(t -> {\n\n3.       OrderPriority orderPriority = order.apply(t);\n\n4.       if(orderPriority == null){\n\n5.         orderPriority = OrderPriority.getLowPriority();\n\n6.       }\n\n7.       return orderPriority.getPriority();\n\n8.     }, Comparator.nullsLast(Comparator.reverseOrder()));\n\n9. } \n```\n\n\n\n##### （3）Consumer\n\n\n\n在向pluginApplicationContext中装配beanDefinition之前，有的时候还需要对beandefinition做一些额外的处理，而这种处理如果用代码来实现的话会非常冗余，这个时候不妨使用一个Consumer来对beanDefinition做最后的处理\n\n\n\n```\n1. protected String register(String beanName,GenericApplicationContext pluginApplicationContext, AnnotatedGenericBeanDefinition beanDefinition, Consumer<AnnotatedGenericBeanDefinition> beanDefinitionConsumer){ \n\n2.  \n\n3.   Objects.requireNonNull(beanName,\"bean名称不能为空\"); \n\n4.  \n\n5.   if(pluginApplicationContext.containsBean(beanName)){ \n\n6.     log.error(\"插件 spring环境中注册bean [{}] 失败：禁止重复注册\",beanName ); \n\n7.     return beanName; \n\n8.   } \n\n9.  \n\n10.   if(beanDefinitionConsumer != null) { \n\n11.     beanDefinitionConsumer.accept(beanDefinition); \n\n12.   } \n\n13.  \n\n14.   pluginApplicationContext.registerBeanDefinition(beanName,beanDefinition); \n\n15.   return beanName; \n\n16. } \n```\n\n\n\nlambda函数结束。\n\n\n\n#### **6、Swagger实时更新**\n\n\n\n**关键字：DocumentationPluginsBootstrapper**\n\n\n\n在springboot-plugin中有个需求：对插件进行启用或者禁用的时候都需要对Swagger文档进行更新\n\n实现思路就是创建个插件事件监听器，在发生启用或者禁用事件的时候去refresh Swagger的上下文\n\n\n\n相关实现代码如下：\n\n\n\n```\n1. public class SwaggerRefreshPluginListener implements PluginListener { \n\n2.  \n\n3.   private final ApplicationContext mainApplicationContext; \n\n4.  \n\n5.   public SwaggerRefreshPluginListener(ApplicationContext mainApplicationContext) { \n\n6.     this.mainApplicationContext = mainApplicationContext; \n\n7.   } \n\n8.  \n\n9.   /** \n\n10.   * 监听插件的注册事件 \n\n11.   * \n\n12.   * @param pluginId 插件Id \n\n13.   * @param isStartInitial 是否是插件初次初始化时的注册事件 \n\n14.   */ \n\n15.   @Override \n\n16.   public void registry(String pluginId, boolean isStartInitial) { \n\n17.     if(isStartInitial){ \n\n18.       return; \n\n19.     } \n\n20.     refresh(); \n\n21.   } \n\n22.  \n\n23.   /** \n\n24.   * 监听插件的注销事件 \n\n25.   * \n\n26.   * @param pluginId \n\n27.   */ \n\n28.   @Override \n\n29.   public void unRegistry(String pluginId) { \n\n30.     refresh(); \n\n31.   } \n\n32.  \n\n33.  \n\n34.   /** \n\n35.   * 刷新Swagger的上下文 \n\n36.   */ \n\n37.   private void refresh(){ \n\n38.     DocumentationPluginsBootstrapper documentationPluginsBootstrapper = mainApplicationContext.getBean(DocumentationPluginsBootstrapper.class); \n\n39.     try { \n\n40.       if(documentationPluginsBootstrapper != null){ \n\n41.         documentationPluginsBootstrapper.stop(); \n\n42.         documentationPluginsBootstrapper.start(); \n\n43.       } \n\n44.     } catch (Exception e) { \n\n45.       e.printStackTrace(); \n\n46.       log.error(\"swagget api实时更新失败：[{}]\",e.getMessage(),e); \n\n47.     } \n\n48.   } \n\n49.  \n\n50. } \n```\n\n\n\nSwagger实时更新结束。\n\n\n\n#### **7、Spring Doc实时更新**\n\n\n\n**关键字：AbstractOpenApiResource、OpenAPIService**\n\n工具类： ClassUtils\n\n\n\n在springboot-plugin中有个需求：对插件进行启用或者禁用的时候都需要对Spring Doc文档进行更新。\n\n实现思路和Swagger不同，Spring Doc更多的是针对Controller层的变换，当发生Controller的变换时才需要进行上下文的刷新。\n\n\n\n相关代码如下：\n\n\n\n```\n1. public class SpringDocControllerProcessorExtension implements PluginControllerExtension { \n\n2.  \n\n3.   private final ApplicationContext applicationContext; \n\n4.  \n\n5.   private List<Class<?>> restControllers; \n\n6.   privateOpenAPIService openAPIService; \n\n7.  \n\n8.   public SpringDocControllerProcessorExtension(ApplicationContext applicationContext) { \n\n9.     this.applicationContext = applicationContext; \n\n10.   } \n\n11.  \n\n12.   @Override \n\n13.   public void initialize() { \n\n14.      AbstractOpenApiResource openApiResource = applicationContext.getBean(AbstractOpenApiResource.class);\n\n15.     if(openApiResource == null){\n\n16.       return;\n\n17.     }\n\n18.     try {\n\n19.       restControllers = (List<Class<?>>)ClassUtils.getReflectionFiled(openApiResource,\"ADDITIONAL_REST_CONTROLLERS\");\n\n20.     } catch (IllegalAccessException e) {\n\n21.       restControllers = null;\n\n22.     }\n\n23.     openAPIService = applicationContext.getBean(OpenAPIService.class);\n\n24.   } \n\n25.  \n\n26.   @Override \n\n27.   public void registry(String pluginId, List<ControllerWrapper> controllerWrappers) throws Exception { \n\n28.     if(restControllers != null){ \n\n29.       controllerWrappers.forEach(controllerWrapper -> restControllers.add(controllerWrapper.getBeanClass())); \n\n30.       this.refresh(); \n\n31.     } \n\n32.   } \n\n33.  \n\n34.   @Override \n\n35.   public void unRegistry(String pluginId, List<ControllerWrapper> controllerWrappers) throws Exception { \n\n36.     if(restControllers != null){ \n\n37.       controllerWrappers.forEach(controllerWrapper -> restControllers.remove(controllerWrapper.getBeanClass())); \n\n38.       this.refresh(); \n\n39.     } \n\n40.   } \n\n41.  \n\n42.   /** \n\n43.   * 刷新springDoc上下文 \n\n44.   */ \n\n45.   private void refresh(){ \n\n46.     if(openAPIService != null){ \n\n47.       openAPIService.setCachedOpenAPI(null); \n\n48.       openAPIService.resetCalculatedOpenAPI(); \n\n49.     } \n\n50.   } \n\n51. } \n```\n\n\n\nSpring Doc实时更新结束。\n\n\n\n#### **8、Thymeleaf扩展**\n\n\n\n在springboot-plugin中有个需求：让插件支持thymeleaf功能，也就是插件中thymeleaf可以被正常的解析和访问。\n\n对于Thymeleaf，类似于Freemarker，如果需要它正确识别出你需要访问的资源，需要TemplateEngine根据ITemplateResolver 去解析用户需要访问的资源。\n\n对于TemplateEngine，我们可以直接从主版本中提取，我们需要自定义ItemplateResolver解析规则，然后将它注册到TemplateEngine中。\n\n\n\n在插件初始化的时候：\n\n\n\n```\n1. public void registry(PluginRegistryInfo pluginRegistryInfo) throws Exception { \n\n2.   SpringTemplateEngine springTemplateEngine = getSpringTemplateEngine(pluginRegistryInfo); \n\n3.   if(springTemplateEngine == null){ \n\n4.     return; \n\n5.   } \n\n6.   SpringBootThymeleafConfig springBootThymeleafConfig = getThymeleafConfig(pluginRegistryInfo); \n\n7.   if(springBootThymeleafConfig == null){ \n\n8.     return; \n\n9.   } \n\n10.   ThymeleafConfig thymeleafConfig = new ThymeleafConfig(); \n\n11.   springBootThymeleafConfig.config(thymeleafConfig); \n\n12.   // 校验用户自定义的thymeleafConfig \n\n13.   verifyThymeleafConfig(thymeleafConfig); \n\n14.  \n\n15.   ClassLoader pluginClassLoader = pluginRegistryInfo.getDefaultPluginClassLoader(); \n\n16.   ClassLoaderTemplateResolver templateResolver =newClassLoaderTemplateResolver(pluginClassLoader); \n\n17.  \n\n18.   // 配置资源解析规则 \n\n19.   templateResolver.setCacheable(thymeleafConfig.isCache()); \n\n20.   templateResolver.setPrefix(thymeleafConfig.getPrefix()); \n\n21.   templateResolver.setSuffix(thymeleafConfig.getSuffix()); \n\n22.   templateResolver.setTemplateMode(thymeleafConfig.getMode()); \n\n23.   if(thymeleafConfig.getEncoding() != null){ \n\n24.     templateResolver.setCharacterEncoding(thymeleafConfig.getEncoding().name()); \n\n25.   } \n\n26.   if(thymeleafConfig.getTemplateResolverOrder() != null){ \n\n27.     templateResolver.setOrder(thymeleafConfig.getTemplateResolverOrder()); \n\n28.   } \n\n29.   templateResolver.setCheckExistence(true); \n\n30.  \n\n31.   springTemplateEngine.addTemplateResolver(templateResolver); \n\n32.  \n\n33.   pluginRegistryInfo.addExtension(PLUGIN_THYMELEAF_TEMPLATE_RESOLVER_KEY,templateResolver); \n\n34. } \n```\n\n\n\n当插件禁用的时候：\n\n\n\n```\n1. @Override \n\n2. public void unRegistry(PluginRegistryInfo pluginRegistryInfo) throws Exception { \n\n3.  \n\n4.   ClassLoaderTemplateResolver templateResolver = (ClassLoaderTemplateResolver)pluginRegistryInfo.getExtension(PLUGIN_THYMELEAF_TEMPLATE_RESOLVER_KEY); \n\n5.   if(templateResolver == null){ \n\n6.     return; \n\n7.   } \n\n8.   SpringTemplateEngine springTemplateEngine = getSpringTemplateEngine(pluginRegistryInfo); \n\n9.   Set<ITemplateResolver> springTemplateResolvers = getSpringTemplateResolvers(springTemplateEngine); \n\n10.   if(springTemplateResolvers != null){ \n\n11.     springTemplateResolvers.remove(templateResolver); \n\n12.   } \n\n13. } \n```\n\n\n\nThymeleaf扩展结束。", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 2}, "2721ff25da3997d86fac2f9c541e901a": {"id": "2721ff25da3997d86fac2f9c541e901a", "item": "实践原理", "title": "SpringBoot自动配置原理", "date": "2024-08-22", "summary": "Spring Boot 自动配置原理是利用条件注解和自动配置类。它在启动时扫描类路径，根据特定条件判断是否需要加载相应配置。通过读取配置文件和依赖中的元数据，自动配置相关组件，极大地简化了开发过程，提高了开发效率。", "body": "\n#### 1. SpringBoot启动类\n\n当SpringBoot应用启动的时候，就从主方法里面进行启动的\n\n```\n1. @SpringBootApplication \n\n2. public class SpringBoot02ConfigAutoconfigApplication { \n\n3.  \n\n4.   public static void main(String[] args) { \n\n5.     SpringApplication.run(SpringBoot02ConfigAutoconfigApplication.class, args); \n\n6.   } \n\n7. } \n```\n\n\n\n它主要加载了@SpringBootApplication注解主配置类，这个@SpringBootApplication注解主配置类里边最主要的功能就是SpringBoot开启了一个@EnableAutoConfiguration注解的自动配置功能。\n\n\n\n#### 2. @EnableAutoConfiguration的作用\n\n它主要利用了一个EnableAutoConfigurationImportSelector选择器给Spring容器中来导入一些组件。\n\n```\n1. @Import(EnableAutoConfigurationImportSelector.class) \n\n2. public @interface EnableAutoConfiguration  \n```\n\n\n\n#### 3. 那么导入了哪些组件呢？\n\n我们来看EnableAutoConfigurationImportSelector这个类的父类AutoConfigurationImportSelector\n\n\n\n这个类规定了一个方法叫selectImports这个方法，查看了selectImports这个方法里面的代码内容就能知道导入了哪些组件了。\n\n```\n1. public String[] selectImports(AnnotationMetadata annotationMetadata) { \n\n2.   if (!this.isEnabled(annotationMetadata)) { \n\n3.     return NO_IMPORTS; \n\n4.   } else { \n\n5.     try { \n\n6.       ... \n\n7.       List<String> configurations = this.getCandidateConfigurations(annotationMetadata, attributes); \n\n8.       ... \n\n9.     } catch (IOException var6) { \n\n10.       throw new IllegalStateException(var6); \n\n11.     } \n\n12.   } \n\n13. } \n\n14.  \n\n15. protected List<String> getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) { \n\n16.   List<String> configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader()); \n\n17.  ... \n\n18. } \n```\n\n- 方法中的getCandidateConfigurations方法，其返回一个自动配置类的类名列表\n\n\n\n#### 4. 那么会得到什么资源？\n\n它是扫描java jar包类路径下的“META-INF/spring.factories”这个文件\n\n```\n1. /** \n\n2. * The location to look for factories. \n\n3. * <p>Can be present in multiple JAR files. \n\n4. */ \n\n5. public static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\"; \n```\n\n\n\n**那么扫描到的这些文件作用**：是把这个文件的urls拿到之后并把这些urls每一个遍历，最终把这些文件整成一个properties对象\n\n```\n1. public static List<String> loadFactoryNames(Class<?> factoryClass, ClassLoader classLoader) { \n\n2.   String factoryClassName = factoryClass.getName(); \n\n3.   try { \n\n4.     Enumeration<URL> urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : \n\n5.         ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); \n\n6.     List<String> result = new ArrayList<String>(); \n\n7.     while (urls.hasMoreElements()) { \n\n8.       URL url = urls.nextElement(); \n\n9.       Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); \n\n10.       String factoryClassNames = properties.getProperty(factoryClassName); \n\n11.       result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); \n\n12.     } \n\n13.     return result; \n\n14.   } \n\n15.     ... \n\n16. } \n```\n\n\n\n它是将文件下的指定factoryClassName相关的值放到List<String>中去并返回。\n\n\n\n我们先看一下这个spring.factories文件长啥样\n\n![img](http://pcc.huitogo.club/0fd1c8425fc1b82ef65b5ea085a2454a)\n\n\n\n相当于一个属性文件，那么loadFactoryNames方法是根据哪个factoryClassName获取它的值呢？\n\n```\n1. protected Class<?> getSpringFactoriesLoaderFactoryClass() { \n\n2.   return EnableAutoConfiguration.class; \n\n3. } \n```\n\n\n\n所以，**@EnableAutoConfiguration的目的就是将META-INF/spring.factories中跟org.springframework.boot.autoconfigure.EnableAutoConfiguration有关的类注入到Spring容器中。**\n\n 其内部实现的关键点有\n\n- ImportSelector 该接口的方法的返回值都会被纳入到spring容器管理中\n- SpringFactoriesLoader 该类可以从classpath中搜索所有META-INF/spring.factories配置文件，并读取配置\n\n\n\n最后我们容器中会添加很多类，比如\n\n![img](http://pcc.huitogo.club/a157d1ae277f35cedb76cabb9476bffa)\n\n\n\n#### 5. 添加很多类到容器中是为了什么？\n\n加入到容器中之后的作用就是**用它们来做自动配置**，这就是Springboot自动配置之源，也就是自动配置的开始，只有这些自动配置类进入到容器中以后，接下来这个自动配置类才开始进行启动。\n\n\n\n#### 6. 那什么是自动配置？\n\n简单说\n\n![img](http://pcc.huitogo.club/d0819ccbe118f5c09c0e0e860f319fec)\n\n\n\n就是这些配置文件怎么生效的！为什么你不用写配置文件或者配置代码了，因为人家SprintBoot自动给你配置了，懂了没？就是将这些配置文件里面的选项变成一个个Bean被我们所用。\n\n\n\n#### 7. 如何自动配置\n\n终于回到了我们的主题\n\n\n\n这就是题5的答案，借助通过@EnableAutoConfiguration注入过来的那么多的类。我们随便打开一个文件看看它是怎么做的吧\n\n\n\n比如我们常见的MybatisAutoConfiguration\n\n```\n@org.springframework.context.annotation.Configuration\n@ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class})\n@ConditionalOnBean({DataSource.class})\n@EnableConfigurationProperties({MybatisProperties.class})\n@AutoConfigureAfter({DataSourceAutoConfiguration.class})\npublic class MybatisAutoConfiguration\n{\n  private static final Logger logger = LoggerFactory.getLogger(MybatisAutoConfiguration.class);\n  private final MybatisProperties properties;\n  private final Interceptor[] interceptors;\n  private final ResourceLoader resourceLoader;\n  private final DatabaseIdProvider databaseIdProvider;\n  private final List<ConfigurationCustomizer> configurationCustomizers;\n```\n\n- @Spring的Configuration是一个通过注解标注的springBean，\n- @ConditionalOnClass({ SqlSessionFactory.class, SqlSessionFactoryBean.class})这个注解的意思是：当存在SqlSessionFactory.class, SqlSessionFactoryBean.class这两个类时才解析MybatisAutoConfiguration配置类,否则不解析这一个配置类。我们需要mybatis为我们返回会话对象，就必须有会话工厂相关类\n- @CondtionalOnBean(DataSource.class):只有处理已经被声明为bean的dataSource\n- @ConditionalOnMissingBean(MapperFactoryBean.class)这个注解的意思是如果容器中不存在name指定的bean则创建bean注入，否则不执行\n\n\n\n以上配置可以保证sqlSessionFactory、sqlSessionTemplate、dataSource等mybatis所需的组件均可被自动配置，@Configuration注解已经提供了Spring的上下文环境，所以以上组件的配置方式与Spring启动时通过mybatis.xml文件进行配置起到一个效果。\n\n**只要一个基于SpringBoot项目的类路径下存在SqlSessionFactory.class, SqlSessionFactoryBean.class，并且容器中已经注册了dataSourceBean，就可以触发自动化配置**，意思说我们**只要在maven的项目中加入了mybatis所需要的若干依赖，就可以触发自动配置**，但引入mybatis原生依赖的话，每集成一个功能都要去修改其自动化配置类，那就得不到开箱即用的效果了。所以Spring-boot为我们提供了统一的starter可以直接配置好相关的类，触发自动配置所需的依赖(mybatis)如下：\n\n```\n<dependency>\n            <groupId>org.mybatis.spring.boot</groupId>\n            <artifactId>mybatis-spring-boot-starter</artifactId>\n</dependency>\n```\n\n因为maven依赖的传递性，我们只要依赖starter就可以依赖到所有需要自动配置的类，实现开箱即用的功能。也体现出Springboot简化了Spring框架带来的大量XML配置以及复杂的依赖管理，让开发人员可以更加关注业务逻辑的开发。\n\n\n\n其他的*AutoConfiguration类都是类似的。\n\n\n\n#### 8. 怎么关闭自动配置？\n\n只有spring.boot.enableautoconfiguration为true（默认为true）的时候，才启用自动配置，所以我们可以配置spring.boot.enableautoconfiguration=false禁用自动配置。\n\n @EnableAutoConfiguration还可以进行排除，排除方式有2中，一是根据class来排除（exclude），二是根据class name（excludeName）来排除", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 2}, "253115bae179e2b3abe4da1a3e45040f": {"id": "253115bae179e2b3abe4da1a3e45040f", "item": "实践原理", "title": "Spring怎么解决循环依赖", "date": "2024-08-22", "summary": "Spring 解决循环依赖主要通过三级缓存。当创建 Bean 时，若发生循环依赖，先从一级缓存找，没有则创建实例放入二级缓存，提前暴露对象引用。等属性注入时从缓存获取依赖对象，完成创建后放入一级缓存，从而有效解决循环依赖问题。", "body": "\n默认情况下，Spring不允许循环依赖，如果存在循环依赖，会抛出`BeanCurrentlyInCreationException`异常。这是因为Spring默认使用构造函数注入或者setter注入的方式创建Bean，如果两个Bean之间存在循环依赖，则无法满足其中一个Bean的创建要求。\n\n但是，在某些情况下，循环依赖是必要的。例如，两个Bean需要相互引用对方的属性或方法才能正常工作。这时，可以将`allowCircularReferences`属性设置为true，允许循环依赖的存在。\n\n当`allowCircularReferences`属性设置为true时，Spring会使用一个特殊的方式创建Bean，即使用代理对象来解决循环依赖的问题。这种方式可以满足循环依赖的要求，但同时也会带来一些额外的性能开销和复杂性。\n\n需要注意的是，循环依赖可能导致一些问题，例如**无限递归**、**死锁**等，因此建议在确保必要性的情况下才使用循环依赖。\n\n\n\nSpring 循环依赖的**场景**有两种：\n\n1. 构造器的循环依赖。\n2. field 属性的循环依赖。\n\n对于构造器的循环依赖，Spring 是无法解决的，只能抛出 `BeanCurrentlyInCreationException` 异常表示循环依赖，**所以下面我们分析的都是基于 field 属性的循环依赖**。\n\n> 注：如果项目中不可避免需要使用循环依赖，则必须使用setter注入替代构造器注入。\n\n\n\n另外Spring 只解决 scope 为 singleton 的循环依赖。对于scope 为 prototype 的 bean ，Spring 无法解决，直接抛出 `BeanCurrentlyInCreationException` 异常。\n\n为什么 Spring 不处理 prototype bean 呢？其实如果理解 Spring 是如何解决 singleton bean 的循环依赖就明白了。这里先卖一个关子，我们先来关注 Spring 是如何解决 singleton bean 的循环依赖的。\n\n\n\n存在循环依赖的场景下的getBean顺序图：\n\n![img](http://pcc.huitogo.club/258fb9ad86259c92030ee4cbb9f68a44)\n\n总结：**借助三个缓存，第一个缓存存储bean实例，第二个缓存存储bean的半成品，第三个缓存存储bean的工厂（避免多次调用bean的创建工厂）**\n\n\n\n源码：\n\n```\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\n    //先存singletonObjects中获取bean，\n    Object singletonObject = this.singletonObjects.get(beanName);\n    //如果bean不存在，并且bean正在创建中\n    if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {\n        synchronized (this.singletonObjects) {\n            //从earlySingletonObjects中获取\n            singletonObject = this.earlySingletonObjects.get(beanName);\n            //如果earlySingletonObjects不存在(allowEarlyReference默认为true)\n            if (singletonObject == null && allowEarlyReference) {\n                //获取singletonFactories\n                ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);\n                if (singletonFactory != null) {\n                    //从singletonFactories中获取bean\n                    singletonObject = singletonFactory.getObject();\n                    //添加到earlySingletonObjects\n                    this..put(beanName, singletonObject);\n                    this.singletonFactories.remove(beanName);\n                }\n            }\n        }\n    }\n    return (singletonObject != NULL_OBJECT ? singletonObject : null);\n}\n\npublic boolean isSingletonCurrentlyInCreation(String beanName) {\n    return this.singletonsCurrentlyInCreation.contains(beanName);\n}\n```\n\n- singletonObjects（成熟体）：缓存key = beanName, value = bean；这里的bean是已经创建完成的，该bean经历过实例化->属性填充->初始化以及各类的后置处理。因此，一旦需要获取bean时，我们第一时间就会寻找一级缓存\n- earlySingletonObjects（半成品）：缓存key = beanName, value = bean；这里跟一级缓存的区别在于，该缓存所获取到的bean是提前曝光出来的，是还没创建完成的。也就是说获取到的bean只能确保已经进行了实例化，但是属性填充跟初始化还没有做完(AOP情况后续分析)，因此该bean还没创建完成，仅仅能作为指针提前曝光，被其他bean所引用\n- singletonFactories（制品工厂）：该缓存key = beanName, value = beanFactory；在bean实例化完之后，属性填充以及初始化之前，如果允许提前曝光，spring会将实例化后的bean提前曝光，也就是把该bean转换成beanFactory并加入到三级缓存。在需要引用提前曝光对象时再通过singletonFactory.getObject()获取。\n\n> 注：三个缓存查找是从上到下，创建是从下到上\n\n\n\n***Q1：为什么不能解决原型模式的循环依赖？***\n\n因为原型模式没有办法提前曝光，初始化A的时候就拿不到指定的B，最后就是死循环\n\n\n\n***Q2：能不能把三个缓存缩减到两个缓存？***\n\n这个问题考虑的是能不能去除singletonFactories缓存，只在earlySingletonObjects里面放一个半成品？\n\n答案是不行\n\n我们要知道Spring里面获取Bean并不一定都是原始对象，也有可能是增强代理，即AOP，所以我们需要考虑B生成的方式，即在找不到B的时候我们第一步应该去找它的生成工厂\n\n这个增强获取代理的逻辑见`#getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean)` 方法\n\n```\n// AbstractAutowireCapableBeanFactory.java\n\n/**\n * 对创建的早期半成品（未初始化）的 Bean 处理引用\n *\n * 例如说，AOP 就是在这里动态织入，创建其代理 Bean 返回\n *\n * Obtain a reference for early access to the specified bean,\n * typically for the purpose of resolving a circular reference.\n * @param beanName the name of the bean (for error handling purposes)\n * @param mbd the merged bean definition for the bean\n * @param bean the raw bean instance\n * @return the object to expose as bean reference\n */\nprotected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {\n\tObject exposedObject = bean;\n\tif (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {\n\t\tfor (BeanPostProcessor bp : getBeanPostProcessors()) {\n\t\t\tif (bp instanceof SmartInstantiationAwareBeanPostProcessor) {\n\t\t\t\tSmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;\n\t\t\t\texposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);\n\t\t\t}\n\t\t}\n\t}\n\treturn exposedObject;\n}\n```\n", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 5}, "931e47aba40955587e9eeb7bead0a2a2": {"id": "931e47aba40955587e9eeb7bead0a2a2", "item": "实践原理", "title": "Spring生命周期", "date": "2024-08-22", "summary": "Spring 生命周期主要分为创建 Bean 实例、依赖注入、初始化、使用和销毁阶段。创建时通过反射机制实例化对象，接着进行属性注入。初始化阶段可执行自定义初始化方法。使用过程中为程序提供服务，容器关闭时执行销毁方法进行资源清理。", "body": "\n关于Spring生命周期，网上的流程图千奇百怪，比如这样的\n\n![img](http://pcc.huitogo.club/b0148eae30ec83be7a84efb5e2ba0a7c)\n\n\n\n下面是我自己总结的一张图，可以对比着看\n\n![img](http://pcc.huitogo.club/9a2b1a2a32a69ca2b4cc022acafbef8f)\n\n\n\n#### 1. 加载相关构造器\n\n这个部分没什么说的，在做这件事之前肯定要将主要涉及的类实例化起来，比如InstantiationAwareBeanPostProcessor、BeanPostProcessor、BeanFactoryPostProcessor这些类和子类（我们扩展的类）\n\n\n\n值得一提的就是在实例化这些相关类后，会执行BeanFactoryPostProcessor.postProcessBeanFactory()这个方法，用来在正式装配Bean之前对装配工厂BeanFactory进行一些设置，也可以通过FactoryBean提前注入我们需要的类。\n\n\n\n#### 2. 实例化\n\n实例化过程类似于我们Java中的new Object()\n\n\n\n但是在Spring框架中这个过程是通过反射实现的\n\n在实例化中主要影响相关的就是InstantiationAwareBeanPostProcessor类\n\n- **实例化前**：InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()\n- **实例化**：使用反射生成，如果Bean是通过构造器注入的话会使用带参构造方法反射生成\n- **实例化后**：InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation()\n\n\n\n#### 3. 填充属性\n\n比如说典型的xml中配置\n\n```\n1. <bean id = \"personService\" class=\"cn.zhanghui.demo.daily.my_spring.beanfactory_set.test.service.PersonService\"> \n\n2.   <property name=\"eatDao\" ref=\"eatDao\" /> \n\n3.   <property name=\"drinkDao\" ref=\"drinkDao\" /> \n\n4.   <property name=\"name\" value=\"zhanghui\" /> \n\n5.   <property name=\"age\" value=\"18\" /> \n\n6. </bean> \n```\n\n\n\n这些property就会在这个阶段被设置到上个阶段实例化后的Bean中\n\n\n\n在设置属性过程中主要的方法就是\n\n- **设置属性前**：InstantiationAwareBeanPostProcessor.postProcessPropertyValues()\n- **设置属性时**如果是按上述xml配置的话，会调用Bean的set方法为它设置属性。\n\n\n\n除了set设置属性外，还有构造器实例化时设置属性和注解设置属性。\n\n当然我们可以通过一些接口获取Spring容器的属性\n\n比如\n\n- BeanNameAware.setBeanName：获取和设置beanName属性\n- BeanFactoryAware.setBeanFactory：获取和设置beanFactory属性\n\n\n\n#### 4. 初始化\n\n现在Bean已经实例化了，里面属性已经设置好了，已经是一个成熟的Bean了，但是我们还是希望它在正式使用前能再包装一下，也就是初始化过程。\n\n\n\n初始化相关的类典型代表就是BeanPostProcessor\n\n- **全局Bean初始化之前**：BeanPostProcessor.postProcessBeforeInitialization()\n- **不常用的单个Bean初始化之前**：InitializingBean.afterPropertiesSet()\n- **常用的单个Bean初始化前**：\n\n在xml中配置\n\n```\n1. <bean id=\"user\" class=\"cn.zhanghui.demo.daily.spring.lifestyle.User\" init-method=\"myInit\" /> \n```\n\n用注解的话就是@PostConstruct\n\n- **全局Bean初始化之后**：BeanPostProcessor.postProcessAfterInitialization()\n\n\n\n#### 5. 使用Bean\n\n初始化后的Bean就可以正式被我们使用了，比如ApplicationContext.getBean()\n\n还有常见的@Autowired、@Resource注入的Bean\n\n当然这个Bean是在它的scope范围内使用的，常见的是singleton，只要Spring Container不关闭，我就一直在\n\n\n\n#### 6. 销毁\n\nBean走到了scope尽头了，或者容器关闭了，那么Bean应该被正确的销毁。\n\n销毁针对单个Bean\n\n- **不常用的单个Bean销毁之前**：DisposableBean.destroy()\n- **常用的单个Bean销毁之前**：\n\n在xml中配置\n\n```\n1. <bean id=\"user\" **class**=\"cn.zhanghui.demo.daily.spring.lifestyle.User\" destroy-method=\"myDestory\" /> \n```\n\n用注解的话就是@PreDestroy\n\n\n\n#### 7. 总结\n\n![img](http://pcc.huitogo.club/b2d197f9ebc2bc749f59d481729e8b52)\n\n\n\n- **Bean 自身的方法**：如调用 Bean 构造函数实例化 Bean，调用 Setter 设置 Bean 的属性值以及通过的 init-method 和 destroy-method 所指定的方法；\n\n- **Bean 级生命周期接口方法**：如 BeanNameAware、 BeanFactoryAware、 InitializingBean 和 DisposableBean，这些接口方法由 Bean 类直接实现；\n\n- **容器级生命周期接口方法**：在上图中带“★” 的步骤是由 InstantiationAwareBean PostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“ 后处理器” 。 后处理器接口一般不由 Bean 本身实现，它们独立于 Bean，实现类以容器附加装置的形式注册到 Spring 容器中并通过接口反射为 Spring 容器预先识别。当Spring 容器创建任何 Bean 的时候，这些后处理器都会发生作用，所以这些后处理器的影响是全局性的。当然，用户可以通过合理地编写后处理器，让其仅对感兴趣Bean 进行加工处理。\n\n\n\n**总结**过来就是\n\nSpring真的是一个扩展性极高的容器，从本章Bean生命周期的过程就可以看的出来，我们几乎可以在Bean的任意时期做一些什么事情，当然基本开发的话是不会考虑这些过程，主要还是对框架研发的时候。", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 1}, "d3830ef3de46141665b15ab0b90cc83a": {"id": "d3830ef3de46141665b15ab0b90cc83a", "item": "实践原理", "title": "一次成功的elasticsearch数据迁移", "date": "2024-08-22", "summary": "记录一次成功的elasticsearch数据迁移过程", "body": "\n记录一次成功的elasticsearch数据迁移，将windows上的elasticsearch迁移到linux上，两个elasticsearch的版本都是7.5.0\n\n使用的方式是基于快照的方式，本地生成一个数据快照，然后发送到远程，然后远程再存储一下这个快照就可以了\n\n1、在windows端\n\n1）声明本地快照仓库地址\n\n需要修改config下的elasticsearch.yml文件，修改如下\n\n![img](http://pcc.huitogo.club/cd1d04bc756f62fd23328f0703e541c2)\n\n这里/backup的目录在elasticsearch安装目录下的根目录下，比如elasticsearch安装在C盘下，这里的/backup就是C:/backup；在linux下不会这样\n\n\n\n2）注册快照仓库\n\n可以通过curl的方式，我这里使用的是postman\n\n![img](http://pcc.huitogo.club/df11aae2d98fac39986647ab15509763)\n\n这里my_backup就是仓库名称\n\n可以通过下面验证\n\n![img](http://pcc.huitogo.club/76b2597b6e8bb0a2a66000e748ea0add)\n\n\n\n3）生成快照\n\n![img](http://pcc.huitogo.club/0153c70e698d13a14dfba9fc3be90bc7)\n\n这里index_name就是索引名称了，如果不知道索引名称的话可以搭建Kibana查看。\n\n然后进入/backup所在的目录，即可看到生成的索引文件。\n\n\n\n2、linux端\n\n1）声明本地快照仓库地址\n\n修改elasticsearch.yml文件\n\n![img](http://pcc.huitogo.club/1cc3ccf5c0727ec4f9a3f8c60006f5d6)\n\n\n\n2）注册快照仓库\n\n```\ncurl -XPUT http://127.0.0.1:9200/_snapshot/my_backup -H \"Content-Type: application/json\" -d '{\"type\": \"fs\",\"settings\":{\"location\":\"/usr/backup\",\"compress\":\"true\"}}'\n```\n\n这里使用curl方式，my_backup仓库名称，不要求和windows端一致，主要是location。\n\n然后将windows生成的索引文件通过ftp工具传到Linux端仓库中，这里是/usr/backup下。\n\n\n\n3）存储快照\n\n```\ncurl -XPOST http://127.0.0.1:9200/_snapshot/my_backup/index_name/_restore\n```\n\n这里index_name就是索引名称了。\n\n\n\n如果显示index_name存在的情况下，需要先删除索引\n\n```\ncurl -XDELETE http://127.0.0.1:9200/post\n```\n\n\n\n到此完成了。", "imgFile": "03.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 2}}, "造轮子系列": {"78af2184812195387b89ed1e9c393935": {"id": "78af2184812195387b89ed1e9c393935", "item": "造轮子系列", "title": "七天写一个Spring框架（一）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第一天", "body": "\n今天实现的类图\n\n在spring-beans中的实现\n\n![img](http://pcc.huitogo.club/ad113a06e1facacd9ff212e09a42c1d6)\n\n\n\n在spring-context中的实现\n\n![img](http://pcc.huitogo.club/8f79d598c22af10d2b5ae78e59e551fc)\n\n\n\n第二天我们的目标是\n\n#### **1、分割DefaultBeanFactory**\n\n将解析xml和装载Bean的过程和暴露出去的获取bean过程分割开来，毕竟我们希望暴露给别人使用的部分越简单越好。\n\n这里我们定义一个接口去操作beanDefinition，让原有的BeanFacory只做getBean()操作\n\n```\n1.  public interface BeanDefinitionRegistry {  \n\n2.      BeanDefinition getBeanDefinition(String id);  \n\n3.      void registryBeanDefinition(String id, BeanDefinition bd);  \n\n4.  } \n```\n\n\n\n我们需要一个类去解析xml配置文件，然后调用上面BeanDefinitionRegistry接口的registryBeaDefinition()方法，前提是这个类有BeanDefinitionRegistry的实例，我们可以在构造方法里面给它赋值。\n\n我们新增**XmlBeanDefinitionReader**类\n\n```\n1.  public class XmlBeanDefinitionReader {  \n\n2.      public static final String ID_ATTRIBUTE = \"id\";  \n\n3.      public static final String CLASS_ATTRIBUTE = \"class\";  \n\n4.      public static final String SCOPE_ATTRIBUTE = \"scope\";  \n\n5.      BeanDefinitionRegistry registry;  \n\n6.      public XmlBeanDefinitionReader(BeanDefinitionRegistry registry) {  \n\n7.          this.registry = registry;  \n\n8.      }  \n\n9.      public void loadBeanDefinition(Resource resource) { // 修改一  \n\n10.         InputStream is = null;  \n\n11.         try {  \n\n12.             is = resource.getInputStream();  \n\n13.             SAXReader reader = new SAXReader();  \n\n14.             Document doc = reader.read(is);  \n\n15.             Element root = doc.getRootElement();  \n\n16.             Iterator<Element> itr = root.elements().iterator();  \n\n17.             while (itr.hasNext()) {  \n\n18.                 Element ele = itr.next();  \n\n19.                 String id = ele.attributeValue(ID_ATTRIBUTE);  \n\n20.                 String beanClassName = ele.attributeValue(CLASS_ATTRIBUTE);  \n\n21.                 BeanDefinition bd = new GenericBeanDefinition(id, beanClassName);  \n\n22. //              if(ele.attribute(SCOPE_ATTRIBUTE) != null) {  // 判断bean的scope  // 修改二  \n\n23. //                  bd.setScope(ele.attributeValue(SCOPE_ATTRIBUTE));  \n\n24. //              }  \n\n25. // 这里用BeanDefinitionRegistry 替代了container  \n\n26.                 this.registry.registryBeanDefinition(id, bd);   /\n\n27.             }  \n\n28.         } catch (DocumentException | IOException e) {  \n\n29.             throw new BeanStoreException(\"configFile is valid xml file!\");  \n\n30.         } finally {  \n\n31.             if (is != null) {  \n\n32.                 try {  \n\n33.                     is.close();  \n\n34.                 } catch (IOException e) {  \n\n35.                     e.printStackTrace();  \n\n36.                 }  \n\n37.             }  \n\n38.         }  \n\n39.     }  \n\n40. }  \n```\n\n\n\n整体步骤跟之前DefaultBeanFactory的地方差不多，但是多了两个改动（修改一和修改二），后面再说，也是这次的目标\n\n到此解析xml的流程就做完了，然后就是让DefaultBeanFactory去实现BeanDefinitionRefgistry，利用BeanDefinitionRefgistry.getBeanDefinition()方法获取BeanDefinition。\n\n\n\n#### **2、获取配置文件的方式**\n\n我们第一天加载xml配置文件的方式是从类运行环境中去获取，即\n\n```\n1.  ClassLoader cl = ClassUtils.getDefaultClassLoader();  \n\n2.  is = cl.getResourceAsStream(configFile); \n```\n\n但实际过程中，我们可能需要各个途径去加载xml，比如文件系统、网络url等。\n\n所以我们抽象出一个Resource接口用于描述xml加载方法，最终我们是希望从这个Resource中获取一个InputStream用来解析\n\n\n\n定义**Resource**接口\n\n```\n1.  public interface Resource {  \n\n2.      public InputStream getInputStream() throws IOException;  \n\n3.      public String getDescription();  \n\n4.  }  \n```\n\n\n\n从类环境加载xml，注意这里的ClassPathResource配置文件是可以配置ClassLoader的\n\n```\n1.  public class ClassPathResource implements Resource {  \n\n2.      private final String configFile;  \n\n3.      private ClassLoader classLoader;  \n\n4.      public ClassPathResource(String configFile) {  \n\n5.          this(configFile, (ClassLoader)null);  \n\n6.      }  \n\n\n7.      public ClassPathResource(String configFile, ClassLoader classLoader) {  \n\n8.          Assert.notNull(configFile, \"configFile must not be null!\");  \n\n9.          this.configFile = configFile;  \n\n10.         this.classLoader = classLoader != null ? classLoader : ClassUtils.getDefaultClassLoader();  \n\n11.     }  \n\n\n12.     @Override  \n\n13.     public InputStream getInputStream() throws IOException {  \n\n14.         return classLoader.getResourceAsStream(configFile);  \n\n15.     }  \n\n\n16.     @Override  \n\n17.     public String getDescription() {  \n\n18.         return \"configFile []\";  \n\n19.     }  \n\n20. }  \n```\n\n\n\n从文件系统中加载xml\n\n```\n1.  public class FileSystemResource implements Resource {  \n\n2.      private final String path;  \n\n3.      private final File file;  \n\n4.      public FileSystemResource(String path) {  \n\n5.          Assert.notNull(path, \"Path must not be null\");  \n\n6.          this.path = path;  \n\n7.          this.file = new File(path);  \n\n8.      }  \n\n\n9.      @Override  \n\n10.     public InputStream getInputStream() throws IOException {  \n\n11.         return new FileInputStream(file);  \n\n12.     }  \n\n13.     @Override  \n\n14.     public String getDescription() {  \n\n15.         return \"file [\" + this.file.getAbsolutePath() + \"] \";  \n\n16.     }  \n\n17. } \n```\n\n\n\n有了这些之后我们就可以回到修改一，就是这么来的\n\n```\n1.  XmlBeanDefinitionReader.loadBeanDefinition(Resource resource){  \n\n2.      //...                \n\n3.          is = resource.getInputStream();  \n\n4.      //...  \n\n5.  }  \n```\n\n\n\n#### **3、Bean的单例模式**\n\n我们都知道spring默认生成的bean都是单例模式的，那我们怎么实现这个呢？\n\n首先我们肯定要在解析xml的时候去看下bean的scope属性是什么，然后设置到对应的BeanDefinition上，默认是单例的，所以没有设置scope属性的时候就是单例的\n\n其次就是在getBean的时候，判断获取到的BeanDefinition是不是单例的，是的话就返回同一个Bean，这里我们可以考虑用一个ConcurrentHashMap去实现\n\n从上面思路出发，单例模式我们认为是一种行为，新建一个接口DefaultSingletonBeanRegistry负责去接收单例Bean\n\n\n\nDefaultSingletonBeanRegistry接口如下：\n\n```\n1.  // 将一个bean放入单例map中和从单例Map中获取bean，是控制scope的核心方法 \n\n2.  public class DefaultSingletonBeanRegistry implements SingletonBeanRegistry {  \n\n3.      private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>();  \n\n4.      @Override  \n\n5.      public void registrySingleton(String beanName, Object singletonObject) {  \n\n6.          Assert.notNull(beanName, \"beanName must not be null\");  \n\n7.          Object oldObject = this.singletonObjects.get(beanName);  \n\n8.          if(oldObject != null) {  \n\n9.              throw new IllegalStateException(\"there is already exists \" + beanName + \"object\");  \n\n10.         }  \n\n11.         this.singletonObjects.put(beanName, singletonObject);  \n\n12.     }  \n\n13.     @Override  \n\n14.     public Object **getSingleton**(String beanName) {  \n\n15.         return singletonObjects.get(beanName);  \n\n16.     }  \n\n17. } \n```\n\n\n\n有了这个接口，首先修改一下BeanDefinition接口，增加scope相关属性和方法\n\n```\n1.  public interface BeanDefinition {  \n\n2.      static final String SCOPE_DEFAULT = \"\"; // scope默认值  \n\n3.      static final String SCOPE_SINGLETON = \"singleton\";   \n\n4.      static final String SCOPE_PROTOTYPE = \"prototype\";   \n\n5.      String getClassName();  \n\n6.      String getId();  \n\n7.      boolean isSingleton();   \n\n8.      boolean isPrototype();  \n\n9.      String getScope();  \n\n10.     void setScope(String scope);  \n\n11. }  \n```\n\n\n\n对应的默认实现类GenericBeanDefinition修改如下，注意setScope方法，因为默认scope就是singleton的\n\n```\n1.  @Data  \n\n2.  public class GenericBeanDefinition implements BeanDefinition {  \n\n3.      private String id;  \n\n4.      private String className;  \n\n5.      private boolean singleton = true;  \n\n6.      private boolean prototype = false;  \n\n7.      private String scope = SCOPE_DEFAULT;  \n\n8.      public GenericBeanDefinition(String id, String className) {  \n\n9.          super();  \n\n10.         this.id = id;  \n\n11.         this.className = className;  \n\n12.     }  \n\n13.     @Override  \n\n14.     public boolean isSingleton() {  \n\n15.         return this.singleton;  \n\n16.     }  \n\n17.     @Override  \n\n18.     public boolean isPrototype() {  \n\n19.         return this.prototype;  \n\n20.     }  \n\n21.     @Override  \n\n22.     public String getScope() {  \n\n23.         return this.scope;  \n\n24.     }  \n\n25.     @Override  \n\n26.     public void setScope(String scope) {  \n\n27.         this.scope = scope;  \n\n28.         this.singleton = SCOPE_SINGLETON.equals(scope) || SCOPE_DEFAULT.equals(scope);  \n\n29.         this.prototype = SCOPE_PROTOTYPE.equals(scope);  \n\n30.     }  \n\n31. }  \n```\n\n\n\n修改完了BeanDefinition后，**在解析xml的时候设置scope属性**\n\n这也就是XmlBeanDefinitionReader.loadBeanDefinition修改二的内容\n\n```\n1.  if(ele.attribute(SCOPE_ATTRIBUTE) != null) {  // 判断bean的scope   \n\n2.      bd.setScope(ele.attributeValue(SCOPE_ATTRIBUTE));  \n\n3.  }  \n```\n\n设置好scope属性，在getBean的时候判断单例，是单例就从DefaultSingletonBeanRegistry的concurrentHashMap中取bean（同一个bean），不是就反射创建一个bean并加入concurrentHashMap中\n\n\n\nDefaultBeanFactory的相关代码修改如下：\n\n```\n1.  @Override  \n\n2.  public Object getBean(String beanId) {  \n\n3.      //...\n\n4.   // 判断单例和获取单例Bean\n\n5.      if(bd.isSingleton()) {   \n\n6.          Object bean = this.getSingleton(beanId);  \n\n7.          if(bean == null) {  \n\n8.              bean = createBean(bd);  \n\n9.              this.registrySingleton(beanId, bean);  \n\n10.         }  \n\n11.         return bean;  \n\n12.     }  \n\n13.     return createBean(bd);  \n\n14. }    \n\n15. }  \n```\n\n\n\n#### **4、使用ApplicationContext封装**\n\n在上面步骤都完成后，我们getBean需要的步骤是这样的\n\n```\n1.  DefaultBeanFactory beanFactory = new DefaultBeanFactory();  \n\n2.  XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(beanFactory);  \n\n3.  ClassPathResource resource = new ClassPathResource(\"applicationContext.xml\");  \n\n4.  reader.loadBeanDefinition(resource);  \n\n5.  BeanDefinition bd = beanFactory.getBeanDefinition(\"student\");  \n\n6.  Student student = (Student) beanFactory.getBean(\"student\");  \n```\n\n\n\n可以看的出来非常繁杂，虽然我们确实实现了各功能分离，那么我们使用过Spring都知道Spring是怎么操作的，类似一下这种\n\n```\n1.  ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");  \n\n2.  Student student = (Student)context.getBean(\"student\")\n```\n\n\n\n这样就很清晰了，那我们怎么实现这种效果呢\n\n首先定义一个ApplicationContext接口，里面有getBean方法\n\n然后根据不同加载xml的方式实现不同的类，比如ClassPathXmlApplicationContext和FileSystemXmlApplicationContext，故名思意就是从类环境和文件系统中加载文件\n\n\n\n**ClassPathXmlApplicationContext**代码如下：\n\n```\n1.  public abstract class ClassPathXmlApplicationContext implements ApplicationContext {  \n\n2.      private DefaultBeanFactory factory = null;  \n\n3.      public ClassPathXmlApplicationContext(String path) {  \n\n4.          factory = new DefaultBeanFactory();  \n\n5.          XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory);  \n\n6.          Resource resource = new ClassPathResource(path);  \n\n7.          reader.loadBeanDefinition(resource);  \n\n8.      }  \n\n9.      public Object getBean(String beanId) {  \n\n10.         return factory.getBean(beanId);  \n\n11.     }  \n\n12. }  \n```\n\n\n\n当我们写**FileSystemXmlApplicationContext**代码的时候发现跟ClassPathXmlApplicationContext非常雷同，区别就是获取Resource的方式不一样\n\n这时候 我们 思考使用**模板方法**来合并FileSystemXmlApplicationContext和ClassPathXmlApplicationContext以及更多类似的内容。\n\n定义一个抽象类**AbstractApplicationContext**继承ApplicationContext，将公有代码放在这个抽象类中，因为不同的Context之间就是Resource不一样，于是在AbstractApplicationContext抽象类中定义一个getResource方法让下面的类去实现\n\n最后的类图如下：\n\n![img](http://pcc.huitogo.club/8f79d598c22af10d2b5ae78e59e551fc)\n\n\n\nAbstractApplicationContext代码如下\n\n```\n1.  public abstract class AbstractApplicationContext implements ApplicationContext {  \n\n2.      private DefaultBeanFactory factory = null;  \n\n3.      public AbstractApplicationContext(String path) {  \n\n4.          factory = new DefaultBeanFactory();  \n\n5.          XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory);  \n\n6.          Resource resource = this.getResourceByPath(path);  \n\n7.          reader.loadBeanDefinition(resource);  \n\n8.      }  \n\n9.      public Object getBean(String beanId) {  \n\n10.         return factory.getBean(beanId);  \n\n11.     }  \n\n12.     protected abstract Resource getResourceByPath(String path);  \n\n13. }  \n```\n\n\n\n修改后ClassPathXmlApplicationContext代码\n\n```\n1.  public class ClassPathXmlApplicationContext extends AbstractApplicationContext {  \n\n2.  //...  \n\n3.      @Override  \n\n4.      protected Resource getResourceByPath(String path) {  \n\n5.          return new ClassPathResource(path, this.getClassLoader());  \n\n6.      }  \n\n7.  } \n```\n\n\n\nFileSystemXmlApplicationContext代码\n\n```\n1.  public class FileSystemXmlApplicationContext extends AbstractApplicationContext{  \n\n2.  //...  \n\n3.      @Override  \n\n4.      protected Resource getResourceByPath(String path) {  \n\n5.          return new FileSystemResource(path);  \n\n6.      }  \n\n7.  }  \n```\n\n\n\n#### **5、自定义classLoader**\n\n在ClassPathResource中我们说过它的构造方法允许自定义ClassLoader的，通过ClassLoader来解析xml，但是在上面构建ApplicationContext的过程中，ClassLoader一直都是默认（getDefaultClassLoader）的，\n\n怎么传入自定义的classLoader呢？\n\n\n\n秉着分离的原则，还是定义接口实现新的行为\n\n定义**ConfigurableBeanFactory**接口来实现classLoader的 (getter/setter)\n\n然后ApplicationContext来继承这个ConfigurableBeanFactory接口，在使用过程中可以直接setClassLoader到ClassPathResouce的classLoader中\n\n\n\nConfigurableBeanFactory接口\n\n```\n1.  public interface ConfigurableBeanFactory extends BeanFactory {  \n\n2.      void setClassLoader(ClassLoader cl);  \n\n3.      ClassLoader getClassLoader();  \n\n4.  }  \n```\n\n\n\n修改AbstractApplicationContext的部分如下：\n\n```\n1.  public abstract class AbstractApplicationContext implements ApplicationContext {  \n\n2.      private ClassLoader cl;  \n\n3.      public AbstractApplicationContext(String path) {  \n\n4.          //...  \n\n5.          factory.setClassLoader(cl);  \n\n6.      }  \n\n7.      @Override  \n\n8.      public void setClassLoader(ClassLoader cl) {  \n\n9.          this.cl = cl;  \n\n10.     }  \n\n11.     @Override  \n\n12.     public ClassLoader getClassLoader() {  \n\n13.         return this.cl != null ? cl : ClassUtils.getDefaultClassLoader();  \n\n14.     }  \n\n15. }  \n```", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 3}, "6682fc9783afeb41a08388e88edcfcda": {"id": "6682fc9783afeb41a08388e88edcfcda", "item": "造轮子系列", "title": "七天写一个Spring框架（七）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第七天", "body": "\n本节目标的类图如下：\n\n![img](http://pcc.huitogo.club/356fe5244625f57dd4d395dfdf8baba1)\n\n\n\n**今天的目标是**\n\n完成Spring Aop的下半节，使满足aop配置的bean生成代理，在调用bean方法的时候去调用代理类的方法，从而实现增强\n\n\n\n上一节我们已经可以根据Advised然后利用CglibProxyFactory去生成指定的代理类，使用起来类似于以下这种：\n\n```\n1.  @Test  \n\n2.  public void testGetProxyClass() throws Throwable {  \n\n3.      AdvisedSupport advised = new AdvisedSupport();  \n\n4.      advised.addAdvice(beforeAdvice);  \n\n5.      advised.addAdvice(afterAdvice);  \n\n6.      advised.setTargetObject(personService);   \n\n7.      CglibProxyFactory proxyFacotry = new CglibProxyFactory(advised);  \n\n8.      PersonService personServiceProxy = (PersonService) proxyFacotry.getProxy();  \n\n9.     // 这里personServiceProxy 已经是一个代理类了  \n\n10.     personServiceProxy.placeOrder();  \n\n11. }  \n```\n\n\n\n要实现我们最终的目标，需要思考的是\n\n1）怎么获取所有的Advice？\n\n2）是不是所有的bean都要生成代理类？\n\n3）什么时候生成代理类？\n\n\n\n#### **1、解析xml中的aop配置**\n\n譬如给定一个aop配置如下：\n\n```\n1.  <aop:config>  \n\n2.      <aop:aspect ref=\"tx\">  \n\n3.          <aop:pointcut expression=\"execution(* my_spring.beanfactory_aop2.test.service.*.placeOrder(..))\" id=\"placeOrder\"/>  \n\n4.          <aop:before method=\"start\" pointcut-ref=\"placeOrder\"></aop:before>  \n\n5.          <aop:after-throwing method=\"rollback\" pointcut-ref=\"placeOrder\"/>   \n\n6.          <aop:after-returning method=\"commit\" pointcut-ref=\"placeOrder\"/>  \n\n7.      </aop:aspect>  \n\n8.  </aop:config>\n```\n\n\n\n我们是希望将<aop:before>转换成AspectJBeforeAdvice，将<aop:after-throwing>转换成AspectJAfterThrowingAdvice，将<aop:after-returning>转换成AspectJAfterAdvice，这样我们才可以将这些Advice放到Advised中去构建代理类\n\n一开始我是以为直接转换成Advice相关类，然后存储到一个List中去，后面在getBean()的时候再一一比对\n\n但是Spring不是这么做的，Spring引入了一个叫**人工合成BeanDefinition**（synthetic）的概念，可以理解成DTO的概念吧（把我们定义的Bean想象成DAO）\n\n这里的目的就是将<aop:before>、<aop:after-throwing>、<aop:after-returning>甚至是<aop:pointcut>标签的信息都转换成人工合成的BeanDefinition\n\n转换<aop:before>等advice的标签后的BeanDefinition如下所示\n\n![img](http://pcc.huitogo.club/88c86f9eeb6c5210cea19176e6e268b4)\n\n\n\n根据上图我们适当修改AbstractAspectJAdvice的构造函数，也就是Advice接口的模板类，使它扩展性更高\n\n```\n1.  public abstract class AbstractAspectJAdvice implements Advice {  \n\n2.      private Method adviceMethod;  \n\n3.      private AspectJExpressionPointcut pointcut;  \n\n4.      private AspectInstanceFactory adviceObjectFactory;  \n\n5.  //修改了构造方法第二和第三个参数\n\n6.      public AbstractAspectJAdvice(Method adviceMethod, AspectJExpressionPointcut pointcut, AspectInstanceFactory adviceObjectFactory) {  \n\n7.          super();  \n\n8.          this.adviceMethod = adviceMethod;  \n\n9.          this.pointcut = pointcut;  \n\n10.         this.adviceObjectFactory = adviceObjectFactory;  \n\n11.     }  \n\n12.     public void invokeAdviceMethod() throws Throwable {  \n\n13.         adviceMethod.invoke(adviceObjectFactory.getAspectBean());  \n\n14.     }  \n\n15.     //...  \n\n16. }  \n```\n\n\n\n构造函数里面的**AspectInstanceFactory**类，这个类用来处理切面的信息，相关代码：\n\n```\n1.  public class AspectInstanceFactory implements BeanFactoryAware {  \n\n2.     // 切面的beanName\n\n3.      private String aspectBeanName;  \n\n4.      private AbstractBeanFactory beanFactory;  \n\n5.      public void setAspectBeanName(String aspectBeanName) {  \n\n6.          this.aspectBeanName = aspectBeanName;  \n\n7.      }  \n\n8.      public Object getAspectBean() {  \n\n9.          return beanFactory.getBean(aspectBeanName);  \n\n10.     }  \n\n11.     @Override  \n\n12.     public void setBeanFactory(BeanFactory beanFactory) {  \n\n13.         this.beanFactory = (AbstractBeanFactory) beanFactory;  \n\n14.     }  \n\n15.     public Object getAspectInstance() {  \n\n16.         return this.beanFactory.getBean(this.aspectBeanName);  \n\n17.     }  \n\n18. }  \n```\n\n\n\n同时修改一下我们上一节用来定位切面方法的**MethodLocatingFactory**，将它的getObject()和setBeanFactory()方法抽象出来\n\n```\n1.  public class MethodLocatingFactory implements FactoryBean<Method>, BeanFactoryAware{  \n\n2.      ...  \n\n3.  }  \n\n4.  public interface FactoryBean<T> {  \n\n5.      T getObject() throws Exception;  \n\n6.      Class<?> getObjectType();  \n\n7.  }  \n\n8.  public interface BeanFactoryAware {  \n\n9.       void setBeanFactory(BeanFactory beanFactory);  \n\n10. }  \n```\n\n这里要注意以下FactoryBean和BeanFactory的区别，**BeanFactory是用来获取Bean的，相当于生产工厂，FactoryBean是用来对Bean进行转换的，相当于加工工厂**。\n\n\n\n下一步就是将pointcut的标签转换成BeanDefinition，如下所示\n\n![img](http://pcc.huitogo.club/bdb0b4a4f76d6041c939511244be3365)\n\n\n\n我们在XmlBeanDefinitionReader.loadBeanDefinition()中对aop标签进行解析\n\n```\n1.  public void loadBeanDefinition(Resource resource) {  \n\n2.      //...  \n\n3.          while (itr.hasNext()) {  \n\n4.              Element ele = itr.next();  \n\n5.              String namespaceUri = ele.getNamespaceURI();  \n\n6.              // 判断标签的命名空间  \n\n7.              if (isDefaultNamespace(namespaceUri)) {  \n\n8.                  parseDefaultElement(ele);  \n\n9.              } else if (isContextNamespace(namespaceUri)) {  \n\n10.                 parseComponentElement(ele);  \n\n11.             }else if(isAOPNamespece(namespaceUri)) {  \n\n12.                 parseAopElement(ele);  \n\n13.             }  \n\n14.         }  \n\n15.         //...  \n\n16. }  \n\n17. private void parseAopElement(Element ele) {  \n\n18.     ConfigBeanDefinitionParser parser = new ConfigBeanDefinitionParser();  \n\n19.     parser.parse(ele, this.registry);  \n\n20. }  \n```\n\n\n\n具体的解析过程在ConfigBeanDefinitionParser.parse()中，ConfigBeanDefinitionParser代码如下：\n\n```\n1.  public class ConfigBeanDefinitionParser {  \n\n2.     //相关标签名称\n\n3.      private static final String ASPECT = \"aspect\";  \n\n4.      private static final String ID = \"id\";  \n\n5.      private static final String REF = \"ref\";  \n\n6.      private static final String AFTER = \"after\";  \n\n7.      private static final String AFTER_RETURNING_ELEMENT = \"after-returning\";  \n\n8.      private static final String AFTER_THROWING_ELEMENT = \"after-throwing\";  \n\n9.      private static final String AROUND = \"around\";  \n\n10.     private static final String BEFORE = \"before\";  \n\n11.     private static final String POINTCUT = \"pointcut\";  \n\n12.     private static final String ASPECT_NAME_PROPERTY = \"aspectName\";  \n\n13.     private static final String POINTCUT_REF = \"pointcut-ref\";  \n\n14.     private static final String EXPRESSION = \"expression\";  \n\n\n15.     public BeanDefinition parse(Element ele, BeanDefinitionRegistry registry) {  \n\n16.         List<Element> childElts = ele.elements();  \n\n17.         for (Element childElem : childElts) {  \n\n18.             String localName = childElem.getName();  \n\n19.             if (ASPECT.equals(localName)) {  \n\n20.                 parseAspect(childElem, registry);  \n\n21.             }  \n\n22.         }  \n\n23.         return null;  \n\n24.     }  \n\n\n25.     //解析<aspect标签>  \n\n26.     private void parseAspect(Element aspectElement, BeanDefinitionRegistry registry) {  \n\n27.         String aspectName = aspectElement.attributeValue(REF);  \n\n28.         List<BeanDefinition> beanDefinitions = new ArrayList<>();  \n\n29.         List<RuntimeBeanReference> beanReferences = new ArrayList<>();  \n\n30.         List<Element> eleList = aspectElement.elements();  \n\n31.         // 是否已经添加new RuntimeBeanReference(aspectName)  \n\n32.         // 只有在有AdviceNode的时候这个beanReferences添加了才有意义  \n\n33.         boolean adviceFoundAlready = false;  \n\n34.         for (int i = 0; i < eleList.size(); i++) {  \n\n35.             Element ele = eleList.get(i);  \n\n36.             if (isAdviceNode(ele)) {  \n\n37.                 if (!adviceFoundAlready) {  \n\n38.                     adviceFoundAlready = true;  \n\n39.                     if (!StringUtils.hasText(aspectName)) {  \n\n40.                         return;  \n\n41.                     }  \n\n42.                     beanReferences.add(new RuntimeBeanReference(aspectName));  \n\n43.                 }  \n\n44.                 GenericBeanDefinition advisorDefinition = parseAdvice(aspectName, i, aspectElement, ele, registry, beanDefinitions, beanReferences);  \n\n45.                 beanDefinitions.add(advisorDefinition);  \n\n46.             }  \n\n47.         }  \n\n48.         List<Element> pointcuts = aspectElement.elements(POINTCUT);  \n\n49.         for (Element pointcutElement : pointcuts) {  \n\n50.             parsePointcut(pointcutElement, registry);  \n\n51.         }  \n\n52.     }  \n\n\n53.     //解析<aop:before>等advice类型的标签  \n\n54.     private GenericBeanDefinition parseAdvice(String aspectName, int order, Element aspectElement,  Element adviceElement, BeanDefinitionRegistry registry, List<BeanDefinition> beanDefinitions, List<RuntimeBeanReference> beanReferences) {  \n\n55.         GenericBeanDefinition methodDefinition = new GenericBeanDefinition(MethodLocatingFactory.class);  \n\n56.         methodDefinition.getPropertyValues().add(new PropertyValue(\"targetBeanName\", aspectName));  \n\n57.         methodDefinition.getPropertyValues().add(new PropertyValue(\"methodName\", adviceElement.attributeValue(\"method\")));  \n\n58.         methodDefinition.setSynthetic(true);  \n\n59.         GenericBeanDefinition aspectFactoryDef = new GenericBeanDefinition(AspectInstanceFactory.class);  \n\n60.         aspectFactoryDef.getPropertyValues().add(new PropertyValue(\"aspectBeanName\", aspectName));  \n\n61.         aspectFactoryDef.setSynthetic(true);  \n\n62.  GenericBeanDefinition adviceDef = createAdviceDefinition(adviceElement, registry, aspectName, order,  methodDefinition, aspectFactoryDef, beanDefinitions, beanReferences);  \n\n63.         adviceDef.setSynthetic(true);  \n\n64.         BeanDefinitionReaderUtils.registerWithGeneratedName(adviceDef, registry);  \n\n65.         return null;  \n\n66.     }  \n\n\n67.     //解析<aop:point>标签  \n\n68.     private GenericBeanDefinition parsePointcut(Element pointcutElement, BeanDefinitionRegistry registry) {  \n\n69.         String id = pointcutElement.attributeValue(ID);  \n\n70.         String expression = pointcutElement.attributeValue(EXPRESSION);  \n\n71.         GenericBeanDefinition pointcutDefinition = null;  \n\n72.         pointcutDefinition = createPointcutDefinition(expression);  \n\n73.         String pointcutBeanName = id;  \n\n74.         if (StringUtils.hasText(pointcutBeanName)) {  \n\n75.             registry.registryBeanDefinition(pointcutBeanName, pointcutDefinition);  \n\n76.         } else {  \n\n77.             BeanDefinitionReaderUtils.registerWithGeneratedName(pointcutDefinition, registry);  \n\n78.         }  \n\n79.         return pointcutDefinition;  \n\n80.     }  \n\n\n81.     //ele是不是<aop:before>等类型advice的标签  \n\n82.     private boolean isAdviceNode(Element ele) {  \n\n83.         if (!(ele instanceof Element)) {  \n\n84.             return false;  \n\n85.         } else {  \n\n86.             String name = ele.getName();  \n\n87.             return (BEFORE.equals(name) || AFTER.equals(name) || AFTER_RETURNING_ELEMENT.equals(name) || AFTER_THROWING_ELEMENT.equals(name) || AROUND.equals(name));  \n\n88.         }  \n\n89.     }  \n\n\n90.     //创建Advice对应的BeanDefinition  \n\n91.     private GenericBeanDefinition createAdviceDefinition(Element adviceElement, BeanDefinitionRegistry registry, String aspectName, int order, GenericBeanDefinition methodDefinition,  GenericBeanDefinition aspectFactoryDef, List<BeanDefinition> beanDefinitions, List<RuntimeBeanReference> beanReferences) {  \n\n92.         GenericBeanDefinition adviceDefinition = new GenericBeanDefinition(getAdviceClass(adviceElement));  \n\n93.         adviceDefinition.getPropertyValues().add(new PropertyValue(ASPECT_NAME_PROPERTY, aspectName));  \n\n94.         // 构建adviceDefinition的构造函数  \n\n95.         ConstructorArgument cav = adviceDefinition.getConstructorArgument();  \n\n96. //第一个构造参数MethodLocatingFactory\n\n97.         cav.addArgumentValue(new ValueHolder(methodDefinition));  \n\n98.    //第二个构造参数 AspectJExpressionPointcut\n\n99.         Object pointcut = parsePointProperty(adviceElement);  \n\n100.         if (pointcut instanceof BeanDefinition) {  \n\n101.             cav.addArgumentValue(new ValueHolder(pointcut));  \n\n102.         } else if (pointcut instanceof String) {  \n\n103.             RuntimeBeanReference pointcutRef = new RuntimeBeanReference((String) pointcut);\n\n104.             beanReferences.add(pointcutRef);  \n\n105.             cav.addArgumentValue(new ValueHolder(pointcutRef));  \n\n106.         }  \n\n107. //第三个构造参数AspectInstanceFactory\n\n108.         cav.addArgumentValue(new ValueHolder(aspectFactoryDef));  \n\n109.         return adviceDefinition;  \n\n110.     }  \n\n\n111.     //解析<aop:pointcut>标签的属性  \n\n112.     private Object parsePointProperty(Element adviceElement) {  \n\n113.         if (adviceElement.attribute(POINTCUT) != null && adviceElement.attribute(POINTCUT_REF) != null) {  \n\n114.             return null;  \n\n115.         } else if (adviceElement.attribute(POINTCUT) != null) {  \n\n116.             String expression = adviceElement.attributeValue(POINTCUT);  \n\n117.             GenericBeanDefinition pointcutDefinition = createPointcutDefinition(expression);\n\n118.             return pointcutDefinition;  \n\n119.         }else if (adviceElement.attribute(POINTCUT_REF) != null) {  \n\n120.             String pointcutRef = adviceElement.attributeValue(POINTCUT_REF);  \n\n121.             if (!StringUtils.hasText(pointcutRef)) {  \n\n122.                 return null;  \n\n123.             }  \n\n124.             return pointcutRef;  \n\n125.         } else {  \n\n126.             return null;  \n\n127.         }  \n\n128.     }  \n\n\n129.     //创建pointcut的BeanDefinition  \n\n130.     private GenericBeanDefinition createPointcutDefinition(String expression) {  \n\n131.         GenericBeanDefinition beanDefinition = new GenericBeanDefinition(AspectJExpressionPointcut.class);  \n\n132.         beanDefinition.setScope(BeanDefinition.SCOPE_PROTOTYPE);  \n\n133.         beanDefinition.setSynthetic(true);  \n\n134.        beanDefinition.getPropertyValues().add(new PropertyValue(EXPRESSION, expression));  \n\n135.         return beanDefinition;  \n\n136.     }  \n\n\n137.     //判断adviceElement标签的advice类型  \n\n138.     private Class<?> getAdviceClass(Element adviceElement) {  \n\n139.         String elementName = adviceElement.getName();  \n\n140.         if (BEFORE.equals(elementName)) {  \n\n141.             return AspectJBeforeAdvice.class;  \n\n142.         } else if (AFTER_RETURNING_ELEMENT.equals(elementName)) {  \n\n143.             return AspectJAfterAdvice.class;  \n\n144.         } else if (AFTER_THROWING_ELEMENT.equals(elementName)) {  \n\n145.             return AspectJAfterThrowingAdvice.class;  \n\n146.         } else {  \n\n147.             return null;  \n\n148.         }  \n\n149.     }  \n\n150. }  \n```\n\n\n\n这是一段冗长的代码，主要的任务就是解析<aop:config>标签里面的<aop:aspect>标签\n\n\n\n来看一下任务相关的代码\n\n**解析<aop:pointcut>标签为BeanDefinition并registry到BeanFactory中**\n\n```\n1.  private GenericBeanDefinition parsePointcut(Element pointcutElement, BeanDefinitionRegistry registry) {  \n\n2.      //...  \n\n3.      GenericBeanDefinition pointcutDefinition = createPointcutDefinition(expression);  \n\n4.      //...  \n\n5.      registry.registryBeanDefinition(pointcutBeanName, pointcutDefinition);  \n\n6.      //...  \n\n7.      return pointcutDefinition;  \n\n8.  }  \n\n\n9.  private GenericBeanDefinition createPointcutDefinition(String expression) {  \n\n10.     GenericBeanDefinition beanDefinition = new GenericBeanDefinition(AspectJExpressionPointcut.class);  \n\n11.     beanDefinition.setScope(BeanDefinition.SCOPE_PROTOTYPE);  \n\n12.     beanDefinition.setSynthetic(true);  \n\n13.     beanDefinition.getPropertyValues().add(new PropertyValue(EXPRESSION, expression));  \n\n14.     return beanDefinition;  \n\n15. }  \n```\n\n\n\n**解析<aop:before>等Advice标签为BeanDefinition并registry到BeanFactory中**\n\n先要生成Advice构造函数中的两个GenericBeanDefinition参数，对应的类是MethodLocatingFactory和AspectInstanceFactory\n\n```\n1.  private GenericBeanDefinition parseAdvice(String aspectName, int order, Element aspectElement, Element adviceElement, BeanDefinitionRegistry registry, List<BeanDefinition> beanDefinitions, List<RuntimeBeanReference> beanReferences) {  \n\n2.      GenericBeanDefinition methodDefinition = new GenericBeanDefinition(MethodLocatingFactory.class);  \n\n3.      methodDefinition.getPropertyValues().add(new PropertyValue(\"targetBeanName\", aspectName));  \n\n4.      methodDefinition.getPropertyValues().add(new PropertyValue(\"methodName\", adviceElement.attributeValue(\"method\")));  \n\n5.      methodDefinition.setSynthetic(true);  \n\n6.      GenericBeanDefinition aspectFactoryDef = new GenericBeanDefinition(AspectInstanceFactory.class);  \n\n7.      aspectFactoryDef.getPropertyValues().add(new PropertyValue(\"aspectBeanName\", aspectName));  \n\n8.      aspectFactoryDef.setSynthetic(true);  \n\n9.      GenericBeanDefinition adviceDef = createAdviceDefinition(adviceElement, registry, aspectName, order, methodDefinition, aspectFactoryDef, beanDefinitions, beanReferences);  \n\n10.     adviceDef.setSynthetic(true);  \n\n11.     BeanDefinitionReaderUtils.registerWithGeneratedName(adviceDef, registry);  \n\n12.     return null;  \n\n13. }  \n```\n\n\n\n再创建这个Advice的BeanDefinition，主要任务花在合成这个BeanDefinition的ConstructorArgument\n\n```\n1.  private GenericBeanDefinition createAdviceDefinition(Element adviceElement, BeanDefinitionRegistry registry, String aspectName, int order, GenericBeanDefinition methodDefinition, GenericBeanDefinition aspectFactoryDef, List<BeanDefinition> beanDefinitions,  List<RuntimeBeanReference> beanReferences) {  \n\n2.      GenericBeanDefinition adviceDefinition = new GenericBeanDefinition(getAdviceClass(adviceElement));  \n\n3.      adviceDefinition.getPropertyValues().add(new PropertyValue(ASPECT_NAME_PROPERTY, aspectName));  \n\n4.      // 构建adviceDefinition的构造函数  \n\n5.      ConstructorArgument cav = adviceDefinition.getConstructorArgument();  \n\n6.  //第一个构造参数MethodLocatingFactory\n\n7.      cav.addArgumentValue(new ValueHolder(methodDefinition));  \n\n8.  //第二个构造参数 AspectJExpressionPointcut\n\n9.      Object pointcut = parsePointProperty(adviceElement);  \n\n10.     if (pointcut instanceof BeanDefinition) {  \n\n11.         cav.addArgumentValue(new ValueHolder(pointcut));  \n\n12.     } else if (pointcut instanceof String) {  \n\n13.         RuntimeBeanReference pointcutRef = new RuntimeBeanReference((String) pointcut);  \n\n14.         beanReferences.add(pointcutRef);  \n\n15.         cav.addArgumentValue(new ValueHolder(pointcutRef));  \n\n16.     }  \n\n17. // 第三个构造参数AspectInstanceFactory\n\n18.     cav.addArgumentValue(new ValueHolder(aspectFactoryDef));  \n\n19.     return adviceDefinition;  \n\n20. }  \n```\n\n至此<aop:before>等advice标签的BeanDefinition就被我们创建完毕并registry到BeanFactory中去\n\n\n\n有个需要注意的就是在Advice的模板类AbstractAspectJAdvice中的构造函数第一个是Method，而我们这里第一个构造函数是MethodLocatingFactory（FactoryBean）类的BeanDefinition，所以在BeanDefinitionValueResolver解析的时候需要添加一项对类型是BeanDefinition的处理，\n\n相关代码如下：\n\n```\n1.  public class BeanDefinitionValueResolver {  \n\n2.      public Object resolveValueIfNecessary(Object value) {  \n\n3.          if (value instanceof RuntimeBeanReference) {  \n\n4.  //...  \n\n5.          } else if (value instanceof TypedStringValue) {  \n\n6.  //...  \n\n7.          } else if (value instanceof BeanDefinition) {  \n\n8.              BeanDefinition bd = (BeanDefinition) value;  \n\n9.              String innerBeanName = \"(inner bean)\" + bd.getClassName() + \"#\"  \n\n10.                     + Integer.toHexString(System.identityHashCode(bd));  \n\n11.             return resolveInnerBean(innerBeanName, bd);  \n\n12.         } else if (value instanceof String) {  \n\n13. //...  \n\n14.         } else {  \n\n15. //...  \n\n16.         }  \n\n17.     }  \n\n\n18.     private Object resolveInnerBean(String innerBeanName, BeanDefinition bd) {  \n\n19.         Object innerBean = this.defaultBeanFactory.createBean(bd);  \n\n20.         if (innerBean instanceof FactoryBean) {  \n\n21.             try {  \n\n22.                 return ((FactoryBean) innerBean).getObject();  \n\n23.             } catch (Exception e) {}  \n\n24.         } else {  \n\n25.             return innerBean;  \n\n26.         }  \n\n27.     }  \n\n28. }  \n```\n\n就是调用了一下FactoryBean的getObject()方法，对这个BeanDefinition进行了转换。\n\n\n\n#### **2、在Bean初始化的时候生成代理类**\n\n我们再来看一下Bean的生命周期，如下图\n\n![img](http://pcc.huitogo.club/2c269631f633da39d566bfa20a49ed97)\n\n很明显，**一个类是否生成代理类应该在它实例化之前去做**，所以我们可以等这个类在初始化后（拥有基本属性和方法了）再去判断是否生成它的代理类\n\n\n\n所以我们新增一个类**AspectJAutoProxyCreater**去实现**BeanPostProcessor**（初始化接口）接口，在afterInitialization()中去做这件事，相关代码如下：\n\n```\n1.  public class AspectJAutoProxyCreater implements BeanPostProcessor {  \n\n2.      AbstractBeanFactory beanFactory;  \n\n3.      public void setBeanFactory(AbstractBeanFactory beanFactory) {  \n\n4.          this.beanFactory = beanFactory;  \n\n5.      }  \n\n6.      @Override  \n\n7.      public Object beforeInitialization(Object bean, String beanName) throws BeanException {\n\n8.          return bean;  \n\n9.      }  \n\n10.     @Override  \n\n11.     public Object afterInitialization(Object bean, String beanName) throws BeanExceptionn {\n\n12.         // 如果这个类本身就是Advice及其子类，那就不要生成动态代理了  \n\n13.         if (isInfrastrureClass(bean.getClass())) {  \n\n14.             return bean;  \n\n15.         }  \n\n16.         List<Advice> advices;  \n\n17.         try {  \n\n18. //获取bean中可用的Advice\n\n19.             advices = getCadidateAdvices(bean);  \n\n20.             if (advices.isEmpty()) {  \n\n21.                 return bean;  \n\n22.             }  \n\n23.             return createProxy(advices, bean);  \n\n24.         } catch (NoSuchBeanDefinitionException e) {  \n\n25.             return null;  \n\n26.         }  \n\n27.     }  \n\n28.     /** \n\n29.      * 根据advices拦截器链创建bean的代理类 \n\n30.      * @param advices \n\n31.      * @param bean \n\n32.      * @return \n\n33.      */  \n\n34.     private Object createProxy(List<Advice> advices, Object bean) {  \n\n35.         AdvisedSupport advised = new AdvisedSupport();  \n\n36.         for (Advice advice : advices) {  \n\n37.             advised.addAdvice(advice);  \n\n38.         }  \n\n39.    //jdk动态代理需要的父类接口数组\n\n40.         Set<Class<?>> targetInterfaces = ClassUtils.getAllInterfacesForClassAsSet(bean.getClass());  \n\n41.         for (Class<?> clazz : targetInterfaces) {  \n\n42.             advised.addInterface(clazz);  \n\n43.         }  \n\n44.         advised.setTargetObject(bean);  \n\n45.         AopProxyFactory proxyFactory = null;  \n\n46.         try {  \n\n47.             // 如果targetBean没有接口的话就使用CGLIB生成代理  \n\n48.             if (advised.getProxiedInterfaces().length == 0) {  \n\n49.                 proxyFactory = new CglibProxyFactory(advised);  \n\n50.             // 有接口就使用jdk动态代理  \n\n51.             } else {  \n\n52.                 proxyFactory = new JdkAopProxyFactory(advised);  \n\n53.             }  \n\n54.             return proxyFactory.getProxy();  \n\n55.         } catch (AopConfigException e) {  \n\n56.             return null;  \n\n57.         }  \n\n58.     }  \n\n59.     private List<Advice> getCadidateAdvices(Object bean) throws NoSuchBeanDefinitionException {  \n\n60.         List<Object> advices = this.beanFactory.getBeansByType(Advice.class);  \n\n61.         List<Advice> result = new ArrayList<>();  \n\n62.         for (Object advice : advices) {  \n\n63.             Pointcut pc = ((Advice) advice).getPointcut();  \n\n64.             if (canApply(pc, bean.getClass())) {  \n\n65.                 result.add((Advice) advice);  \n\n66.             }  \n\n67.         }  \n\n68.         return result;  \n\n69.     }  \n\n70.     /** \n\n71.      * 判断targetClass有没有方法满足pc表达式 \n\n72.      * @param pc \n\n73.      * @param targetClass \n\n74.      * @return \n\n75.      */  \n\n76.     private boolean canApply(Pointcut pc, Class<? extends Object> targetClass) {  \n\n77.         MethodMatcher methodMatcher = pc.getMethodMatcher();  \n\n78.        Set<Class> classes = new LinkedHashSet<>(ClassUtils.getAllInterfacesForClassAsSet(targetClass));  \n\n79.         classes.add(targetClass);  \n\n80.         for (Class<?> clazz : classes) {  \n\n81.             Method[] methods = clazz.getDeclaredMethods();  \n\n82.             for (Method method : methods) {  \n\n83.                 if (methodMatcher.match(method)) {  \n\n84.                     return true;  \n\n85.                 }  \n\n86.             }  \n\n87.         }  \n\n88.         return false;  \n\n89.     }  \n\n90.     /** \n\n91.      * 判断beanClass是不是Advice的子类 \n\n92.      * @param beanClass \n\n93.      * @return \n\n94.      */  \n\n95.     private boolean isInfrastrureClass(Class<? extends Object> beanClass) {  \n\n96.         boolean retVal = Advice.class.isAssignableFrom(beanClass);  \n\n97.         return retVal;  \n\n98.     }  \n\n99. }  \n```\n\n这里就是在BeanPostProcessor的afterInitialization（初始化后）方法中去判断当前是否需要生成代理，以及用什么样的方式去生成代理。\n\n\n\n上面的步骤解释如下：\n\n先判断这个Bean里面有没有method满足Advice的PointcutExpression\n\n在有Advice的情况下，根据这个Bean有没有实现接口去判断使用CGLIB还是JDK动态代理去生成Bean的代理对象。\n\n这里就运用到我们上一节的**CglibProxyFactory**和**JdkAopProxyFactory**\n\n```\n1.  if (advised.getProxiedInterfaces().length == 0) {  \n\n2.      proxyFactory = new CglibProxyFactory(advised);  \n\n3.      // 有接口就使用jdk动态代理  \n\n4.  } else {  \n\n5.      proxyFactory = new JdkAopProxyFactory(advised);  \n\n6.  }  \n\n7.  return proxyFactory.getProxy();  \n```\n\n\n\n做好这件事后我们回到DefaultBeanFactory中去添加Bean初始化时操作（BeanPostProcessor接口下的实现类）\n\n```\n1.  public class DefaultBeanFactory extends AbstractBeanFactory implements BeanDefinitionRegistry {  \n\n2.  //...\n\n3.  //Bean的初始化   \n\n4.   protected Object createBean(BeanDefinition bd) {  \n\n5.          // 初始化Bean  \n\n6.          Object bean = initalBean(bd);  \n\n7.          // 给bean设置属性  \n\n8.          populateBean(bd, bean);  \n\n9.          // 对于BeanFactoryAware接口的Bean设置BeanFactory  \n\n10.         // 是否生成代理类  \n\n11.         bean = initalizeBean(bd, bean);  \n\n12.         return bean;  \n\n13.     }  \n\n14.     protected Object initalizeBean(BeanDefinition bd, Object bean) {  \n\n15.         invokeAwareMethods(bean);  \n\n16.         //是否人工合成的BeanDefinition  \n\n17.         if(!bd.isSynthetic()) {   \n\n18.             // 创建Bean的代理类  \n\n19.             return applyBeanPostProcessorAfterInitalization(bean, bd.getId());  \n\n20.         }  \n\n21.         return bean;  \n\n22.     }  \n\n23.     private void invokeAwareMethods(final Object bean) {  \n\n24.         if(bean instanceof BeanFactoryAware) {  \n\n25.             ((BeanFactoryAware) bean).setBeanFactory(this);  \n\n26.         }  \n\n27.     }  \n\n28.     //调用bean生命周期中初始化的过程  \n\n29.     private Object applyBeanPostProcessorAfterInitalization(Object existingBean, String beanName) {  \n\n30.         Object result = existingBean;  \n\n31.         for(BeanPostProcessor beanPostProcessor : getBeanPostProcessor()) {  \n\n32. //这里调用bean初始化后的方法\n\n33.             result = beanPostProcessor.afterInitialization(result, beanName);  \n\n34.             if(result == null) {  \n\n35.                 return result;  \n\n36.             }  \n\n37.         }  \n\n38.         return result;  \n\n39.     }  \n\n40. }  \n```\n\n这样我们就在bean初始化后判断是否生成Bean代理类，顺便还将继承了BeanFactoryAware的Bean（这里指人工合成的Bean）设置了一下BeanFactory，Perfect！\n\n\n\n#### **3、总结**\n\n1）相比较来说，解析xml生成Advice对象这个过程还是比较复杂的，核心是将<aop:before>转换成BeanDefinition<AspectJBeforeAdvice>，需要考虑的就是它的List<Property>和ConstructorArgument怎么构建，需要什么就去补什么，但是典型的由大化小的思想。\n\n2）进一步理解了Bean的生命以及在Spring中的体现，实现了BeanPostProcessor的类可以在Bean初始化中做一些事情，实现了InstantiationAwareBeanPostProcessor的接口可以在Bean实例化中做一些事情，等等。\n\n3）理解了BeanFactory和FactoryBean的区别，两个都是SpringBean中重要的接口，BeanFactory是Bean的生产车间，FactoryBean是Bean的转换车间。\n\n4）jdk动态代理和Cglib在SpringAop中都有应用，因为两者各有优劣势，比如没有实现任何接口的类只能用CGLIB来实现，有接口的类用jdk动态代理实现，因为jdk动态创建代理速度更快。", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "de461e76a0a53dccb925686bd052fc20": {"id": "de461e76a0a53dccb925686bd052fc20", "item": "造轮子系列", "title": "七天写一个Spring框架（三）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第三天", "body": "\n本节目标的类图如下：\n\n![img](http://pcc.huitogo.club/1deb436961a7ef6ecde535bb25b24fa5)\n\n\n\n今天的目标也是\n\n获取bean的属性值和引用对象，但不同于上节，上节讲的通过bean的get +属性名和xml配置<property>标签中的name相对应进行匹配和赋值操作，这节复杂一点，我们通过bean的构造函数中的参数和xml中的<constuct-arg>标签进行对应和赋值操作。\n\n\n\n在xml中如下所示\n\n```\n1.  <bean id = \"personService\" class=\"my_spring.beanfactory_construt.test.service.PersonService\">  \n\n2.      <constructor-arg index=\"2\" ref=\"drinkDao\" />  \n\n3.      <constructor-arg name=\"eatDao\" ref=\"eatDao\" />  \n\n4.      <constructor-arg index=\"3\" type=\"java.lang.String\" value=\"zhanghui\" />  \n\n5.      <constructor-arg index=\"4\" type=\"java.lang.Integer\" value=\"18\" />  \n\n6.  </bean>  \n```\n\n\n\n编写出来的成功测试用例跟上节一样\n\n```\n1.  @Test  \n\n2.  public void testGetBeanProperties() {  \n\n3.      ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");  \n\n4.      PersonService personService = (PersonService) context.getBean(\"personService\");  \n\n5.      Assert.notNull(personService.getEatDao());  \n\n6.      Assert.notNull(personService.getDrinkDao());  \n\n7.      assertTrue(\"zhanghui\".equals(personService.getName()));  \n\n8.      assertTrue(personService.getAge() == 18);  \n\n9.  }  \n```\n\n既然本节目标跟上节目标一致，自然设计思路也差不多\n\n\n\n#### **1、第一步**\n\n在xml解析的时候将<bean>标签中<construct-arg>列表抽象出来放到对应的Beandefinition中去\n\n我们新增一个对象**ConstructorArgument**来存储<construct-arg>标签列表\n\n```\n1.  public class ConstructorArgument {  \n\n2.      private List<ValueHolder> argumentValues = new LinkedList<>();  \n\n3.      public List<ValueHolder> getArgumentValues() {  \n\n4.          return Collections.unmodifiableList(argumentValues);  \n\n5.      }  \n\n6.      public void addArgumentValue(ValueHolder valueHolder) {  \n\n7.          this.argumentValues.add(valueHolder);  \n\n8.      }  \n\n9.      public int getArgumentCount() {  \n\n10.         return argumentValues.size();  \n\n11.     }  \n\n12.     public boolean isEmpty() {  \n\n13.         return this.argumentValues.isEmpty();  \n\n14.     }  \n\n\n15.     // 对应一个<construct-arg>  \n\n16.     @Data  \n\n17.     @NoArgsConstructor  \n\n18.     public static class ValueHolder {  \n\n19.         private Object value;  \n\n20.         private String type;  \n\n21.         private String name;  \n\n22.         private int index;  \n\n23.         public ValueHolder(Object value) {  \n\n24.             this.value = value;  \n\n25.         }  \n\n26.     }  \n\n27. }  \n```\n\n\n\n在BeanDefinition接口中定义操作ConstructorArgument的方法\n\n```\n1.  public interface BeanDefinition {  \n\n2.      //...  \n\n3.      ConstructorArgument getConstructorArgument();  \n\n4.      boolean hasConstructorArgumentValues();  \n\n5.  }  \n```\n\n\n\n在GenericBeanDefinition中实现\n\n```\n1.  @Data  \n\n2.  public class GenericBeanDefinition implements BeanDefinition {  \n\n3.      public ConstructorArgument constructorArgument = new ConstructorArgument();  \n\n4.      @Override  \n\n5.      public boolean hasConstructorArgumentValues() {  \n\n6.          return !this.constructorArgument.isEmpty();  \n\n7.      }  \n\n8.  } \n```\n\n\n\n#### **2、第二步**\n\n这个时候BeanDefinition里面已经有了construct-arg列表了，而且可以获取到bean实例，那么怎么将<construct-arg>标签属性放到ConstructorArgument的ValueHolder中呢？\n\n思路就是**在bean实例中找到对应<construct-arg>标签列表的构造函数**\n\n比如construct-arg列表是下面这个\n\n```\n1.  <bean id = \"personService\" class=\"my_spring.beanfactory_construt.test.service.PersonService\">  \n\n2.      <constructor-arg index=\"1\" name=\"eatDao\" ref=\"eatDao\" />  \n\n3.      <constructor-arg index=\"2\" ref=\"drinkDao\" />  \n\n4.      <constructor-arg index=\"3\" type=\"java.lang.String\" value=\"zhanghui\" />  \n\n5.      <constructor-arg index=\"4\" type=\"java.lang.Integer\" value=\"18\" />  \n\n6.  </bean>\n```\n\n\n\n对应的构造函数就应该是这样\n\n```\n1.  public PersonService(EatDao eatDao, DrinkDao drinkDao, String name, int age) {  \n\n2.      super();  \n\n3.      this.eatDao = eatDao;  \n\n4.      this.drinkDao = drinkDao;  \n\n5.      this.name = name;  \n\n6.      this.age = age;  \n\n7.  } \n```\n\n\n\n我们定义**ConstructorResolver**去做这件事情，用代码实现如下：\n\n```\n1.  public class ConstructorResolver {  \n\n2.      protected final Logger log = LoggerFactory.getLogger(ConstructorResolver.class);  \n\n3.      private final ConfigurableBeanFactory beanFactory;  \n\n4.      public ConstructorResolver(ConfigurableBeanFactory beanFactory) {  \n\n5.          super();  \n\n6.          this.beanFactory = beanFactory;  \n\n7.      }  \n\n\n8.      /** \n\n9.       * 根据xml中配置的construct-arg列表，找到bd对应类中最合适的构造函数进行关联 \n\n10.      */  \n\n11.     public Object autowiredConstructor(BeanDefinition bd) {  \n\n12.         // 匹配成功后对应的构造函数  \n\n13.         Constructor<?> constructorToUse = null;  \n\n14.         // 用来存放将ConstructorArgument中的argumentValues进行\n\n15.         BeanDefinitionValueResolver.resolveValueIfNecessary转换后的值  \n\n16.         Object[] argsToUse = null;  \n\n17.         Class<?> beanClass = null;  \n\n18.         try {  \n\n19.             beanClass = this.beanFactory.getClassLoader().loadClass(bd.getClassName());  \n\n20.             Constructor<?>[] candidates = beanClass.getDeclaredConstructors();  \n\n21.             BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this.beanFactory);  \n\n22.             ConstructorArgument args = bd.getConstructorArgument();  \n\n23.             SimpleTypeConverter typeConverter = new SimpleTypeConverter();  \n\n24.             // 获取构造函数的参数名称  \n\n25.             LocalVariableTableParameterNameDiscoverer parameterNameDiscoverer = new LocalVariableTableParameterNameDiscoverer();  \n\n26.             for (int i = 0; i < candidates.length; i++) {  \n\n27.                 Parameter param[] = candidates[i].getParameters();  \n\n28.                 String[] paramsName = parameterNameDiscoverer.getParameterNames(candidates[i]);  \n\n29. //先对参数长度进行判断\n\n30.                 if (param.length != args.getArgumentCount()) {  \n\n31.                     continue;  \n\n32.                 }  \n\n33.                 argsToUse = new Object[param.length];  \n\n34.                 // 进行类型匹配  \n\n35.                 boolean result = this.valueMatchTypes(param, paramsName, args.getArgumentValues(), argsToUse, valueResolver, typeConverter);  \n\n36.                 if (result) {  \n\n37.                     constructorToUse = candidates[i];  \n\n38.                     break;  \n\n39.                 }  \n\n40.             }  \n\n41.             if (constructorToUse == null) {  \n\n42.                 throw new BeanCreateException(bd.getId(), \"can`t find  a apporiate constructor\");  \n\n43.             }  \n\n44.             try {  \n\n45. //找到匹配的构造函数后，直接根据<construct-arg>标签列表的值进行实例化\n\n46.                 return constructorToUse.newInstance(argsToUse);  \n\n47.             } catch (Exception e) {  \n\n48.                 throw new BeanCreateException(bd.getId(), \"can`t find  a create instance using\" + argsToUse);  \n\n49.             }  \n\n50.         } catch (ClassNotFoundException e) {  \n\n51.             e.printStackTrace();  \n\n52.         }  \n\n53.         return null;  \n\n54.     }  \n\n55. }  \n```\n\n\n\n上述过程就是遍历出bean实例的所有构造函数\n\n```\nConstructor<?>[] candidates = beanClass.getDeclaredConstructors(); \n```\n\n进行类型匹配\n\n```\nboolean result = this.**valueMatchTypes**(param, paramsName, args.getArgumentValues(), argsToUse, valueResolver, typeConverter); \n```\n\n匹配成功根据construct-arg列表给的值实例化bean\n\n```\nreturn constructorToUse.newInstance(argsToUse); \n```\n\n\n\n这里重点是valueMatchTypes这个匹配方法\n\n鉴于ValueHolder属性也就是<construct-arg>标签中的属性有index、name、type\n\n那么就基于这三个维度去做过滤，当然第一道过滤是判断参数个数不用说\n\n对应valueMatchTypes如下\n\n```\n1. private boolean valueMatchTypes(Parameter[] params, String[] paramsName, List<ValueHolder> argumentValues, Object[] argsToUse, BeanDefinitionValueResolver valueResolver, SimpleTypeConverter typeConverter) throws ClassNotFoundException {  \n\n2.      //根据index排序  \n\n3.      argumentValues = countSort(argumentValues);  \n\n4.      for (int i = 0; i < params.length; i++) {  \n\n5.          ConstructorArgument.ValueHolder valueHolder = argumentValues.get(i);  \n\n6.          //判断名称name  \n\n7.          if (StringUtils.isNotBlank(valueHolder.getName())) {  \n\n8.              if (!StringUtils.equals(paramsName[i], valueHolder.getName())) {  \n\n9.                  return false;  \n\n10.             }  \n\n11.         }  \n\n12.         //判断类型type  \n\n13.         if (StringUtils.isNotBlank(valueHolder.getType())) {  \n\n14.             Class valueClazz = Class.forName(valueHolder.getType());  \n\n15.             if (!ClassUtils.isAssignable(valueClazz, params[i].getType())) {  \n\n16.                 return false;  \n\n17.             }  \n\n18.         }  \n\n19.         // 默认进行类型匹配  \n\n20.         try {  \n\n21.             Object resolveValue = valueResolver.resolveValueIfNecessary(valueHolder.getValue());  \n\n22.             // 核心在这里，如果不能将argumentValues中的值转换成parameterTypes中对应的类，则转型失败，类型不匹配  \n\n23.             Object convertedValue = typeConverter.convertIfNecessary(resolveValue, params[i].getType());  \n\n24.             // 转型成功，记录下来  \n\n25.             argsToUse[i] = convertedValue;  \n\n26.         } catch (TypeMismatchException e) {  \n\n27.             log.error(e.getMessage());  \n\n28.             return false;  \n\n29.         } catch (RuntimeException e) {  \n\n30.             log.error(e.getMessage());  \n\n31.             return false;  \n\n32.         }  \n\n33.     }  \n\n34.     return true;  \n\n35. }  \n```\n\n\n\n上述过程就是\n\n1）先给construct-arg根据index排序，这里有个细节就是不能打乱默认顺序，比如两个index都是0（默认）的construct-arg不能在排序后打乱先后顺序\n\n排序算法如下，注意这里用的是 >=\n\n```\n1.  private List<ValueHolder> countSort(List<ValueHolder> argumentValues) {  \n\n2.      List<ValueHolder> result = argumentValues.stream().sorted((t1, t2) -> {  \n\n3.          return t1.getIndex() >= t2.getIndex() ? 1 : -1;  \n\n4.      }).collect(Collectors.toList());  \n\n5.      return result;  \n\n6.  } \n```\n\n\n\n2）在根据name、type匹配，不匹配说明当前构造函数不是我要找的\n\na. 在name匹配的时候，需要注意的是在反射获取属性的时候Paramenter中的name属性其实是arg0、arg1，这里使用了Spring的org.springframework.core.**LocalVariableTableParameterNameDiscoverer**这个类，**使用ASM字节码工具去修改class文件获取真实的属性name**\n\n也就是这两句\n\n```\n1.  LocalVariableTableParameterNameDiscoverer parameterNameDiscoverer = new LocalVariableTableParameterNameDiscoverer();     \n\n2.  String[] paramsName = parameterNameDiscoverer.getParameterNames(candidates[i]); \n```\n\n\n\nb. 在type匹配的时候，需要注意的是要看两个类有没有子孙关系，本来用AClass.isAssignableFrom(BClass)就可以了，但是**考虑到有类的属性有可能是原始类型，那么这个方法就用不了**，**比如int.class和java.lang.Integer.class就不会匹配**\n\nSpring对应的关联方法如下，将基本类型做了一下转换：\n\n```\n1.  static {  \n\n2.      primitiveWrapperTypeMap.put(Boolean.class, Boolean.TYPE);  \n\n3.      primitiveWrapperTypeMap.put(Byte.class, Byte.TYPE);  \n\n4.      primitiveWrapperTypeMap.put(Character.class, Character.TYPE);  \n\n5.      primitiveWrapperTypeMap.put(Double.class, Double.TYPE);  \n\n6.      primitiveWrapperTypeMap.put(Float.class, Float.TYPE);  \n\n7.      primitiveWrapperTypeMap.put(Integer.class, Integer.TYPE);  \n\n8.      primitiveWrapperTypeMap.put(Long.class, Long.TYPE);  \n\n9.      primitiveWrapperTypeMap.put(Short.class, Short.TYPE);  \n\n10.     Map.Entry<Class<?>, Class<?>> entry;  \n\n11.     for (Iterator localIterator = primitiveWrapperTypeMap.entrySet().iterator(); localIterator.hasNext();) {  \n\n12.         entry = (Map.Entry) localIterator.next();  \n\n13.         primitiveTypeToWrapperMap.put(entry.getValue(), entry.getKey());  \n\n14.     }  \n\n15. }  \n\n16. public static boolean isAssignable(Class<?> lhsType, Class<?> rhsType) {  \n\n17.     if (lhsType.isAssignableFrom(rhsType)) {  \n\n18.         return true;  \n\n19.     }  \n\n20.     if (lhsType.isPrimitive()) {  \n\n21.         Class<?> resolvedPrimitive = (Class) primitiveWrapperTypeMap.get(rhsType);  \n\n22.         if (lhsType == resolvedPrimitive) {  \n\n23.             return true;  \n\n24.         }  \n\n25.     } else {  \n\n26.         Class<?> resolvedWrapper = (Class) primitiveTypeToWrapperMap.get(rhsType);  \n\n27.         if ((resolvedWrapper != null) && (lhsType.isAssignableFrom(resolvedWrapper))) {  \n\n28.             return true;  \n\n29.         }  \n\n30.     }  \n\n31.     return false;  \n\n32. } \n```\n\n\n\n3）匹配成功或者说所有的<construct-arg>标签都没有index、name、type属性，这时候对bean的每一个属性进行尝试赋值操作，这里核心内容就是\n\n```\n// 核心在这里，如果不能将argumentValues中的值转换成parameterTypes中对应的类，则转型失败，类型不匹配  \n\nObject convertedValue = typeConverter.convertIfNecessary(resolveValue, params[i].getType()); \n```\n\n就是将resolveValue尝试转换成params[i].getType()的类，成功说明这个属性成功匹配，失败就是当前构造函数不是我要找的咯\n\n\n\n#### **3、第三步**\n\n在getBean()的时候判断下这个Bean中ConstructorArgument有没有值，如果有的话，说明有配置<construct-arg>标签，那么就调用上面的步骤尝试去匹配Bean中的构造函数，没有的话就new一个\n\n对应代码如下：\n\n```\n1.  /*** \n\n2.   * 根据BeanDefinition初始化Bean \n\n3.   */  \n\n4.  private Object initalBean(BeanDefinition bd) {  \n\n5.      if(bd.hasConstructorArgumentValues()) {  \n\n6.          ConstructorResolver constructorResolver = new ConstructorResolver(this);  \n\n7.          return constructorResolver.autowiredConstructor(bd);  \n\n8.      }  \n\n9.      //...  \n\n10. }  \n```", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 5}, "8831361e4f3b738c6e4fa41aedfbd286": {"id": "8831361e4f3b738c6e4fa41aedfbd286", "item": "造轮子系列", "title": "七天写一个Spring框架（二）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第二天", "body": "\n本节目标的类图如下：\n\n![img](http://pcc.huitogo.club/abb372169aca567b8cc5ae10e101e53c)\n\n\n\n今天的目标是\n\n获取bean的属性值和引用对象，在xml中如下所示\n\n```\n1.  <bean id = \"personService\" class=\"my_spring.beanfactory_set.test.service.PersonService\">  \n\n2.      <property name=\"eatDao\" ref=\"eatDao\" />  \n\n3.      <property name=\"drinkDao\" ref=\"drinkDao\" />  \n\n4.      <property name=\"name\" value=\"zhanghui\" />  \n\n5.      <property name=\"age\" value=\"18\" />  \n\n6.  </bean>  \n```\n\n\n\n编写出来的成功测试用例如下\n\n```\n1.  @Test  \n\n2.  public void testGetBeanProperties() {  \n\n3.      ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");  \n\n4.      PersonService personService = (PersonService) context.getBean(\"personService\");  \n\n5.      Assert.notNull(personService.getEatDao());  \n\n6.      Assert.notNull(personService.getDrinkDao());  \n\n7.      assertTrue(\"zhanghui\".equals(personService.getName()));  \n\n8.      assertTrue(personService.getAge() == 18);  \n\n9.  }  \n```\n\n带着这个目的出发开始思考怎么设计了\n\n对于<property>标签，我们使用PropertyValue来表示\n\n在解析xml的时候，将每个<bean>标签下的<property>标签解析成PropertyValue，放入到对应BeanDefinition中的List<PropertyValue>中\n\n在getBean()的时候，需要根据BeanDefinition里的List<PropertyValue>给bean设置属性值\n\n\n\n在PropertyValue中\n\n对于name-value的property存储的是propertyName - value（常量）\n\n对于name-ref的property存储的是propertyName - ref （BeanName）\n\n所以**对于name-ref的property在设置属性之前还需要解析出真正的bean实例**\n\n\n\n对于细节问题，后面进行的时候再考虑\n\n先构建**PropertyValue**来存储bean中property的键值，并且在BeanDefinition中加入List<PropertyValue>相关方法\n\nPropertyValue代码如下\n\n```\n1.  @Data  \n\n2.  public class PropertyValue {  \n\n3.      private final String name;  \n\n4.      private final Object value;  \n\n5.      private boolean converted = false; // 对于name-ref的情形是否已转换        \n\n6.      private  String convertedValue; // name-ref情形转换后的值  \n\n7.      public PropertyValue(String name, Object value) {  \n\n8.          super();  \n\n9.          this.name = name;  \n\n10.         this.value = value;  \n\n11.     }  \n\n12. } \n```\n\n\n\n这个时候考虑到name-value和name-ref的情况，所以对PropertyValue的value值创建不同的实例来表示\n\nname-value的情况用**TypedStringValue**表示PropertyValue的value\n\n```\n1.  @Data  \n\n2.  public class TypedStringValue {  \n\n3.      private final String value;  \n\n4.  }\n```\n\n\n\nname-ref的情况用**RuntimeBeanReference**表示PropertyValue的value\n\n```\n1.  @Data  \n\n2.  public class RuntimeBeanReference {  \n\n3.      private final String name;  \n\n4.  }  \n```\n\n\n\n解析xml中<bean>标签下的<property>标签成PropertyValue并放到对应BeanDefinition的List<PropertyValue>中\n\n```\n1.  public void loadBeanDefinition(Resource resource) {  \n\n2.       //...  \n\n3.      // 解析bean的property放到propertyValue中  \n\n4.      this.parsePropertyElement(ele, bd);  \n\n5.        this.registry.registryBeanDefinition(id, bd);   \n\n6.  }  \n\n\n7.  /** \n\n8.   * 解析ele下的所有property标签，并放入BeanDefinition中PropertyValue的集合中 \n\n9.   */  \n\n10. public void parsePropertyElement(Element ele, BeanDefinition bd) {  \n\n11.     Iterator itr = ele.elementIterator(PROPERTY_ELEMENT);  \n\n12.     while (itr.hasNext()) {  \n\n13.         Element propElement = (Element) itr.next();  \n\n14.         String propertyName = propElement.attributeValue(NAME_ATTRIBUTE);  \n\n15.         if (!StringUtils.hasLength(propertyName)) {  \n\n16.             return;  \n\n17.         }  \n\n18. //这里value可以是TypedStringValue也可能是RuntimeBeanReference\n\n19.         Object value = this.parsePropertyValue(propElement, bd, propertyName);  \n\n20.         bd.getPropertyValues().add(new PropertyValue(propertyName, value));  \n\n21.     }  \n\n22. }  \n\n\n23. /** \n\n24.  * 根据property标签的name去解析这个property的value，这个value可以是ref，也可以是value \n\n25.  */  \n\n26. public Object parsePropertyValue(Element ele, BeanDefinition bd, String propertyName) {  \n\n27.     String elementName = (propertyName != null) ? \"<property> element for property '\" + propertyName + \"'\" : \"<construct-arg> element\";  \n\n28.     boolean hasRefAttribute = (ele.attribute(REF_ATTRIBUTE) != null);  \n\n29.     boolean hasValueAttribute = (ele.attribute(VALUE_ATTRIBUTE) != null);  \n\n30.     if (hasRefAttribute) {  \n\n31.         String refName = ele.attributeValue(REF_ATTRIBUTE);  \n\n32.         if (!StringUtils.hasText(refName)) {  \n\n33.             System.err.println(elementName + \"contains empty 'ref' attribute\");  \n\n34.         }  \n\n35.         RuntimeBeanReference ref = new RuntimeBeanReference(refName);  \n\n36.         return ref;  \n\n37.     } else if (hasValueAttribute) {  \n\n38.         TypedStringValue valueHolder = new TypedStringValue(ele.attributeValue(VALUE_ATTRIBUTE));  \n\n39.         return valueHolder;  \n\n40.     } else {  \n\n41.         throw new RuntimeException(elementName + \"must specify a ref or value\");  \n\n42.     }  \n\n43. }  \n```\n\n\n\n在getBean()中对bean设置属性之前有两个问题\n\n1）对于property是name-ref的话，我们应该给bean设置的是ref的实例bean，这就涉及一个获取实例bean的问题\n\n2）对于property是name-value的话，如果value是int类型，我们给bean做setValue是报错的，如果value是string类型就不会报错，这就涉及一个将int转换成string的问题\n\n\n\n对于问题一\n\n使用一个接口**BeanDefinitionValueResolver**去实现转换实例bean\n\n```\n1.  /** \n\n2.   * 将beanId解析成实例Bean \n\n3.   */  \n\n4.  public class BeanDefinitionValueResolver {  \n\n5.      private final DefaultBeanFactory defaultBeanFactory;  \n\n6.      public BeanDefinitionValueResolver(DefaultBeanFactory defaultBeanFactory) {  \n\n7.          super();  \n\n8.          this.defaultBeanFactory = defaultBeanFactory;  \n\n9.      }  \n\n\n10. //这里解析PropertyValue中TypedStringValue 和 RuntimeBeanReference \n\n11.     public Object resolveValueIfNecessary(Object value) {  \n\n12.         if (value instanceof RuntimeBeanReference) {  \n\n13.             RuntimeBeanReference ref = (RuntimeBeanReference) value;  \n\n14.             String refName = ref.getName();  \n\n15.             Object bean = this.defaultBeanFactory.getBean(refName);  \n\n16.             return bean;  \n\n17.         } else if (value instanceof TypedStringValue) {  \n\n18.             TypedStringValue stringValue = (TypedStringValue) value;  \n\n19.             return stringValue.getValue();  \n\n20.         } else {  \n\n21.             throw new RuntimeException(\"the value \" + value + \" has not implemented\");  \n\n22.         }  \n\n23.     }  \n\n24. }  \n```\n\n\n\n对于问题二，也需要做一下类型转换\n\n定义接口**TypeConverter**如下\n\n```\n1.  public interface TypeConverter {  \n\n2.      public abstract <T> T convertIfNecessary(Object value, Class<T> requiredType) throws TypeMismatchException;  \n\n3.  } \n```\n\n\n\nTypeConverter接口的默认实现类**SimpleTypeConverter**\n\n这里涉及到的如何将String转换成number以及String转换成boolean因为比较复杂，用的就是spring源码的\n\n```\n1.  public class SimpleTypeConverter implements TypeConverter {  \n\n2.      private Map<Class<?>, PropertyEditor> defaultEditors;  \n\n3.      @Override  \n\n4.      public <T> T convertIfNecessary(Object value, Class<T> requiredType) throws TypeMismatchException{  \n\n5.  // 判断value的类型是不是requiredType类或者子类  \n\n6.          if(ClassUtils.isAssignableValue(requiredType, value)) { \n\n7.              return (T)value;  \n\n8.          }else {  \n\n9.              if(value instanceof String) {   \n\n10. // 这个就是用来转换的工具类，核心就是PropertyEditor \n\n11.                 PropertyEditor editor = findDefaultEditor(requiredType); \n\n12.                 try {  \n\n13.                     editor.setAsText((String)value);    \n\n14.                 } catch (IllegalArgumentException e) {  \n\n15.                     throw new TypeMismatchException(\"illegal argument \" + value);  \n\n16.                 }  \n\n17.                 return (T)editor.getValue();  \n\n18.             }else {  \n\n19.                 throw new RuntimeException(\"can`t convert value for \" + value + \" class:\" + requiredType);  \n\n20.             }  \n\n21.         }  \n\n22.     }  \n\n\n23.     private PropertyEditor findDefaultEditor(Class<?> requiredType) {  \n\n24.         PropertyEditor editor = this.getDefaultEditor(requiredType);  \n\n25.         if(editor == null) {  \n\n26.             throw new RuntimeException(\"Editor for \" + requiredType + \"has not been implemented!\");  \n\n27.         }  \n\n28.         return editor;  \n\n29.     }  \n\n\n30.     private PropertyEditor getDefaultEditor(Class<?> requiredType) {  \n\n31.         if(this.defaultEditors == null) {  \n\n32.             createDefaultEditors();  \n\n33.         }  \n\n34.         return this.defaultEditors.get(requiredType);  \n\n35.     }  \n\n\n36.     private void createDefaultEditors() {  \n\n37.         this.defaultEditors = new HashMap<>(64);  \n\n38.  // 转换成boolean  \n\n39.         this.defaultEditors.put(boolean.class, new CustomBooleanEditor(false));\n\n40.         this.defaultEditors.put(Boolean.class, new CustomBooleanEditor(true));  \n\n41.         // 转换成int \n\n42.         this.defaultEditors.put(int.class, new CustomNumberEditor(Integer.class, false));  \n\n43.         this.defaultEditors.put(Integer.class, new CustomNumberEditor(Integer.class, true);\n\n44.         //TODO（其他类型的Editor都可以在这里加入）  \n\n45.     }  \n\n46. }  \n```\n\n\n\n有了解析类和转换类之后，在getBean()时的代码修改如下：\n\n```\n1.  @Override  \n\n2.  public Object getBean(String beanId) {  \n\n3.      BeanDefinition bd = this.getBeanDefinition(beanId);  \n\n4.      if (bd == null) {  \n\n5.          return null;  \n\n6.      }  \n\n7.  // 放入单例和获取单例\n\n8.      if (bd.isSingleton()) {   \n\n9.          Object bean = this.getSingleton(beanId);  \n\n10.         if (bean == null) {  \n\n11.             bean = createBean(bd);  \n\n12.             this.registrySingleton(beanId, bean);  \n\n13.         }  \n\n14.         return bean;  \n\n15.     }  \n\n16. // 初始化bean\n\n17.     return createBean(bd);  \n\n18. }  \n\n\n19. /** \n\n20.  * 创造bean，并给bean的property赋值 \n\n21.  */  \n\n22. public Object createBean(BeanDefinition bd) {  \n\n23.     Object bean = initalBean(bd);  \n\n24.     // 给bean设置属性  \n\n25.     populateBean(bd, bean);  \n\n26.     return bean;  \n\n27. }  \n\n\n28. /**\n\n29.  * 根据BeanDefinition初始化Bean \n\n30.  */  \n\n31. public Object initalBean(BeanDefinition bd) {  \n\n32.     String className = bd.getClassName();  \n\n33.     ClassLoader cl = this.getClassLoader();  \n\n34.     try {  \n\n35.         Class<?> clazz = cl.loadClass(className);  \n\n36.         return clazz.newInstance();  \n\n37.     } catch (Exception e) {  \n\n38.         throw new BeanCreateException(\"create bean \" + className + \"failed!\");  \n\n39.     }  \n\n40. }  \n\n\n41. /** \n\n42.  * 给bean设置属性 \n\n43.  */  \n\n44. protected void populateBean(BeanDefinition bd, Object bean) {  \n\n45.     List<PropertyValue> pvList = bd.getPropertyValues();  \n\n46.     if (pvList.isEmpty()) {  \n\n47.         return;  \n\n48.     }  \n\n49.     BeanDefinitionValueResolver resolver = new BeanDefinitionValueResolver(this);  \n\n50.     SimpleTypeConverter typeConverter = new SimpleTypeConverter();  \n\n51.     for (PropertyValue pv : pvList) {  \n\n52.         String propertyName = pv.getName();  \n\n53.         Object orignalValue = pv.getValue();  \n\n54. //获取转换之后的数据\n\n55.         Object resolvedValue = resolver.resolveValueIfNecessary(orignalValue);  \n\n56.         try {  \n\n57.             // 反射设置属性  \n\n58.             BeanInfo beanInfo = Introspector.getBeanInfo(bean.getClass());  \n\n59.             PropertyDescriptor[] pds = beanInfo.getPropertyDescriptors();  \n\n60.             for (PropertyDescriptor pd : pds) {  \n\n61.                 if (propertyName.equals(pd.getName())) {  \n\n62.                     // 类型不匹配时进行转换，主要是将string类型转换成其他类  \n\n63.                     Object convertedValue = typeConverter.convertIfNecessary(resolvedValue, pd.getPropertyType());  \n\n64.                     pd.getWriteMethod().invoke(bean, convertedValue);  \n\n65.                 }  \n\n66.             }  \n\n67.         } catch (Exception e) {  \n\n68.             log.error(e.getMessage(),e);  \n\n69.         } \n\n70.     }  \n\n71. }  \n```\n\n\n\n上述写法是Spring里面源码的写法，其实对于将String转换成Number和给bean设置属性值有个封装好的工具类org.apache.commons.beanutils.BeanUtils.setProperty()\n\n```\n1.  for (PropertyValue pv : pvList) {  \n\n2.      String propertyName = pv.getName();  \n\n3.      Object orignalValue = pv.getValue();  \n\n4.      Object resolvedValue = resolver.resolveValueIfNecessary(orignalValue);  \n\n5.      // 本节的String转换成Number和给bean设置属性的过程可以直接用这个代替  \n\n6.      try {  \n\n7.          BeanUtils.setProperty(bean, propertyName, resolvedValue);  \n\n8.      } catch (IllegalAccessException e) {  \n\n9.          log.error(e.getMessage());  \n\n10.     } catch (InvocationTargetException e) {  \n\n11.         log.error(e.getMessage());  \n\n12.     } \n\n13. }\n```", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "37f403ef81065b40a4f51a6f65257d4f": {"id": "37f403ef81065b40a4f51a6f65257d4f", "item": "造轮子系列", "title": "七天写一个Spring框架（五）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第五天", "body": "\n本节目标的类图如下：\n\n![img](http://pcc.huitogo.club/cc2ab9a9034f11351c1557eeecd63236)\n\n\n\n**今天的目标是**\n\n帮助实例BeanA中被@Autowired修饰的字段或方法进行实例化，并且将这个实例化的Bean赋给实例BeanA，也就是实现通过@Autowired的方法为实例A赋属性值。\n\n实现的总体思想先将@Autowired修饰的字段或方法转换成对应的Bean，然后如果是字段的话就直接将这个Bean赋值给这个字段，如果是set方法的话，就反射调用这个set方法完成赋值，最后需要考虑在一个合适的时机调用这些实例化和赋值操作。\n\n\n\n#### **1、转换Bean**\n\n第一步将@Autowired修饰的字段或方法转换成对应的Bean\n\n我们需要一个类来表示被@Autowired修饰的方法或者字段\n\n这里新建一个类DependencyDescriptor\n\n```\n1.  public class DependencyDescriptor {  \n\n2.      //被修饰的字段  \n\n3.      private final  Member member;  \n\n4.      //是否必须有值存在  \n\n5.      private final boolean required;  \n\n6.      public DependencyDescriptor(Member member, boolean required) {  \n\n7.          this.member = member;  \n\n8.          this.required = required;  \n\n9.      }  \n\n10.     public Class<?> getDependencyType(){  \n\n11.         if(this.member instanceof Field) {  \n\n12.             Field field = (Field) member;  \n\n13.             return field.getType();  \n\n14.         }  \n\n15.         // 如果是放在setter方法上，取第一个参数的类型  \n\n16.         if(this.member instanceof Method) {   \n\n17.             Method method = (Method)member;  \n\n18.             return method.getParameterTypes()[0];  \n\n19.         }  \n\n20.         throw new RuntimeException(\"only support field and method dependency\");  \n\n21.     }  \n\n22.     public boolean isRequired() {  \n\n23.         return required;  \n\n24.     }  \n\n25. }  \n```\n\n这里getDependencyType()可以根据修饰的类型获取对应的Class。\n\n现在我们赋予BeanFactory新的能力，可以根据DependencyDescriptor（其实就是想要里面解析出来的Class）映射Bean，这里的Bean自然就是BeanFactory的Bean容器里面的\n\n\n\n定义新的接口AutowiredCapableBeanFactory和它的实现\n\n```\n1.  public interface AutowiredCapableBeanFactory{  \n\n2.      Object resolveDependency(DependencyDescriptor descriptor);  \n\n3.  }  \n\n\n4.  public class DefaultBeanFactory extends DefaultSingletonBeanRegistry  \n\n5.          implements BeanDefinitionRegistry, ConfigurableBeanFactory, AutowiredCapableBeanFactory {  \n\n6.     //...  \n\n7.     // 尝试解析descriptor中Class成BeanDefinition  \n\n8.      @Override  \n\n9.      public Object resolveDependency(DependencyDescriptor descriptor) {  \n\n10.         Class<?> typeToMatch = descriptor.getDependencyType();  \n\n11.         for (BeanDefinition bd : this.container.values()) {  \n\n12.             resolveBeanClass(bd);  \n\n13.             Class<?> beanClass = bd.getBeanClass();  \n\n14.             if (typeToMatch.isAssignableFrom(beanClass)) {  \n\n15.                 return this.getBean(bd.getId());  \n\n16.             }  \n\n17.         }  \n\n18.         return null;  \n\n19.     }  \n\n20.      //...  \n\n21. }  \n```\n\n\n\n好了，到此将字段、方法映射成对应的Bean就完成了，怎么用呢？\n\n```\n1.  @Test  \n\n2.  public void testResolveDependency() throws NoSuchFieldException, SecurityException {  \n\n3.      DefaultBeanFactory beanFactory = new DefaultBeanFactory();  \n\n4.      XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(beanFactory);  \n\n5.      reader.loadBeanDefinition(new ClassPathResource(\"applicationContext3.xml\"));  \n\n6.      Field f =  PersonService.class.getDeclaredField(\"eatDao\");  \n\n7.      DependencyDescriptor descriptor = new DependencyDescriptor(f, true);  \n\n8.      Object o = beanFactory.resolveDependency(descriptor);  \n\n9.      Assert.assertTrue(o instanceof EatDao);  \n\n10. }  \n```\n\n\n\n#### **2、将转换的Bean赋给它所在的Bean A**\n\n在此之前，我们需要对上面转换过程进行一次封装，Spring的实现过程就是一步步的封装隐藏细节，最后用一个类和方法来实现所需要的功能\n\n所以，针对Field和Method以及其他情况，我们抽象出一个接口InjectionElement\n\n```\n1.  public abstract class InjectionElement {  \n\n2.      protected Member member;  \n\n3.      protected AutowiredCapableBeanFactory factory;  \n\n4.      public InjectionElement(Member member, AutowiredCapableBeanFactory factory) {  \n\n5.          super();  \n\n6.          this.member = member;  \n\n7.          this.factory = factory;  \n\n8.      }  \n\n9.      public abstract void inject(Object target);  \n\n10. } \n```\n\n这里最重要的就是inject的实现，它的作用就是将BeanFacotry.resolveDependency出来的Bean赋给target\n\n\n\n这里来看一下Field的inject实现\n\n```\n1.  public class AutowiredFieldElement extends InjectionElement {  \n\n2.      //...  \n\n3.      @Override  \n\n4.      public void inject(Object target) {   \n\n5.          Field field = getField();  \n\n6.          try {  \n\n7.              DependencyDescriptor descriptor = new DependencyDescriptor(field, required);  \n\n8.              Object fieldObj = factory.resolveDependency(descriptor);  \n\n9.              if (fieldObj != null) {  \n\n10.                 // 使field可用，在field为final、private修饰的情况下，accessible为false的  \n\n11.                 ReflectionUtils.makeAccessible(field);  \n\n12.                 field.set(target, fieldObj);  \n\n13.             }else if (required) {  \n\n14.                 throw new BeanAutowiredException(\"could not find a bean named[\"  \n\n15.                         + descriptor.getDependencyType().getName() + \"] used to autowired for\" + target);  \n\n16.             }  \n\n17.         } catch (Throwable e) {  \n\n18.             throw new BeanCreateException(\"could not autowird field :\" + field, e);  \n\n19.         }  \n\n20.     }  \n\n21.     //...  \n\n22. }  \n```\n\n这里直接是通过 field.set(target, fieldObj); 赋值的\n\n\n\n对应Method的inject实现\n\n```\n1.  public class AutowiredMethodElementextends InjectionElement {  \n\n2.      //...  \n\n3.      @Override  \n\n4.      public void inject(Object target) {   \n\n5.          Method method = getMethod();  \n\n6.          try {  \n\n7.              DependencyDescriptor descriptor = new DependencyDescriptor(method, required);  \n\n8.              Object fieldObj = factory.resolveDependency(descriptor);  \n\n9.              if (fieldObj != null) {  \n\n10.                 // 使field可用，在field为final、private修饰的情况下，accessible为false的  \n\n11.                 ReflectionUtils.makeAccessible(method);  \n\n12.                 method.invoke(target, methodReturnObj);  \n\n13.             }else if (required) {  \n\n14.                 throw new BeanAutowiredException(\"could not find a bean named[\"  \n\n15.                         + descriptor.getDependencyType().getName() + \"] used to autowired for\" + target);  \n\n16.             }  \n\n17.         } catch (Throwable e) {  \n\n18.             throw new BeanCreateException(\"could not autowird method:\" + method, e);  \n\n19.         }  \n\n20.     }  \n\n21.     //...  \n\n22. }  \n```\n\n可以看到Method是通过 method.invoke(target, methodReturnObj); 赋值的\n\n\n\n听过你们好奇这个ReflectionUtils.makeAccessible()方法，来来来，贴下短小的源码\n\n```\n1.  public static void makeAccessible(Method method) {  \n\n2.      if ((!Modifier.isPublic(method.getModifiers()) ||  \n\n3.              !Modifier.isPublic(method.getDeclaringClass().getModifiers())) && !method.isAccessible()) {  \n\n4.          method.setAccessible(true);  \n\n5.      }  \n\n6.  }  \n```\n\n除了Field和Method的情况，其实应该还有Constructor的情形，这里就没有实现了\n\n\n\n在进行下一步之前，我们觉得对应每一个Method和Field难道都一个个去inject到target?\n\n还是来封装一下吧，把这些InjectionElement放到一个List中去，然后统一inject，完美！\n\n新建一个类InjectionMetadata来做这件事，它就负责将elements全部注入到targetClass中\n\n```\n1.  @Getter  \n\n2.  public class InjectionMetadata {  \n\n3.      private final Class<?> targetClass;  \n\n4.      private final List<InjectionElement> elements;  \n\n5.      public InjectionMetadata(Class<?> targetClass, List<InjectionElement> elements) {  \n\n6.          this.targetClass = targetClass;  \n\n7.          this.elements = elements;  \n\n8.      }  \n\n9.      public void inject(Object target) {  \n\n10.         if(elements == null || elements.isEmpty()) {  \n\n11.             return;  \n\n12.         }  \n\n13.         for(InjectionElement injectionElement : elements) {  \n\n14.             injectionElement.inject(target);  \n\n15.         }  \n\n16.     }  \n\n17. } \n```\n\n\n\n这时候使用起来就是这样\n\n```\n1.  @Test  \n\n2.  public void testInject() throws NoSuchFieldException, SecurityException {  \n\n3.      DefaultBeanFactory beanFactory = new DefaultBeanFactory();  \n\n4.      XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(beanFactory);  \n\n5.      reader.loadBeanDefinition(new ClassPathResource(\"applicationContext3.xml\"));  \n\n6.      Class<?> clazz = PersonService.class;  \n\n7.      LinkedList<InjectionElement> elements = new LinkedList<>();  \n\n8.      {  \n\n9.          Field f = clazz.getDeclaredField(\"eatDao\");  \n\n10.         InjectionElement injectionEle = new AutowiredFieldElement(f, true, beanFactory);  \n\n11.         elements.add(injectionEle);  \n\n12.     }  \n\n13.     {  \n\n14.         Field f = clazz.getDeclaredField(\"drinkDao\");  \n\n15.         InjectionElement injectionEle = new AutowiredFieldElement(f, true, beanFactory);  \n\n16.         elements.add(injectionEle);  \n\n17.     }  \n\n18.     // 这里是真正的注入过程，将elemenets中的变量通过setter的方式放到clazz中  \n\n19.     // metadata.inject()实质调用的是InjectionElement.inject()  \n\n20.     InjectionMetadata metadata = new InjectionMetadata(clazz, elements);  \n\n21.     PersonService personServie = new PersonService();  \n\n22.     metadata.inject(personServie);  \n\n23.     Assert.assertTrue(personServie.getEatDao() instanceof EatDao);  \n\n24.     Assert.assertTrue(personServie.getDrinkDao() instanceof DrinkDao);  \n\n25. }  \n```\n\n\n\n#### **3、将targetClass中所有被@Autowired修饰的地方转换成InjectionMeta**\n\n第二步中，我们可以将一个Filed或Method转换成InjectionElement，并且可以inject到targetClass中，现在我们怎么获取或者筛选这些Field或者Method呢？\n\n我们新建一个类AutowiredAnnotationProcessor来做这件事，它的任务就是在targetClass筛选出这些Field和Method并且转换成InjectionElement，最后组装一个InjectionMetadata返回出来\n\n\n\nAutowiredAnnotationProcessor代码如下：\n\n```\n1.  public class AutowiredAnnotationProcessor{  \n\n2.      private AutowiredCapableBeanFactory beanFactory;  \n\n3.      private String requiredParameterName = \"required\";  \n\n4.      private boolean requiredParameterValue = true;  \n\n5.  //这里使用一个集合装载可以被解析的注释类\n\n6.  private final Set<Class<? extends Annotation>> autowiredAnnotationTypes  = new LinkedHashSet<>();\n\n7.     public AutowiredAnnotationProcessor() {\n\n8.  this.autowiredAnnotationTypes.add(Autowired.class);\n\n9.  }\n\n\n10.     public InjectionMetadata buildAutowiringMetadata(Class<?> clazz) {  \n\n11.         LinkedList<InjectionElement> elements = new LinkedList<>();  \n\n12.         Class<?> targetClass = clazz;  \n\n13.         do {  \n\n14.             LinkedList<InjectionElement> currentElements = new LinkedList<>();  \n\n15.             for (Field field : targetClass.getDeclaredFields()) {  \n\n16.                 //查找@Autowired注释  \n\n17.                 Annotation ann = findAutowiredAnnotation(field);  \n\n18.                 if (ann != null) {  \n\n19.                     // 确认被修饰的字段是否是static的  \n\n20.                     if (Modifier.isStatic(field.getModifiers())) {  \n\n21.                         continue;  \n\n22.                     }  \n\n23.                     boolean required = determinedRequiredStatus(ann);  \n\n24.                     // 新增一条InjectionElement  \n\n25.                     currentElements.add(new AutowiredFieldElement(field, required, beanFactory));  \n\n26.                 }  \n\n27.             }  \n\n28.             for (Method method : targetClass.getDeclaredMethods()) {  \n\n29.                 //查找@Autowired注释  \n\n30.                 Annotation ann = findAutowiredAnnotation(method);  \n\n31.                 if (ann != null) {  \n\n32.                     // 确认被修饰的字段是否是static的  \n\n33.                     if (Modifier.isStatic(method.getModifiers())) {  \n\n34.                         continue;  \n\n35.                     }  \n\n36.                     boolean required = determinedRequiredStatus(ann);  \n\n37.                     // 新增一条InjectionElement  \n\n38.                     currentElements.add(new AutowiredMethodElement(method, required, beanFactory));  \n\n39.                 }  \n\n40.             }  \n\n41.             elements.addAll(0, currentElements);  \n\n42.             targetClass = targetClass.getSuperclass();  \n\n43.         } while (targetClass != null && targetClass != Object.class);  \n\n44.         return new InjectionMetadata(clazz, elements);  \n\n45.     }  \n\n46.     /** \n\n47.      * 在ao上查找autowiredAnnotationTypes中的注释 \n\n48.      * 这里查找方式说明，如果在变量或者方法上面加上了@Autowired和@Resource注释的话，只会生效第一个 \n\n49.      * @param ao \n\n50.      * @return \n\n51.      */  \n\n52.     private Annotation findAutowiredAnnotation(AccessibleObject ao) {  \n\n53.         for (Class<? extends Annotation> type : this.autowiredAnnotationTypes) {  \n\n54.             Annotation ann = AnnotationUtils.getAnnotation(ao, type);  \n\n55.             if (ann != null) {  \n\n56.                 return ann;  \n\n57.             }  \n\n58.         }  \n\n59.         return null;  \n\n60.     }  \n\n\n61.     /** \n\n62.      * 获取注释（这里指@Autowired）的required属性 \n\n63.      * @param ann \n\n64.      * @return \n\n65.      */  \n\n66.     private boolean determinedRequiredStatus(Annotation ann) {  \n\n67.         try {  \n\n68.             Method method = ReflectionUtils.findMethod(ann.annotationType(), this.requiredParameterName);  \n\n69.             if (method == null) {  \n\n70.                 return true;  \n\n71.             }  \n\n72.             return (this.requiredParameterValue == (Boolean) ReflectionUtils.invokeMethod(method, ann));  \n\n73.         } catch (Exception e) {  \n\n74.             return true;  \n\n75.         }  \n\n76.     }  \n```\n\n过程也不是很复杂，核心方法就是buildAutowiringMetadata()，这里需要注意的是筛选targetClass是一个do-while的过程，也就是我不仅要得到当前类的，还有它的父类的父类的父类，直到Object类。\n\n\n\n#### **4、在合适的地方去调用AutowiredAnnotationProcessor.buildAutowiringMetadata()**\n\n这里我们需要简单认识一下SpringBean的生命周期\n\n初始化 --> 实例化 --> 执行中 --> 销毁，可以参考下图\n\n![img](http://pcc.huitogo.club/2c269631f633da39d566bfa20a49ed97)\n\n\n\n所以在Spring中是定义了这样的过程，抽象到一个更高的层次了。\n\n新建BeanPostProcessor接口定义bean初始化前和初始化后的行为\n\n```\n1.  public interface BeanPostProcessor {  \n\n2.      //初始化前  \n\n3.      Object beforeInitialization(Object bean, String beanName) throws BeanExceptionn;  \n\n4.      //初始化后  \n\n5.      Object afterInitialization(Object bean, String beanName) throws BeanExceptionn;  \n\n6.  }  \n```\n\n\n\n新建InstantiationAwareBeanPostProcessor接口定义bean实例化的过程\n\n```\n1.  public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor {  \n\n2.      //实例化前  \n\n3.      Object beforeInstantiation(Class<?> beanClass, String beanName) throws BeanExceptionn;  \n\n4.      //实例化后  \n\n5.      boolean afterInstantiation(Object bean, String beanName);  \n\n6.      //注入属性\n\n7.      void postProcessorPropertyValues(Object  bean, String beanName);  \n\n8.  }  \n```\n\n\n\n我们希望AutowiredAnnotationProcessor是在实例化过程中赋值属性的\n\n```\n1.  public class AutowiredAnnotationProcessor implements InstantiationAwareBeanPostProcessor{  \n\n2.  //...\n\n3.      @Override  \n\n4.      public void postProcessorPropertyValues(Object bean, String beanName) {  \n\n5.          InjectionMetadata metadata = buildAutowiringMetadata(bean.getClass());  \n\n6.          try {  \n\n7.              metadata.inject(bean);  \n\n8.          } catch (Throwable e) {  \n\n9.              throw new BeanCreateException(\"Inject dependency failure!\");  \n\n10.         }  \n\n11.     }      \n\n12. }  \n```\n\n\n\n现在可以来实现第四步了，我们当然希望是在getBean的时候为这个Bean注入属性了，所以DefaultBeanFactory.populateBean()中进行实现\n\n```\n1.  public class DefaultBeanFactory extends DefaultSingletonBeanRegistry  \n\n2.          implements BeanDefinitionRegistry, ConfigurableBeanFactory, AutowiredCapableBeanFactory {  \n\n3.      //...  \n\n4.      protected List<BeanPostProcessor> postProcessorsList = new ArrayList<>();  \n\n5.      @Override  \n\n6.      public void addBeanPostProcessor(BeanPostProcessor postProcessor) {  \n\n7.          this.postProcessorsList.add(postProcessor);  \n\n8.      }  \n\n9.      @Override  \n\n10.     public List<BeanPostProcessor> getBeanPostProcessor() {  \n\n11.         return this.postProcessorsList;  \n\n12.     }  \n\n\n13.     /** \n\n14.      * 给bean设置赋值（注入）属性 \n\n15.      * @param bd \n\n16.      * @param bean \n\n17.      */  \n\n18.     private void populateBean(BeanDefinition bd, Object bean) {  \n\n19.         // 为bean Autowired属性  \n\n20.         // 这里说明在bean中@Autowired的属性会在getBean的时候进行注入  \n\n21.         for (BeanPostProcessor processor : this.getBeanPostProcessor()) {  \n\n22.             // 是否有实例化的BeanPostProcessor  \n\n23.             if (processor instanceof InstantiationAwareBeanPostProcessor) {  \n\n24.                 ((InstantiationAwareBeanPostProcessor) processor).postProcessorPropertyValues(bean, bd.getClassName());  \n\n25.             }  \n\n26.         }  \n\n27.         //...  \n\n28.     }  \n\n29.     //  \n\n30. }  \n```\n\n这里需要注意的是，DefaultBeanFactory里面维护的是一个BeanPostProcessor列表，这里不仅考虑的是在getBean之前为这个Bean注入属性，而是所有需要在Bean初始化前和初始化后以及实例化前和实例化后的操作，是一个更高的层次！Bean生命周期过程在这里体现！\n\n\n\n#### **5、总结**\n\n1）跳出当前这个点，往高处看，不要面向实现，对所有实现的操作都进行封装，到最后最好用一个接口和类就可以得到想要的结果，比如Spring中的ApplicationContext接口。\n\n2）理解了Bean的生命周期。\n\n3）对于抽象出来使用的接口是越简单越好。", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "46abd9ce272e84daae913ed1db8e37e7": {"id": "46abd9ce272e84daae913ed1db8e37e7", "item": "造轮子系列", "title": "七天写一个Spring框架（六）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第六天", "body": "\n本节目标的类图如下：\n\n![img](http://pcc.huitogo.club/b41e9c6cbed4ccfbad222c83104ba367)\n\n\n\n**今天的目标是**\n\n完成Spring Aop的上半节，比如现在给一个方法，和一堆拦截器，我希望这些拦截器可以有序执行，没错，就是Spring Aop中切面上拦截器链怎么执行的。\n\n\n\n#### **1、识别哪些方法需要被拦截**\n\n通常我们使用aop的时候都会定义一个切面，切面中有个重要的pointcut表达式，这个表达式定义着哪些方法需要被增强，第一步就是根据pointcut判断某个方法需不需要被增强\n\n这里Spring实现没有自己去实现，而是直接使用了AspectJ里面的方法进行实现\n\n\n\n这些新建一个类AspectJExpressionPointcut，代码如下：\n\n```\n1.  @Getter  \n\n2.  @Setter  \n\n3.  public class AspectJExpressionPointcut implements Pointcut, MethodMatcher {  \n\n4.      private static final Set<PointcutPrimitive> SUPPORTED_PRIMITIVES = new HashSet<>();  \n\n5.      static {  \n\n6.          SUPPORTED_PRIMITIVES.add(PointcutPrimitive.EXECUTION);  \n\n7.          SUPPORTED_PRIMITIVES.add(PointcutPrimitive.ARGS);  \n\n8.          SUPPORTED_PRIMITIVES.add(PointcutPrimitive.REFERENCE);  \n\n9.          SUPPORTED_PRIMITIVES.add(PointcutPrimitive.THIS);  \n\n10.         SUPPORTED_PRIMITIVES.add(PointcutPrimitive.TARGET);  \n\n11.         SUPPORTED_PRIMITIVES.add(PointcutPrimitive.WITHIN);  \n\n12.         SUPPORTED_PRIMITIVES.add(PointcutPrimitive.AT_ANNOTATION);  \n\n13.         SUPPORTED_PRIMITIVES.add(PointcutPrimitive.AT_WITHIN);  \n\n14.         SUPPORTED_PRIMITIVES.add(PointcutPrimitive.AT_ARGS);  \n\n15.         SUPPORTED_PRIMITIVES.add(PointcutPrimitive.AT_TARGET);  \n\n16.     }  \n\n17.     private String expression;  \n\n18.     private PointcutExpression pointcutExpression;  \n\n19.     private ClassLoader pointcutClassLoader;  \n\n20.     public AspectJExpressionPointcut() {  \n\n21.     }  \n\n22.     @Override  \n\n23.     public boolean match(Method method) {  \n\n24.         //参数校验并解析expression为PointcutExpression  \n\n25.         checkReadytoMatch();  \n\n26.         //返回method是否匹配PointcurExpression  \n\n27.         ShadowMatch shadowMatch = getShadowMatch(method);  \n\n28.         if (shadowMatch.alwaysMatches()) {  \n\n29.             return true;  \n\n30.         }  \n\n31.         return false;  \n\n32.     }  \n\n\n33.     private void checkReadytoMatch() {  \n\n34.         if (getExpression() == null) {  \n\n35.             throw new IllegalStateException(\"Must set property 'expression' before attempting to match\");  \n\n36.         }  \n\n37.         if (this.pointcutExpression == null) {  \n\n38.             this.pointcutClassLoader = ClassUtils.getDefaultClassLoader();  \n\n39.             this.pointcutExpression = buildPointcutExpression(this.pointcutClassLoader);  \n\n40.         }  \n\n41.     }  \n\n42.     /** \n\n43.      * 解析expression为PointcutExpression \n\n44.      * @param classLoader \n\n45.      * @return \n\n46.      */  \n\n47.     private PointcutExpression buildPointcutExpression(ClassLoader classLoader) {  \n\n48.         PointcutParser parser = PointcutParser .getPointcutParserSupportingSpecifiedPrimitivesAndUsingSpecifiedClassLoaderForResolution(  \n\n50.                         SUPPORTED_PRIMITIVES, classLoader);  \n\n51.         return parser.parsePointcutExpression(replaceBooleanOperators(getExpression()), null, new PointcutParameter[0]);  \n\n52.     }  \n\n\n53.     private String replaceBooleanOperators(String expression) {  \n\n54.         String result = StringUtils.replace(expression, \" and \", \" && \");  \n\n55.         result = StringUtils.replace(expression, \" or \", \" || \");  \n\n56.         result = StringUtils.replace(expression, \" not \", \" ! \");  \n\n57.         return result;  \n\n58.     }  \n\n\n59.     private ShadowMatch getShadowMatch(Method method) {  \n\n60.         ShadowMatch shadowMatch = null;  \n\n61.         shadowMatch = this.pointcutExpression.matchesMethodExecution(method);  \n\n62.         return shadowMatch;  \n\n63.     }  \n\n64.     @Override  \n\n65.     public MethodMatcher getMethodMatcher() {  \n\n66.         return this;  \n\n67.     }  \n\n68. }  \n```\n\n\n\n这里主要就是将配置文件里面的pointcut表示式转换成AspectJ的PointcutExpression，然后做一下mathch操作，也就是下面这个操作\n\n```\n1.      private PointcutExpression buildPointcutExpression(ClassLoader classLoader) {  \n\n2.          PointcutParser parser = PointcutParser  \n\n3.                  .getPointcutParserSupportingSpecifiedPrimitivesAndUsingSpecifiedClassLoaderForResolution(  \n\n4.                          SUPPORTED_PRIMITIVES, classLoader);  \n\n5.          return parser.parsePointcutExpression(replaceBooleanOperators(getExpression()), null, new PointcutParameter[0]);  \n\n6.      } \n```\n\n\n\n#### **2、根据aop配置文件定位被增强的方法**\n\n比如我们aop配置的文件如下\n\n```\n1.  <bean id=\"tx\" **class**=\"my_spring.beanfactory_aop.test.tx.TransactionManager\" />  \n\n2.  <aop:config>  \n\n3.      <aop:aspect ref=\"tx\">  \n\n4.          <aop:pointcut expression=\"execution(* my_spring.beanfactory_aop.test.service.*.placeOrder(..))\" id=\"placeOrder\"/>  \n\n5.          <aop:before  method=\"start\" pointcut-ref=\"placeOrder\"></aop:before>  \n\n6.          <aop:after-throwing method=\"rollback\" pointcut-ref=\"placeOrder\"/>  \n\n7.          <aop:after-returning method=\"commit\" pointcut-ref=\"placeOrder\"/>  \n\n8.      </aop:aspect>  \n\n9.  </aop:config>  \n```\n\n\n\n我们肯定是想知道，这个<aop:before>里面的start方法是什么方法，到底存不存在，所以我们先实现怎么去找到这个start方法\n\n实现的思路很简单，从Beafactory中去找这个ref=”tx”里面tx对应的bean，然后获取它的start方法就可以了\n\n新建MethodLocatingFactory，相关代码如下：\n\n```\n1.  @Getter  \n\n2.  @Setter  \n\n3.  public class MethodLocatingFactory {  \n\n4.      private String methodName;  \n\n5.      private String targetBeanName;  \n\n6.      private Method method;  \n\n7.      public void setBeanFactory(DefaultBeanFactory beanFactory) throws NoSuchBeanDefinitionException {  \n\n8.          if(!StringUtils.hasText(this.targetBeanName)) {  \n\n9.              throw new IllegalArgumentException(\"Property 'targetBeanName' is required\" );  \n\n10.         }  \n\n11.         if(!StringUtils.hasText(this.methodName)) {  \n\n12.             throw new IllegalStateException(\"Property 'methodName' is required\" );  \n\n13.         }  \n\n14.         Class<?> beanClass = beanFactory.getType(this.targetBeanName);  \n\n15.         if(beanClass == null) {  \n\n16.             throw new IllegalArgumentException(\"Can`t determine type of bean with name'\" + this.targetBeanName + \"'\");  \n\n17.         }  \n\n18.         // 获取相关方法  \n\n19.         this.method = BeanUtils.resolveSignature(this.methodName, beanClass);  \n\n20.         if(this.method == null) {  \n\n21.             throw new IllegalStateException(\"Unable to locate method [\" + this.methodName + \"] on bean [\" + this.targetBeanName +\"]\");    \n\n22.         }  \n\n23.     }  \n\n\n24.     public Method getObject() {  \n\n25.         return this.method;  \n\n26.     }  \n\n27. }  \n```\n\n\n\n#### **3、拦截器链的有序调用**\n\n现在我们可以考虑这里怎么实现拦截器链的有序调用\n\n其实对于方法的增强，也就是在方法上加上一个拦截器，在aop中叫做**MethodInterceptor**，Spring在这基础上做了进一步的扩展，也就是**Advice**，针对方法前后等不同位置和不同功能的拦截器就又区分为**AspectJAfterAdvice**、**AspectJBeforeAdvice**等。\n\n关系如下图：\n\n![img](http://pcc.huitogo.club/cb188101cba7ee280cfd6ecba8e3e20e)\n\n\n\nAdvice和相关子类代码如下，其中Advice的子类没有一一列举\n\n```\n1.  public interface Advice extends MethodInterceptor {  \n\n2.      public Pointcut getPointcut();  \n\n3.  }     \n\n4.  /** \n\n5.   * Advice接口的模板类 \n\n6.   */  \n\n7.  public abstract class AbstractAspectJAdvice implements Advice {  \n\n8.      private Method adviceMethod;  \n\n9.      private Pointcut pointcut;  \n\n10.     private Object adviceObject;  \n\n11.     public AbstractAspectJAdvice(Method adviceMethod, Pointcut pointcut, Object adviceObject) {  \n\n12.         super();  \n\n13.         this.adviceMethod = adviceMethod;  \n\n14.         this.pointcut = pointcut;  \n\n15.         this.adviceObject = adviceObject;  \n\n16.     }  \n\n17.     public void invokeAdviceMethod() throws Throwable {  \n\n18.         adviceMethod.invoke(adviceObject);  \n\n19.     }  \n\n20.     @Override  \n\n21.     public Pointcut getPointcut() {  \n\n22.         return pointcut;  \n\n23.     }  \n\n24.     public Method getAdviceMethod() {  \n\n25.         return this.adviceMethod;  \n\n26.     }  \n\n27. }  \n\n\n28. public class AspectJAfterAdvice extends AbstractAspectJAdvice{  \n\n29.     public AspectJAfterAdvice(Method adviceMethod, Pointcut pointcut, Object adviceObject) {  \n\n30.         super(adviceMethod, pointcut, adviceObject);  \n\n31.     }  \n\n32.     //拦截的逻辑\n\n33.     @Override  \n\n34.     public Object invoke(MethodInvocation mi) throws Throwable {  \n\n35.         Object o = mi.proceed();  \n\n36.         this.invokeAdviceMethod();  \n\n37.         return o;  \n\n38.     }  \n\n39. }  \n\n\n40. public class AspectJAfterThrowingAdvice extends AbstractAspectJAdvice{  \n\n41.     public AspectJAfterThrowingAdvice(Method adviceMethod, Pointcut pointcut, Object adviceObject) {  \n\n42.         super(adviceMethod, pointcut, adviceObject);  \n\n43.     }  \n\n44.     //拦截的逻辑\n\n45.     @Override  \n\n46.     public Object invoke(MethodInvocation mi) throws Throwable {  \n\n47.         try {  \n\n48.             return mi.proceed();  \n\n49.         } catch (Throwable e) {  \n\n50.             this.invokeAdviceMethod();  \n\n51.             throw e;  \n\n52.         }  \n\n53.     }  \n\n54. }  \n```\n\n\n\n现在我们可以创建一堆Advice了，怎么在给定的方法上有序执行呢？\n\n我们知道在MethodInterceptor的接口有个invoke方法，就是成功拦截到方法后需要做的操作，invoke方法的参数是一个MethodInvocation，那我们是否可以自己实现一个MethodInvocation去有序的调用那一堆Advice呢？\n\n新建一个**ReflectiveMethodInvocation**去做这件事，相关代码如下：\n\n```\n1.  public class ReflectiveMethodInvocation implements MethodInvocation {  \n\n2.      protected final Object targetObject;  \n\n3.      protected final Method targetMethod;  \n\n4.      protected Object[] arguments;  \n\n5.      protected final List<MethodInterceptor>  interceptors;  \n\n6.      private int currentInterceptrorIndex = -1;  \n\n7.      public ReflectiveMethodInvocation(Object targetObject, Method targetMethod, Object[] arguments,  List<MethodInterceptor> interceptors) {  \n\n8.          super();  \n\n9.          this.targetObject = targetObject;  \n\n10.         this.targetMethod = targetMethod;  \n\n11.         this.arguments = arguments;  \n\n12.         this.interceptors = interceptors;  \n\n13.     }  \n\n14.     @Override  \n\n15.     public Object[] getArguments() {  \n\n16.         return this.arguments;  \n\n17.     }  \n\n18.     @Override  \n\n19.     public AccessibleObject getStaticPart() {  \n\n20.         return this.targetMethod;  \n\n21.     }  \n\n22.     @Override  \n\n23.     public Object getThis() {  \n\n24.         return this.targetObject;  \n\n25.     }  \n\n\n26.     @Override  \n\n27.     public Object proceed() throws Throwable {  \n\n28.         //所有拦截器已经完成  \n\n29.         if(this.currentInterceptrorIndex == this.interceptors.size() -1) {  \n\n30.             return invokeJointpoint();  \n\n31.         }  \n\n32.         this.currentInterceptrorIndex ++;  \n\n33.         MethodInterceptor interceptor = this.interceptors.get(currentInterceptrorIndex);  \n\n34.         //这里会有一个递归的调用，每个Advice都会回调proceed()方法  \n\n35.         return interceptor.invoke(this);  \n\n36.     }  \n\n\n37. //调用被拦截的方法\n\n38.     private Object invokeJointpoint() throws IllegalAccessException, IllegalArgumentException, InvocationTargetException {  \n\n39.         return this.targetMethod.invoke(this.targetObject, this.arguments);  \n\n40.     }  \n\n41.     @Override  \n\n42.     public Method getMethod() {  \n\n43.         return this.targetMethod;  \n\n44.     }     \n\n45. }  \n```\n\n\n\n这里可以看到有一个巧妙的设计，也就是每一个Advice里面的invoke都会调用ReflectiveMethodInvocation的procced方法，然后procced方法又会去调用Advice里面的invoke这样一个递归操作，直到每一个Advice都调用到了，才会真正去调用被拦截的方法。\n\n这样做的话其实已经实现了我们想要的拦截器链的有序调用\n\n所有被拦截的方法之前的增强内容已经调用到了，然后调用被拦截方法，最后是被拦截的方法之后的增强内容调用，所以说这种设计还是很巧妙的。\n\n\n\n#### **4、aop增强的实现**\n\n##### **（1）CGLIB的实现**\n\n我们都知道Spring Aop的实现是预编译和动态代理，这里动态代理是既使用了jdk的动态代理，又包括了CGLIB。这里我们使用CGLIB实现方法的代理类，当然这个代理类已经对需要增强的方法进行了增强。\n\n\n\n首先了解一下CGLIB的简单使用\n\n```\n1.  @Test  \n\n2.  public void testCGLib() {  \n\n3.      Enhancer enhancer = new Enhancer();  \n\n4.      enhancer.setSuperclass(PersonService.class);  \n\n5.      //设置拦截器  \n\n6.      enhancer.setCallback(this);  \n\n7.      PersonService personService = (PersonService) enhancer.create();  \n\n8.      personService.placeOrder();  \n\n9.  }  \n\n\n10. @Test  \n\n11. public void testFilter() {  \n\n12.     Enhancer enhancer = new Enhancer();  \n\n13.     enhancer.setSuperclass(PersonService.class);  \n\n14.     enhancer.setInterceptDuringConstruction(false);  \n\n15.     Callback[] callbacks = new Callback[] {this, NoOp.INSTANCE};  \n\n16.     Class<?>[] types = new Class<?>[callbacks.length];  \n\n17.     for(int i = 0; i < callbacks.length; i++) {  \n\n18.         types[i] = callbacks[i].getClass();  \n\n19.     }  \n\n20.     //设置过滤器  \n\n21.     enhancer.setCallbackFilter(new CGLibTest().new ProxyCallbackFilter());  \n\n22.     enhancer.setCallbacks(callbacks);  \n\n23.     enhancer.setCallbackTypes(types);  \n\n24.     PersonService personService = (PersonService) enhancer.create();  \n\n25.     personService.placeOrder();  \n\n26.     personService.toString();  \n\n27. }  \n\n28. @Override  \n\n29. public Object intercept(Object obj, Method targetMethod, Object[] args, MethodProxy proxy) throws Throwable {  \n\n30.     TransactionManager tx = new TransactionManager();  \n\n31.     tx.start();  \n\n32.     Object result = proxy.invokeSuper(obj, args);  \n\n33.     tx.commit();  \n\n34.     return result;  \n\n35. }  \n\n36. class ProxyCallbackFilter implements CallbackFilter{  \n\n37.     @Override  \n\n38.     public int accept(Method method) {  \n\n39.         // 如果拦截方法名以place开头，使用第一个拦截器  \n\n40.         if(method.getName().startsWith(\"place\")) {  \n\n41.             return 0;  \n\n42.         //否则使用第二个拦截器      \n\n43.         }else {  \n\n44.             return 1;  \n\n45.         }  \n\n46.     }  \n\n47. }  \n```\n\n这里可以看到CGLIB使用了一个Enhancer中间类，可以利用这个Enhancer去指定需要被代理的类、拦截器MethodInterceptor和判断方法需要使用哪个拦截器的过滤器CallbackFilter，最后调用Enhancer.create()可以获取代理类。\n\n\n\n现在我们知道怎么利用CGLIB去获取一个类增强后的代理类了，在Spring Aop中也是这么做的，生成代理类，代理类里面的每个方法进行拦截后都要和配置的Advice的PointcutExpression做Match判断，如果匹配执行符合条件的Advice的拦截器链，否则不做增强处理，直接调用被拦截的方法。\n\n在此之前，Spring声明了一个Advised类来声明增强类的信息，相当于AdviceConfig\n\n```\n1.  public interface Advised {  \n\n2.      Class<?> getTargetClass();  \n\n3.      Object getTargetObject();  \n\n4.      List<Advice> getAdvices();  \n\n5.      void addAdvice(Advice advice);  \n\n6.      List<Advice> getAdvices(Method method);  \n\n7.  }  \n\n8.  //Advised的默认实现类  \n\n9.  public class AdvisedSupport implements Advised {  \n\n10.     private Object targetObject = null;  \n\n11.     private List<Advice> advices = new ArrayList<>();  \n\n12.     public AdvisedSupport() {  \n\n13.         super();  \n\n14.     }  \n\n15.     @Override  \n\n16.     public Class<?> getTargetClass() {  \n\n17.         return this.targetObject.getClass();  \n\n18.     }  \n\n19.     public void setTargetObject(Object targetObject) {  \n\n20.         this.targetObject = targetObject;  \n\n21.     }  \n\n22.     @Override  \n\n23.     public Object getTargetObject() {  \n\n24.         return this.targetObject;  \n\n25.     }  \n\n26.     @Override  \n\n27.     public List<Advice> getAdvices() {  \n\n28.         return this.advices;  \n\n29.     }  \n\n30.     @Override  \n\n31.     public void addAdvice(Advice advice) {  \n\n32.         this.advices.add(advice);  \n\n33.     }  \n\n34.     @Override  \n\n35.     public List<Advice> getAdvices(Method method) {  \n\n36.         List<Advice> result = new ArrayList<>();  \n\n37. // 对method做匹配操作\n\n38.         for(Advice  advice : this.advices) {  \n\n39.             Pointcut pc = advice.getPointcut();  \n\n40.             if(pc.getMethodMatcher().match(method)) {  \n\n41.                 result.add(advice);  \n\n42.             }  \n\n43.         }  \n\n44.         return result;  \n\n45.     }  \n\n46. }  \n```\n\n\n\n这里Advised的最终目的就是获取method上符合条件的Advice\n\n```\n1.  if(pc.getMethodMatcher().match(method)) {  \n\n2.      result.add(advice);  \n\n3.  }  \n```\n\n\n\n有了被增强类和查找Advice的功能后，可以去实现获取这个被增强类的代理了\n\n相关代码如下：\n\n```\n1.  public interface AopProxyFactory {  \n\n2.      Object getProxy();  \n\n3.      Object getProxy(ClassLoader classLoader);  \n\n4.  }  \n\n5.  public class CglibProxyFactory implements AopProxyFactory {  \n\n6.      // 这些常量相当于是CallbackFilter中根据method返回的Interceptor的下标  \n\n7.      private static final int AOP_PROXY = 0;  \n\n8.      protected Logger log = LoggerFactory.getLogger(CglibProxyFactory.class);  \n\n9.      protected Advised advised;  \n\n10.     private Object[] constructorArgs;  \n\n11.     private Class<?>[] constructorArgsTypes;  \n\n12.     public CglibProxyFactory(Advised advised) throws AopConfigException {  \n\n13.         if (advised.getAdvices().size() == 0) {  \n\n14.             throw new AopConfigException(\"No advisors and no TargetSource specified\");  \n\n15.         }  \n\n16.         this.advised = advised;  \n\n17.     }  \n\n18.     public void setConstructorArguments(Object[] constructorArgs, Class<?>[] constructorArgsTypes) {  \n\n19.         if (constructorArgs == null || constructorArgsTypes == null) {  \n\n20.             throw new IllegalArgumentException(  \n\n21.                     \"Both 'constructArgs' and 'constructorArgsTypes' can`t be null together\");  \n\n22.         }  \n\n23.         if (this.constructorArgs.length != constructorArgsTypes.length) {  \n\n24.             throw new IllegalArgumentException(\"Number of 'constructArgs' (\" + constructorArgs.length  \n\n25.                     + \") must match number of 'constructorArgsTypes' (\" + constructorArgsTypes.length + \")\");  \n\n26.         }  \n\n27.         this.constructorArgs = constructorArgs;  \n\n28.         this.constructorArgsTypes = constructorArgsTypes;  \n\n29.     }  \n\n30.     @Override  \n\n31.     public Object getProxy() {  \n\n32.         return getProxy(null);  \n\n33.     }  \n\n34.     @Override  \n\n35.     public Object getProxy(ClassLoader classLoader) {  \n\n36.         if (log.isDebugEnabled()) {  \n\n37.             log.debug(\"Creating CGLIB proxy: target source is \" + this.advised.getTargetClass());  \n\n38.         }  \n\n39.         Class<?> rootClass = this.advised.getTargetClass();  \n\n40.         Enhancer enhancer = new Enhancer();  \n\n41.         if (classLoader != null) {  \n\n42.             enhancer.setClassLoader(classLoader);  \n\n43.         }  \n\n44.         enhancer.setSuperclass(rootClass);  \n\n45.         // 创建的代理类命名规则，默认后缀加上\"BySpringCGLIB\"  \n\n46.         enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);  \n\n47.         enhancer.setInterceptDuringConstruction(false);  \n\n48.         Callback[] callbacks = getCallbacks(rootClass);  \n\n49.         Class<?>[] types = new Class<?>[callbacks.length];  \n\n50.         for (int x = 0; x < callbacks.length; x++) {  \n\n51.             types[x] = callbacks[x].getClass();  \n\n52.         }  \n\n53.         enhancer.setCallbackFilter(new ProxyCallbackFilter(this.advised));  \n\n54.         enhancer.setCallbacks(callbacks);  \n\n55.         enhancer.setCallbackTypes(types);  \n\n56.         Object proxy;  \n\n57.         if (this.constructorArgs != null) {  \n\n58.             proxy = enhancer.create(constructorArgsTypes, constructorArgs);  \n\n59.         } else {  \n\n60.             proxy = enhancer.create();  \n\n61.         }  \n\n62.         return proxy;  \n\n63.     }  \n\n64.     private Callback[] getCallbacks(Class<?> rootClass) {  \n\n65.         Callback aopInterceptor = new DynamicAdvisedInterceptor(this.advised);  \n\n66.         Callback[] callbacks = new Callback[] { aopInterceptor };  \n\n67.         return callbacks;  \n\n68.     }  \n\n69.     private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable {  \n\n70.         private final Advised advised;  \n\n71.         public DynamicAdvisedInterceptor(Advised advised) {  \n\n72.             super();  \n\n73.             this.advised = advised;  \n\n74.         }  \n\n75.         @Override  \n\n76.         public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {  \n\n77.             Class<?> targetClass = null;  \n\n78.             Object target = this.advised.getTargetObject();  \n\n79.             if (target != null) {  \n\n80.                 targetClass = target.getClass();  \n\n81.             }  \n\n82.             List<Advice> chain = this.advised.getAdvices(method);  \n\n83.             Object retVal;  \n\n84.             if (chain.isEmpty() && Modifier.isPublic(method.getModifiers())) {  \n\n85.                 retVal = methodProxy.invoke(target, args);  \n\n86.             } else {  \n\n87.                 List<org.aopalliance.intercept.MethodInterceptor> interceptors = new ArrayList<>();  \n\n88.                 interceptors.addAll(chain);  \n\n89.                 // 核心方法在这里  \n\n90.                 retVal = new ReflectiveMethodInvocation(target, method, args, interceptors).proceed();  \n\n91.             }  \n\n92.             return retVal;  \n\n93.         }  \n\n94.     }  \n\n95.     private static class ProxyCallbackFilter implements CallbackFilter {  \n\n96.         private final Advised advised;  \n\n97.         public ProxyCallbackFilter(Advised advised) {  \n\n98.             this.advised = advised;  \n\n99.         }  \n\n100.         @Override  \n\n101.         public int accept(Method method) {  \n\n102.             return AOP_PROXY;  \n\n103.         }  \n\n104.     }  \n\n105. }  \n```\n\n\n\n这里核心要关注的是getProxy()这个方法，怎么去获取代理类\n\n首先声明被代理类\n\n```\nenhancer.setSuperclass(rootClass); \n```\n\n\n\n其次声明拦截器\n\n可以看到拦截器对被代理类的每个方法进行拦截，然后尝试获取method上的Advices，如果没有的话就直接调用，如果有的话就就运用到我们第三步的内容了，使用ReflectiveMethodInvocation有序调用拦截器链。\n\n```\n1.  private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable {\n\n2.     //...  \n\n3.     @Override  \n\n4.      public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {  \n\n5.      //...  \n\n6.          List<Advice> chain = this.advised.getAdvices(method);  \n\n7.          Object retVal;  \n\n8.          if (chain.isEmpty() && Modifier.isPublic(method.getModifiers())) {  \n\n9.              retVal = methodProxy.invoke(target, args);  \n\n10.         } else {  \n\n11.             List<org.aopalliance.intercept.MethodInterceptor> interceptors = new ArrayList<>();  \n\n12.             interceptors.addAll(chain);  \n\n13.             // 核心方法在这里  \n\n14.             retVal = new ReflectiveMethodInvocation(target, method, args, interceptors).proceed();  \n\n15.         }  \n\n16.         return retVal;  \n\n17.     }  \n\n18. }  \n```\n\n\n\n最后声明过滤器\n\n这里默认使用的就是aop的拦截器，其实Spring这里面还有很多其他的实现\n\n```\n1.  private static class ProxyCallbackFilter implements CallbackFilter {  \n\n2.  //... \n\n3.      @Override  \n\n4.      public int accept(Method method) {  \n\n5.          return AOP_PROXY;  \n\n6.      }  \n\n7.  }  \n```\n\n现在一个指定类增强后的代理就完成了，调用Enhancer.create()可以生成一个类的代理类，调用这个类的所有方法都会经过代理类。\n\n\n\n##### **（2）Jdk动态代理的实现**\n\njdk动态的实现相比较CGLIB来说简单一些，它只需要被代理的接口数组，然后声明一个InvocationHandler（反射调用的时候增强方法）\n\n新增一个类JdkAopProxyFactory去做实现，相关代码如下：\n\n```\n1.  public class JdkAopProxyFactory implements AopProxyFactory, InvocationHandler {  \n\n2.      private final Advised advised;  \n\n3.      public JdkAopProxyFactory(Advised advised) throws AopConfigException {  \n\n4.          if(advised.getAdvices().size() == 0) {  \n\n5.              throw new AopConfigException(\"No advices specified\");  \n\n6.          }  \n\n7.          this.advised = advised;  \n\n8.      }  \n\n9.      @Override  \n\n10.     public Object getProxy() {  \n\n11.         return getProxy(null);  \n\n12.     }  \n\n13.     @Override  \n\n14.     public Object getProxy(ClassLoader classLoader) {  \n\n15.         if(classLoader == null) {  \n\n16.             classLoader = ClassUtils.getDefaultClassLoader();  \n\n17.         }  \n\n18.         Class<?>[] proxiedInterfaces =  advised.getProxiedInterfaces();  \n\n19.         return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);  \n\n20.     }  \n\n21.     @Override  \n\n22.     public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {  \n\n23.         Object target = this.advised.getTargetObject();  \n\n24.         //核心代理类的拦截方法  \n\n25.         List<Advice> chain = this.advised.getAdvices(method);  \n\n26.         Object retVal;  \n\n27.         if (chain.isEmpty() && Modifier.isPublic(method.getModifiers())) {  \n\n28.             retVal = method.invoke(target, args);  \n\n29.         } else {  \n\n30.             List<org.aopalliance.intercept.MethodInterceptor> interceptors = new ArrayList<>();  \n\n31.             interceptors.addAll(chain);  \n\n32.             // 核心方法在这里  \n\n33.             retVal = new ReflectiveMethodInvocation(target, method, args, interceptors).proceed();  \n\n34.         }  \n\n35.         return retVal;  \n\n36.     }     \n\n37. }  \n```\n\n相关的增强方法的逻辑和CGLIB一样，就不多赘述了。\n\n\n\n#### **5、总结**\n\n1）使用CGLIB生成代理类时可以添加过滤器（过滤器需实现CallbackFilter接口）指定方法拦截器。\n\n2）如何实现拦截器链的有序调用，Spring使用了一个很巧妙的递归方法。\n\n3）学会了AspectJ里面一些方法的使用，比如expression转PointcutExpression这一块\n\n4）进一步理解了Spring的开发理念，由点到面，一步步小功能可以实现一个比较大的概念。", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "7a174f59416c8f0c9010f4afbf2590b0": {"id": "7a174f59416c8f0c9010f4afbf2590b0", "item": "造轮子系列", "title": "七天写一个Spring框架（准备）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之准备工作", "body": "\n今天开始跟着刘欣老师学spring，来一次重复造轮子\n\n开始之前首先普及一下TDD的开发理念，也就是测试驱动开发，使用充分的测试方法和测试用例来保证每一个方法的正确性，更重要的是保证后面开发的代码不会影响前面的开发部分，步骤如下：\n\n- 思考用例\n- 启动失败\n- 编写just enough代码 让测试通过\n- 重构代码 让测试通过]\n\n今天学习的主要目标，从spring的xml配置文件中获取我们定义的bean实例\n\n类图如下：\n\n![img](http://pcc.huitogo.club/d985d56d3e983d44ba4681ad64b9eb8c)\n\n\n\n首先摆出测试用例\n\n```\n1.  @Test  \n\n2.  public void testGetBean()  \n\n3.          throws ClassNotFoundException, InstantiationException, IllegalAccessException, DocumentException {  \n\n4.      BeanFactory beanFactory = new DefaultBeanFactory(\"applicationContext.xml\");  \n\n5.      BeanDefinition bd = beanFactory.getBeanDefinition(\"car\");  \n\n6.      assertEquals(\"my_spring.beanfactory.bean.Car\", bd.getClassName());  \n\n7.      Car car = (Car) beanFactory.getBean(\"car\");  \n\n8.      assertNotNull(car);  \n\n9.  }  \n\n\n10. @Test  \n\n11. public void testValidBean() {  \n\n12.     BeanFactory beanFactory = new DefaultBeanFactory(\"applicationContext.xml\");  \n\n13.     try {  \n\n14.         beanFactory.getBean(\"invalidBean\");  \n\n15.     } catch (BeanCreateException e) {  \n\n16.         return;  \n\n17.     }  \n\n18.     Assert.fail(\"unexpected result\");  \n\n19. }  \n\n\n20. @Test  \n\n21. public void testValidXml() {  \n\n22.     BeanFactory beanFactory;  \n\n23.     try {  \n\n24.         beanFactory = new DefaultBeanFactory(\"appxxx.xml\");  \n\n25.     } catch (BeanStoreException e) {  \n\n26.         return;  \n\n27.     }  \n\n28.     beanFactory.getBean(\"car\");  \n\n29.     Assert.fail(\"unexpected result\");  \n\n30. } \n```\n\n\n\n我们需要定义一个BeanFactory接口 封装了对Bean操作的方法，主要是getBean(String beanName)\n\n```\n1.  public interface BeanFactory {  \n\n2.      Object getBean(String string);  \n\n3.      BeanDefinition getBeanDefinition(String string);  \n\n4.  }  \n```\n\n\n\n再定义一个BeanDefinition接口封装了Bean的属性\n\n```\n1.  public interface BeanDefinition {  \n\n2.      String getClassName();  \n\n3.      String getId();  \n\n4.  }  \n```\n\n\n\n定义一个GenericBeanDefinition类默认实现BeanDefinition\n\n```\n1.  @AllArgsConstructor  \n\n2.  @Data  \n\n3.  public class GenericBeanDefinition implements BeanDefinition {  \n\n4.      private String id;  \n\n5.      private String className;  \n\n6.  }  \n```\n\n\n\n定义一个DefaultBeanFactory类默认实现BeanFactory接口\n\n这里我们希望利用DefaultBeanFactory构造方法去解析spring的xml配置文件，将解析出来的bean放入map中，map的key是beanName，value就是beanDefinition\n\n```\n1.  public DefaultBeanFactory(String configFile) {  \n\n2.      loadBeanDefinition(configFile); // 装载xml配置文件  \n\n3.  }  \n\n4.  private void loadBeanDefinition(String configFile) {  \n\n5.      InputStream is = null;  \n\n6.      try {  \n\n7.          ClassLoader cl = ClassUtils.getDefaultClassLoader();  \n\n8.          is = cl.getResourceAsStream(configFile); // 从当前类加载环境中获取配置文件  \n\n9.          SAXReader reader = new SAXReader(); // dom4j解析xml  \n\n10.         Document doc = reader.read(is);  \n\n11.         Element root = doc.getRootElement();  \n\n12.         Iterator<Element> itr = root.elements().iterator();  \n\n13.         while(itr.hasNext()) { // 遍历bean xml标签放入map中  \n\n14.             Element ele = itr.next();  \n\n15.             String id = ele.attributeValue(ID_ATTRIBUTE);  \n\n16.             String beanClassName = ele.attributeValue(CLASS_ATTRIBUTE);  \n\n17. // 生成BeanDefinition  \n\n18.             BeanDefinition bd = new GenericBeanDefinition(id, beanClassName); \n\n19.             container.put(id, bd);  \n\n20.         }  \n\n21.     } catch (DocumentException e) {  \n\n22.         throw new BeanStoreException(configFile + \"is valid xml file!\");  \n\n23.     } finally {  \n\n24.         if(is != null) {  \n\n25.             try {  \n\n26.                 is.close();  \n\n27.             } catch (IOException e) {  \n\n28.                 e.printStackTrace();  \n\n29.             }  \n\n30.         }  \n\n31.     }  \n\n32. }  \n```\n\n\n\n实现BeanFactory的getBean()和getBeanDefinition()方法，通过上面代码我们可以直接从map中根据key去取出对应的BeanDefinition即可，对于getBean()需要返回的Object，我们直接通过BeanDefinition的className反射获取。\n\n```\n1.  @Override  \n\n2.  public BeanDefinition getBeanDefinition(String beanId) {  \n\n3.      return container.get(beanId);  \n\n4.  }  \n\n5.  @Override  \n\n6.  public Object getBean(String beanId) {  \n\n7.      BeanDefinition bd = container.get(beanId);  \n\n8.      if(bd == null){  \n\n9.          throw new BeanCreateException(\"Bean is not definied!\");  \n\n10.     }  \n\n11.     String className = bd.getClassName();  \n\n12.     ClassLoader cl = ClassUtils.getDefaultClassLoader();  // 反射获取实例  \n\n13.     try {  \n\n14.         Class<?> clazz = cl.loadClass(className);  \n\n15.         return clazz.newInstance();  \n\n16.     } catch (Exception e) {  \n\n17.         throw new BeanCreateException(\"create bean \" + className + \"failed!\");  \n\n18.     }   \n\n19. }  \n```\n\n上面的代码中我们做出一个小优化，使用自定义Exception做异常处理，比如在loadBeanDefinition时抛出的BeanStoreException表示装载xml中出现的异常，在getBean时抛出的BeanCreateException表示获取Bean时（无效bean等）出现的异常，在Spring中还有很多这种自定义异常。", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "1e4f1a4fb081009bd930123e0c9a3a62": {"id": "1e4f1a4fb081009bd930123e0c9a3a62", "item": "造轮子系列", "title": "七天写一个Spring框架（四）", "date": "2024-08-22", "summary": "七天手写一个Spring轻量级框架之第四天", "body": "\n本节目标的类图如下：\n\n![img](http://pcc.huitogo.club/859ca9538a1d872a025bda82c6b6a11a)\n\n\n\n**今天的目标是**\n\n将指定目录下的文件（通常在spring的配置中以<context:component-scan base-package=””/>说明文件目录）被@Component（可以扩展更多，如@Service、@Controller）注释的类转换成Beandefinition并registry到BeanFactory中去\n\n乍一看，挺简单\n\n扫描目录下文件 --> 判断有没有@Component注释 --> 有的话生成BeanDefinition\n\n细想的话，怎么检测class文件中有没有这个注释，以及@Component注释的类怎么转换成BeanDefinition呢？\n\n先一步步实现吧\n\n\n\n#### **1、获取目录下Resource**\n\n扫描指定目录下的文件，然后返回Resource\n\n这里涉及到一个递归使用，遍历目录使用递归应该还是容易想到的，将得到的File，实例化到FileSystemResource中去即可\n\n新建一个PackageResourceLoader\n\n```\n1.  public Resource[] getResources(String basepackage) {  \n\n2.      Assert.notNull(basepackage, \"basepackage must not be null\");  \n\n3.      String location = ClassUtils.convertClassNameToResourcePath(basepackage);  \n\n4.      ClassLoader cl = getClassLoader();  \n\n5.      URL url = cl.getResource(location);  \n\n6.      File rootDir = new File(url.getFile());  \n\n7.      Set<File> matchingFiles = retrieveMatchingFiles(rootDir);  \n\n8.      Resource[] result = new Resource[matchingFiles.size()];  \n\n9.      int i = 0;  \n\n10.     for (File file : matchingFiles) {  \n\n11.         result[i++] = new FileSystemResource(file);  \n\n12.     }  \n\n13.     return result;  \n\n14. }  \n\n\n15. /** \n\n16.  * 获取rootDir子目录中的文件 \n\n17.  */  \n\n18. private Set<File> retrieveMatchingFiles(File rootDir) {  \n\n19.     if (!rootDir.exists()) {  \n\n20.         if (log.isDebugEnabled()) {  \n\n21.             log.debug(\"Skipping [\" + rootDir.getAbsolutePath() + \"] because it is not found!\");  \n\n22.         }  \n\n23.         return Collections.emptySet();  \n\n24.     }  \n\n25.     if (!rootDir.isDirectory()) {  \n\n26.         if (log.isWarnEnabled()) {  \n\n27.             log.debug(\"Skipping [\" + rootDir.getAbsolutePath() + \"] because it does not denote a directory!\");  \n\n28.         }  \n\n29.         return Collections.emptySet();  \n\n30.     }  \n\n31.     if (!rootDir.canRead()) {  \n\n32.         if (log.isWarnEnabled()) {  \n\n33.             log.debug(\"Skipping [\" + rootDir.getAbsolutePath()  + \"] because the application is not allowed to read the directory!\");  \n\n35.         }  \n\n36.         return Collections.emptySet();  \n\n37.     }  \n\n38.     Set<File> result = new LinkedHashSet<>();  \n\n39.     doRetrieveMatchingFiles(rootDir, result);  \n\n40.     return result;  \n\n41. }  \n\n\n42. /** \n\n43.  * 递归获取rootDir中的file文件 \n\n44.  */  \n\n45. private void doRetrieveMatchingFiles(File rootDir, Set<File> result) {  \n\n46.     File[] fileList = rootDir.listFiles();  \n\n47.     if (fileList == null) {  \n\n48.         if (log.isWarnEnabled()) {  \n\n49.             log.debug(\"Could not retrieve contents of direcotry [\" + rootDir.getAbsolutePath() + \"]\");  \n\n50.         }  \n\n51.         return;  \n\n52.     }  \n\n53.     for (File content : fileList) {  \n\n54.         if (content.isDirectory()) {  \n\n55.             if (!content.canRead()) {  \n\n56.                 if (log.isDebugEnabled()) {  \n\n57.                     log.debug(\"Skipping subdirectory [\" + content.getAbsolutePath() + \"] because the application is not allowed to read the directory!\");  \n\n59.                 }  \n\n60.             } else {  \n\n61.                 doRetrieveMatchingFiles(content, result);  \n\n62.             }  \n\n63.         } else {  \n\n64.             result.add(content);  \n\n65.         }  \n\n66.     }  \n\n67. }  \n```\n\n去掉那些打印日志和判定文件的操作外代码还是很简短的。\n\n\n\n#### **2、获取Resource中的注释信息**\n\n在第一步中我们已经获取了目录下的所有文件，并且转换成了Resource，现在我们要尝试读取Resource并获得注释信息，需要注意的是这里的Resource是Java文件编译后的class文件，所以我们需要借助ASM字节码工具。\n\n首先介绍一下ASM的工作机制\n\n1）新建一个ClassReader去读取指定class文件\n\n2）新建一个ClassVisitor去接收ClassReader读取的值\n\n这里接收的值 有visit --> visit annotation --> visit filed --> visit method --> visit end这些过程\n\n3）ClassVisiot接收到值后可以借助ClassWriter再将修改后的值写入class文件\n\n\n\n需要注意的是，这里ClassVisitor需要自定义，也就是自己实现ClassVisitor接口\n\n我们先尝试去实现简单的读取类信息\n\n先定义一个ClassMetadataReadingVistor去接收读取到的类信息\n\n```\n1.  @Data  \n\n2.  public class ClassMetadataReadingVistor extends ClassVisitor implements ClassMetadata {  \n\n3.      private String className;  \n\n4.      private boolean isInterface;  \n\n5.      private boolean isAbstract;  \n\n6.      private boolean isFinal;  \n\n7.      private String superClassName;  \n\n8.      private String[] interfaces;  \n\n9.      public ClassMetadataReadingVistor() {  \n\n10.         super(SpringAsmInfo.ASM_VERSION);  \n\n11.     }  \n\n\n12.     /** \n\n13.      * 这里只覆盖了一个方法获取class文件的类信息 \n\n14.      */  \n\n15.     @Override  \n\n16.     public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) {  \n\n17.         this.className = ClassUtils.convertResourcePathToClassName(name);  \n\n18.         this.isInterface = (access & Opcodes.ACC_INTERFACE) != 0;  \n\n19.         this.isAbstract = (access & Opcodes.ACC_ABSTRACT) != 0;  \n\n20.         this.isFinal = (access & Opcodes.ACC_FINAL) != 0;  \n\n21.         if(StringUtils.isNotBlank(superName)) {  \n\n22.             this.superClassName = ClassUtils.convertResourcePathToClassName(superName);  \n\n23.         }  \n\n24.         this.interfaces = new String[interfaces.length];  \n\n25.         System.arraycopy(interfaces, 0, this.interfaces, 0, interfaces.length);  \n\n26.         this.interfaces = Stream.of(this.interfaces).map(str -> ClassUtils.convertResourcePathToClassName(str)).toArray(String[]::new);  \n\n27.     }     \n\n28. }     \n```\n\n\n\nClassVisitor跟ClassReader交互的过程非常简单，类似这种\n\n```\n1.  ClassPathResource resource = new ClassPathResource( \"my_spring/beanfactory_annotation/test/service/PersonService.class\");  \n\n3.  ClassReader reader = new ClassReader(resource.getInputStream());  \n\n4.  ClassMetadataReadingVistor visitor = new ClassMetadataReadingVistor();  \n\n5.  reader.accept(visitor, ClassReader.SKIP_DEBUG);  \n```\n\n这个过程就感觉像是两个人在打电话，一个人（Visitor）希望另一个人(Reader)帮它查点东西，这里就是resource的信息，accept方法表示 电话通了，开始沟通\n\n\n\n现在我们开始去读取注释信息\n\n因为注释信息里面有很多属性，比如@Component(value=”personService”)中的value = personService\n\n先新建一个AnnotationAttribute去装这些属性\n\n```\n1.  public class AnnotationAttribute extends LinkedHashMap<String, Object> {  \n\n2.      public AnnotationAttribute(int initialCapacity) {  \n\n3.          super(initialCapacity);  \n\n4.      }  \n\n5.      public String getString(String attributeName) {  \n\n6.          return doGet(attributeName, String.class);  \n\n7.      }  \n\n\n8.      private <T> T doGet(String attribteName, Class<T> expectedType){  \n\n9.          Object value = get(attribteName);  \n\n10.         if (!expectedType.isInstance(value) && expectedType.isArray() && expectedType.getComponentType().isInstance(value)) {  \n\n12.             Object array = Array.newInstance(expectedType.getComponentType(), 1);  \n\n13.             Array.set(array, 0, value);  \n\n14.             value = array;  \n\n15.         }  \n\n16.         return (T)value;  \n\n17.     }  \n\n18. }  \n```\n\n其实就是一个LinkedHashMap，只是多了一个将map中的value转换成任意类型的能力，也就是doGet方法\n\n\n\n现在可以新建一个AnnotationMetadataReadingVisitor来接收ClassReader传递的注释信息\n\n```\n1.  @Data  \n\n2.  public class AnnotationMetadataReadingVisitor extends ClassMetadataReadingVistor{  \n\n3.      private final Set<String> annotationTypes = new LinkedHashSet<>();  \n\n4.      private final Map<String, AnnotationAttribute> attributeMap = new LinkedHashMap<>(4);  \n\n5.      @Override  \n\n6.      public AnnotationVisitor visitAnnotation(final String desc, boolean visible) {  \n\n7.          String annotationName = Type.getType(desc).getClassName();  \n\n8.          this.annotationTypes.add(annotationName);  \n\n9.          // 这里ClassReader已经将类的注释类传过来了，然后我告诉它，如果这个类有详情的话打我下面这个电话  \n\n10.         return new AnnotationAttributesReadingVisitor(annotationName, this.attributeMap);  \n\n11.     }  \n\n12.     public AnnotationAttribute getAnnotationAttribute(String annotation) {  \n\n13.         return attributeMap.get(annotation);  \n\n14.     }  \n\n15.     public boolean hasAnnotation(String annotation) {  \n\n16.         return this.annotationTypes.contains(annotation);  \n\n17.     }  \n\n18. }\n```\n\n这里AnnotationMetadataReadingVisitor是ClassMetadataReadingVistor的子类\n\n\n\n注意这里visitAnnotation接收的只是注释的大概信息，如果想知道详细信息的话还得给ClassReader留一个“电话”（AnnotationVisitor）\n\n这里新建AnnotationAttributesReadingVisitor去接收指定注释的详细信息\n\n```\n1.  public class AnnotationAttributesReadingVisitor extends AnnotationVisitor {  \n\n2.      private final String annotationType;  \n\n3.      private final Map<String, AnnotationAttribute> attributeMap;  \n\n4.      AnnotationAttribute attribute = new AnnotationAttribute();  \n\n5.      public AnnotationAttributesReadingVisitor(String annotationType, Map<String, AnnotationAttribute> attributeMap) {  \n\n7.          super(SpringAsmInfo.ASM_VERSION);  \n\n8.          this.annotationType = annotationType;  \n\n9.          this.attributeMap = attributeMap;  \n\n10.     }  \n\n11.     @Override  \n\n12.     public void visit(String name, Object value) {  \n\n13.         this.attribute.put(name, value);  \n\n14.     }  \n\n15.     @Override  \n\n16.     public void visitEnd() {  \n\n17.         this.attributeMap.put(this.annotationType, this.attribute);  \n\n18.     }  \n\n19. }\n```\n\n现在我们就完成了从Resource中读取注释信息的目的了\n\n\n\n#### **3、包装一下Reader和Visitor的交互过程**\n\n虽然我们已经完成了从Resource中读取注释信息，但是我们使用这些东西的时候是非常繁琐的，而且会将ASM操作的方法暴露出来，很明显这不符合解耦隔离的设计理念\n\n再看一下如何从Resource中读取注释信息\n\n```\n1.  ClassPathResource resource = new ClassPathResource( \"my_spring/beanfactory_annotation/test/service/PersonService.class\");  \n\n3.  ClassReader reader = new ClassReader(resource.getInputStream());  \n\n4.  AnnotationMetadataReadingVisitor visitor = new AnnotationMetadataReadingVisitor();  \n\n5.  reader.accept(visitor, ClassReader.SKIP_DEBUG);  \n\n6.  String annotation = \"my_spring.beanfactory_annotation.stereotype.Component\";  \n\n7.  AnnotationAttribute attribute = visitor.getAnnotationAttribute(annotation);  \n```\n\n\n\n其实上面的内容我们操作的地方就是传入一个Resouce地址，然后获取到一个Visitor\n\n这里进行包装一下，使用包装类解析Resource，返回Visitor\n\n秉着面向接口开发而不是面向实现的原则，新建MetadataReader接口\n\n```\n1.  public interface MetadataReader {  \n\n2.      Resource getResource();  \n\n3.      ClassMetadata getClassMetadata();  \n\n4.      AnnotationMetadata getAnnotationMetadata();  \n\n5.  }  \n```\n\n\n\n新建一个MetadataReader接口的默认实现类SimpleMetadaReader\n\n```\n1.  @Data  \n\n2.  public class SimpleMetadaReader implements MetadataReader {  \n\n3.      private final Resource resource;  \n\n4.      private final ClassMetadata classMetadata;  \n\n5.      private final AnnotationMetadata annotationMetadata;  \n\n6.      public SimpleMetadaReader(Resource resource) throws IOException {  \n\n7.          ClassReader reader;  \n\n8.          try (InputStream is = new BufferedInputStream(resource.getInputStream())) {  \n\n9.              reader = new ClassReader(is);  \n\n10.         }  \n\n11.         AnnotationMetadataReadingVisitor visitor = new AnnotationMetadataReadingVisitor();  \n\n12.         reader.accept(visitor, ClassReader.SKIP_DEBUG);  \n\n13.         this.classMetadata = visitor;  \n\n14.         this.annotationMetadata = visitor;  \n\n15.         this.resource = resource;  \n\n16.     }  \n\n17. }  \n```\n\n可以看到熟悉的代码，没错，就是把visitor跟reader交互的过程在这里做了。\n\n\n\n现在利用这个包装类我们读取Resource的步骤如下\n\n```\n1.  ClassPathResource resource = new ClassPathResource(\"my_spring/beanfactory_annotation/test/service/PersonService.class\");  \n\n3.  MetadataReader reader = new SimpleMetadaReader(resource);  \n\n4.  AnnotationMetadata amd = reader.getAnnotationMetadata();  \n\n5.  String annotation = Component.class.getName();  \n\n6.  AnnotationAttribute attribute = amd.getAnnotationAttribute(annotation);  \n```\n\n隐藏了ASM的实现细节，一个简单的包装类就完成了。\n\n\n\n#### **4、主要流程**\n\n现在我们已经具备筛选具备@Component注释的Resource的能力了，下一步就是将这些Resource转换成BeanDefinition，并且转到BeanFactory中\n\n首先Resource转换过来的BeanDefinition用GenericBeanDefinition来装肯定是不合适的，所以我们新建了一个ScannedGenericBeanDefinition \n\nScannedGenericBeanDefinition 和BeanDefinition关系如下图：\n\n![img](http://pcc.huitogo.club/943a3b46cd1edf1457ca108e96f7fb34)\n\n\n\nScannedGenericBeanDefinition 代码如下：\n\n```\n1.  // 新建一个接口赋予新的BeanDefinition新能力  \n\n2.  public interface AnnotatedBeanDefinition extends BeanDefinition {  \n\n3.      AnnotationMetadata getMetadata();  \n\n4.  }  \n\n5.  public class ScannedGenericBeanDefinition extends GenericBeanDefinition implements AnnotatedBeanDefinition{  \n\n6.      private final AnnotationMetadata metadata;  \n\n7.      public ScannedGenericBeanDefinition(AnnotationMetadata metadata) {  \n\n8.          super();  \n\n9.          this.metadata = metadata;  \n\n10.         setClassName(metadata.getClassName());  \n\n11.     }  \n\n12.     @Override  \n\n13.     public AnnotationMetadata getMetadata() {  \n\n14.         return metadata;  \n\n15.     }  \n\n16. } \n```\n\n\n\n现在我们新建一个类ClassPathBeanDefinitionScanner负责扫描指定目录进行筛选和装载的操作\n\n```\n1.  public class ClassPathBeanDefinitionScanner {  \n\n2.      private final BeanDefinitionRegistry registry;  \n\n3.      private PackageResourceLoader resourceLoader = new PackageResourceLoader();  \n\n4.      private BeanNameGenerator beanNameGenerator = new AnnotationBeanNameGenerator();  \n\n5.      protected final Logger logger = LoggerFactory.getLogger(getClass());  \n\n6.      public ClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry) {  \n\n7.          this.registry = registry;  \n\n8.      }  \n\n\n9.      /** \n\n10.      * 扫描指定的数组包，生成BeaDefinition集合，并注册到BeanFactory中 \n\n11.      * @param packagesToScan \n\n12.      * @return \n\n13.      * @throws IOException \n\n14.      */  \n\n15.     public Set<BeanDefinition> doScan(String packagesToScan) throws IOException {  \n\n16.         String[] basePackages = StringUtils.split(packagesToScan, \",\");  \n\n17.         Set<BeanDefinition> beanDefinitions = new LinkedHashSet<>();  \n\n18.         for (String basePackage : basePackages) {  \n\n19.             Set<BeanDefinition> candidates = findCandidateComponents(basePackage);  \n\n20.             for(BeanDefinition candidate :candidates) {  \n\n21.                 beanDefinitions.add(candidate);  \n\n22.                 registry.registryBeanDefinition(candidate.getId(), candidate);  \n\n23.             }  \n\n24.         }  \n\n25.         return beanDefinitions;  \n\n26.     }  \n\n\n27.     private Set<BeanDefinition> findCandidateComponents(String basePackage) throws IOException {  \n\n28.         Set<BeanDefinition> candidates = new LinkedHashSet<>();  \n\n29.         Resource[] resources = resourceLoader.getResources(basePackage);  \n\n30.         MetadataReader reader = null;  \n\n31.         AnnotationMetadata metadata = null;  \n\n32.         ScannedGenericBeanDefinition beanDefinition = null;  \n\n33.         String componentName = Component.class.getName();  \n\n34.         for (Resource resource : resources) {  \n\n35.             reader = new SimpleMetadaReader(resource);  \n\n36.             metadata = reader.getAnnotationMetadata();  \n\n37.             if (metadata.hasAnnotation(componentName)) {  \n\n38.                 beanDefinition = new ScannedGenericBeanDefinition(metadata);  \n\n39.                 // 根据BeanDefinition生成对应的beanName  \n\n40.                 String beanId = beanNameGenerator.generateBeanName(beanDefinition, registry);  \n\n41.                 beanDefinition.setId(beanId);  \n\n42.                 candidates.add(beanDefinition);  \n\n43.             }  \n\n44.         }  \n\n45.         return candidates;  \n\n46.     }  \n\n47. }  \n```\n\n\n\n过程还是很简单的，通过步骤3中的包装类解析Resource获得AnnotationMetadata，然后传给ScannedGenericBeanDefinition 就可以了\n\n这里有一点要注意的就是ScannedGenericBeanDefinition 的beanId怎么确认？\n\n1）如果@Component的value属性有值就用这个值\n\n2）如果没有就拿className，需要将className首字母小写\n\n\n\n这部分Spring代码个人觉得太繁琐了就不展示了\n\n其实就是从AnnotationMetadata中获取到@Component对应的value属性，判断一下，没有值就对className处理一下就当作beanId了。\n\n使用ClassPathBeanDefinitionScanner扫描目录并装载BeanDefinition的代码如下：\n\n```\n1.  DefaultBeanFactory factory = new DefaultBeanFactory();  \n\n2.  String basePackage = \"my_spring.beanfactory_annotation\";  \n\n3.  ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(factory);  \n\n4.  scanner.doScan(basePackage);  \n\n5.  BeanDefinition bd = factory.getBeanDefinition(\"personService\");  \n\n6.  //...  \n```\n\n\n\n#### **5、在xml加载的时候进行扫描装载**\n\n这个过程比较简单了，我们顺便重构一下之前的XmlBeanDefinitionReader.loadBeanDefinition这部分代码\n\n之前我们只考虑从xml中获取Bean并装载，现在多了个扫描目录文件 + 装载\n\n重构后的代码如下：\n\n```\n1.  public void loadBeanDefinition(Resource resource) {  \n\n2.      InputStream is = null;  \n\n3.      try {  \n\n4.          is = resource.getInputStream();  \n\n5.          SAXReader reader = new SAXReader();  \n\n6.          Document doc = reader.read(is);  \n\n7.          Element root = doc.getRootElement();  \n\n8.          Iterator<Element> itr = root.elements().iterator();  \n\n9.          while (itr.hasNext()) {  \n\n10.             Element ele = itr.next();  \n\n11.             String namespaceUri = ele.getNamespaceURI();  \n\n12.             // 判断标签的命名空间  \n\n13.             if (isDefaultNamespace(namespaceUri)) {  \n\n14.                 parseDefaultElement(ele);  \n\n15.             } else if (isContextNamespace(namespaceUri)) {  \n\n16.                 parseComponentElement(ele);  \n\n17.             }  \n\n18.         }  \n\n19.     } catch (DocumentException | IOException e) {  \n\n20.         throw new BeanStoreException(\"configFile is valid xml file!\");  \n\n21.     } finally {  \n\n22.         if (is != null) {  \n\n23.             try {  \n\n24.                 is.close();  \n\n25.             } catch (IOException e) {  \n\n26.                 e.printStackTrace();  \n\n27.             }  \n\n28.         }  \n\n29.     }  \n\n30. }  \n\n\n31.  /** \n\n32.  * 解析Bean类型的标签 \n\n33.  */  \n\n34. private void parseDefaultElement(Element ele) {  \n\n35.     String id = ele.attributeValue(ID_ATTRIBUTE);  \n\n36.     String beanClassName = ele.attributeValue(CLASS_ATTRIBUTE);  \n\n37.     BeanDefinition bd = new GenericBeanDefinition(id, beanClassName);  \n\n38.     if (ele.attribute(SCOPE_ATTRIBUTE) != null) { // 判断bean的scope  \n\n39.         bd.setScope(ele.attributeValue(SCOPE_ATTRIBUTE));  \n\n40.     }  \n\n41.     // 解析bean中construct-arg标签，放入到BeanDefinition中的constructorArguments中  \n\n42.     this.parseConstructorArgElements(ele, bd);  \n\n43.     // 解析bean的property标签，放入到BeanDefinition中的propertyValue中  \n\n44.     this.parsePropertyElement(ele, bd);  \n\n45.     // 向BeanFactory注册BeanDefinition  \n\n46.     this.registry.registryBeanDefinition(id, bd); // 这里用BeanDefinitionRegistry 替代了container  \n\n47. }  \n\n\n48. /** \n\n49.  * 解析context类型的标签 \n\n50.  */  \n\n51. private void parseComponentElement(Element ele) throws IOException {  \n\n52.     String basePackage = ele.attributeValue(BASE_PACKAGE_ATTRIBUTE);  \n\n53.     ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(registry);  \n\n54.     scanner.doScan(basePackage);  \n\n55. }  \n\n\n56. /** \n\n57.  * 判断命名方式是不是bean(default) \n\n58.  */  \n\n59. private boolean isDefaultNamespace(String namespaceUri) {  \n\n60.     return (!StringUtils.hasLength(namespaceUri) || BEANS_NAMESPACE_URI.equals(namespaceUri));  \n\n61. }  \n\n\n62. /** \n\n63.  * 判断命名方式是不是context \n\n64.  */  \n\n65. private boolean isContextNamespace(String namespaceUri) {  \n\n66.     return (!StringUtils.hasLength(namespaceUri) || CONTEXT_NAMESPACE_URI.equals(namespaceUri));  \n\n67. }  \n```\n\n这里就是多了一步判断，看看你是不是使用的context下的标签，也就是<context:component-scan>，如果是的就用ClassPathBeanDefinitionScanner去扫描装载，不然就用之前的方法就可以了。\n\n\n\n#### **6、总结**\n\n1）如何使用ASM去操作class文件，获取想要的信息。\n\n2）面向接口编程，而不是面向实现编程，凡事多用接口，比如这里对于MetaDataVisitor，都先新建对应的接口MetaData，以及在扩展BeanDefiniton的时候先使用一个接口AnnotatedBeanDefinition来表示新能力。\n\n3）面向修改关闭，面向扩展开放，比如这里面需要扩展BeanDefiniton的时候，使用一个接口AnnotatedBeanDefinition来表示新能力，并且还让这个新扩展出来的BeanDefinition去继承老的BeanDefinition。", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "80f3414de799cfcf86e5fa8e289a2bee": {"id": "80f3414de799cfcf86e5fa8e289a2bee", "item": "造轮子系列", "title": "手写Rpc通信框架上", "date": "2024-08-22", "summary": "记录一次手写Rpc通信框架的上半部分", "body": "\n这是一节手动造轮子系列\n\n先讲一下基本的设计思路\n\n\n\n参考rpc通信框架的经典dubbo，dubbo的简易架构如下\n\n\n\n![img](http://pcc.huitogo.club/c518b5bada3cdf5f11f7b0e58026b443)\n\n\n\n基本业内rpc框架需要考虑到的要素和配置dubbo都已经实现了，当然我们今天不是造一个dubbo，而是仿照dubbo的理念自己造一个轮子\n\n我们的架构长什么样呢？\n\n\n\n![img](http://pcc.huitogo.club/92505f81dff143477d5480ef87fc4bd2)\n\n\n\n就是这个小巧的样子。\n\n作为一个rpc框架应该具备哪些功能呢？\n\n\n\n![img](http://pcc.huitogo.club/6983e64ac0fd58db8ff8705c3bcb618e)\n\n\n\n我们仿照rpc框架的要求，实现的框架如下\n\n\n\n![img](http://pcc.huitogo.club/a9f859660243433c06dad0067dfdffab)\n\n\n\n接下来讲解实现的内容就是上图中介绍的功能\n\n\n\n#### **1、编码思路**\n\n\n\n首先是三个重要组件的任务\n\n\n\n##### **1）消费端**\n\n\n\n消费端需要将自己的服务（包括服务名和调用地址）暴露出去，也就是上传到注册中心\n\n消费端需要处理服务端的连接请求和调用请求，我们还加上了心跳包处理\n\n消费端需要及时断开无用连接，并对有效客户端保持长连接\n\n\n\n##### **2）客户端**\n\n客户端需要去注册中心拿到自己需要调用的服务地址，我们加上了负载均衡\n\n客户端需要连接服务端并对服务端发起通信\n\n客户端需要处理服务端响应结果作为自己的调用返回值\n\n\n\n##### **3）注册中心**\n\n注册中心的任务就是保存和提供服务地址\n\n\n\n编码过程思路如下\n\n\n\n```\n1、zk Registry and discovery （loadBalance）\n\n \n\n2、service Provider (expose for use) and service definition\n\n \n\n3、refer dubbo SPI design for extension\n\n \n\n4、netty server or socket server for receive requestMessage\n\n \n\nnetty : encode + decode + messageHandler\n\nencode/decode：serializer + compress\n\n \n\n5、netty client or socket client for send requestMessage\n\n \n\n6、producer and consumer in spring lifestyle with SpringBeanPostProcessor\n\n \n\nthe service provided by producer which was annotated by @RpcService will be registered  to \nregistration center\n\n \n\nthe field annotated by @RpcReference in consumer will create proxy object to be replaced into the field and it`s method will be invoked by proxy object \n\n \n\n7、scan the packages and find the class which was annotated by @RpcService and the detected packages was assigned by user with @RpcScan\n\n \n\n8、create client and server to test this rpc framework\n```\n\n\n\n下面实现细节就是根据这些思路编码的\n\n\n\n#### **2、实现细节**\n\n\n\n##### **（1）注册中心**\n\n\n\n先从简单的注册中心交互开始编码\n\n本着抽象的原则，定义注册服务和查找服务的接口\n\n\n\n```\n1. @SPI \n\n2. public interface ServiceRegistry { \n\n3.  \n\n4.   void registerService(String rpcServiceName, InetSocketAddress inetSocketAddress); \n\n5. } \n\n6.  \n\n7. @SPI \n\n8. public interface ServiceDiscovery { \n\n9.  \n\n10.   InetSocketAddress lookupService(String rpcServiceName); \n\n11. } \n```\n\n\n\n这里@SPI代表着我们使用SPI来扩展这些服务的\n\n我们注册中心采用zookeeper，所以基于zk的实现\n\n\n\nZkServiceRegistry：zk服务注册\n\n\n\n```\n1. public class ZkServiceRegistry implements ServiceRegistry { \n\n2.   @Override \n\n3.   public void registerService(String rpcServiceName, InetSocketAddress inetSocketAddress) { \n\n4.     String serviceNodePath = CuratorUtils.ZK_REGISTER_ROOT_PATH + \"/\" + rpcServiceName + inetSocketAddress.toString(); \n\n5.  \n\n6.     CuratorFramework zkClient = CuratorUtils.getZkClient(); \n\n7.  \n\n8.     CuratorUtils.createPersistentNode(zkClient, serviceNodePath); \n\n9.   } \n\n10. } \n```\n\n\n\nZkServiceDiscovery：zk服务发现\n\n\n\n```\n1. @Slf4j \n\n2. public class ZkServiceDiscovery implements ServiceDiscovery { \n\n4.   private LoadBalance loadBalance; \n\n6.   public ZkServiceDiscovery() { \n\n7.     // default loadBalance \n\n8.     this.loadBalance = new RandomLoadBalance(); \n\n9.   } \n\n10.  \n\n11.   public ZkServiceDiscovery(LoadBalance loadBalance) { \n\n12.     this.loadBalance = loadBalance; \n\n13.   } \n\n14.  \n\n15.   @Override \n\n16.   public InetSocketAddress lookupService(String rpcServiceName) { \n\n18.     CuratorFramework zkClient = CuratorUtils.getZkClient(); \n\n19.     List<String> serviceUrlList = CuratorUtils.getChildrenNodes(zkClient, rpcServiceName); \n\n20.  \n\n21.     if (serviceUrlList.size() == 0) { \n\n22.       throw new RpcException(RpcErrorMessageEnum.SERVICE_CAN_NOT_BE_FOUND, rpcServiceName); \n\n23.     } \n\n24.     // load balancing \n\n25.     String targetServiceUrl = loadBalance.selectServiceAddress(serviceUrlList); \n\n26.  \n\n27.     log.info(\"Successfully found the service address:[{}]\", targetServiceUrl); \n\n28.     String[] socketAddressArray = targetServiceUrl.split(\":\"); \n\n29.  \n\n30.     String host = socketAddressArray[0]; \n\n31.     int port = Integer.parseInt(socketAddressArray[1]); \n\n32.  \n\n33.     return new InetSocketAddress(host, port); \n\n34.   } \n\n35. } \n```\n\n\n\n这里有一个**zk的第三方工具包**Curator的封装类CuratorUtils\n\n主要提供创建节点和查找节点的任务\n\n\n\n这里服务发现的时候我们添加了**负载均衡**，如果服务提供者很多的话会根据负载均衡策略访问其中一个\n\n\n\nLoadBalance接口和随机策略的实现类\n\n\n\n```\n1. public interface LoadBalance { \n\n3.   String selectServiceAddress(List<String> serviceAddresses); \n\n4. } \n\n5.  \n\n6. public abstract class AbstractLoadBalance implements LoadBalance { \n\n8.   @Override \n\n9.   public String selectServiceAddress(List<String> serviceAddresses) { \n\n10.     if (serviceAddresses == null || serviceAddresses.size() == 0) { \n\n11.       return null; \n\n12.     } \n\n13.  \n\n14.     if (serviceAddresses.size() == 1) { \n\n15.       return serviceAddresses.get(0); \n\n16.     } \n\n17.     return doSelect(serviceAddresses); \n\n18.   } \n\n19.  \n\n20.   public abstract String doSelect(List<String> serviceAddresses); \n\n21. } \n\n22.  \n\n23. public class RandomLoadBalance extends AbstractLoadBalance { \n\n24.  \n\n25.   @Override \n\n26.   public String doSelect(List<String> serviceAddresses) { \n\n27.     Random random = new Random(); \n\n28.     return serviceAddresses.get(random.nextInt(serviceAddresses.size())); \n\n29.   } \n\n30. } \n```\n\n\n\n这里采用模板模式将负载策略的公有特性提取出来\n\n\n\n刚刚讲到了扩展ServiceDiscovery和ServiceRegistry采用SPI的设计理念，那这个**SPI怎么用**？\n\n\n\n在resources/META-INF/目录下新建配置文件（类似Properties键值对文件），内容如下\n\n\n\n```\n1. zk=com.zhanghui.registry.zk.ZkServiceDiscovery \n```\n\n\n\n然后借助ExtensionLoader工具类，当然这个工具类是从dubbo上抄的\n\n在使用的时候不需要new我们的ServiceDiscovery实现类，而是\n\n\n\n```\n1. ServiceRegistry serviceRegistry = ExtensionLoader.getExtensionLoader(ServiceRegistry.class).getExtension(\"zk\"); \n```\n\n\n\n现在我们已经基于zk实现服务的注册和发现，而且基于SPI我们可以开发出更多的扩展功能，并且可以动态加载这些扩展类，但是我们还需要封装一下给开发人员使用\n\n\n\n定义ServiceProvider接口提供服务的发布\n\n\n\n```\n1. public interface ServiceProvider { \n\n2.  \n\n3.   void addService(Object service, Class<?> serviceClass, RpcServiceProperties rpcServiceProperties); \n\n4.  \n\n5.   Object getService(RpcServiceProperties rpcServiceProperties); \n\n6.  \n\n7.   void publishService(Object service, RpcServiceProperties rpcServiceProperties); \n\n8.  \n\n9.   void publishService(Object service); \n\n10. } \n```\n\n\n\nServiceProvider的实现类ServiceProviderImpl\n\n\n\n```\n1. @Slf4j \n\n2. public class ServiceProviderImpl implements ServiceProvider { \n\n3.  \n\n4.   private final Map<String, Object> serviceMap; \n\n5.  \n\n6.   private final Set<String> registeredService; \n\n7.  \n\n8.   private final ServiceRegistry serviceRegistry; \n\n9.  \n\n10.   public ServiceProviderImpl() { \n\n11.     this.serviceMap = new ConcurrentHashMap<>(); \n\n12.     registeredService = ConcurrentHashMap.newKeySet(); \n\n13.  \n\n14.     serviceRegistry = ExtensionLoader.getExtensionLoader(ServiceRegistry.class).getExtension(\"zk\"); \n\n15.   } \n\n16.  \n\n17.   @Override \n\n18.   public void addService(Object service, Class<?> serviceClass, RpcServiceProperties rpcServiceProperties) { \n\n19.     String rpcServiceName = rpcServiceProperties.toRpcServiceName(); \n\n20.     if (registeredService.contains(rpcServiceName)) { \n\n21.       return; \n\n22.     } \n\n23.     registeredService.add(rpcServiceName); \n\n24.     serviceMap.put(rpcServiceName, service); \n\n25.     log.info(\"Add service: {} and interfaces:{}\", rpcServiceName, service.getClass().getInterfaces()); \n\n26.   } \n\n27.  \n\n28.   @Override \n\n29.   public Object getService(RpcServiceProperties rpcServiceProperties) { \n\n30.     Object service = serviceMap.get(rpcServiceProperties.toRpcServiceName()); \n\n31.     if (null == service) { \n\n32.       throw new RpcException(RpcErrorMessageEnum.SERVICE_CAN_NOT_BE_FOUND); \n\n33.     } \n\n34.     return service; \n\n35.   } \n\n36.  \n\n37.   @Override \n\n38.   public void publishService(Object service) { \n\n39.     this.publishService(service, RpcServiceProperties.builder().group(\"\").version(\"\").build()); \n\n40.   } \n\n41.  \n\n42.   @Override \n\n43.   public void publishService(Object service, RpcServiceProperties rpcServiceProperties) { \n\n44.     try { \n\n45.       String host = InetAddress.getLocalHost().getHostAddress(); \n\n46.       Class<?> serviceRelatedInterface = service.getClass().getInterfaces()[0]; \n\n47.  \n\n48.       String serviceName = serviceRelatedInterface.getCanonicalName(); \n\n49.  \n\n50.       rpcServiceProperties.setServiceName(serviceName); \n\n51.       this.addService(service, serviceRelatedInterface, rpcServiceProperties); \n\n52.  \n\n53.       serviceRegistry.registerService(rpcServiceProperties.toRpcServiceName(), new InetSocketAddress(host, NettyServer.PORT)); \n\n54.  \n\n55.     } catch (UnknownHostException e) { \n\n56.       log.error(\"occur exception when getHostAddress\", e); \n\n57.     } \n\n58.   } \n\n59. } \n```\n\n\n\n这里发布服务的时候还向本地缓存一份，减少调用zk的次数。\n\n\n\n##### **（2）服务端**\n\n\n\n服务端和客户端的交互的方式我们这里有两种，**netty**和**socket**\n\n\n\n先来看一下**netty**\n\n\n\nNettyServer：服务端启动\n\n\n\n```\n1. @Slf4j \n\n2. @Component \n\n3. public class NettyServer { \n\n4.  \n\n5.   public static final int PORT = 9998; \n\n6.  \n\n7.   private final ServiceProvider serviceProvider = SingletonFactory.getInstance(ServiceProviderImpl.class); \n\n8.  \n\n9.   public void registerService(Object service, RpcServiceProperties rpcServiceProperties) { \n\n10.     serviceProvider.publishService(service, rpcServiceProperties); \n\n11.   } \n\n12.  \n\n13.   @SneakyThrows \n\n14.   public void start() { \n\n15.  \n\n16.     // clear all \n\n17.     CustomShutdownHook customShutdownHook = new CustomShutdownHook(); \n\n18.     customShutdownHook.clearAll(); \n\n19.  \n\n20.     String host = InetAddress.getLocalHost().getHostAddress(); \n\n21.  \n\n22.     EventLoopGroup bossGroup = new NioEventLoopGroup(1); \n\n23.     EventLoopGroup workerGroup = new NioEventLoopGroup(); \n\n24.  \n\n25.     DefaultEventExecutorGroup eventExecutors = new DefaultEventExecutorGroup(RuntimeUtil.cpus(), ThreadPoolFactoryUtils.createThreadFactory(\"server-handler-group\", false)); \n\n26.  \n\n27.     ServerBootstrap serverBootstrap = new ServerBootstrap(); \n\n28.  \n\n29.     try { \n\n30.       serverBootstrap.group(bossGroup, workerGroup) \n\n31.           .channel(NioServerSocketChannel.class) \n\n32.           // TCP默认开启了 Nagle 算法，该算法的作用是尽可能的发送大数据快，减少网络传输。TCP_NODELAY 参数的作用就是控制是否启用 Nagle 算法。 \n\n33.           .childOption(ChannelOption.TCP_NODELAY, true) \n\n34.           // 是否开启长连接 \n\n35.           .childOption(ChannelOption.SO_KEEPALIVE, true) \n\n36.           //表示系统用于临时存放已完成三次握手的请求的队列的最大长度,如果连接建立频繁，服务器处理创建新连接较慢，可以适当调大这个参数 \n\n37.           .option(ChannelOption.SO_BACKLOG, 128) \n\n38.           .handler(new LoggingHandler(LogLevel.INFO)) \n\n39.           // 当客户端第一次进行请求的时候才会进行初始化 \n\n40.           .childHandler(new ChannelInitializer<SocketChannel>() { \n\n41.             @Override \n\n42.             protected void initChannel(SocketChannel ch) { \n\n43.               ChannelPipeline p = ch.pipeline(); \n\n44.               // 30 秒之内没有收到客户端请求的话就关闭连接 \n\n45.               p.addLast(new IdleStateHandler(30, 0, 0, TimeUnit.SECONDS)); \n\n46.               p.addLast(new RpcMessageEncoder()); \n\n47.               p.addLast(new RpcMessageDecoder()); \n\n48.               p.addLast(eventExecutors, new **ServerMessageHandler**()); \n\n49.             } \n\n50.           }); \n\n51.  \n\n52.       // 绑定端口，同步等待绑定成功 \n\n53.       ChannelFuture future = serverBootstrap.bind(host, PORT).sync(); \n\n54.  \n\n55.       // 等待服务端监听端口关闭 \n\n56.       future.channel().closeFuture().sync(); \n\n57.     } catch (InterruptedException e) { \n\n58.       log.error(\"occur exception when start server:\", e); \n\n59.     } finally { \n\n60.       log.error(\"shutdown bossGroup and workerGroup\"); \n\n61.       bossGroup.shutdownGracefully(); \n\n62.       workerGroup.shutdownGracefully(); \n\n63.       eventExecutors.shutdownGracefully(); \n\n64.     } \n\n65.   } \n\n66. } \n```\n\n\n\nnetty服务端监听9998等待客户端的连接和请求\n\n这里定义了一个自定义的ShutdownHook，在Netty Server每次start之前clen一下\n\n\n\nCustomShutdownHook代码如下\n\n\n\n```\n1. @Slf4j \n\n2. public class CustomShutdownHook { \n\n3.   private static final CustomShutdownHook CUSTOM_SHUTDOWN_HOOK = new CustomShutdownHook(); \n\n4.  \n\n5.   public static CustomShutdownHook getCustomShutdownHook() { \n\n6.     return CUSTOM_SHUTDOWN_HOOK; \n\n7.   } \n\n8.  \n\n9.   public void clearAll() { \n\n10.     log.info(\"addShutdownHook for clearAll\"); \n\n11.     Runtime.getRuntime().addShutdownHook(new Thread(() -> { \n\n12.       CuratorUtils.clearRegistry(CuratorUtils.getZkClient()); \n\n13.       ThreadPoolFactoryUtils.shutDownAllThreadPool(); \n\n14.     })); \n\n15.   } \n\n16. } \n```\n\n\n\n这个ShutdownHook的任务就是清除zk端的服务节点和关闭系统正在运行的线程池。\n\n在客户端的请求到达之后会依次经过**IdleStateHandler**（空闲连接处理）、**RpcMessageEncoder** 和**RpcMessageDecoder**。\n\n\n\n这里有个非常重要的概念，就是通信协议，也就是我们通常说的报文格式\n\n这里我们自定义了报文的编码和解码方式RpcMessageEncoder和RpcMessageDecoder\n\n\n\n首先说一下自定义的特殊报文格式\n\n\n\n![img](http://pcc.huitogo.club/6e14dfd06d32638c6dc9fff6c60254ac)\n\n\n\n这里4字节魔法数的意义就是防止出现非法报文段，做过滤使用的。\n\n\n\n对于编码的核心代码\n\n\n\n```\n1. @Override \n\n2. protected void encode(ChannelHandlerContext ctx, RpcMessage rpcMessage, ByteBuf out) { \n\n3.   try { \n\n4.     out.writeBytes(RpcConstants.MAGIC_NUMBER); \n\n5.     out.writeByte(RpcConstants.VERSION); \n\n6.     // leave a place to write the value of full length \n\n7.     out.writerIndex(out.writerIndex() + 4); \n\n8.     byte messageType = rpcMessage.getMessageType(); \n\n9.     out.writeByte(messageType); \n\n10.     out.writeByte(rpcMessage.getCodec()); \n\n11.     out.writeByte(CompressTypeEnum.GZIP.getCode()); \n\n12.     out.writeInt(ATOMIC_INTEGER.getAndIncrement()); \n\n13.     // build full length \n\n14.     byte[] bodyBytes = null; \n\n15.     int fullLength = RpcConstants.HEAD_LENGTH; \n\n16.     // if messageType is not heartbeat message,fullLength = head length + body length \n\n17.     if (messageType != RpcConstants.HEARTBEAT_REQUEST_TYPE \n\n18.         && messageType != RpcConstants.HEARTBEAT_RESPONSE_TYPE) { \n\n19.       // serialize the object \n\n20.       String codecName = SerializationTypeEnum.getName(rpcMessage.getCodec()); \n\n21.       Serializer serializer = ExtensionLoader.getExtensionLoader(Serializer.class) \n\n22.           .getExtension(codecName); \n\n23.       bodyBytes = serializer.serialize(rpcMessage.getData()); \n\n24.       // compress the bytes \n\n25.       String compressName = CompressTypeEnum.getName(rpcMessage.getCompress()); \n\n26.       Compress compress = ExtensionLoader.getExtensionLoader(Compress.class) \n\n27.           .getExtension(compressName); \n\n28.       bodyBytes = compress.compress(bodyBytes); \n\n29.       fullLength += bodyBytes.length; \n\n30.     } \n\n31.  \n\n32.     if (bodyBytes != null) { \n\n33.       out.writeBytes(bodyBytes); \n\n34.     } \n\n35.     int writeIndex = out.writerIndex(); \n\n36.     out.writerIndex(writeIndex - fullLength + RpcConstants.MAGIC_NUMBER.length + 1); \n\n37.     out.writeInt(fullLength); \n\n38.     out.writerIndex(writeIndex); \n\n39.   } catch (Exception e) { \n\n40.     log.error(\"Encode request error!\", e); \n\n41.   } \n\n42.  \n\n43. } \n```\n\n\n\n对于解码的核心代码\n\n\n\n```\n1. private Object decodeFrame(ByteBuf in) { \n\n2.   // note: must read ByteBuf in order \n\n3.   // read the first 4 bit, which is the magic number, and compare \n\n4.   int len = RpcConstants.MAGIC_NUMBER.length; \n\n5.   byte[] tmp = new byte[len]; \n\n6.   in.readBytes(tmp); \n\n7.   for (int i = 0; i < len; i++) { \n\n8.     if (tmp[i] != RpcConstants.MAGIC_NUMBER[i]) { \n\n9.       throw new IllegalArgumentException(\"Unknown magic code: \" + Arrays.toString(tmp)); \n\n10.     } \n\n11.   } \n\n12.   // read the version and compare \n\n13.   byte version = in.readByte(); \n\n14.   if ( version!= RpcConstants.VERSION) { \n\n15.     throw new RuntimeException(\"version isn't compatible\" + version); \n\n16.   } \n\n17.   int fullLength = in.readInt(); \n\n18.   // build RpcMessage object \n\n19.   byte messageType = in.readByte(); \n\n20.   byte codecType = in.readByte(); \n\n21.   byte compressType = in.readByte(); \n\n22.   int requestId = in.readInt(); \n\n23.   RpcMessage rpcMessage = RpcMessage.builder() \n\n24.       .codec(codecType) \n\n25.       .requestId(requestId) \n\n26.       .messageType(messageType).build(); \n\n27.   if (messageType == RpcConstants.HEARTBEAT_REQUEST_TYPE) { \n\n28.     rpcMessage.setData(RpcConstants.PING); \n\n29.   } else if (messageType == RpcConstants.HEARTBEAT_RESPONSE_TYPE) { \n\n30.     rpcMessage.setData(RpcConstants.PONG); \n\n31.   } else { \n\n32.     int bodyLength = fullLength - RpcConstants.HEAD_LENGTH; \n\n33.     if (bodyLength > 0) { \n\n34.       byte[] bs = new byte[bodyLength]; \n\n35.       in.readBytes(bs); \n\n36.       // decompress the bytes \n\n37.       String compressName = CompressTypeEnum.getName(compressType); \n\n38.       Compress compress = ExtensionLoader.getExtensionLoader(Compress.class) \n\n39.           .getExtension(compressName); \n\n40.       bs = compress.decompress(bs); \n\n41.       // deserialize the object \n\n42.       String codecName = SerializationTypeEnum.getName(rpcMessage.getCodec()); \n\n43.       Serializer serializer = ExtensionLoader.getExtensionLoader(Serializer.class) \n\n44.           .getExtension(codecName); \n\n45.       if (messageType == RpcConstants.REQUEST_TYPE) { \n\n46.         RpcRequest tmpValue = serializer.deserialize(bs, RpcRequest.class); \n\n47.         rpcMessage.setData(tmpValue); \n\n48.       } else { \n\n49.         RpcResponse tmpValue = serializer.deserialize(bs, RpcResponse.class); \n\n50.         rpcMessage.setData(tmpValue); \n\n51.       } \n\n52.     } \n\n53.   } \n\n54.   return rpcMessage; \n\n55.  \n\n56. } \n```\n\n\n\n我们这里对消息体采用的序列化方式是kyro，压缩方式是gzip\n\n在经过编解码处理后，我们得到客户端的请求体RpcMessage，到我们的MessageHandler\n\n\n\nServerMessageHandler：消息处理类\n\n\n\n```\n1. @Slf4j \n\n2. public class ServerMessageHandler extends ChannelInboundHandlerAdapter { \n\n3.  \n\n4.   private final RpcRequestHandler rpcRequestHandler; \n\n5.  \n\n6.   public ServerMessageHandler() { \n\n7.     this.rpcRequestHandler = SingletonFactory.getInstance(RpcRequestHandler.class); \n\n8.   } \n\n9.  \n\n10.   @Override \n\n11.   public void channelRead(ChannelHandlerContext ctx, Object msg) { \n\n12.     try { \n\n13.       if (msg instanceof RpcMessage) { \n\n14.         log.info(\"server receive msg: [{}] \", msg); \n\n15.         byte messageType = ((RpcMessage) msg).getMessageType(); \n\n16.         if (messageType == RpcConstants.HEARTBEAT_REQUEST_TYPE) { \n\n17.           RpcMessage rpcMessage = new RpcMessage(); \n\n18.           rpcMessage.setCodec(SerializationTypeEnum.KYRO.getCode()); \n\n19.           rpcMessage.setCompress(CompressTypeEnum.GZIP.getCode()); \n\n20.           rpcMessage.setMessageType(RpcConstants.HEARTBEAT_RESPONSE_TYPE); \n\n21.           rpcMessage.setData(RpcConstants.PONG); \n\n22.           ctx.writeAndFlush(rpcMessage).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); \n\n23.         } else { \n\n24.           RpcRequest rpcRequest = (RpcRequest) ((RpcMessage) msg).getData(); \n\n25.           // Execute the target method (the method the client needs to execute) and return the method result \n\n26.           Object result = rpcRequestHandler.handle(rpcRequest); \n\n27.           log.info(String.format(\"server get result: %s\", result.toString())); \n\n28.           if (ctx.channel().isActive() && ctx.channel().isWritable()) { \n\n29.             RpcResponse<Object> rpcResponse = RpcResponse.success(result, rpcRequest.getRequestId()); \n\n30.             RpcMessage rpcMessage = new RpcMessage(); \n\n31.             rpcMessage.setCodec(SerializationTypeEnum.KYRO.getCode()); \n\n32.             rpcMessage.setCompress(CompressTypeEnum.GZIP.getCode()); \n\n33.             rpcMessage.setMessageType(RpcConstants.RESPONSE_TYPE); \n\n34.             rpcMessage.setData(rpcResponse); \n\n35.             ctx.writeAndFlush(rpcMessage).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); \n\n36.           } else { \n\n37.             RpcResponse<Object> rpcResponse = RpcResponse.fail(RpcResponseCodeEnum.FAIL); \n\n38.             RpcMessage rpcMessage = new RpcMessage(); \n\n39.             rpcMessage.setCodec(SerializationTypeEnum.KYRO.getCode()); \n\n40.             rpcMessage.setCompress(CompressTypeEnum.GZIP.getCode()); \n\n41.             rpcMessage.setMessageType(RpcConstants.RESPONSE_TYPE); \n\n42.             rpcMessage.setData(rpcResponse); \n\n43.             ctx.writeAndFlush(rpcMessage).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); \n\n44.             log.error(\"not writable now, message dropped\"); \n\n45.           } \n\n46.         } \n\n47.       } \n\n48.  \n\n49.     } finally { \n\n50.       //Ensure that ByteBuf is released, otherwise there may be memory leaks \n\n51.       ReferenceCountUtil.release(msg); \n\n52.     } \n\n53.   } \n```\n\n\n\n服务端消息处理器只处理客户端心跳消息和客户端的报文请求\n\n这里将报文请求核心处理内容提取到RpcRequestHandler中\n\n\n\n```\n1. @Slf4j \n\n2. public class RpcRequestHandler { \n\n3.  \n\n4.   private final ServiceProvider serviceProvider; \n\n5.  \n\n6.   public RpcRequestHandler() { \n\n7.     serviceProvider = SingletonFactory.getInstance(ServiceProviderImpl.class); \n\n8.   } \n\n9.  \n\n10.   /** \n\n11.   * Processing rpcRequest: call the corresponding method, and then return the method \n\n12.   */ \n\n13.   public Object handle(RpcRequest rpcRequest) { \n\n14.     Object service = serviceProvider.getService(rpcRequest.toRpcProperties()); \n\n15.     return invokeTargetMethod(rpcRequest, service); \n\n16.   } \n\n17.  \n\n18.   /** \n\n19.   * get method execution results \n\n20.   * \n\n21.   * @param rpcRequest client request \n\n22.   * @param service  service object \n\n23.   * @return the result of the target method execution \n\n24.   */ \n\n25.   private Object invokeTargetMethod(RpcRequest rpcRequest, Object service) { \n\n26.     Object result; \n\n27.     try { \n\n28.       Method method = service.getClass().getMethod(rpcRequest.getMethodName(), rpcRequest.getParamTypes()); \n\n29.  \n\n30.       result = method.invoke(service, rpcRequest.getParameters()); \n\n31.       log.info(\"service:[{}] successful invoke method:[{}]\", rpcRequest.getInterfaceName(), rpcRequest.getMethodName()); \n\n32.     } catch (NoSuchMethodException | IllegalAccessException | InvocationTargetException e) { \n\n33.       throw new RpcException(e.getMessage(), e); \n\n34.     } \n\n35.     return result; \n\n36.   } \n\n37. } \n```\n\n\n\n处理过程就是通过请求报文中的类名、方法名和参数值使用反射调用获取结果\n\n然后NettyServer将返回结果封装成RpcMessage后writeAndFlush到客户端\n\n\n\n看完netty的服务端后再来看一下基于socket的服务端\n\n\n\n```\n1. @Slf4j \n\n2. public class SocketServer { \n\n3.  \n\n4.   private final ExecutorService threadPool; \n\n5.   private final ServiceProvider serviceProvider; \n\n6.  \n\n7.   public SocketServer() { \n\n8.     serviceProvider = SingletonFactory.getInstance(ServiceProviderImpl.class); \n\n9.     threadPool = ThreadPoolFactoryUtils.createCustomThreadPoolIfAbsent(\"rpc-socket-server-pool\"); \n\n10.   } \n\n11.  \n\n12.   public void registerService(Object service) { \n\n13.     serviceProvider.publishService(service); \n\n14.   } \n\n15.  \n\n16.   public void registerService(Object service, RpcServiceProperties rpcServiceProperties) { \n\n17.     serviceProvider.publishService(service, rpcServiceProperties); \n\n18.   } \n\n19.  \n\n20.   public void start() { \n\n21.     try (ServerSocket serverSocket = new ServerSocket()) { \n\n22.       String host = InetAddress.getLocalHost().getHostAddress(); \n\n23.       serverSocket.bind(new InetSocketAddress(host, NettyServer.PORT)); \n\n24.       CustomShutdownHook.getCustomShutdownHook().clearAll(); \n\n25.       Socket socket; \n\n26.       while ((socket = serverSocket.accept()) != null) { \n\n27.         log.info(\"client connected [{}]\", socket.getInetAddress()); \n\n28.         threadPool.execute(new SocketRequestHanlderRunnable(socket)); \n\n29.       } \n\n30.       threadPool.shutdown(); \n\n31.     } catch (IOException ex) { \n\n32.       log.error(\"occur Exception, \", ex); \n\n33.     } \n\n34.   } \n\n35. } \n```\n\n\n\nsocket的服务端在accept等待客户端连接\n\n在有连接请求过来的时候使用线程池处理请求，处理过程如下\n\n\n\n```\n1. @Slf4j \n\n2. public class SocketRequestHanlderRunnable implements Runnable { \n\n3.  \n\n4.   private final Socket socket; \n\n5.   private final RpcRequestHandler rpcRequestHandler; \n\n6.  \n\n7.   public SocketRequestHanlderRunnable(Socket socket) { \n\n8.     this.socket = socket; \n\n9.     rpcRequestHandler = SingletonFactory.getInstance(RpcRequestHandler.class); \n\n10.   } \n\n11.  \n\n12.   @Override \n\n13.   public void run() { \n\n14.     log.info(\"server handle message from client by thread: [{}]\", Thread.currentThread().getName()); \n\n15.     try (ObjectInputStream inputStream = new ObjectInputStream(socket.getInputStream()); \n\n16.       ObjectOutputStream outputStream = new ObjectOutputStream(socket.getOutputStream())) { \n\n17.  \n\n18.       RpcRequest rpcRequest = (RpcRequest) inputStream.readObject(); \n\n19.       Object result = rpcRequestHandler.handle(rpcRequest); \n\n20.       outputStream.writeObject(RpcResponse.success(result, rpcRequest.getRequestId())); \n\n21.       outputStream.flush(); \n\n22.     } catch (IOException | ClassNotFoundException ex) { \n\n23.       log.error(\"occur exception:\", ex); \n\n24.     } \n\n25.   } \n\n26. } \n```\n\n\n\n借助ObjectStream读写消息体，核心处理还是RpcRequestHandler", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "59c819dcc6652f9d59f4d18e9d78719f": {"id": "59c819dcc6652f9d59f4d18e9d78719f", "item": "造轮子系列", "title": "手写Rpc通信框架下", "date": "2024-08-22", "summary": "记录一次手写Rpc通信框架的下半部分", "body": "\n#### **1. 消费端**\n\n\n\n对于消费端的发送请求也是分netty client和socket client分别处理了\n\n\n\n先看下netty client\n\nNetty client：连接Netty Server 获取Channel\n\n\n\n```\n1. @Slf4j \n\n2. public class NettyClient { \n\n3.  \n\n4.   private final Bootstrap bootstrap; \n\n5.  \n\n6.   private final EventLoopGroup workersGroup; \n\n7.  \n\n8.   // initialize resources such as EventLoopGroup, Bootstrap \n\n9.   public NettyClient() { \n\n10.  \n\n11.     workersGroup = new NioEventLoopGroup(); \n\n12.  \n\n13.     bootstrap = new Bootstrap(); \n\n14.     bootstrap.group(workersGroup) \n\n15.         .channel(NioSocketChannel.class) \n\n16.         .handler(new LoggingHandler(LogLevel.INFO)) \n\n17.         // The timeout period of the connection. \n\n18.         // If this time is exceeded or the connection cannot be established, the connection fails. \n\n19.         .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000) \n\n20.         .handler(new ChannelInitializer<SocketChannel>() { \n\n21.           @Override \n\n22.           protected void initChannel(SocketChannel ch) throws Exception { \n\n23.             ChannelPipeline pipeline = ch.pipeline(); \n\n24.             // If no data is sent to the server within 15 seconds, a heartbeat request is sent \n\n25.             pipeline.addLast(new IdleStateHandler(0, 15, 0, TimeUnit.SECONDS)); \n\n26.             pipeline.addLast(new RpcMessageEncoder()); \n\n27.             pipeline.addLast(new RpcMessageDecoder()); \n\n28.             pipeline.addLast(new ClientMessageHandler()); \n\n29.           } \n\n30.         }); \n\n31.   } \n\n32.  \n\n33.   /** \n\n34.   * connect server and get the channel ,so that you can send rpc message to server \n\n35.   * \n\n36.   * @param socketAddress server address \n\n37.   * @return the channel \n\n38.   */ \n\n39.   @SneakyThrows \n\n40.   public Channel doConnect(InetSocketAddress socketAddress) { \n\n41.  \n\n42.     CompletableFuture<Channel> completableFuture = new CompletableFuture<>(); \n\n43.  \n\n44.     bootstrap.connect(socketAddress).addListener((ChannelFutureListener) future -> { \n\n45.       if (future.isSuccess()) { \n\n46.         log.info(\"The client has connected [{}] successful\", socketAddress.toString()); \n\n47.         completableFuture.complete(future.channel()); \n\n48.       } else { \n\n49.         completableFuture.completeExceptionally(future.cause()); \n\n50.         throw new RpcException(RpcErrorMessageEnum.CLIENT_CONNECT_SERVER_FAILURE, \"connect \" + socketAddress.toString() + \" failure\"); \n\n51.       } \n\n52.     }); \n\n53.     return completableFuture.get(); \n\n54.   } \n\n55.  \n\n56.   public void close() { \n\n57.     workersGroup.shutdownGracefully(); \n\n58.   } \n\n59. } \n```\n\n\n\nNetty client 对于响应消息的处理也是经过IdleStateHandler（空闲连接处理类）、RpcMessageEncoder和RpcMessageDecoder\n\n对于ClientMessageHandler我们待会儿再看\n\n通过Netty client连接到Netty server获取到Channel后，我们可以基于Channel发送报文和心跳包\n\n\n\n对于消费端发送请求，这里抽象出ClientTransport接口做扩展用\n\n\n\n```\n1. @SPI \n\n2. public interface ClientTransport { \n\n3.  \n\n4.   Object sendRpcRequest(RpcRequest rpcRequest); \n\n5. } \n```\n\n\n\n对于Netty的实现NettyClientTransport\n\n\n\n```\n1. @Slf4j \n\n2. public class NettyClientTransport implements ClientTransport { \n\n3.  \n\n4.   private final ServiceDiscovery serviceDiscovery; \n\n5.   private final ChannelProvider channelProvider; \n\n6.   private final UnProcessedRequest unProcessedRequest; \n\n7.  \n\n8.   public NettyClientTransport() { \n\n9.     serviceDiscovery = ExtensionLoader.getExtensionLoader(ServiceDiscovery.class).getExtension(\"zk\"); \n\n10.     channelProvider = SingletonFactory.getInstance(ChannelProvider.class); \n\n11.     unProcessedRequest = SingletonFactory.getInstance(UnProcessedRequest.class); \n\n12.   } \n\n13.  \n\n14.   @Override \n\n15.   public CompletableFuture<RpcResponse> sendRpcRequest(RpcRequest rpcRequest) { \n\n16.  \n\n17.     CompletableFuture<RpcResponse> completableFuture = new CompletableFuture<>(); \n\n18.  \n\n19.     unProcessedRequest.put(rpcRequest.getRequestId(),completableFuture); \n\n20.  \n\n21.     String rpcServiceName = rpcRequest.toRpcProperties().toRpcServiceName(); \n\n22.  \n\n23.     InetSocketAddress inetAddress = serviceDiscovery.lookupService(rpcServiceName); \n\n24.  \n\n25.     Channel channel = channelProvider.get(inetAddress); \n\n26.  \n\n27.     if (channel != null && channel.isActive()) { \n\n28.       RpcMessage rpcMessage = new RpcMessage(); \n\n29.       rpcMessage.setCodec(SerializationTypeEnum.KYRO.getCode()); \n\n30.       rpcMessage.setCompress(CompressTypeEnum.GZIP.getCode()); \n\n31.       rpcMessage.setData(rpcRequest); \n\n32.       rpcMessage.setMessageType(RpcConstants.REQUEST_TYPE); \n\n33.  \n\n34.       channel.writeAndFlush(rpcMessage).addListener((ChannelFutureListener) future -> { \n\n35.         if (future.isSuccess()) { \n\n36.           log.info(\"client send message: [{}]\", rpcMessage); \n\n37.         } else { \n\n38.           future.channel().close(); \n\n39.           completableFuture.completeExceptionally(future.cause()); \n\n40.           log.error(\"Send failed:\", future.cause()); \n\n41.         } \n\n42.       }); \n\n43.     } else { \n\n44.       throw new RpcException(RpcErrorMessageEnum.CLIENT_CONNECT_SERVER_FAILURE); \n\n45.     } \n\n46.     return completableFuture; \n\n47.   } \n\n48. } \n```\n\n\n\n这里需要注意的有三点\n\n\n\n1）使用CompletableFuture做sendRpcRequest方法返回值的结果\n\n\n\n对于netty在writeAndFlush后使用ChannelFutureListener只能监听请求发送情况，而不能获取sever端返回的内容，我们需要一个异步的同时支持多线程操作的容器\n\n\n\n2）我们不能每次调用服务端都要doConnect一次，因为我们使用的是长连接\n\n\n\n所以这里借助ChannelProvider来尝试获取我们的缓存Channel\n\nChannelProvider：从缓存中获取Channel，如果不存在或者Channel已失效则doConnect\n\n\n\n```\n1. @Slf4j \n\n2. public class ChannelProvider { \n\n3.  \n\n4.   private final Map<String, Channel> channelMap; \n\n5.   private final NettyClient nettyClient; \n\n6.  \n\n7.   public ChannelProvider() { \n\n8.     this.channelMap = new ConcurrentHashMap<>(); \n\n9.     this.nettyClient = SingletonFactory.getInstance(NettyClient.class); \n\n10.   } \n\n11.  \n\n12.  \n\n13.   public Channel get(InetSocketAddress inetSocketAddress) { \n\n14.  \n\n15.     String key = inetSocketAddress.toString(); \n\n16.  \n\n17.     //determine whether there is a connection in cache map \n\n18.     if (channelMap.containsKey(key)) { \n\n19.  \n\n20.       Channel cacheChannel = channelMap.get(key); \n\n21.       // determine the cache connection is available \n\n22.       if (cacheChannel != null && cacheChannel.isActive()) { \n\n23.         return cacheChannel; \n\n24.       } else { \n\n25.         channelMap.remove(key); \n\n26.       } \n\n27.     } \n\n28.  \n\n29.     // return new connection \n\n30.     Channel newChannel = nettyClient.doConnect(inetSocketAddress); \n\n31.  \n\n32.     channelMap.put(key, newChannel); \n\n33.  \n\n34.     return newChannel; \n\n35.   } \n\n36.  \n\n37.   public void remove(InetSocketAddress inetSocketAddress) { \n\n38.     String key = inetSocketAddress.toString(); \n\n39.  \n\n40.     channelMap.remove(key); \n\n41.  \n\n42.     log.info(\"has remove [{}] connection from cache\", key); \n\n43.   } \n\n44. } \n```\n\n\n\n可以看到核心原理是缓存了一个Map\n\n\n\n3）使用UnProcessedRequest来异步填充CompletableFuture的value\n\n\n\n怎么填充呢？借助RpcMessage中的唯一requestId\n\n先来看下UnProcessedRequest类\n\n\n\n```\n1. public class UnProcessedRequest { \n\n2.  \n\n3.   private static final Map<String, CompletableFuture<RpcResponse>> UNPROCESSED_RESPONSE_FUTURES = new ConcurrentHashMap<>(); \n\n4.  \n\n5.   public void put(String requestId, CompletableFuture<RpcResponse> future) { \n\n6.     UNPROCESSED_RESPONSE_FUTURES.put(requestId, future); \n\n7.   } \n\n8.  \n\n9.   public void complete(RpcResponse response) { \n\n10.     CompletableFuture future = UNPROCESSED_RESPONSE_FUTURES.remove(response.getRequestId()); \n\n11.  \n\n12.     if (future != null) { \n\n13.       future.complete(response); \n\n14.     } else { \n\n15.       throw new IllegalStateException(); \n\n16.     } \n\n17.   } \n\n18. } \n```\n\n\n\n里面只有一个Map，key是requestId，value是CompletableFuture\n\n\n\n在sendRpcRequest的时候往Map里面填充key/value，那什么时候为里面的CompletableFuture填充值呢？\n\n\n\n又回到了ClientMessageHandler，因为netty client只能接收netty server发送过来的报文来获取自己之前请求的响应结果\n\n\n\n```\n1. @Slf4j \n\n2. public class ClientMessageHandler extends ChannelInboundHandlerAdapter { \n\n3.  \n\n4.   private final UnProcessedRequest unProcessedRequest; \n\n5.   private final ChannelProvider channelProvider; \n\n6.  \n\n7.   public ClientMessageHandler() { \n\n8.     this.unProcessedRequest = SingletonFactory.getInstance(UnProcessedRequest.class); \n\n9.     this.channelProvider = SingletonFactory.getInstance(ChannelProvider.class); \n\n10.   } \n\n11.  \n\n12.   @Override \n\n13.   public void channelRead(ChannelHandlerContext ctx, Object msg) { \n\n14.     try { \n\n15.       log.info(\"client receive msg: [{}]\", msg); \n\n16.       if (msg instanceof RpcMessage) { \n\n17.         RpcMessage rpcMessage = (RpcMessage) msg; \n\n18.         if (rpcMessage.getMessageType() == RpcConstants.HEARTBEAT_RESPONSE_TYPE) { \n\n19.           log.info(\"heart [{}]\", rpcMessage.getData()); \n\n20.         } else if (rpcMessage.getMessageType() == RpcConstants.RESPONSE_TYPE) { \n\n21.           RpcResponse response = (RpcResponse) rpcMessage.getData(); \n\n22.           unProcessedRequest.complete(response); \n\n23.         } \n\n24.       } \n\n25.     } finally { \n\n26.       ReferenceCountUtil.release(msg); \n\n27.     } \n\n28.   } \n\n29.  \n\n30.   @Override \n\n31.   public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { \n\n32.  \n\n33.     // send heartbeat package to server when client is in idle state (we set the time is 15 seconds) \n\n34.     if (evt instanceof IdleStateEvent) { \n\n35.       log.info(\"write idle happen [{}]\", ctx.channel().remoteAddress()); \n\n36.  \n\n37.       Channel channel = channelProvider.get((InetSocketAddress) ctx.channel().remoteAddress()); \n\n38.  \n\n39.       RpcMessage rpcMessage = new RpcMessage(); \n\n40.       rpcMessage.setMessageType(RpcConstants.HEARTBEAT_REQUEST_TYPE); \n\n41.       rpcMessage.setCodec(SerializationTypeEnum.KYRO.getCode()); \n\n42.       rpcMessage.setCompress(CompressTypeEnum.GZIP.getCode()); \n\n43.       rpcMessage.setData(RpcConstants.PING); \n\n44.  \n\n45.       channel.writeAndFlush(rpcMessage).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); \n\n46.     } else { \n\n47.       super.userEventTriggered(ctx, evt); \n\n48.     } \n\n49.   } \n\n50.  \n\n51.   @Override \n\n52.   public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { \n\n53.     log.error(\"client catch exception：\", cause); \n\n54.     cause.printStackTrace(); \n\n55.     ctx.close(); \n\n56.   } \n\n57. } \n```\n\n\n\n所以我们通过ClientMessageHandler 来为UnProcessedReqeust下面Map中指定requestId的CompletableFuture填充value。\n\n这里可以看到在IdleStateEvent触发的时候消费端会主动向服务端发送心跳包，这就是我们心跳机制的实现了。\n\n\n\n基于netty实现的client请求已经完成了\n\n\n\n基于socket怎么实现呢？借助Socket就可以了\n\n\n\nSocketClientTransport：基于Socket实现ClientTransport\n\n\n\n```\n1. public class SocketClientTransport implements ClientTransport { \n\n2.  \n\n3.   private final ServiceDiscovery serviceDiscovery; \n\n4.  \n\n5.   public SocketClientTransport() { \n\n6.     this.serviceDiscovery = ExtensionLoader.getExtensionLoader(ServiceDiscovery.class).getExtension(\"zk\"); \n\n7.   } \n\n8.  \n\n9.   @Override \n\n10.   public Object sendRpcRequest(RpcRequest rpcRequest) { \n\n11.     // build rpc service name by rpcRequest \n\n12.     String rpcServiceName = RpcServiceProperties.builder() \n\n13.         .serviceName(rpcRequest.getInterfaceName()) \n\n14.         .group(rpcRequest.getGroup()) \n\n15.         .version(rpcRequest.getVersion()) \n\n16.         .build().toRpcServiceName(); \n\n17.     InetSocketAddress socketAddress = serviceDiscovery.lookupService(rpcServiceName); \n\n18.     try (Socket socket = new Socket()) { \n\n19.       socket.connect(socketAddress); \n\n20.       ObjectOutputStream outputStream = new ObjectOutputStream(socket.getOutputStream()); \n\n21.       outputStream.writeObject(rpcRequest); \n\n22.       ObjectInputStream inputStream = new ObjectInputStream(socket.getInputStream()); \n\n23.       return inputStream.readObject(); \n\n24.  \n\n25.     } catch (IOException | ClassNotFoundException ex) { \n\n26.       throw new RpcException(\"调用服务失败:\", ex); \n\n27.     } \n\n28.   } \n\n29. } \n```\n\n\n\n可以看到就是基于Socket端口传输RpcRequest对象\n\n\n\n#### **2. 嵌入Spring**\n\n\n\n这里嵌入Spring主要指使用注解的方式实现rpc的通信\n\n正如dubbo中使用的\n\n\n\n```\n1. @Reference(check =false, timeout = 10000,version=\"0.0.1\",group=\"AS_SSC_BE_SSCPLAT\") \n\n2. com.dap.api.IService iService2; \n\n3.  \n\n4. @Component \n\n5. @Service(version = \"1.0.0\",timeout = 10000,interfaceClass = RemoteUserService.class) \n\n6. public class RemoteUserServiceImpl implements RemoteUserService {} \n```\n\n\n\n我们也定义两个注解RpcReference和RpcService，当然使用方式和dubbo是一样的\n\n\n\n```\n1. @Documented \n\n2. @Retention(RetentionPolicy.RUNTIME) \n\n3. @Target({ElementType.FIELD}) \n\n4. @Inherited \n\n5. public @interface RpcReference { \n\n6.  \n\n7.   String version() default \"\"; \n\n8.  \n\n9.   String group() default \"\"; \n\n10.  \n\n11. } \n\n12.  \n\n13. @Documented \n\n14. @Retention(RetentionPolicy.RUNTIME) \n\n15. @Target({ElementType.TYPE}) \n\n16. @Inherited \n\n17. public @interface RpcService { \n\n18.  \n\n19.   String version() default \"\"; \n\n20.  \n\n21.   String group() default \"\"; \n\n22.  \n\n23. } \n```\n\n\n\n@RpcService是注解在type上的，我们希望被@RpcService注释的bean在程序启动的时候就将自己的服务注册到zookeeper上\n\n@RpcReference是注解在field上的，我们希望如果Bean中有field被@RpcReference注解了，那么我们将这个field的变量替换成我们指定的代理对象，让代理对象调用ClientTransport中的sendRpcRequest方法获取我们想要的结果\n\n\n\n因此我们想到了Spring生命周期中的BeanPostProcessor\n\n\n\nSpringBeanPostProcessor：处理被@RpcService或者@RpcReference注解的Bean或者Bean中的field\n\n\n\n```\n1. @Slf4j \n\n2. @Component \n\n3. public class SpringBeanPostProcessor implements BeanPostProcessor { \n\n4.  \n\n5.   private final ServiceProvider serviceProvider; \n\n6.   private final ClientTransport clientTransport; \n\n7.  \n\n8.   public SpringBeanPostProcessor() { \n\n9.     this.serviceProvider = SingletonFactory.getInstance(ServiceProviderImpl.class); \n\n10.     this.clientTransport = ExtensionLoader.getExtensionLoader(ClientTransport.class).getExtension(\"nettyClientTransport\"); \n\n11.   } \n\n12.  \n\n13.   @Override \n\n14.   public Object postProcessBeforeInitialization(Object bean, String beanName) { \n\n15.  \n\n16.     // registry the service annotated by @RpcService \n\n17.     if (bean.getClass().isAnnotationPresent(RpcService.class)) { \n\n18.       log.info(\"[{}] is annotated with [{}]\", bean.getClass().getName(), RpcService.class.getCanonicalName()); \n\n19.       RpcService rpcService = bean.getClass().getAnnotation(RpcService.class); \n\n20.       RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n21.           .version(rpcService.version()).group(rpcService.group()).build(); \n\n22.       serviceProvider.publishService(bean, rpcServiceProperties); \n\n23.     } \n\n24.     return bean; \n\n25.   } \n\n26.  \n\n27.   @Override \n\n28.   public Object postProcessAfterInitialization(Object bean, String beanName) { \n\n29.     Class targetClass = bean.getClass(); \n\n30.  \n\n31.     Field[] fields = targetClass.getDeclaredFields(); \n\n32.  \n\n33.     for (Field field : fields) { \n\n34.  \n\n35.       // check the field which was annotated by @RpcReference \n\n36.       RpcReference rpcReference = field.getAnnotation(RpcReference.class); \n\n37.       if (rpcReference != null) { \n\n38.         RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n39.             .version(rpcReference.version()).group(rpcReference.group()).build(); \n\n40.  \n\n41.         // aim to create proxy object for the bean which was annotated by @RpcReference \n\n42.         RpcClientProxy rpcClientProxy = new RpcClientProxy(clientTransport, rpcServiceProperties); \n\n43.         Object serviceProxy = rpcClientProxy.getProxy(field.getType()); \n\n44.  \n\n45.         // set the field accessible when it`s decorated by private \n\n46.         field.setAccessible(true); \n\n47.  \n\n48.         try { \n\n49.           field.set(bean, serviceProxy); \n\n50.         } catch (IllegalAccessException e) { \n\n51.           throw new RpcException(e.getMessage(), e.getCause()); \n\n52.         } \n\n53.       } \n\n54.     } \n\n55.     return bean; \n\n56.   } \n\n57. } \n```\n\n\n\n基本实现思路跟我们上述分析的一样，这里我们实现代理的方式使用jdk动态代理，反正调用的Service肯定是一个接口\n\n\n\nRpcClientProxy：为被@RpcReference注解的field生成jdk动态代理对象\n\n\n\n```\n1. @Slf4j \n\n2. public class RpcClientProxy implements InvocationHandler { \n\n3.  \n\n4.   private final RpcServiceProperties rpcServiceProperties; \n\n5.   private static final String INTERFACE_NAME = \"interfaceName\"; \n\n6.  \n\n7.   /** \n\n8.   * Used to send requests to the server.And there are two implementations: socket and netty \n\n9.   */ \n\n10.   private final ClientTransport clientTransport; \n\n11.  \n\n12.   public RpcClientProxy(ClientTransport clientTransport, RpcServiceProperties rpcServiceProperties) { \n\n13.     this.clientTransport = clientTransport; \n\n14.     if (rpcServiceProperties.getGroup() == null) { \n\n15.       rpcServiceProperties.setGroup(\"\"); \n\n16.     } \n\n17.     if (rpcServiceProperties.getVersion() == null) { \n\n18.       rpcServiceProperties.setVersion(\"\"); \n\n19.     } \n\n20.     this.rpcServiceProperties = rpcServiceProperties; \n\n21.   } \n\n22.  \n\n23.  \n\n24.   public RpcClientProxy(ClientTransport clientTransport) { \n\n25.     this.clientTransport = clientTransport; \n\n26.     this.rpcServiceProperties = RpcServiceProperties.builder().group(\"\").version(\"\").build(); \n\n27.   } \n\n28.  \n\n29.   @SuppressWarnings(\"unchecked\") \n\n30.   public <T> T getProxy(Class<T> clazz) { \n\n31.     return (T) Proxy.newProxyInstance(clazz.getClassLoader(), new Class<?>[]{clazz}, this); \n\n32.   } \n\n33.  \n\n34.   /** \n\n35.   * This method is actually called when you use a proxy object to call a method. \n\n36.   * The proxy object is the object you get through the getProxy method. \n\n37.   */ \n\n38.   @SneakyThrows \n\n39.   @Override \n\n40.   public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { \n\n41.     log.info(\"invoked method: [{}]\", method.getName()); \n\n42.     RpcRequest rpcRequest = RpcRequest.builder().methodName(method.getName()) \n\n43.         .parameters(args) \n\n44.         .interfaceName(method.getDeclaringClass().getName()) \n\n45.         .paramTypes(method.getParameterTypes()) \n\n46.         .requestId(UUID.randomUUID().toString()) \n\n47.         .group(rpcServiceProperties.getGroup()) \n\n48.         .version(rpcServiceProperties.getVersion()).build(); \n\n49.  \n\n50.     RpcResponse rpcResponse = null; \n\n51.  \n\n52.     if (clientTransport instanceof NettyClientTransport) { \n\n53.       CompletableFuture<RpcResponse> completableFuture = ((NettyClientTransport) clientTransport).sendRpcRequest(rpcRequest); \n\n54.       rpcResponse = completableFuture.get(); \n\n55.     } else if (clientTransport instanceof SocketClientTransport) { \n\n56.       rpcResponse = (RpcResponse) clientTransport.sendRpcRequest(rpcRequest); \n\n57.     } \n\n58.     this.check(rpcResponse, rpcRequest); \n\n59.     return rpcResponse.getData(); \n\n60.   } \n\n61.  \n\n62.   private void check(RpcResponse rpcResponse, RpcRequest rpcRequest) { \n\n63.     if (rpcResponse == null) { \n\n64.       throw new RpcException(RpcErrorMessageEnum.SERVICE_INVOCATION_FAILURE, INTERFACE_NAME + \":\" + rpcRequest.getInterfaceName()); \n\n65.     } \n\n66.  \n\n67.     if (!rpcRequest.getRequestId().equals(rpcResponse.getRequestId())) { \n\n68.       throw new RpcException(RpcErrorMessageEnum.REQUEST_NOT_MATCH_RESPONSE, INTERFACE_NAME + \":\" + rpcRequest.getInterfaceName()); \n\n69.     } \n\n70.  \n\n71.     if (rpcResponse.getCode() == null || !rpcResponse.getCode().equals(RpcResponseCodeEnum.SUCCESS.getCode())) { \n\n72.       throw new RpcException(RpcErrorMessageEnum.SERVICE_INVOCATION_FAILURE, INTERFACE_NAME + \":\" + rpcRequest.getInterfaceName()); \n\n73.     } \n\n74.   } \n\n75. } \n```\n\n\n\n因为我们这里对NettyClientTransport和SocketClientTransport两种方式的结果做了判断，所以代码稍微冗长了一定。\n\n核心原理就是封装RpcRequest，调用ClientTranspor的sendRpcRequest方法\n\n\n\n现在我们已经实现了刚刚分析的两个小目标，现在问题来了，怎么将@RpcService注解的类和我们rpc-framework-core中的Spring Bean放到用户的Spring上下文中\n\n所以我们自定义扫描机制\n\n\n\n先定义一个扫描注解\n\n\n\n```\n1. @Target({ElementType.TYPE, ElementType.METHOD}) \n\n2. @Retention(RetentionPolicy.RUNTIME) \n\n3. @Import(CustomScannerRegistrar.class) \n\n4. @Documented \n\n5. public @interface RpcScan { \n\n6.  \n\n7.   String[] basePackage(); \n\n8.  \n\n9. } \n```\n\n\n\n这里我们会对被@RpcScan注解的class或者method做一些事情，什么事情呢？\n\n没错，就是获取当前用户Spring的上下文，然后注入被@RpcService注解的类和我们rpc-framework-core包中或者其他包中的bean\n\n\n\nCustomScannerRegistrar：向用户的Spring上下文中注入需要的bean\n\n\n\n```\n1. @Slf4j \n\n2. public class CustomScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware { \n\n3.   private static final String SPRING_BEAN_BASE_PACKAGE = \"com.zhanghui.spring\"; \n\n4.  \n\n5.   private static final String NETTY_SERVER_PACKAGE = \"com.zhanghui.remoting.transport.netty.server\"; \n\n6.  \n\n7.   private static final String BASE_PACKAGE_ATTRIBUTE_NAME = \"basePackage\"; \n\n8.  \n\n9.   private ResourceLoader resourceLoader; \n\n10.  \n\n11.   @Override \n\n12.   public void setResourceLoader(ResourceLoader resourceLoader) { \n\n13.     this.resourceLoader = resourceLoader; \n\n14.   } \n\n15.  \n\n16.   @Override \n\n17.   public void registerBeanDefinitions(AnnotationMetadata classMetadata, BeanDefinitionRegistry registry) { \n\n18.  \n\n19.     // get the attributes and values of @RpcScan annotation \n\n20.     AnnotationAttributes rpcScanAnnotationAttributes = AnnotationAttributes.fromMap(classMetadata.getAnnotationAttributes(RpcScan.class.getName())); \n\n21.  \n\n22.     String[] rpcScanPackages = new String[0]; \n\n23.  \n\n24.     if (rpcScanAnnotationAttributes != null) { \n\n25.       rpcScanPackages = rpcScanAnnotationAttributes.getStringArray(BASE_PACKAGE_ATTRIBUTE_NAME); \n\n26.     } \n\n27.  \n\n28.     // default scan packages \n\n29.     if (rpcScanPackages.length == 0) { \n\n30.       rpcScanPackages = new String[]{((StandardAnnotationMetadata) classMetadata).getIntrospectedClass().getPackage().getName()}; \n\n31.     } \n\n32.  \n\n33.     // customize scanner for scan the specified annotation \n\n34.     CustomScan rpcServiceScanner = new CustomScan(registry, RpcService.class); \n\n35.     CustomScan springBeanScanner = new CustomScan(registry, Component.class); \n\n36.  \n\n37.     // scan the class which was annotated by @RpcService \n\n38.     int rpcServiceAnnoCount = rpcServiceScanner.scan(rpcScanPackages); \n\n39.     log.info(\"rpcServiceScanner扫描的数量 [{}]\", rpcServiceAnnoCount); \n\n40.  \n\n41.     // scan the SpringBeanPostProcessor to spring lifestyle \n\n42.     int springBeanAnnoCount = springBeanScanner.scan(SPRING_BEAN_BASE_PACKAGE,NETTY_SERVER_PACKAGE); \n\n43.     log.info(\"springBeanScanner扫描的数量 [{}]\", springBeanAnnoCount); \n\n44.   } \n\n45. } \n```\n\n\n\n实现ResourceLoaderAware接口获取当前的ResourceLoader\n\n实现ImportBeanDefinitionRegistrar接口注册BeanDefinition\n\n\n\n这里我们自定义CustomScan在basePackage下扫描我们指定的注解@RpcService和@Component\n\nCustomScan：指定BeanDefinitionRegistry和Annotation在basePackage下进行扫描\n\n\n\n```\n1. public class CustomScan extends ClassPathBeanDefinitionScanner { \n\n2.  \n\n3.   public CustomScan(BeanDefinitionRegistry registry, Class<? extends Annotation> annoType) { \n\n4.     super(registry); \n\n5.     super.addIncludeFilter(new AnnotationTypeFilter(annoType)); \n\n6.   } \n\n7.  \n\n8.   @Override \n\n9.   public int scan(String... basePackages) { \n\n10.     return super.scan(basePackages); \n\n11.   } \n\n12. } \n```\n\n\n\n需要实现ClassPathBeanDefinitionScanner接口实现scan操作\n\n\n\n至此我们的简易版的rpc-framework已经讲解完毕\n\n接下来是**测试环节，这里仅用于测试**\n\n\n\n#### **3. open-api**\n\n\n\n```\n1. public interface HelloService { \n\n2.   String hello(Hello hello); \n\n3. } \n```\n\n\n\n#### **4. example-server**\n\n\n\nHelloServiceImpl：需要暴露的服务\n\n\n\n```\n1. @RpcService(group = \"test1\", version = \"version1\") \n\n2. public class HelloServiceImpl implements HelloService { \n\n3.  \n\n4.   static { \n\n5.     System.out.println(\"HelloServiceImpl被创建\"); \n\n6.   } \n\n7.  \n\n8.   @Override \n\n9.   public String hello(Hello hello) { \n\n10.     log.info(\"HelloServiceImpl收到: {}.\", hello.getMessage()); \n\n11.     String result = \"Hello description is \" + hello.getDescription(); \n\n12.     log.info(\"HelloServiceImpl返回: {}.\", result); \n\n13.     return result; \n\n14.   } \n\n15. } \n```\n\n\n\nNetty Server方式启动\n\n\n\n```\n1. @RpcScan(basePackage = {\"com.zhanghui.service\"}) \n\n2. public class NettyServerMain { \n\n3.   public static void main(String[] args) { \n\n4.     // Register service via annotation \n\n5.     AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(NettyServerMain.class); \n\n6.     NettyServer nettyServer = (NettyServer) applicationContext.getBean(\"nettyServer\"); \n\n7.     // Register service manually \n\n8.     HelloService helloService2 = new HelloServiceImpl2(); \n\n9.     RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n10.         .group(\"test2\").version(\"version2\").build(); \n\n11.     nettyServer.registerService(helloService2, rpcServiceProperties); \n\n12.     nettyServer.start(); \n\n13.   } \n\n14. } \n```\n\n\n\nSocket Server方式启动\n\n\n\n```\n1. public class RpcFrameworkSimpleServerMain { \n\n2.   public static void main(String[] args) { \n\n3.     HelloService helloService = new HelloServiceImpl(); \n\n4.     SocketServer socketRpcServer = new SocketServer(); \n\n5.     RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n6.         .group(\"test2\").version(\"version2\").build(); \n\n7.     socketRpcServer.registerService(helloService, rpcServiceProperties); \n\n8.     socketRpcServer.start(); \n\n9.   } \n\n10. } \n```\n\n\n\n#### **5. example-client**\n\n\n\nHelloController：请求示例\n\n\n\n```\n1. @Component \n\n2. public class HelloController { \n\n3.  \n\n4.   @RpcReference(version = \"version1\", group = \"test1\") \n\n5.   private HelloService helloService; \n\n6.  \n\n7.   public void test() throws InterruptedException { \n\n8.     String hello = this.helloService.hello(new Hello(\"111\", \"222\")); \n\n9. //    //如需使用 assert 断言，需要在 VM options 添加参数：-ea \n\n10. //    assert \"Hello description is 222\".equals(hello); \n\n11.     Thread.sleep(12000); \n\n12.     for (int i = 0; i < 10; i++) { \n\n13.       System.out.println(helloService.hello(new Hello(\"111\", \"222\"))); \n\n14.     } \n\n15.   } \n\n16. } \n```\n\n\n\nNetty Client方式启动，调用请求\n\n\n\n```\n1. @RpcScan(basePackage = {\"com.zhanghui\"}) \n\n2. public class NettyClientMain { \n\n3.  \n\n4.   public static void main(String[] args) throws Exception { \n\n5.     AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(NettyClientMain.class); \n\n6.     HelloController controller = (HelloController) context.getBean(\"helloController\"); \n\n7.     controller.test(); \n\n8.   } \n\n9.  \n\n10. } \n```\n\n\n\nSocket Client方式启动，调用请求\n\n\n\n```\n1. public class RpcFrameworkSimpleClientMain { \n\n2.   public static void main(String[] args) { \n\n3.     ClientTransport clientTransport = new SocketClientTransport(); \n\n4.     RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n5.         .group(\"test2\").version(\"version2\").build(); \n\n6.     RpcClientProxy rpcClientProxy = new RpcClientProxy(clientTransport, rpcServiceProperties); \n\n7.     HelloService helloService = rpcClientProxy.getProxy(HelloService.class); \n\n8.     String hello = helloService.hello(new Hello(\"111\", \"222\")); \n\n9.     System.out.println(hello); \n\n10.   } \n\n11. } \n```\n\n\n\n#### **6. 总结**\n\n\n\n对于rpc通信框架简单的原理就是两端的通信，消费端拿着方法名、类名、参数值去向服务端要结果。\n\n重点在于设计这其中的细节部分\n\n\n\n比如说\n\n\n\n1）**缓存**，在rpc-framework大量使用缓存结果，保证系统的高可用。\n\n比如向消费端zk端查找服务地址，消费端向指定channel发送请求等。\n\n\n\n2）**长连接**，对于服务端和消费端为了避免建立连接的开销，可以通过心跳机制保持必要的长连接。\n\n\n\n3）**通信协议**的编写，通信通信，这最基本的报文格式编码和解码该怎么设计。\n\n\n\n4）如何让消费端像调用本地方法一样调用远程方法，这就涉及到**远程代理**了。\n\n\n\n5）结合到**Spring**的生命周期我们可以做出更多的设计，比如BeanPostProcessor。\n\n\n\n6）CompletableFuture在异步多线程环境下的使用。\n\n\n\n7）**线程池**的合理使用，对于Netty使用EventLoopGroup天然使用线程池，而Socket场景则需要我们创建线程池去处理请求。\n\n\n\n最后是该项目目前并不完善，比如基本的monitor组件并没有创建，后期根据情况会对项目进行更近一步的优化", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "b542fb34c110d221b826057ac48be702": {"id": "b542fb34c110d221b826057ac48be702", "item": "造轮子系列", "title": "手写rpc通信框架之基于xml配置", "date": "2024-08-22", "summary": "记录一次手写Rpc通信框架的拓展部分", "body": "\n这一章主要实现自定义rpc框架基于xml配置的方式实现服务的注册和消费\n\n顺便更改测试项目到SpringBoot环境下，由SpringBoot管理Spring\n\n\n\n#### **1. 自定义xml格式**\n\n\n\n首先我们需要申明xml的格式，可以自定义标签名和校验规则，核心是编写rpc.xsd文件\n\n这里简单介绍下让我们编写的rpc.xsd生效和自动解析xml\n\n\n\n##### **1）编写rpc.xsd**\n\n\n\n如\n\n\n\n```\n1. <?xml version=\"1.0\" encoding=\"UTF-8\" ?> \n\n2. <schema xmlns=\"http://www.w3.org/2001/XMLSchema\" \n\n3.   targetNamespace=\"http://www.zhangh.com/schema/rpc\" \n\n4.     elementFormDefault=\"qualified\"> \n\n5.  \n\n6.   <element name=\"user\"> \n\n7.     <complexType> \n\n8.       <attribute name=\"id\" type=\"string\" /> \n\n9.       <attribute name=\"name\" type=\"string\" /> \n\n10.       <attribute name=\"email\" type=\"string\" /> \n\n11.     </complexType> \n\n12.   </element> \n\n13. </schema> \n```\n\n\n\n##### **2）注册rpc.xsd**\n\n\n\n配置rpc.xsd的命名空间和让它解析生效，在文件META-INF/Spring.schemas中加入\n\n\n\n```\n1. http://www.zhangh.com/schema/rpc.xsd=com.zhangh.xsd/schema/rpc.xsd \n```\n\n\n\n##### **3）编写解析类（直接映射成Bean）**\n\n\n\n实现BeanDefinitionParser接口，定义解析规则\n\n\n\n```\n1. public class RpcBeanDefinitionParser extends AbstractSingleBeanDefinitionParser { \n\n2.  \n\n3.   protected Class getBeanClass(Element element){ \n\n4.     return User.class; \n\n5.   } \n\n6.   protected void doParse(Element element, BeanDefinitionBuilder bean) { \n\n7.     String userName = element.getAttribute(\"name\"); \n\n8.     String email = element.getAttribute(\"email\"); \n\n9.  \n\n10.     if(StringUtils.hasText(userName)) { \n\n11.       bean.addPropertyValue(\"name\", userName); \n\n12.     } \n\n13.  \n\n14.     if (StringUtils.hasText(email)) { \n\n15.       bean.addPropertyValue(\"email\", email); \n\n16.     } \n\n17.   } \n\n18. } \n```\n\n\n\n扩展NamespaceHandlerSupport类：注册解析类\n\n\n\n```\n1. public class MyNamespaceHandler extends NamespaceHandlerSupport { \n\n2.   public void init() { \n\n3.     registerBeanDefinitionParser(\"rpc\",new RpcBeanDefinitionParser());\n\n4.   } \n\n5. } \n```\n\n\n\n##### **4）注册解析器**\n\n\n\n在META-INF/Spring.handlers文件中加入：\n\n\n\n```\n1. http://www.zhangh.com/schema/rpc=com.zhangh.xsd.paser.MyNamespaceHandler \n```\n\n\n\n当引用http://www.zhangh.com/schema/rpc 时会使用MyNamespaceHandler解析引用对象\n\n这里我偷个懒没有自定义xml格式，直接用的dubbo的，而且我们需要解析的过程也不是简单将xml里面的内容封装成Bean并注册到Spring中，所以上面的内容仅供学习。\n\n\n\n#### **2. 解析xml文件**\n\n\n\n这里我本来想学Spring来个XmlBeanDefinitionReader的，后来优化掉了，因为一直考虑这个xml文件路径怎么传进来\n\n\n\n最后发现**Spring有个@ImportResource注解**里面可以定义解析器，所以最后实现起来是这样的\n\n\n\n```\n1. @Slf4j \n\n2. public class RpcBeanDefinitionReader extends AbstractBeanDefinitionReader { \n\n3.  \n\n4.   private final RpcParserResult rpcParserResult = new RpcParserResult(); \n\n5.  \n\n6.   private final ServiceProvider serviceProvider; \n\n7.  \n\n8.   private final ClientTransport clientTransport; \n\n9.  \n\n10.   private final BeanDefinitionRegistry registry; \n\n11.  \n\n12.   public static final String DUBBO_NAMESPACE_URI = \"http://code.alibabatech.com/schema/dubbo\"; \n\n13.  \n\n14.   public static final String SERVICE_ELEMENT = \"service\"; \n\n15.  \n\n16.   public static final String CONSUMER_ELEMENT = \"reference\"; \n\n17.  \n\n18.   public static final String ID_ATTRIBUTE = \"id\"; \n\n19.  \n\n20.   public static final String GROUP_ATTRIBUTE = \"group\"; \n\n21.  \n\n22.   public static final String VERSION_ATTRIBUTE = \"version\"; \n\n23.  \n\n24.   public static final String REF_ATTRIBUTE = \"ref\"; \n\n25.  \n\n26.   public static final String INTERFACE_ATTRIBUTE = \"interface\"; \n\n27.  \n\n28.   public RpcBeanDefinitionReader(BeanDefinitionRegistry registry){ \n\n29.     super(registry); \n\n30.     this.registry = registry; \n\n31.     this.serviceProvider = SingletonFactory.getInstance(ServiceProviderImpl.class); \n\n32.     this.clientTransport = ExtensionLoader.getExtensionLoader(ClientTransport.class).getExtension(\"nettyClientTransport\"); \n\n33.   } \n\n34.  \n\n35.   @Override \n\n36.   public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException { \n\n37.  \n\n38.     int beanCount = registry.getBeanDefinitionCount(); \n\n39.  \n\n40.     if (resource == null || !resource.exists()) { \n\n41.       throw new RpcException(RpcErrorMessageEnum.INIT_RESOURCE_NOT_NULL); \n\n42.     } \n\n43.  \n\n44.     try (InputStream is = resource.getInputStream()) { \n\n45.  \n\n46.       SAXReader reader = new SAXReader(); \n\n47.       Document document = reader.read(is); \n\n48.       Element root = document.getRootElement(); \n\n49.  \n\n50.       Iterator<Element> iterator = root.elements().iterator(); \n\n51.       while (iterator.hasNext()) { \n\n52.         Element element = iterator.next(); \n\n53.         String namespaceUri = element.getNamespaceURI(); \n\n54.         if (isDubboNamespace(namespaceUri)) { \n\n55.           parseDubboElement(element); \n\n56.         } \n\n57.       } \n\n58.     } catch (IOException | DocumentException ex) { \n\n59.       log.error(\"occur exception when parse the resource [{}]\", resource.getDescription()); \n\n60.     } \n\n61.  \n\n62.     this.doRegisterServce(); \n\n63.     this.doCreateProxy(); \n\n64.  \n\n65.     log.info(\"has registred beanDefinition nums [{}])\", registry.getBeanDefinitionCount() - beanCount); \n\n66.     return registry.getBeanDefinitionCount() - beanCount; \n\n67.   } \n\n68.  \n\n69.   private void parseDubboElement(Element ele) { \n\n70.     if (SERVICE_ELEMENT.equals(ele.getName())) { \n\n71.       String interfaceName = ele.attributeValue(INTERFACE_ATTRIBUTE); \n\n72.       try { \n\n73.         if(Class.forName(interfaceName) == null){ \n\n74.           throw new ResourceParserException(ParserErrorMessageEnum.SERVICE_NOT_FOUND,interfaceName); \n\n75.         } \n\n76.       } catch (ClassNotFoundException e) { \n\n77.         throw new ResourceParserException(ParserErrorMessageEnum.SERVICE_NOT_FOUND,interfaceName); \n\n78.       } \n\n79.  \n\n80.       String ref = ele.attributeValue(REF_ATTRIBUTE); \n\n81.       String group = ele.attributeValue(GROUP_ATTRIBUTE); \n\n82.       String version = ele.attributeValue(VERSION_ATTRIBUTE); \n\n83.  \n\n84.       RpcProvider rpcProvider = RpcProvider.builder() \n\n85.           .interfaceName(interfaceName) \n\n86.           .group(group) \n\n87.           .version(version) \n\n88.           .ref(ref).build(); \n\n89.  \n\n90.       this.rpcParserResult.addRpcService(rpcProvider); \n\n91.     } else if (CONSUMER_ELEMENT.equals(ele.getName())) { \n\n92.       String interfaceName = ele.attributeValue(INTERFACE_ATTRIBUTE); \n\n93.  \n\n94.       try { \n\n95.         if(Class.forName(interfaceName) == null){ \n\n96.           throw new ResourceParserException(ParserErrorMessageEnum.SERVICE_NOT_FOUND,interfaceName); \n\n97.         } \n\n98.       } catch (ClassNotFoundException e) { \n\n99.         throw new ResourceParserException(ParserErrorMessageEnum.SERVICE_NOT_FOUND,interfaceName); \n\n100.       } \n\n101.  \n\n102.       String id = ele.attributeValue(ID_ATTRIBUTE); \n\n103.       String group = ele.attributeValue(GROUP_ATTRIBUTE); \n\n104.       String version = ele.attributeValue(VERSION_ATTRIBUTE); \n\n105.  \n\n106.       RpcConsumer rpcConsumer = RpcConsumer.builder() \n\n107.           .interfaceName(interfaceName) \n\n108.           .group(group) \n\n109.           .version(version) \n\n110.           .id(id).build(); \n\n111. \n\n112.       this.rpcParserResult.addRpcConsumer(rpcConsumer); \n\n113.     } \n\n114.   } \n\n115.  \n\n116.   /** \n\n117.   * 判断命名方式是不是dubbo \n\n118.   */ \n\n119.   private boolean isDubboNamespace(String namespaceUri) { \n\n120.     return (!StringUtils.hasLength(namespaceUri) || DUBBO_NAMESPACE_URI.equals(namespaceUri)); \n\n121.   } \n\n122.  \n\n123.   public void doRegisterServce() { \n\n124.     Iterator<RpcProvider> iterator = this.rpcParserResult.listRpcServices(); \n\n125.  \n\n126.     while (iterator.hasNext()) { \n\n127.       RpcProvider rpcProvider = iterator.next(); \n\n128.       this.registerServie(rpcProvider); \n\n129.     } \n\n130.   } \n\n131.  \n\n132.   /** \n\n133.   * 生成代理对象 \n\n134.   */ \n\n135.   public void doCreateProxy() { \n\n136.     Iterator<RpcConsumer> iterator = this.rpcParserResult.listRpcConsumers(); \n\n137.  \n\n138.     while (iterator.hasNext()) { \n\n139.       RpcConsumer rpcConsumer = iterator.next(); \n\n140.       RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n141.           .version(rpcConsumer.getVersion()).group(rpcConsumer.getGroup()).build(); \n\n142.       RpcClientProxy clientProxy = new RpcClientProxy(clientTransport, rpcServiceProperties); \n\n143.  \n\n144.       try { \n\n145.         Class targetClass = Class.forName(rpcConsumer.getInterfaceName()); \n\n146.        Object proxyBean = clientProxy.getProxy(targetClass); \n\n147.         ((DefaultListableBeanFactory)registry).registerSingleton(rpcConsumer.getId(),proxyBean); \n\n148.       } catch (ClassNotFoundException e) { \n\n149.         throw new ResourceParserException(ParserErrorMessageEnum.SERVICE_NOT_FOUND, rpcConsumer.getInterfaceName()); \n\n150.       } \n\n151.     } \n\n152.   } \n\n153.  \n\n154.   /** \n\n155.   * 向zk注册服务 \n\n156.   */ \n\n157.   private void registerServie(RpcProvider rpcProvider) { \n\n158.  \n\n159.     RpcServiceProperties rpcServiceProperties = RpcServiceProperties.builder() \n\n160.         .version(rpcProvider.getVersion()).group(rpcProvider.getGroup()) \n\n161.         .serviceName(rpcProvider.getInterfaceName()).build(); \n\n162.  \n\n163.     String refBeanName = rpcProvider.getRef(); \n\n164.  \n\n165.     Object refBean = ((DefaultListableBeanFactory)registry).getBean(refBeanName); \n\n166.  \n\n167.     if (refBean == null) { \n\n168.       log.error(\"can`t find bean with beanName [{}]\", refBeanName); \n\n169.       throw new ResourceParserException(ParserErrorMessageEnum.SERVICE_NO_REALIZE, refBeanName); \n\n170.     } \n\n171.     serviceProvider.publishService(refBean, rpcServiceProperties); \n\n172.   } \n\n173. } \n```\n\n\n\n实现起来基本的思路就是：\n\n\n\n1）将xml文件中的<dubbo:service>标签解析成RpcProvider并通过ServiceProvider给它publish出去。\n\n\n\n2）将xml文件中的<dubbo:reference>标签解析成RpcConsumer并通过RpcClientProxy给它创建代理对象并放到Spring容器中去\n\n\n\n注意这个时候我们使用消费服务的时候**只能通过@Resource**方法获取，因为我们放进Spring的是代理类\n\n\n\n```\n1. Class targetClass = Class.forName(rpcConsumer.getInterfaceName()); \n\n2.  \n\n3. Object proxyBean = clientProxy.getProxy(targetClass); \n\n4.  \n\n5. ((DefaultListableBeanFactory)registry).registerSingleton(rpcConsumer.getId(),proxyBean); \n```\n\n\n\n这样之后我们通过在SpringBoot的启动类加上@ImportResource注解即可完成自动解析\n\n\n\n```\n1. @ImportResource(locations =\"classpath:dubbo-consumer.xml\", reader = RpcBeanDefinitionReader.class) \n\n2. public class HelloClientApplication { \n\n3.  \n\n4.   public static void main(String[] args) { \n\n5.  \n\n6.     SpringApplication.run(HelloClientApplication.class, args); \n\n7.   } \n\n8.  \n\n9.  \n\n10. } \n```\n\n\n\n#### **3. 配置服务端**\n\n\n\n服务端和消费端的区别在于服务端会启动一个netty或者socket一直去监听端口，所以需要加以区分\n\n这里我的处理方式就是通过@EnableRpcServer注解去实现\n\n\n\n@EnableRpcServer：是否开启服务端\n\n\n\n```\n1. @Target(ElementType.TYPE) \n\n2. @Retention(RetentionPolicy.RUNTIME) \n\n3. @Documented \n\n4. @Import(CustomStarterRegistrar.class) \n\n5. public @interface EnableRpcServer { \n\n6.  \n\n7.   boolean isServer() default false; \n\n8.  \n\n9.   ServiceProviderEnum providerType() default ServiceProviderEnum.NETTY_SERVER; \n\n10.  \n\n11. } \n```\n\n\n\n这里我们希望实现注解的自动解析和相关操作，引入一个ImportBeanDefinitionRegistrar的扩展类，这个类本意是希望引入我们自己的Bean到Spring中，可以通过扫描或者手动添加的方式，因为我们可以拿到一个BeanDefinitionRegistry。\n\n\n\n在@RpcScan注解中我们就是通过扩展ImportBeanDefinitionRegistrar类，用扫描方式将我们核心里spring注解修饰的类和自定义注解类修改的类注入到当前Spring上下文中\n\n\n\n```\n1. CustomScan rpcServiceScanner = new CustomScan(registry, RpcService.class); \n\n2. CustomScan springBeanScanner = new CustomScan(registry, Component.class); \n\n3.  \n\n4. // scan the class which was annotated by @RpcService \n\n5. int rpcServiceAnnoCount = rpcServiceScanner.scan(rpcScanPackages); \n\n6. log.info(\"rpcServiceScanner扫描的数量 [{}]\", rpcServiceAnnoCount); \n\n7.  \n\n8. // scan the SpringBeanPostProcessor to spring lifestyle \n\n9. int springBeanAnnoCount = springBeanScanner.scan(SPRING_BEAN_BASE_PACKAGE); \n\n10. log.info(\"springBeanScanner扫描的数量 [{}]\", springBeanAnnoCount); \n```\n\n\n\n除了ImportBeanDefinitionRegistrar接口还有一个ImportSelector接口，这个类的意思就是可以通过注解里面的内容，一般有条件或者默认值，有选择的向Spring上下文注入Configuration类，实质也是Bean\n\n\n\n比如@EnableCaching中\n\n\n\n```\n1. @Target(ElementType.TYPE) \n\n2. @Retention(RetentionPolicy.RUNTIME) \n\n3. @Documented \n\n4. @Import(CachingConfigurationSelector.class) \n\n5. public @interface EnableCaching { \n\n6.   //... \n\n7.  \n\n8.   AdviceMode mode() default AdviceMode.PROXY; \n\n9.  \n\n10.   //... \n\n11. } \n\n12.  \n\n13. //AdviceModeImportSelector是ImportSelector的扩展类 \n\n14. public class CachingConfigurationSelector extends AdviceModeImportSelector<EnableCaching> { \n\n15.      \n\n16.   //... \n\n17.      \n\n18.   // 这里返回结果是需要注入Spring的类名集合 \n\n19.   @Override \n\n20.   public String[] selectImports(AdviceMode adviceMode) { \n\n21.     switch (adviceMode) { \n\n22.       case PROXY: \n\n23.         return getProxyImports(); \n\n24.       case ASPECTJ: \n\n25.         return getAspectJImports(); \n\n26.       default: \n\n27.         return null; \n\n28.     } \n\n29.   } \n\n30.      \n\n31.   //... \n\n32.  \n\n33. } \n```\n\n\n\n好了，言归正传，看一下我们的ImportBeanDefinitionRegistrar 扩展类实现了什么内容\n\n\n\n其实很简单，就是**启动Server**\n\n\n\n```\n1. @Slf4j \n\n2. public class CustomStarterRegistrar implements ImportBeanDefinitionRegistrar { \n\n3.  \n\n4.   private static final String PROVIDER_TYPE = \"providerType\"; \n\n5.  \n\n6.   private static final String IS_SERVER = \"isServer\"; \n\n7.  \n\n8.  \n\n9.   @Override \n\n10.   public void registerBeanDefinitions(AnnotationMetadata classMetadata, BeanDefinitionRegistry registry) { \n\n11.  \n\n12.     // get the attributes and values of @RpcScan annotation \n\n13.     AnnotationAttributes annotationAttributes = AnnotationAttributes.fromMap(classMetadata.getAnnotationAttributes(EnableRpcServer.class.getName())); \n\n14.  \n\n15.     boolean isServer = annotationAttributes.getBoolean(IS_SERVER); \n\n16.  \n\n17.     ServiceProviderEnum providerEnum = annotationAttributes.getEnum(PROVIDER_TYPE); \n\n18.  \n\n19.     if(isServer){ \n\n20.       if(providerEnum == ServiceProviderEnum.NETTY_SERVER){ \n\n21.         new NettyServer().start(); \n\n22.       }else if(providerEnum == ServiceProviderEnum.SOCKET_SERVER){ \n\n23.         new SocketServer().start(); \n\n24.       } \n\n25.     } \n\n26.   } \n\n27. } \n```\n\n\n\n到此，我们就完成了这次优化的内容\n\n\n\n#### **4. 总结**\n\n\n\n1）第一个就是我们想自定义xml文件的时候怎么做，xsd标签怎么让它生效，自动化解析的过程\n\n\n\n2）借助@ImportSource可以自定义解析过程，在解析过程中可以拿到BeanDefinitionRegistry完成对Spring上下文的操作。\n\n\n\n3）使用@Import可以引入ImportBeanDefinitionRegistrar和ImportSelector的扩展类来实现对Spring上下文的操作，在这个过程中也可以拿到BeanDefinitionRegistry\n\n\n\n4）在设计过程中考虑到了一些设计问题，比如抽象、解耦合，解决问题的思路从根源出发，下次尝试下使用TDD开发模式。\n\n\n\n期待下一次的优化！", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "205644f3d01200cef669b7f311b28f42": {"id": "205644f3d01200cef669b7f311b28f42", "item": "造轮子系列", "title": "手写分布式调度框架之客户端", "date": "2024-08-22", "summary": "记录一次手写分布式调度框架的客户端部分", "body": "\n上一节讲完了对于Admin端需要做的事情，这一节来看一下Client端的任务，首先还是贴一下Client端的任务图\n\n\n\n![img](http://pcc.huitogo.club/0295b27392bc01c3243b70304c65120e)\n\n\n\n#### **1. 扫描Job并注册**\n\n\n\n所以我们需要在Client端启动的时候扫描含有@TestJob注解的类并封装成请求信息，最后尝试向Admin端进行注册\n\n\n\n先看一下@TestJob注解吧\n\n\n\n```\n1. @Target({ElementType.TYPE}) \n\n2. @Retention(RetentionPolicy.RUNTIME) \n\n3. public @interface SchedulerJob { \n\n4.   @NotBlank String triggerName(); \n\n5.  \n\n6.   String groupName() default \"\"; \n\n7.  \n\n8.   /** \n\n9.   * cron表达式 \n\n10.   */ \n\n11.   String cron() default \"\"; \n\n12.  \n\n13.   /** \n\n14.   * trigger描述信息 \n\n15.   */ \n\n16.   String desc() default \"\"; \n\n17.  \n\n18.   /** \n\n19.   * 集群环境下执行的路由策略 \n\n20.   */ \n\n21.   RouterStategyEnum strategy() default RouterStategyEnum.SCHEDULER_STRATEGY_RANDOM; \n\n22.  \n\n23.   /** \n\n24.   * 失败重试次数，默认0 为不重试 \n\n25.   */ \n\n26.   int retryTimes() default 0; \n\n27.  \n\n28.   /** \n\n29.   * 分片数 \n\n30.   */ \n\n31.   int shardingNum() default 1; \n\n32.  \n\n33.   /** \n\n34.   * 是否留存日志记录 \n\n35.   */ \n\n36.   boolean isLog() default false; \n\n37.  \n\n38.   /** \n\n39.   * 开启状态，默认开启 \n\n40.   */ \n\n41.   TriggerStatusEnum status() default TriggerStatusEnum.TRGGER_STATUS_STARTING; \n\n42. } \n```\n\n\n\n基本上我们需要这个注解给我们提供关于Trigger的所有信息\n\n\n\n然后再看一下我们是怎么把@TestJob注解的类变成我们想要的信息\n\n\n\n```\n1. @Slf4j \n\n2. public class JobDetailBeanFactoryPostProcessor implements BeanFactoryPostProcessor, EnvironmentAware { \n\n3.    \n\n4.   // ... \n\n5.  \n\n6.   @Override \n\n7.   public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { \n\n8.  \n\n9.     String[] beanDefinitionNames = beanFactory.getBeanDefinitionNames(); \n\n10.  \n\n11.     Arrays.asList(beanDefinitionNames).parallelStream().forEach(beanName -> { \n\n12.       BeanDefinition beanDefinition = beanFactory.getBeanDefinition(beanName); \n\n13.  \n\n14.       String beanClassName = beanDefinition.getBeanClassName(); \n\n15.  \n\n16.       if (StringUtils.isEmpty(beanClassName)) { \n\n17.         return; \n\n18.       } \n\n19.       try { \n\n20.         Class<?> clazz = Class.forName(beanClassName); \n\n21.         SchedulerJob schedulerJob; \n\n22.         if (clazz != null && (schedulerJob = clazz.getAnnotation(SchedulerJob.class)) != null) { \n\n23.           if (!JobHandler.class.isAssignableFrom(clazz)) { \n\n24.             log.error(\"SchedulerJob注解必须加在JobHanlder类上，{}不符合要求\", clazz.getCanonicalName()); \n\n25.             return; \n\n26.           } \n\n27.           ClientJobDetail clientJobDetail = ClientJobDetail.builder() \n\n28.               .className(beanClassName) \n\n29.               .triggerName(schedulerJob.triggerName()) \n\n30.               .groupName(StringUtils.isEmpty(schedulerJob.groupName()) ? applicationName : schedulerJob.groupName()) \n\n31.               .cron(schedulerJob.cron()) \n\n32.               .desc(schedulerJob.desc()) \n\n33.               .retryTimes(schedulerJob.retryTimes()) \n\n34.               .shardingNum(schedulerJob.shardingNum()) \n\n35.               .isLog(schedulerJob.isLog()) \n\n36.               .strategy(schedulerJob.strategy().getStatus()) \n\n37.               .status(schedulerJob.status().getStatus()) \n\n38.               .build(); \n\n39.  \n\n40.           beanFactory.registerSingleton(NAME_FORMATTER + BEAN_IDX.incrementAndGet(), clientJobDetail); \n\n41.         } \n\n42.  \n\n43.       } catch (ClassNotFoundException e) { \n\n44.         e.printStackTrace(); \n\n45.       } \n\n46.     }); \n\n47.   } \n```\n\n\n\n借助Spring的钩子函数BeanFactoryPostProcessor.postProcessBeanFactory，对被Spring管理的Bean进行筛选，有@TestJob注释的就封装一下，然后再把这个集合再塞回Spring中去\n\n\n\n其实这一块强制要求被@TestJob注释的类必须是Spring的Bean，也可以用**ImportBeanDefinitionRegistrar**进行扫描包啊，但是前提需要配置一下扫描包的路径。\n\n\n\n现在Spring中已经有了我们希望注册的Job集合了，是时候该向Admin端进行注册了\n\n\n\n来看一下注册线程RegistryJobThread的任务\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   log.info(\"客户端注册线程启动....^0^\"); \n\n4.   try { \n\n5.     List<TesseractAdminJobDetailDTO> jobDetailDTOList = initRegistry(); \n\n6.     TesseractAdminRegistryRequest tesseractAdminRegistryRequest = buildRequest(jobDetailDTOList); \n\n7.  \n\n8.     while (!isStop) { \n\n9.       //todo serverAddress可以是集群，集群注册在这里处理 \n\n10.       TesseractExecutorResponse response = doRegistry(tesseractAdminRegistryRequest); \n\n11.  \n\n12.       afterRegistry(response.getBody()); \n\n13.  \n\n14.       Thread.sleep(REGISTRY_INTEVAL_TIME); \n\n15.     } \n\n16.   } catch (Exception e) { \n\n17.     log.error(\"注册[{}]出现异常：{}\", clientJobDetailList, e.getMessage(), e.getCause()); \n\n18.   } \n\n19. } \n\n20.  \n\n21. private TesseractExecutorResponse doRegistry(TesseractAdminRegistryRequest tesseractAdminRegistryRequest) throws URISyntaxException { \n\n22.   log.info(\"开始注册，注册内容:{}\", tesseractAdminRegistryRequest); \n\n23.  \n\n24.   TesseractExecutorResponse response = clientFeignService.registry(new URI(adminServerAddress + REGISTRY_MAPPING), tesseractAdminRegistryRequest); \n\n25.   if (response.getStatus() == TesseractExecutorResponse.SUCCESS_STATUS) { \n\n26.     log.info(\"注册成功,当前未成功注册的JobDetail信息有:{}\", response.getBody()); \n\n27.     return response; \n\n28.   } \n\n29.   log.error(\"注册失败,状态码：{},信息：{}\", response.getStatus(), response.getBody()); \n\n30.   return response; \n\n31. } \n```\n\n\n\n注册任务很简单，向Admin端发送请求即可，然后这里加了重试处理，对Admin返回的未注册的Job进行判断，如果是因为一些非程序异常而注册失败的话，是允许进行重新注册的。\n\n\n\n重试判断和重试策略是在首次注册后进行afterRegistry\n\n\n\n```\n1. private void afterRegistry(Object respBody) throws UnknownHostException, URISyntaxException { \n\n2.  \n\n3.   if (respBody == null) { \n\n4.     return; \n\n5.   } \n\n6.  \n\n7.   TesseractAdminRegistryResDTO registryResDTO = JSON.parseObject(JSON.toJSONString(respBody), TesseractAdminRegistryResDTO.class); \n\n8.  \n\n9.   List<TesseractAdminRegistryFailInfo> registryFailInfoList = registryResDTO.getNotRegistryJobList(); \n\n10.  \n\n11.   if (CollectionUtils.isEmpty(registryFailInfoList)) { \n\n12.     isStop = true; \n\n13.     return; \n\n14.   } \n\n15.  \n\n16.   List<TesseractAdminJobDetailDTO> repeatRegistryJobList =Collections.synchronizedList(Lists.newArrayListWithCapacity(registryFailInfoList.size())); \n\n17.  \n\n18.   registryFailInfoList.stream().forEach(registryFailInfo -> { \n\n19.  \n\n20.     // 处理需要重复注册的JobDetails \n\n21.     if (Objects.equals(SERVER_ERROR, registryFailInfo.getErrorCode())) {\n\n22.       repeatRegistryJobList.add(registryFailInfo.getJobDetailDTO()); \n\n23.     } \n\n24.  \n\n25.     // 其他错误直接在客户端启动的时候传递给他们了 \n\n26.   }); \n\n27.  \n\n28.   if (CollectionUtils.isEmpty(repeatRegistryJobList)) { \n\n29.     isStop = true; \n\n30.     return; \n\n31.   } \n\n32.  \n\n33.   // 尝试重新注册 \n\n34.   repeatRegistry(repeatRegistryJobList); \n\n35. } \n```\n\n\n\n也就是我想知道为什么失败了，有没有可能去重新注册。\n\n注册这一块就是这样，这个RegistryJobThread线程在注册完成后是会关闭的，不会一直进行，但是在心跳失败后，这个线程会尝试重新运行。\n\n\n\n#### **2. 心跳请求**\n\n\n\n在Admin端我们知道Client会不断向Admin端发起心跳来维护ExecutorDetails信息，所以这个发起心跳部分是由Client端承担的。\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   log.info(\"HeartbeatThread start\"); \n\n4.   while (!isStop) { \n\n5.     //开始心跳 \n\n6.     //todo 在集群情况下会向每一台admin发送心跳 \n\n7.     heartbeat(); \n\n8.     try { \n\n9.       Thread.sleep(HEART_INTERVAL_TIME); \n\n10.     } catch (InterruptedException e) { \n\n11.     } \n\n12.   } \n\n13. } \n\n14.  \n\n15. private void heartbeat() { \n\n16.   try { \n\n17.     TesseractHeartbeatRequest tesseractHeartbeatRequest = buildHeartbeatRequest(); \n\n18.  \n\n19.     TesseractExecutorResponse response = clientFeignService.heartbeat(new URI(adminServerAddress + HEARTBEAT_MAPPING), tesseractHeartbeatRequest); \n\n20.  \n\n21.     if (response.getStatus() == TesseractExecutorResponse.SUCCESS_STATUS) { \n\n22.       log.info(\"心跳成功\"); \n\n23.       return; \n\n24.     } \n\n25.     if (response.getStatus() == EXECUTOR_DETAIL_NOT_FIND) { \n\n26.       log.info(\"机器{}已失效，将重新发起注册\", adminServerAddress); \n\n27.       // 重新发起注册 \n\n28.       registryJobThread.startRegistry(); \n\n29.       return; \n\n30.     } \n\n31.     log.error(\"心跳失败:{}\", response); \n\n32.   } catch (Exception e) { \n\n33.     log.error(\"心跳失败:{}\", e.getMessage(),e.getCause()); \n\n34.   } \n\n35. } \n```\n\n\n\n就是隔10秒发送心跳包，但是这里有个发起重新注册处理，这个主要用在Admin端集群环境下，一个机器失效了，会将当前Client端的Job组重新注册，如果重复了也无所谓，因为Admind端不允许重复注册。\n\n\n\n#### **3. 执行Admin端调度请求**\n\n\n\n这一部分就是怎么样去执行Admin端定期发起的调度请求，对于这种定期啊或者频繁调用的远程请求当然需要线程池啦\n\n\n\n```\n1. public static TesseractExecutorResponse execute(TesseractExecutorRequest tesseractExecutorRequest) { \n\n2.   jobNotifyHandlerThreadPool.execute(new ExecutorWorkerRunnable(tesseractExecutorRequest)); \n\n3.   return TesseractExecutorResponse.builder().status(TesseractExecutorResponse.SUCCESS_STATUS).body(\"成功进入队列\").build(); \n\n4. } \n```\n\n\n\n这里也就直接将调用请求塞进线程池里面，然后返回入队成功，最后异步返回调用结果。\n\n\n\n来看一下真正执行调用请求的线程ExecutorWorkerRunnable干了什么活\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   String className = tesseractExecutorRequest.getClassName(); \n\n4.   TesseractAdminJobNotify tesseractAdminJobNotify = buildJobNotify(tesseractExecutorRequest); \n\n5.   TesseractExecutorResponse notifyResponse = null; \n\n6.   try { \n\n7.     Class<?> aClass = Class.forName(className); \n\n8.     JobHandler jobHandler = (JobHandler) aClass.newInstance(); \n\n9.  \n\n10.     JobClientContext jobClientContext = new JobClientContext(); \n\n11.     jobClientContext.setShardingIndex(tesseractExecutorRequest.getShardingIndex()); \n\n12.     jobHandler.execute(jobClientContext); \n\n13.     // 异步回调执行结果\n\n14.     notifyResponse = clientFeignService.notify(new URI(adminServerAddress + NOTIFY_MAPPING), tesseractAdminJobNotify); \n\n15.   } catch (Exception e) { \n\n16.     log.error(\"执行异常:{}\", e.getMessage()); \n\n17.     tesseractAdminJobNotify.setException(e.getMessage()); \n\n18.     try { \n\n19.       notifyResponse = clientFeignService.notify(new URI(adminServerAddress + NOTIFY_MAPPING), tesseractAdminJobNotify); \n\n20.     } catch (URISyntaxException ex) { \n\n21.       log.error(\"执行异常URI异常:{}\", e.getMessage()); \n\n22.     } \n\n23.   } \n\n24.   if (notifyResponse != null && notifyResponse.getStatus() != TesseractExecutorResponse.SUCCESS_STATUS) { \n\n25.     log.error(\"通知执行器出错:{}\", notifyResponse); \n\n26.   } \n\n27.   log.info(\"执行通知结果:{}\", notifyResponse); \n\n28. } \n```\n\n\n\n这里就是简单的用反射调用Job的execute方法，前面说了Job类必须实现JobHandler接口，所以相当于直接抓住接口，剩下就靠多态去执行了。\n\n\n\n最后异步向Admin端发送调用结果。\n\n\n\n到此Client端的任务就已经完成了，毕竟只是一个Client端。\n\n\n\n#### **4. 总结**\n\n\n\n对于Client端和Admin端的交互就像下面这张图，过程是比较简单的\n\n\n\n![img](http://pcc.huitogo.club/414b33b1a1072859ed6f8c11c279370c)\n\n\n\n只是应和标题，分布式调度框架，那就是说会有多个Admin端和多个Client端，在复杂的环境下如何保证调度安全和程序的健壮性。\n\n\n\n其实还有好多事没做，列举一下\n\n\n\n1）Admin端的真正处理JobDetail的线程池，这个配置应该根据现实环境去配置的，在并发高的情况是可以考虑分Group进行处理的。\n\n\n\n2）邮件提醒功能还没做。\n\n\n\n3）Client端和Admin端集群下的处理还没做，不过已经预留出扩展地方了。\n\n\n\n4）希望有些配置信息是由用户来写的，比如说调度的间隔时间和重试次数，目前都是在程序中写死的。\n\n\n\n5）自己写的线程池ISchedulerThreadPool不够完美，需要朝着ThreadPoolExecutor努力。\n\n\n\n6）对于Trigger的groupName，如果用户指定了这个属性自然是美好的，不然会取spring.application.name这个属性，但是如果这个也没有的话，目前只能取用户线程的主方法名，比如我的DistributedJobSampleApplication，这个还不知道怎么解决，因为在我们程序中Group是很重要的，groupName也是不允许重复的。\n\n\n\n7）对于Admin端的一些核心代码已经干扰到了它自身的业务代码，比如说心跳和回调，这些不应该出现在它自身的业务方法里，这一点可以用netty来优化的，毕竟这可是netty的活啊。\n\n\n\n最后，继续磨磨吧，期待下一次优化。", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}, "26090b1266e32146043ebcba4d45cd1e": {"id": "26090b1266e32146043ebcba4d45cd1e", "item": "造轮子系列", "title": "手写分布式调度框架之服务端", "date": "2024-08-22", "summary": "记录一次手写分布式调度框架的服务端部分", "body": "\n这是一节造轮子系列\n\n\n\n任务调度框架，类似于quartz这种，但是又不同于quartz\n\n\n\n整体分为admin端和client端，出于可视化界面操作考虑，admin端是可以通过页面访问和配置的，但是在本节中我是没有加入这些页面配置功能，所以只能在client端通过环境注入或者注解的方式进行配置。\n\n\n\nadmin端和client交互的流程非常简单\n\n\n\n![img](http://pcc.huitogo.club/414b33b1a1072859ed6f8c11c279370c)\n\n\n\n然后讲一下这个框架中涉及到的主要元素\n\n\n\n![img](http://pcc.huitogo.club/eda728985166936740ba38b1fc9145be)\n\n\n\n接下来我们再详细说一下admin端和client端各自需要做的事情\n\n\n\n**admin端**\n\n\n\n![img](http://pcc.huitogo.club/d25f9b953334c7a8318bbc646871d669)\n\n\n\n**client端**\n\n\n\n![img](http://pcc.huitogo.club/0295b27392bc01c3243b70304c65120e)\n\n\n\n这里trigger、group、jobDetails类似quartz中，还包括后面的firedTrigger和lock\n\n我们自己加入了executorDetails元素，因为Client端和Admin端是分布式的，会有多个Client端，所以需要进行对应的管理\n\n还加入了log元素，作为任务调度中执行过程的一致性和数据持久化保证。\n\n\n\n大致讲完了这个框架中涉及到的元素，最后呈上编写代码的思路\n\n\n\n```\n1. 1、设计表 ，根据mybatis-plus一键生成代码工具生成CRUD代码 \n\n2.  \n\n3. 2、admin启动时 的操作 \n\n4.  \n\n5. 1）一个检测线程，检测客户端的连接，也就是job的执行者 \n\n6.  \n\n7. 2）按分组（项目或者业务）生成ScheduleThread 扫描业务下的Trigger  \n\n8.  \n\n9. 再将Trigger交给TriggerDispatcher执行 \n\n10.  \n\n11. 在TriggerDispatcher中对Trigger下的多个Job执行 \n\n12.  \n\n13. 3、client端启动时操作 \n\n14.  \n\n15. 注册自身JobHandler到admin端 \n\n16.  \n\n17. 发送心跳包到admin端 \n\n18.  \n\n19. 接收admin端的job执行请求并调用admin的回调接口返回结果 \n```\n\n\n\n其实很多思路都是在开发中想到的\n\n\n\n以下仅介绍服务端核心代码\n\n\n\n\n\n#### **1. 定时调度**\n\n\n\nadmin端会根据当前的group进行分组\n\n对每个group会生成一个SchedulerGroupInfo对象\n\n\n\n```\n1. public class SchedulerGroupInfo { \n\n2.  \n\n3.   private final SchedulerThread schedulerThread; \n\n4.  \n\n5.   private final ExecutorScanner executorScanner; \n\n6.  \n\n7.   public SchedulerGroupInfo(SchedulerThread schedulerThread, ExecutorScanner executorScanner) { \n\n8.     this.schedulerThread = schedulerThread; \n\n9.     this.executorScanner = executorScanner; \n\n10.   } \n\n11.  \n\n12.   public void startSchedule(){ \n\n13.     if(this.schedulerThread!=null){ \n\n14.       schedulerThread.startThread(); \n\n15.     } \n\n16.     if(this.executorScanner!=null){ \n\n17.       executorScanner.startThread(); \n\n18.     } \n\n19.   } \n\n20.  \n\n21.   public void stopSchedule(){ \n\n22.     if(this.schedulerThread!=null){ \n\n23.       schedulerThread.stopThread(); \n\n24.     } \n\n25.     if(this.executorScanner!=null){ \n\n26.       executorScanner.stopThread(); \n\n27.     } \n\n28.   } \n\n29. } \n```\n\n\n\n这个对象里面有两个线程，SchedulerThread线程和ExecutorScanner线程\n\n\n\n核心是SchedulerThread线程，所以我们先看下SchedulerThread线程干了啥\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   log.info(\"SchedulerThread {} start\", tesseractGroup.getName()); \n\n4.   while (!isStop) { \n\n5.     // 获取当前Group分发器可用线程数\n\n6.     int blockGetAvailableThreadnum = tesseractTriggerDispatcher.blockGetAvailableThreadNum(); \n\n7.  \n\n8.     List<TesseractTrigger> triggerList = tesseractTriggerService.findTriggerWithLockInCache(tesseractGroup.getName(), blockGetAvailableThreadnum, System.currentTimeMillis(), TIME_WINDOW_SIZE); \n\n9.    \n\n10.     if (!CollectionUtils.isEmpty(triggerList)) { \n\n11.       // 选取最近触发的一个trigger \n\n12.       TesseractTrigger latestTrigger = triggerList.get(0); \n\n13.       Long nextTriggerTime = latestTrigger.getNextTriggerTime(); \n\n14.       long gapTime = nextTriggerTime - System.currentTimeMillis(); \n\n15. \n\n16.       // 如果触发时间还早（大于我们预设的最短时间），则让线程休息去吧 \n\n17.       if (gapTime > ACCURATE_TIME) { \n\n18.         synchronized (this) { \n\n19.           try { \n\n20.             this.wait(gapTime); \n\n21.           } catch (InterruptedException e) { \n\n22.             e.printStackTrace(); \n\n23.           } \n\n24.         } \n\n25.       } \n\n26.       // 否则，或者线程唤醒 ,交由任务分发器进行分发 \n\n27.       tesseractTriggerDispatcher.dispatchTrigger(triggerList); \n\n28.       continue; \n\n29.     } \n\n30.  \n\n31.     try { \n\n32.       // 进入睡眠 \n\n33.       Thread.sleep(MIN_SLEEP_TIME); \n\n34.     } catch (InterruptedException e) { \n\n35.       e.printStackTrace(); \n\n36.     } \n\n37.   } \n\n38. } \n```\n\n\n\n好像一下子就戳到了核心代码了，其实调度原理就是这么简单，**SchedulerThread不断轮询着去查询Trigger的状态，有触发时间小于当前时间就让它执行，否则sleep等待**\n\n\n\n来看下**查询Trigger**的代码findTriggerWithLockInCache方法\n\n\n\n```\n1. @Transactional \n\n2. @Override \n\n3. public List<TesseractTrigger> findTriggerWithLockInCache(String groupName, int triggerSize, long time, Integer timeWindowSize) { \n\n4.   // redis分布式锁，保证一个trigger事件只能触发一次，避免分布式环境下多个服务端同时拿到同一组trigger  \n\n5.   RedissLockUtil.lock(groupName); \n\n6.  \n\n7.   try { \n\n8.     Query query = new Query(); \n\n9.     query.addCriteria(Criteria.where(\"groupName\").is(groupName) \n\n10.         .and(\"status\").is(TRGGER_STATUS_STARTING) \n\n11.         .and(\"nextTriggerTime\").lte(time + timeWindowSize)); \n\n12.     query.with(new Sort(new Sort.Order(Sort.Direction.DESC, \"nextTriggerTime\"))); \n\n13.  \n\n14.     query.skip(0); \n\n15.     query.limit(triggerSize); \n\n16.   \n\n17.     // 从mongoDB中去拿Trigger\n\n18.     List<TesseractTrigger> triggerList = triggerMongoCache.findByQuery(query, groupName); \n\n19.  \n\n20.     if (!CollectionUtils.isEmpty(triggerList)) { \n\n21.       List<TesseractTrigger> updateTriggerList = calculateNextTrigger(triggerList);\n\n22. \n\n23.       // 更新到mongoDb，可以看到这里是没有对数据库同步更新的 \n\n24.       triggerMongoCache.addBatchTriggerToCache(updateTriggerList, groupName); \n\n25.     } \n\n26.     return triggerList; \n\n27.   } finally { \n\n28.     RedissLockUtil.unlock(groupName); \n\n29.   } \n\n30. } \n\n31.  \n\n32. /** \n\n33. * 计算下一次触发时间 \n\n34. */ \n\n35. private List<TesseractTrigger> calculateNextTrigger(List<TesseractTrigger> prevTriggerList) { \n\n36.   List<TesseractTrigger> updateTriggerList = Lists.newArrayList(); \n\n37.   prevTriggerList.parallelStream().forEach(trigger -> { \n\n38.     CronExpression cronExpression = null; \n\n39.     try { \n\n40.       cronExpression = new CronExpression(trigger.getCron()); \n\n41.     } catch (ParseException e) { \n\n42.       e.printStackTrace(); \n\n43.     } \n\n44.     TesseractTrigger updateTrigger = new TesseractTrigger(); \n\n45.     updateTrigger.setId(trigger.getId()); \n\n46.     // 计算下一次触发时间 用于更新数据 \n\n47.     updateTrigger.setNextTriggerTime(cronExpression.getTimeAfter(new Date()).getTime()); \n\n48.     updateTrigger.setPrevTriggerTime(System.currentTimeMillis()); \n\n49.     log.info(\"触发器 {} 下一次执行时间:{}\", trigger.getName(), new Date(updateTrigger.getNextTriggerTime())); \n\n50.     updateTriggerList.add(updateTrigger); \n\n51.   }); \n\n52.   return updateTriggerList; \n\n53. } \n```\n\n\n\n这里因为感觉每秒查询和更新Trigger（假如有每秒执行的任务）貌似对数据库太残忍了，所以这么残忍的事情还是交给专业的人做吧，这里也就引入了mongoDB\n\n还有一个考虑就是多个admin端启动的情况下防止同时拿到同一组Trigger，那就完犊子了，所以引入redis分布式锁进行加锁处理，只有设置完当前trigger的下一次执行时间后才可能放开这把锁。\n\n\n\n看完怎么获取Trigger的代码后，再看一下如果发现**trigger可以执行的时候怎么做的**？\n\n\n\n这里我们抽象出一个**分发器**的概念TesseractTriggerDispatcher，它里面是维护着一个**线程池**，这个线程池是模仿ThreadPoolExecutor写的简单的线程池\n\n\n\n```\n1. public void dispatchTrigger(List<TesseractTrigger> triggerList) { \n\n2.   triggerList.stream().forEach(trigger -> threadPool.runJob(new TaskRunnable(trigger))); \n\n3. } \n\n4.  \n\n5. @Override \n\n6. public void runJob(Runnable runnable) { \n\n7.   if (isStop) { \n\n8.     log.error(\"线程池已关闭\"); \n\n9.     return; \n\n10.   } \n\n11.   synchronized (lock) { \n\n12.     // todo 当前线程池的设计就是没有空闲线程可用时等待，原ThreadPool的设计是放入Queue中,可以考虑进行优化 \n\n13.     while (busyWorkerList.size() == threadNum) { \n\n14.       try { \n\n15.         lock.wait(); \n\n16.       } catch (InterruptedException e) { \n\n17.         e.printStackTrace(); \n\n18.       } \n\n19.     } \n\n20.     WorkerThread workerThread; \n\n21.  \n\n22.     if(availableWorkerList.size() > 0){ \n\n23.       workerThread = availableWorkerList.remove(0); \n\n24.     }else{ \n\n25.       workerThread = new WorkerThread(availableWorkerList,busyWorkerList); \n\n26.       workerThread.start(); \n\n27.       busyWorkerList.add(workerThread); \n\n28.     } \n\n29.     workerThread.setRunnable(runnable); \n\n30.   } \n\n31. } \n```\n\n\n\n这里将每一个trigger作为一个Task看待，TesseractTriggerDispatcher负责运行这些task，因为每个trigger之间可以相隔很近，如果单线程顺序执行的话会产生延时的结果。\n\n\n\n这里每个trigger的Task自身也是一个线程\n\n\n\n```\n1. class TaskRunnable implements Runnable{ \n\n2.  \n\n3.   private final TesseractTrigger tesseractTrigger; \n\n4.  \n\n5.   public TaskRunnable(TesseractTrigger tesseractTrigger){ \n\n6.     this.tesseractTrigger = tesseractTrigger; \n\n7.   } \n\n8.  \n\n9.   @Override \n\n10.   public void run() { \n\n11.  \n\n12.     QueryWrapper<TesseractJobDetail> jobQueryWrapper = new QueryWrapper<>(); \n\n13.  \n\n14.     jobQueryWrapper.lambda().eq(TesseractJobDetail::getTriggerId,tesseractTrigger.getId()); \n\n15.     List<TesseractJobDetail> jobDetailList = tesseractJobDetailService.list(jobQueryWrapper); \n\n16.  \n\n17.     if(CollectionUtils.isEmpty(jobDetailList)){ \n\n18.       return; \n\n19.     } \n\n20.  \n\n21.     QueryWrapper<TesseractExecutorDetail> executorDetailQueryWrapper = new QueryWrapper<>(); \n\n22.     executorDetailQueryWrapper.lambda().eq(TesseractExecutorDetail::getGroupId,tesseractTrigger.getGroupId()); \n\n23.     List<TesseractExecutorDetail> executorDetailList = executorDetailService.list(executorDetailQueryWrapper); \n\n24.  \n\n25.     if (CollectionUtils.isEmpty(executorDetailList)) { \n\n26.       return; \n\n27.     } \n\n28.  \n\n29.     //路由发送执行(负载策略) \n\n30.     TaskContextInfo taskContextInfo = TaskExecuteDelegator.createTaskContextInfo(tesseractTrigger,executorDetailList,jobDetailList); \n\n31.  \n\n32.     TaskExecuteDelegator.routerExecute(taskContextInfo); \n\n33.   } \n\n34.  \n\n35. } \n```\n\n\n\ntirgger对应的Task线程任务查询当前trigger下的所有JobDetails然后生成TaskContextInfo对象，也就是任务上下文信息，最后交给TaskExecuteDelegator执行，这个不同于TesseractTriggerDispatcher任务分发器，TaskExecuteDelegator是真正的任务执行器，根据Task线程生成的TaskContextInfo对象进行执行任务。\n\n\n\n```\n1. public class TaskExecuteDelegator { \n\n2.  \n\n3.   private static final String THREADPOOL_NAME_PREFIX = \"job-executor-threadpool-\"; \n\n4.  \n\n5.   // todo 目前用一个线程池执行所有Group下所有trigger相关联的jobDetail \n\n6.   private static final ExecutorService TRIGGER_EXCUTE_THREAD_POOL = ThreadPoolFactoryUtils.createCustomThreadPoolIfAbsent(THREADPOOL_NAME_PREFIX); \n\n7.  \n\n8.   /** \n\n9.   * 路由执行器 \n\n10.   * \n\n11.   * @param taskContextInfo 任务上下文 \n\n12.   */ \n\n13.   public static void routerExecute(TaskContextInfo taskContextInfo) { \n\n14.     TesseractTrigger trigger = taskContextInfo.getTrigger(); \n\n15.     //路由选择 \n\n16.     @NotNull Integer strategy = trigger.getStrategy(); \n\n17.  \n\n18.     if (SCHEDULER_STRATEGY_BROADCAST.equals(strategy)) { \n\n19.       // 广播调用\n\n20.       executeBroadcast(taskContextInfo); \n\n21.     } else if (SCHEDULER_STRATEGY_SHARDING.equals(strategy)) { \n\n22.       // 分片调用\n\n23.       executeSharding(taskContextInfo); \n\n24.     } else { \n\n25.       //正常调用 \n\n26.       executeGeneral(taskContextInfo); \n\n27.     } \n\n28.   } \n\n29. } \n```\n\n\n\nTaskExecuteDelegator里面也是有一个线程池的，目前这个线程池负责处理所有Trigger下的所有JobDetais的执行任务，所以压力可能有点大。\n\n\n\n然后对于JobDetail的真正执行是通过Trigger配置的路由策略去寻找一个或者多个ExecutorDetails进行远程调用\n\n\n\n下面是除了广播和分片（调用多个ExecutorDetails）外的正常调用（调用一个ExecutorDetails）executeGeneral\n\n\n\n```\n1. /** \n\n2. * 正常调用 \n\n3. * \n\n4. * @param taskContextInfo \n\n5. */ \n\n6. private static void executeGeneral(TaskContextInfo taskContextInfo) { \n\n7.   taskContextInfo.getJobDetailList().forEach(jobDetail -> { \n\n8.     TesseractExecutorDetail executorDetail = routeExecutorDetail(taskContextInfo,null); \n\n9.  \n\n10.     if (executorDetail != null) { \n\n11.       // 创建任务信息\n\n12.       TaskInfo taskInfo = createTaskInfo(taskContextInfo.getTrigger(), executorDetail, jobDetail); \n\n13.  \n\n14.       TRIGGER_EXCUTE_THREAD_POOL.execute(new TriggerExecuteThread(taskContextInfo,taskInfo)); \n\n15.     } \n\n16.   }); \n\n17. } \n```\n\n\n\n前面说了TaskExecuteDelegator维护者一个线程池，去执行JobDetail\n\n\n\n所以对于每个JobDetail的执行也是分线程执行的，下面是对JobDetail执行线程TriggerExecuteThread的任务\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   // 构建请求 \n\n4.   TesseractExecutorRequest executorRequest = createExecutorRequest(); \n\n5.  \n\n6.   // 先写入日志 \n\n7.   TesseractLog tesseractLog = createExecutorRequestLog(executorRequest); \n\n8.  \n\n9.   // 保存触发器执行情况 \n\n10.   TesseractFiredTrigger tesseractFiredTrigger = saveFiredTrigger(); \n\n11.  \n\n12.   // 是否进行日志追踪 \n\n13.   if (isLog) { \n\n14.     executorRequest.setLogId(tesseractLog.getId()); \n\n15.   } \n\n16.  \n\n17.   //发送调度请求 \n\n18.   TesseractExecutorResponse response = executeRequestURI(executorRequest, tesseractLog); \n\n19.  \n\n20.   log.info(\"调度返回结果:{}\", response.getBody()); \n\n21.  \n\n22.   //移出执行表 \n\n23.   firedTriggerService.removeById(tesseractFiredTrigger.getId()); \n\n24. } \n```\n\n\n\n一些CRUD操作不用解释，这里有个地方就是我做了日志追踪判断，因为我觉得有些任务没有必要进行日志追踪，比如每秒执行的任务，如果报错或者异常通过邮件提醒即可，不然的话除非使用kafka了，每秒插入和更新数据库。但是对于每天执行的同步或者迁移任务必须要进行追踪的。\n\n\n\n然后看一下执行远程调用的过程executeRequestURI\n\n\n\n```\n1. /** \n\n2. * 执行feign的远程调用 \n\n3. */ \n\n4. private TesseractExecutorResponse executeRequestURI(TesseractExecutorRequest executorRequest, TesseractLog tesseractLog) { \n\n5.   TesseractExecutorResponse response; \n\n6.  \n\n7.   log.info(\"开始调度:{}\", executorRequest); \n\n8.  \n\n9.   try { \n\n10.     response = feignService.sendToExecutor(new URI(HTTP_PREFIX + executorDetail.getSocket() + EXECUTE_MAPPING), executorRequest); \n\n11.     if (response.getStatus() != TesseractExecutorResponse.SUCCESS_STATUS && isRetryAble()) { \n\n12.       response = retryRequest(executorRequest); \n\n13.     } \n\n14.   } catch (Exception e) { \n\n15.     log.error(\"出现调度异常:[{}]\", e.getMessage(), e.getCause()); \n\n16.     response = TesseractExecutorResponse.builder().body(e.getMessage()).status(TesseractExecutorResponse.FAIL_STAUTS).build(); \n\n17.  \n\n18.     // 是否允许重试 \n\n19.     if (isRetryAble()) { \n\n20.       response = retryRequest(executorRequest); \n\n21.     } \n\n22.   } \n\n23.  \n\n24.   if(isLog){ \n\n25.     if(response.getStatus() == TesseractExecutorResponse.SUCCESS_STATUS){ \n\n26.       tesseractLog.setStatus(LOG_NO_CONFIRM); \n\n27.     }else{ \n\n28.       tesseractLog.setStatus(LOG_FAIL); \n\n29.       tesseractLog.setMsg(JSON.toJSONString(response.getBody())); \n\n30.     } \n\n31.     tesseractLog.setEndTime(System.currentTimeMillis()); \n\n32.     tesseractLogService.updateById(tesseractLog); \n\n33.   } \n\n34.   return response; \n\n35. } \n```\n\n\n\n这里使用feign进行远程调用，对log的更新以及根据trigger配置的重试策略进行失败重试retryRequest\n\n\n\n```\n1. private TesseractExecutorResponse retryRequest(TesseractExecutorRequest executorRequest) { \n\n2.   TesseractExecutorResponse response = null; \n\n3.   for (int i = 0; i < tesseractTrigger.getRetryCount(); i++) { \n\n4.     // 每次尽量获取不同的executorDetail去执行jobDetail \n\n5.     executorDetail = TaskExecuteDelegator.routeExecutorDetail(taskContextInfo,executorDetail); \n\n6.  \n\n7.     try { \n\n8.       response = feignService.sendToExecutor(new URI(HTTP_PREFIX + executorDetail.getSocket() + EXECUTE_MAPPING), executorRequest); \n\n9.       if (response.getStatus() == TesseractExecutorResponse.SUCCESS_STATUS) { \n\n10.         return response; \n\n11.       } \n\n12.     } catch (Exception e) { \n\n13.       log.error(\"出现调度异常:[{}]\", e.getMessage(), e.getCause()); \n\n14.       response = TesseractExecutorResponse.builder().body(e.getMessage()).status(TesseractExecutorResponse.FAIL_STAUTS).build(); \n\n15.     } \n\n16.   } \n\n17.   return response; \n\n18. } \n```\n\n\n\n对于远程调用失败的话说明当前ExecutorDetails是失效的，所以这里尽可能的切换不同的ExecutorDetails进行调用，为什么说尽可能呢？因为我这里处理只是将上一次失败的ExecutorDetails作为参数传递，然后在随机生成ExecutorDetails的过程中进行判断，选择ExecutorDetails的过程如下\n\n\n\n```\n1. /** \n\n2. * 通过路由规则获得执行器 \n\n3. * 为了保证两次获取不能取相同值，使用preExecutor保存上一次获取的结果 \n\n4. */ \n\n5. public static TesseractExecutorDetail routeExecutorDetail(TaskContextInfo taskContextInfo, TesseractExecutorDetail preExecutor){ \n\n6.  \n\n7.   IScheduleRouter scheduleRouter = SCHEDULE_ROUTER_MAP.getOrDefault(taskContextInfo.getTrigger().getStrategy(), new RandomRouter()); \n\n8.   TesseractExecutorDetail executorDetail = scheduleRouter.routerExecutor(taskContextInfo.getExecutorDetailList()); \n\n9.  \n\n10.   List<TesseractExecutorDetail> executorDetailList = taskContextInfo.getExecutorDetailList(); \n\n11.  \n\n12.   if(executorDetailList.size() == 0){ \n\n13.     return null; \n\n14.   }else if(executorDetailList.size() == 1){ \n\n15.     return executorDetailList.get(0); \n\n16.   }else if(executorDetail == preExecutor){ // 重新选择\n\n17.     executorDetail = \n\n18. scheduleRouter.routerExecutor(taskContextInfo.getExecutorDetailList()); \n\n19.   } \n\n20.   return executorDetail; \n\n21. } \n```\n\n\n\n到这里基本Admin进行定时调度的核心代码讲解完了，接下来就是等待Client端执行远程调用过程的回调，来更新log状态。\n\n\n\nClient端回调的处理方法如下\n\n\n\n```\n1. @Override \n\n2. public void notify(TesseractAdminJobNotify tesseractAdminJobNotify) { \n\n3.  \n\n4.   TesseractLog tesseractLog = getById(tesseractAdminJobNotify.getLogId()); \n\n5.  \n\n6.   if(tesseractLog == null){ \n\n7.     // 无效日志 \n\n8.     return; \n\n9.   } \n\n10.  \n\n11.   if(StringUtils.isEmpty(tesseractAdminJobNotify.getException())){ \n\n12.     tesseractLog.setStatus(LOG_SUCCESS); \n\n13.     tesseractLog.setMsg(\"执行成功\"); \n\n14.   }else{ \n\n15.     tesseractLog.setStatus(LOG_FAIL); \n\n16.     tesseractLog.setMsg(tesseractAdminJobNotify.getException()); \n\n17.   } \n\n18.   tesseractLog.setEndTime(System.currentTimeMillis()); \n\n19.   this.updateById(tesseractLog); \n\n20. } \n```\n\n\n\n主要是为了维护追踪日志的状态，对于不需要追踪日志的在调度请求在报错后需要进行邮件提醒。\n\n\n\n#### **2. 扫描清除**\n\n\n\n其实就是我希望有一个线程来进行清理工作，你可以理解成JVM的GC线程。\n\n\n\n比如说对于无效的Group，我希望给它清理掉，因为前面说了，我们对每个Group都会生成一个ScheduleThread不断去执行查询Trigger的任务，那么对于没有绑定Trigger的Group，我们当然不希望这个ScheduleThread在运行\n\n\n\n直接看一下ServiceCheckScanner线程的清理过程吧\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   log.info(\"serviceCheckScannerThread start...\"); \n\n4.  \n\n5.   List<Integer> removeGroupIds = Lists.newArrayList(); \n\n6.   List<String> removeGroupNames = Lists.newArrayList(); \n\n7.  \n\n8.   while (!isStop) { \n\n9.     List<TesseractGroup> groups = tesseractGroupService.listAllIdAndName(); \n\n10.  \n\n11.     QueryWrapper<TesseractTrigger> queryWrapper = new QueryWrapper<>(); \n\n12.     if (!CollectionUtils.isEmpty(groups)) { \n\n13.       groups.stream().forEach(group -> { \n\n14.         queryWrapper.lambda().eq(TesseractTrigger::getGroupId, group.getId()); \n\n15.         Integer exists = tesseractTriggerService.findIfExistsByWrapper(queryWrapper); \n\n16.  \n\n17.         if (exists == null) { \n\n18.           removeGroupIds.add(group.getId()); \n\n19.           removeGroupNames.add(group.getName()); \n\n20.         } \n\n21.         queryWrapper.clear(); \n\n22.       }); \n\n23.  \n\n24.       if (!CollectionUtils.isEmpty(removeGroupIds)) { \n\n25.         log.info(\"发现未绑定trigger的group [{}]，即将移除\", removeGroupNames); \n\n26.         tesseractGroupService.removeByIds(removeGroupIds); \n\n27.  \n\n28.         removeGroupNames.forEach(groupName->{ \n\n29.           // 删除group下的groupScheduler线程组 \n\n30.           JobServerBootstrap.deleteGroupScheduler(groupName); \n\n31.  \n\n32.           // 删除group下的mongodb缓存 \n\n33.           triggerMongoCache.removeAllTriggerFromCache(groupName); \n\n34.         }); \n\n35.         removeGroupIds.clear(); \n\n36.         removeGroupNames.clear(); \n\n37.       } \n\n38.     } \n\n39.  \n\n40.     try { \n\n41.       // 间隔5分钟执行一次 \n\n42.       Thread.sleep(SCAN_INTERVAL_TIME); \n\n43.     } catch (InterruptedException e) { \n\n44.       log.error(\"serviceCheckScannerThread 在sleep期间被interrupt：[{}]\", e.getMessage()); \n\n45.     } \n\n46.   } \n\n47. } \n```\n\n\n\n后续更多的清理任务可以在这里添加，毕竟5分钟执行一次的话对于一个线程来说是没有什么压力的。\n\n\n\n除了清理线程还有一个检测线程，姑且叫检测吧，它的任务就是检测出无效的ExecutorDetails，前面说了ExecutorDetails是连接Admin端的客户端，是依赖心跳包来维持存活状态的，对于断开连接的Client端是需要定期清除的\n\n\n\n清理线程ExecutorScanner执行任务如下\n\n\n\n```\n1. @Override \n\n2. public void run() { \n\n3.   log.info(\"ExecutorScannerThread Start...\"); \n\n4.   while (!isStop) { \n\n5.     List<TesseractExecutorDetail> inValidExecutos = executorDetailService.listInvalid(); \n\n6.  \n\n7.     if (!CollectionUtils.isEmpty(inValidExecutos)) { \n\n8.       List<Integer> inValidExecutorIds = inValidExecutos.stream().map(executorDetail -> executorDetail.getId()).collect(Collectors.toList()); \n\n9.       log.info(\"发现失效的机器 {},执行移除操作\", inValidExecutos); \n\n10.       // 先删除数据库，再删除缓存 \n\n11.       executorDetailService.removeByIds(inValidExecutorIds); \n\n12.       inValidExecutos.forEach(executorDetail -> executorDetailCache.removeCacheExecutor(executorDetail.getSocket())); \n\n13.     } \n\n14.  \n\n15.     try { \n\n16.       // 间隔15s执行一次 \n\n17.       Thread.sleep(SCAN_INTERVAL_TIME); \n\n18.     } catch (InterruptedException e) { \n\n19.       e.printStackTrace(); \n\n20.     } \n\n21.   } \n\n22. } \n```\n\n\n\n判断ExecutorDetails是否失效也就是根据心跳包的最近上传时间来判断Client端有没有断开连接，这里对ExecutorDetails是有一个缓存操作的，也就是executorDetailCache，后面讲心跳包的处理时候再说\n\n\n\n到此，清理任务就讲完了，可能还会有更多的考虑，后面优化点会想出来。\n\n\n\n#### **3. 心跳处理**\n\n\n\n心跳处理就是对Client定期上传的心跳包进行处理，这里主要任务就是更新Client端对应的ExecutorDetails的修改时间，防止它被清理线程给清除了。\n\n\n\n对于心跳包的处理\n\n\n\n```\n1. @Override \n\n2. @Transactional(rollbackFor = Exception.class) \n\n3. public void heartBeat(TesseractHeartbeatRequest heartBeatRequest) { \n\n4.   String socket = heartBeatRequest.getSocket(); \n\n5.   // 从缓存中拿 \n\n6.   ExecutorDetailHolder cacheExecutor = jobServerBootstrap.getExecutorDetailCache().getCacheExecutor(socket); \n\n7.   \n\n8.   // 重新计算负载因子，也就是executorCache的value\n\n9.   ExecutorDetailHolder executorDetailHolder = new ExecutorDetailHolder(calculateLoadFactor(heartBeatRequest)); \n\n10.  \n\n11.   // 缓存中有的情况下 进行批量更新 \n\n12.   if (cacheExecutor != null) { \n\n13.     QueryWrapper<TesseractExecutorDetail> executorDetailQueryWrapper = new QueryWrapper<>(); \n\n14.     executorDetailQueryWrapper.lambda().eq(TesseractExecutorDetail::getSocket, socket); \n\n15.     List<TesseractExecutorDetail> executorDetailList = list(executorDetailQueryWrapper); \n\n16.  \n\n17.     if (CollectionUtils.isEmpty(executorDetailList)) { \n\n18.       return; \n\n19.     } \n\n20.  \n\n21.     // 修改executorDetail状态 \n\n22.     executorDetailList.forEach(executorDetail -> { \n\n23.       executorDetail.setLoadFactor(executorDetailHolder.get()); \n\n24.       executorDetail.setUpdateTime(System.currentTimeMillis()); \n\n25.     }); \n\n26.  \n\n27.     this.updateBatchById(executorDetailList); \n\n28.   } else { // 进行批量插入 \n\n29.     List<TesseractExecutorDetail> executorDetailList = batchCreateExecutorDetail(heartBeatRequest.getClientJobGroups(), executorDetailHolder, socket); \n\n30.     if (this.saveBatch(executorDetailList)) { \n\n31.       // 插入缓存 \n\n32.       jobServerBootstrap.getExecutorDetailCache().addCacheExecutor(socket, executorDetailHolder); \n\n33.     } \n\n34.   } \n\n35. } \n```\n\n\n\n这里主要就是对ExecutorDetail和executorDetailCache的维护，对于executorDetailCache中存在Client端socket的情况下批量更新就好了，如果没有就需要批量新增。\n\n\n\n这里有一个计算Client端负载因子的算法，因为在trigger的负载策略里面有一个加权轮询策略。\n\n\n\n对于心跳包的处理就完成了，主要是对ExecutorDetails的维护。\n\n\n\n#### **4. 注册Trigger和JobDetails**\n\n\n\n这一部分是来处理Client端注册过来的Trigger和JobDetails\n\n\n\n```\n1. @Override \n\n2. public TesseractAdminRegistryResDTO registry(TesseractAdminRegistryRequest registryRequest){ \n\n3.   String socketAddress = registryRequest.getIp() + \":\" + registryRequest.getPort(); \n\n4.   List<TesseractAdminJobDetailDTO> jobDetailDTOS = registryRequest.getTesseractAdminJobDetailDTOList(); \n\n5.  \n\n6.   log.info(\"注册来自{}的Jobs[{}]\", socketAddress, jobDetailDTOS); \n\n7.  \n\n8.   // 装载注册失败的Job并返回给客户端 \n\n9.   List<TesseractAdminRegistryFailInfo> notRegistryJobList = Collections.synchronizedList(Lists.newArrayList()); \n\n10.  \n\n11.   jobDetailDTOS.stream().forEach(jobDetailDTO -> { \n\n12.  \n\n13.     RegistryTransportDTO registryTransportDTO = new RegistryTransportDTO(); \n\n14.     registryTransportDTO.setJobDetailDTO(jobDetailDTO); \n\n15.  \n\n16.     try { \n\n17.       // 注册 \n\n18.       doRegistry(notRegistryJobList, registryTransportDTO); \n\n19.  \n\n20.     } catch (Exception e) { \n\n21.       String errorMessage = String.format(\"注册jobDetail出现异常:[%s]\", e.getMessage()); \n\n22.       log.error(errorMessage, e.getCause()); \n\n23.       TesseractAdminRegistryFailInfo registryFailInfo = TesseractAdminRegistryFailInfo.build(jobDetailDTO, SERVER_ERROR, errorMessage); \n\n24.       notRegistryJobList.add(registryFailInfo); \n\n25.     } \n\n26.   }); \n\n27.  \n\n28.   return new TesseractAdminRegistryResDTO(notRegistryJobList); \n\n29. } \n```\n\n\n\n实际进行注册的这一部分我采用的是责任链的写法，对于可能存在的Group、Trigger和JobDetail分别做不同的处理\n\n\n\n```\n1. private void doRegistry(List<TesseractAdminRegistryFailInfo> notRegistryJobList , RegistryTransportDTO registryTransportDTO){ \n\n2.   AbstractRegistryHandler groupRegistryHandler = new GroupRegistryHandler(); \n\n3.   AbstractRegistryHandler triggerRegistryHandler = new TriggerRegistryHandler(); \n\n4.   AbstractRegistryHandler jobDetailRegistryHandler = new JobDetailRegistryHandler(); \n\n5.  \n\n6.   groupRegistryHandler.setSuccessor(triggerRegistryHandler); \n\n7.   triggerRegistryHandler.setSuccessor(jobDetailRegistryHandler); \n\n8.  \n\n9.   OperateResult<TesseractAdminRegistryFailInfo> operateResult = groupRegistryHandler.handler(registryTransportDTO); \n\n10.  \n\n11.   if(!operateResult.isSuccess()){ \n\n12.     notRegistryJobList.add(operateResult.get()); \n\n13.   } \n\n14. } \n```\n\n\n\n最终将没有成功注册的JobDetail返回给Client端，由Client端做处理。\n\n\n\n最后Admin端的任务还剩下管理Group和Trigger没讲，这些是希望通过Web页面来进行交互的实现的，也比较简单，这里就没有做了。\n\n\n\n#### **5. 我们再放上Admin的任务图来回顾一下**\n\n\n\n![img](http://pcc.huitogo.club/d25f9b953334c7a8318bbc646871d669)", "imgFile": "06.jpg", "author": "huizhang43", "cmtCnt": 0, "visitCnt": 0}}}